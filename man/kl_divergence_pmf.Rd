% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/12_a2_kl.R
\name{kl_divergence_pmf}
\alias{kl_divergence_pmf}
\title{KL Divergence Between Two PMFs}
\usage{
kl_divergence_pmf(p, q, eps = 1e-15)
}
\arguments{
\item{p}{Numeric vector; target PMF (reference distribution).}

\item{q}{Numeric vector; comparison PMF.}

\item{eps}{Numeric; small value to prevent \code{log(0)}. Default: 1e-15.}
}
\value{
Numeric scalar; the KL divergence (non-negative).
}
\description{
Computes the Kullback-Leibler divergence \eqn{D_{KL}(p \| q)} between two
probability mass functions.
}
\details{
The KL divergence is defined as:
\deqn{D_{KL}(p \| q) = \sum_k p(k) \log\frac{p(k)}{q(k)}}

Only indices where \eqn{p(k) > \epsilon} are included in the sum.

\strong{Properties:}
\itemize{
\item \eqn{D_{KL}(p \| q) \geq 0} with equality iff \eqn{p = q}
\item Not symmetric: \eqn{D_{KL}(p \| q) \neq D_{KL}(q \| p)}
}
}
\examples{
p <- c(0.2, 0.5, 0.3)
kl_divergence_pmf(p, p)  # 0

q <- c(0.3, 0.4, 0.3)
kl_divergence_pmf(p, q)

}
\seealso{
\code{\link{kl_divergence_K}} for KL divergence with induced PMF
}
