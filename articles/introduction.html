<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>DPprior: Why Prior Elicitation Matters ‚Ä¢ DPprior</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="96x96" href="../favicon-96x96.png">
<link rel="icon" type="‚Äùimage/svg+xml‚Äù" href="../favicon.svg">
<link rel="apple-touch-icon" sizes="180x180" href="../apple-touch-icon.png">
<link rel="icon" sizes="any" href="../favicon.ico">
<link rel="manifest" href="../site.webmanifest">
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="DPprior: Why Prior Elicitation Matters">
<meta name="description" content="An introduction to the DPprior package for principled elicitation of Gamma  hyperpriors on the Dirichlet Process concentration parameter Œ±, with emphasis  on its utility in low-information settings such as multisite trials and  meta-analyses.
">
<meta property="og:description" content="An introduction to the DPprior package for principled elicitation of Gamma  hyperpriors on the Dirichlet Process concentration parameter Œ±, with emphasis  on its utility in low-information settings such as multisite trials and  meta-analyses.
">
<meta property="og:image" content="https://joonho112.github.io/DPprior/logo.svg">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-primary" data-bs-theme="dark" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">DPprior</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">1.0.0</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-vignettes" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Vignettes</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-vignettes">
<li><h6 class="dropdown-header" data-toc-skip>--- Applied Track ---</h6></li>
    <li><a class="dropdown-item" href="../articles/introduction.html">Introduction</a></li>
    <li><a class="dropdown-item" href="../articles/quick-start.html">Quick Start</a></li>
    <li><a class="dropdown-item" href="../articles/applied-guide.html">Applied Guide</a></li>
    <li><a class="dropdown-item" href="../articles/dual-anchor.html">Dual-Anchor Framework</a></li>
    <li><a class="dropdown-item" href="../articles/diagnostics.html">Diagnostics</a></li>
    <li><a class="dropdown-item" href="../articles/case-studies.html">Case Studies</a></li>
    <li><h6 class="dropdown-header" data-toc-skip>--- Methodological Track ---</h6></li>
    <li><a class="dropdown-item" href="../articles/theory-overview.html">Theory Overview</a></li>
    <li><a class="dropdown-item" href="../articles/theory-stirling.html">Stirling Numbers</a></li>
    <li><a class="dropdown-item" href="../articles/theory-approximations.html">Approximations (A1)</a></li>
    <li><a class="dropdown-item" href="../articles/theory-newton.html">Newton Algorithm (A2)</a></li>
    <li><a class="dropdown-item" href="../articles/theory-weights.html">Weight Distributions</a></li>
    <li><a class="dropdown-item" href="../articles/api-reference.html">API Reference</a></li>
  </ul>
</li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">Changelog</a></li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/joonho112/DPprior/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.svg" class="logo" alt=""><h1>DPprior: Why Prior Elicitation Matters</h1>
                        <h4 data-toc-skip class="author">JoonHo Lee</h4>
            
            <h4 data-toc-skip class="date">2026-02-13</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/joonho112/DPprior/blob/main/vignettes/introduction.Rmd" class="external-link"><code>vignettes/introduction.Rmd</code></a></small>
      <div class="d-none name"><code>introduction.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<p>The <strong>DPprior</strong> package provides tools for principled
prior elicitation on the concentration parameter
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ±</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>
in Dirichlet Process (DP) mixture models. Rather than requiring
researchers to think directly in terms of the abstract parameter
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ±</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>,
DPprior allows specification through two intuitive dimensions:
<em>expected cluster counts</em>‚Äîhow many distinct groups do you
anticipate?‚Äîand <em>cluster weight concentration</em>‚Äîhow evenly do you
expect observations to be distributed across those groups? These are
quantities that applied researchers can often reason about based on
domain knowledge, and DPprior translates such beliefs into principled
Gamma hyperpriors on
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ±</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>.</p>
<div class="section level3">
<h3 id="installation">Installation<a class="anchor" aria-label="anchor" href="#installation"></a>
</h3>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># From CRAN (when available)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/install.packages.html" class="external-link">install.packages</a></span><span class="op">(</span><span class="st">"DPprior"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># From GitHub (development version)</span></span>
<span><span class="fu">devtools</span><span class="fu">::</span><span class="fu">install_github</span><span class="op">(</span><span class="st">"joonho112/DPprior"</span><span class="op">)</span></span></code></pre></div>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://joonho112.github.io/DPprior/">DPprior</a></span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="the-core-problem">The Core Problem<a class="anchor" aria-label="anchor" href="#the-core-problem"></a>
</h3>
<p>When using DP mixture models for applications such as multisite
trials, meta-analysis, or Bayesian nonparametric density estimation,
researchers must specify a prior on the concentration parameter
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ±</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>.
This parameter governs the model‚Äôs clustering behavior, affecting
multiple dimensions:</p>
<ul>
<li>
<strong>How many clusters</strong> will the model tend to
produce?</li>
<li>
<strong>How are observations distributed</strong> across
clusters‚Äîevenly, or with one dominant group?</li>
<li>
<strong>How much shrinkage</strong> will the posterior exhibit
toward a common mean?</li>
</ul>
<p>In low-information settings‚Äîwhere the number of observations
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>J</mi><annotation encoding="application/x-tex">J</annotation></semantics></math>
is moderate (e.g., 25‚Äì100) and per-observation information is
limited‚Äîthe prior on
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ±</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>
can substantially influence posterior inference. The DPprior package
addresses the critical question: <em>How should researchers translate
their domain knowledge into a principled prior on
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ±</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>?</em></p>
</div>
</div>
<div class="section level2">
<h2 id="the-core-challenge-why-alpha-matters">The Core Challenge: Why
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ±</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>
Matters<a class="anchor" aria-label="anchor" href="#the-core-challenge-why-alpha-matters"></a>
</h2>
<div class="section level3">
<h3 id="the-dirichlet-process-mixture-model">The Dirichlet Process Mixture Model<a class="anchor" aria-label="anchor" href="#the-dirichlet-process-mixture-model"></a>
</h3>
<p>In a DP mixture model, we place a Dirichlet Process prior on an
unknown distribution
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>G</mi><annotation encoding="application/x-tex">G</annotation></semantics></math>:
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi><mo>‚àº</mo><mtext mathvariant="normal">DP</mtext><mrow><mo stretchy="true" form="prefix">(</mo><mi>Œ±</mi><mo>,</mo><msub><mi>G</mi><mn>0</mn></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>,</mo></mrow><annotation encoding="application/x-tex">
G \sim \text{DP}(\alpha, G_0),
</annotation></semantics></math> where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>G</mi><mn>0</mn></msub><annotation encoding="application/x-tex">G_0</annotation></semantics></math>
is the base (centering) measure and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Œ±</mi><mo>&gt;</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\alpha &gt; 0</annotation></semantics></math>
is the concentration parameter. Observations
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œ∏</mi><mn>1</mn></msub><mo>,</mo><mi>‚Ä¶</mi><mo>,</mo><msub><mi>Œ∏</mi><mi>J</mi></msub></mrow><annotation encoding="application/x-tex">\theta_1, \ldots, \theta_J</annotation></semantics></math>
are then drawn from
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>G</mi><annotation encoding="application/x-tex">G</annotation></semantics></math>:
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œ∏</mi><mi>j</mi></msub><mo>‚à£</mo><mi>G</mi><mover><mo>‚àº</mo><mrow><mi>i</mi><mi>i</mi><mi>d</mi></mrow></mover><mi>G</mi><mi>.</mi></mrow><annotation encoding="application/x-tex">
\theta_j \mid G \stackrel{iid}{\sim} G.
</annotation></semantics></math></p>
<p>A fundamental property of the DP is that draws from
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>G</mi><annotation encoding="application/x-tex">G</annotation></semantics></math>
exhibit <em>clustering</em>: multiple observations can share the same
value, with the number of distinct values
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>K</mi><mi>J</mi></msub><annotation encoding="application/x-tex">K_J</annotation></semantics></math>
depending critically on
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ±</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>.
This clustering behavior makes the DP particularly useful for
applications where the number of underlying groups is unknown‚Äîsuch as
identifying distinct treatment effect patterns across sites in a
multisite trial, or discovering latent subpopulations in
meta-analysis.</p>
</div>
<div class="section level3">
<h3 id="what-does-alpha-control">What Does
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ±</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>
Control?<a class="anchor" aria-label="anchor" href="#what-does-alpha-control"></a>
</h3>
<p>The concentration parameter
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ±</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>
influences the model‚Äôs behavior in three interconnected ways:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Number of clusters
(<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>K</mi><mi>J</mi></msub><annotation encoding="application/x-tex">K_J</annotation></semantics></math>)</strong>:
Larger
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ±</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>
leads to more clusters on average; smaller
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ±</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>
concentrates mass on fewer clusters. Specifically,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ùîº</mi><mrow><mo stretchy="true" form="prefix">[</mo><msub><mi>K</mi><mi>J</mi></msub><mo stretchy="false" form="prefix">|</mo><mi>Œ±</mi><mo stretchy="true" form="postfix">]</mo></mrow><mo>‚âà</mo><mi>Œ±</mi><mo>log</mo><mi>J</mi></mrow><annotation encoding="application/x-tex">\mathbb{E}[K_J | \alpha] \approx \alpha \log J</annotation></semantics></math>
for large
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>J</mi><annotation encoding="application/x-tex">J</annotation></semantics></math>
(Antoniak, 1974).</p></li>
<li><p><strong>Stick-breaking weights</strong>: In Sethuraman‚Äôs (1994)
representation,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>G</mi><annotation encoding="application/x-tex">G</annotation></semantics></math>
is constructed via stick-breaking weights
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>w</mi><mn>1</mn></msub><mo>,</mo><msub><mi>w</mi><mn>2</mn></msub><mo>,</mo><mi>‚Ä¶</mi><mo stretchy="true" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">(w_1, w_2, \ldots)</annotation></semantics></math>
where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mi>h</mi></msub><mo>=</mo><msub><mi>v</mi><mi>h</mi></msub><msub><mo>‚àè</mo><mrow><mo>‚Ñì</mo><mo>&lt;</mo><mi>h</mi></mrow></msub><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo>‚àí</mo><msub><mi>v</mi><mo>‚Ñì</mo></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">w_h = v_h \prod_{\ell &lt; h}(1 - v_\ell)</annotation></semantics></math>
with
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>v</mi><mi>h</mi></msub><mo>‚àº</mo><mtext mathvariant="normal">Beta</mtext><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo>,</mo><mi>Œ±</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">v_h \sim \text{Beta}(1, \alpha)</annotation></semantics></math>.
Smaller
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ±</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>
produces weights concentrated on early atoms (one or two clusters
dominate); larger
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ±</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>
spreads weights more evenly across many clusters. As Vicentini &amp;
Jermyn (2025) emphasize, these weights represent asymptotic relative
cluster sizes and are a fundamental quantity distinct from the cluster
count.</p></li>
<li><p><strong>Posterior shrinkage</strong>: The prior on
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ±</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>
affects how much the posterior borrows strength across observations. In
multisite trials, this determines the degree of shrinkage toward a
common mean‚Äîa key consideration when sites have varying sample sizes or
precision (Lee et al., 2025).</p></li>
</ol>
<p>The figure below illustrates how different values of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ±</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>
lead to dramatically different partition structures.</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Simulate stick-breaking for different alpha values</span></span>
<span><span class="va">n_atoms</span> <span class="op">&lt;-</span> <span class="fl">15</span></span>
<span><span class="va">alpha_values</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.5</span>, <span class="fl">2</span>, <span class="fl">10</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span></span>
<span><span class="va">sb_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/do.call.html" class="external-link">do.call</a></span><span class="op">(</span><span class="va">rbind</span>, <span class="fu"><a href="https://rdrr.io/r/base/lapply.html" class="external-link">lapply</a></span><span class="op">(</span><span class="va">alpha_values</span>, <span class="kw">function</span><span class="op">(</span><span class="va">a</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="co"># Simulate stick-breaking</span></span>
<span>  <span class="va">v</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Beta.html" class="external-link">rbeta</a></span><span class="op">(</span><span class="va">n_atoms</span>, <span class="fl">1</span>, <span class="va">a</span><span class="op">)</span></span>
<span>  <span class="va">w</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html" class="external-link">numeric</a></span><span class="op">(</span><span class="va">n_atoms</span><span class="op">)</span></span>
<span>  <span class="va">w</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="va">v</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span></span>
<span>  <span class="kw">for</span> <span class="op">(</span><span class="va">h</span> <span class="kw">in</span> <span class="fl">2</span><span class="op">:</span><span class="va">n_atoms</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">w</span><span class="op">[</span><span class="va">h</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="va">v</span><span class="op">[</span><span class="va">h</span><span class="op">]</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/prod.html" class="external-link">prod</a></span><span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="va">v</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="op">(</span><span class="va">h</span><span class="op">-</span><span class="fl">1</span><span class="op">)</span><span class="op">]</span><span class="op">)</span></span>
<span>  <span class="op">}</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span></span>
<span>    atom <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="va">n_atoms</span>,</span>
<span>    weight <span class="op">=</span> <span class="va">w</span>,</span>
<span>    alpha <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste0</a></span><span class="op">(</span><span class="st">"Œ± = "</span>, <span class="va">a</span><span class="op">)</span></span>
<span>  <span class="op">)</span></span>
<span><span class="op">}</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">sb_data</span><span class="op">$</span><span class="va">alpha</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html" class="external-link">factor</a></span><span class="op">(</span><span class="va">sb_data</span><span class="op">$</span><span class="va">alpha</span>, </span>
<span>                        levels <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste0</a></span><span class="op">(</span><span class="st">"Œ± = "</span>, <span class="va">alpha_values</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="fu">ggplot</span><span class="op">(</span><span class="va">sb_data</span>, <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">atom</span>, y <span class="op">=</span> <span class="va">weight</span>, fill <span class="op">=</span> <span class="va">alpha</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_bar</span><span class="op">(</span>stat <span class="op">=</span> <span class="st">"identity"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">facet_wrap</span><span class="op">(</span><span class="op">~</span><span class="va">alpha</span>, nrow <span class="op">=</span> <span class="fl">1</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">scale_fill_manual</span><span class="op">(</span>values <span class="op">=</span> <span class="va">palette_main</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">3</span><span class="op">]</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">labs</span><span class="op">(</span>x <span class="op">=</span> <span class="st">"Atom Index"</span>, </span>
<span>       y <span class="op">=</span> <span class="st">"Stick-Breaking Weight"</span>,</span>
<span>       title <span class="op">=</span> <span class="st">"Effect of Œ± on Cluster Weight Distribution"</span>,</span>
<span>       subtitle <span class="op">=</span> <span class="st">"One realization from GEM(Œ±) for each value"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme_minimal</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme</span><span class="op">(</span>legend.position <span class="op">=</span> <span class="st">"none"</span>,</span>
<span>        strip.text <span class="op">=</span> <span class="fu">element_text</span><span class="op">(</span>face <span class="op">=</span> <span class="st">"bold"</span>, size <span class="op">=</span> <span class="fl">12</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<img src="introduction_files/figure-html/alpha-visual-demo-1.png" class="r-plt" alt="Illustration of stick-breaking weights for different values of Œ±. Smaller Œ± concentrates mass on the first few atoms, while larger Œ± spreads weights more evenly." width="85%"><p class="caption">
Illustration of stick-breaking weights for different values of Œ±.
Smaller Œ± concentrates mass on the first few atoms, while larger Œ±
spreads weights more evenly.
</p>
</div>
</div>
<div class="section level3">
<h3 id="the-distribution-of-k_j">The Distribution of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>K</mi><mi>J</mi></msub><annotation encoding="application/x-tex">K_J</annotation></semantics></math><a class="anchor" aria-label="anchor" href="#the-distribution-of-k_j"></a>
</h3>
<p>Given
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ±</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>,
the number of distinct clusters
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>K</mi><mi>J</mi></msub><annotation encoding="application/x-tex">K_J</annotation></semantics></math>
among
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>J</mi><annotation encoding="application/x-tex">J</annotation></semantics></math>
observations follows the <em>Antoniak distribution</em> (Antoniak,
1974). The probability mass function is:
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>K</mi><mi>J</mi></msub><mo>=</mo><mi>k</mi><mo stretchy="false" form="prefix">|</mo><mi>Œ±</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mfrac><mrow><mrow><mo stretchy="true" form="prefix">|</mo><mi>s</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>J</mi><mo>,</mo><mi>k</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="true" form="postfix">|</mo></mrow><mo>‚ãÖ</mo><msup><mi>Œ±</mi><mi>k</mi></msup></mrow><msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>Œ±</mi><mo stretchy="true" form="postfix">)</mo></mrow><mi>J</mi></msub></mfrac><mo>,</mo></mrow><annotation encoding="application/x-tex">
P(K_J = k | \alpha) = \frac{|s(J,k)| \cdot \alpha^k}{(\alpha)_J},
</annotation></semantics></math> where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="true" form="prefix">|</mo><mi>s</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>J</mi><mo>,</mo><mi>k</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="true" form="postfix">|</mo></mrow><annotation encoding="application/x-tex">|s(J,k)|</annotation></semantics></math>
are unsigned Stirling numbers of the first kind and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>Œ±</mi><mo stretchy="true" form="postfix">)</mo></mrow><mi>J</mi></msub><mo>=</mo><mi>Œ±</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>Œ±</mi><mo>+</mo><mn>1</mn><mo stretchy="true" form="postfix">)</mo></mrow><mi>‚ãØ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>Œ±</mi><mo>+</mo><mi>J</mi><mo>‚àí</mo><mn>1</mn><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">(\alpha)_J = \alpha(\alpha+1)\cdots(\alpha+J-1)</annotation></semantics></math>
is the rising factorial. The expectation is:
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ùîº</mi><mrow><mo stretchy="true" form="prefix">[</mo><msub><mi>K</mi><mi>J</mi></msub><mo>‚à£</mo><mi>Œ±</mi><mo stretchy="true" form="postfix">]</mo></mrow><mo>=</mo><munderover><mo>‚àë</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>J</mi></munderover><mfrac><mi>Œ±</mi><mrow><mi>Œ±</mi><mo>+</mo><mi>i</mi><mo>‚àí</mo><mn>1</mn></mrow></mfrac><mo>‚âà</mo><mi>Œ±</mi><mo>log</mo><mi>J</mi><mspace width="1.0em"></mspace><mrow><mtext mathvariant="normal">(for large </mtext><mspace width="0.333em"></mspace></mrow><mi>J</mi><mtext mathvariant="normal">)</mtext><mi>.</mi></mrow><annotation encoding="application/x-tex">
\mathbb{E}[K_J \mid \alpha] = \sum_{i=1}^{J} \frac{\alpha}{\alpha + i - 1} 
\approx \alpha \log J \quad \text{(for large } J\text{)}.
</annotation></semantics></math></p>
<p>This relationship provides the foundation for DPprior‚Äôs elicitation
approach: if a researcher can express beliefs about
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>K</mi><mi>J</mi></msub><annotation encoding="application/x-tex">K_J</annotation></semantics></math>,
we can back out an appropriate prior on
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ±</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>.</p>
<p>Importantly, Zito et al.¬†(2024) showed that when
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ±</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>
is random with a Gamma prior, the marginal distribution of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>K</mi><mi>J</mi></msub><annotation encoding="application/x-tex">K_J</annotation></semantics></math>
converges to a Negative Binomial as
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>J</mi><mo>‚Üí</mo><mi>‚àû</mi></mrow><annotation encoding="application/x-tex">J \to \infty</annotation></semantics></math>.
This theoretical result‚Äîwhich the DPprior package exploits for
closed-form initial solutions‚Äîexplains why randomizing
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ±</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>
leads to more robust clustering behavior compared to fixing it.</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Demonstrate E[K] vs alpha relationship</span></span>
<span><span class="va">alpha_grid</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html" class="external-link">seq</a></span><span class="op">(</span><span class="fl">0.1</span>, <span class="fl">5</span>, by <span class="op">=</span> <span class="fl">0.1</span><span class="op">)</span></span>
<span><span class="va">J_values</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">25</span>, <span class="fl">50</span>, <span class="fl">100</span><span class="op">)</span></span>
<span></span>
<span><span class="va">k_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/do.call.html" class="external-link">do.call</a></span><span class="op">(</span><span class="va">rbind</span>, <span class="fu"><a href="https://rdrr.io/r/base/lapply.html" class="external-link">lapply</a></span><span class="op">(</span><span class="va">J_values</span>, <span class="kw">function</span><span class="op">(</span><span class="va">J</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">EK</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html" class="external-link">sapply</a></span><span class="op">(</span><span class="va">alpha_grid</span>, <span class="kw">function</span><span class="op">(</span><span class="va">a</span><span class="op">)</span> <span class="fu"><a href="../reference/mean_K_given_alpha.html">mean_K_given_alpha</a></span><span class="op">(</span><span class="va">J</span>, <span class="va">a</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span>alpha <span class="op">=</span> <span class="va">alpha_grid</span>, E_K <span class="op">=</span> <span class="va">EK</span>, J <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste0</a></span><span class="op">(</span><span class="st">"J = "</span>, <span class="va">J</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">k_data</span><span class="op">$</span><span class="va">J</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html" class="external-link">factor</a></span><span class="op">(</span><span class="va">k_data</span><span class="op">$</span><span class="va">J</span>, levels <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste0</a></span><span class="op">(</span><span class="st">"J = "</span>, <span class="va">J_values</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="fu">ggplot</span><span class="op">(</span><span class="va">k_data</span>, <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">alpha</span>, y <span class="op">=</span> <span class="va">E_K</span>, color <span class="op">=</span> <span class="va">J</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_line</span><span class="op">(</span>linewidth <span class="op">=</span> <span class="fl">1.2</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">scale_color_manual</span><span class="op">(</span>values <span class="op">=</span> <span class="va">palette_main</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">3</span><span class="op">]</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">labs</span><span class="op">(</span>x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/expression.html" class="external-link">expression</a></span><span class="op">(</span><span class="va">alpha</span><span class="op">)</span>, </span>
<span>       y <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/expression.html" class="external-link">expression</a></span><span class="op">(</span><span class="va">E</span><span class="op">*</span><span class="st">"["</span><span class="op">*</span><span class="va">K</span><span class="op">[</span><span class="va">J</span><span class="op">]</span><span class="op">*</span><span class="st">"|"</span><span class="op">*</span><span class="va">alpha</span><span class="op">*</span><span class="st">"]"</span><span class="op">)</span>,</span>
<span>       title <span class="op">=</span> <span class="st">"Expected Clusters vs. Concentration Parameter"</span>,</span>
<span>       subtitle <span class="op">=</span> <span class="st">"Larger J requires larger Œ± to achieve the same E[K]"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme_minimal</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme</span><span class="op">(</span>legend.position <span class="op">=</span> <span class="st">"bottom"</span>,</span>
<span>        legend.title <span class="op">=</span> <span class="fu">element_blank</span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<img src="introduction_files/figure-html/k-vs-alpha-1.png" class="r-plt" alt="Expected number of clusters as a function of Œ± for different sample sizes J. The approximately logarithmic relationship motivates the package's elicitation approach." width="85%"><p class="caption">
Expected number of clusters as a function of Œ± for different sample
sizes J. The approximately logarithmic relationship motivates the
package‚Äôs elicitation approach.
</p>
</div>
</div>
</div>
<div class="section level2">
<h2 id="the-low-information-problem">The Low-Information Problem<a class="anchor" aria-label="anchor" href="#the-low-information-problem"></a>
</h2>
<div class="section level3">
<h3 id="when-does-the-prior-matter">When Does the Prior Matter?<a class="anchor" aria-label="anchor" href="#when-does-the-prior-matter"></a>
</h3>
<p>In standard Bayesian analysis, priors become less influential as data
accumulate‚Äîthe posterior converges toward the likelihood. However, in
many practical applications, the data provide limited information about
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ±</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>,
and the prior can substantially influence posterior inference.</p>
<p>Zito et al.¬†(2024) demonstrated this sensitivity dramatically: in
their Figure 1, fixing
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Œ±</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\alpha = 1</annotation></semantics></math>
versus
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Œ±</mi><mo>=</mo><mn>5</mn></mrow><annotation encoding="application/x-tex">\alpha = 5</annotation></semantics></math>
causes the posterior mode of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>K</mi><mi>n</mi></msub><annotation encoding="application/x-tex">K_n</annotation></semantics></math>
to shift from four to eight clusters, even when data are generated from
a well-separated four-component mixture. Randomizing
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ±</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>
through an appropriate prior attenuates this sensitivity, but raises the
question: how should that prior be specified?</p>
<p><a href="https://doi.org/10.3102/10769986241254286" class="external-link">Lee et
al.¬†(2025)</a> addressed this question in the context of multisite
trials by defining an <em>informativeness index</em>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>I</mi><annotation encoding="application/x-tex">I</annotation></semantics></math>:
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>I</mi><mo>=</mo><mfrac><msup><mi>œÉ</mi><mn>2</mn></msup><mrow><msup><mi>œÉ</mi><mn>2</mn></msup><mo>+</mo><mo>exp</mo><mrow><mo stretchy="true" form="prefix">(</mo><mfrac><mn>1</mn><mi>J</mi></mfrac><munderover><mo>‚àë</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>J</mi></munderover><mo>log</mo><mrow><mo stretchy="true" form="prefix">(</mo><msubsup><mover><mrow><mi>s</mi><mi>e</mi></mrow><mo accent="true">ÃÇ</mo></mover><mi>j</mi><mn>2</mn></msubsup><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="true" form="postfix">)</mo></mrow></mrow></mfrac><mo>,</mo></mrow><annotation encoding="application/x-tex">
I = \frac{\sigma^2}{\sigma^2 + \exp\left(\frac{1}{J}\sum_{j=1}^{J} \log(\widehat{se}_j^2)\right)},
</annotation></semantics></math> where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>œÉ</mi><mn>2</mn></msup><annotation encoding="application/x-tex">\sigma^2</annotation></semantics></math>
is the between-site variance and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mover><mrow><mi>s</mi><mi>e</mi></mrow><mo accent="true">ÃÇ</mo></mover><mi>j</mi></msub><annotation encoding="application/x-tex">\widehat{se}_j</annotation></semantics></math>
are the within-site standard errors. The index
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>I</mi><annotation encoding="application/x-tex">I</annotation></semantics></math>
ranges from 0 to 1, with higher values indicating that the observed
estimates
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mover><mi>œÑ</mi><mo accent="true">ÃÇ</mo></mover><mi>j</mi></msub><annotation encoding="application/x-tex">\hat{\tau}_j</annotation></semantics></math>
provide greater information about the true site effects
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>œÑ</mi><mi>j</mi></msub><annotation encoding="application/x-tex">\tau_j</annotation></semantics></math>.
When
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>I</mi><annotation encoding="application/x-tex">I</annotation></semantics></math>
is small (e.g.,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>&lt;</mo><mn>0.3</mn></mrow><annotation encoding="application/x-tex">&lt; 0.3</annotation></semantics></math>),
the site-specific estimates are noisy relative to the between-site
heterogeneity, and the prior on
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ±</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>
can dominate the posterior.</p>
</div>
<div class="section level3">
<h3 id="characteristics-of-low-information-settings">Characteristics of Low-Information Settings<a class="anchor" aria-label="anchor" href="#characteristics-of-low-information-settings"></a>
</h3>
<p>Low-information settings commonly arise in:</p>
<ul>
<li>
<strong>Multisite trials</strong> with moderate numbers of sites
(<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>J</mi><mo>=</mo><mn>25</mn></mrow><annotation encoding="application/x-tex">J = 25</annotation></semantics></math>‚Äì<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mn>100</mn><annotation encoding="application/x-tex">100</annotation></semantics></math>)
and small within-site samples. Lee et al.¬†(2025) found that for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>J</mi><mo>‚â§</mo><mn>50</mn></mrow><annotation encoding="application/x-tex">J \leq 50</annotation></semantics></math>
and low
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>I</mi><annotation encoding="application/x-tex">I</annotation></semantics></math>,
even misspecified Gaussian models with appropriate posterior summaries
can outperform DP models with poorly chosen priors.</li>
<li>
<strong>Meta-analyses</strong> with heterogeneous effect sizes and
varying study precision</li>
<li>
<strong>Educational studies</strong> where school or classroom
effects exhibit substantial variability</li>
<li>
<strong>Healthcare quality assessment</strong> with limited patient
counts per provider</li>
</ul>
<p>In these settings, researchers cannot simply ‚Äúlet the data speak‚Äù‚Äîthe
prior matters, and choosing it thoughtfully is essential. As Lee et
al.¬†(2025) showed, the combination of an informative prior (DP-inform)
with appropriate posterior summaries outperforms diffuse approaches
precisely because it incorporates meaningful prior knowledge about the
expected clustering structure.</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Conceptual illustration of prior influence</span></span>
<span><span class="co"># Create a schematic showing prior vs posterior at different I levels</span></span>
<span><span class="va">I_levels</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"Low (I = 0.2)"</span>, <span class="st">"Medium (I = 0.5)"</span>, <span class="st">"High (I = 0.8)"</span><span class="op">)</span></span>
<span><span class="va">alpha_grid</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html" class="external-link">seq</a></span><span class="op">(</span><span class="fl">0.01</span>, <span class="fl">6</span>, length.out <span class="op">=</span> <span class="fl">200</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Create synthetic data for illustration</span></span>
<span><span class="va">concept_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/do.call.html" class="external-link">do.call</a></span><span class="op">(</span><span class="va">rbind</span>, <span class="fu"><a href="https://rdrr.io/r/base/lapply.html" class="external-link">lapply</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/seq.html" class="external-link">seq_along</a></span><span class="op">(</span><span class="va">I_levels</span><span class="op">)</span>, <span class="kw">function</span><span class="op">(</span><span class="va">i</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">I</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.2</span>, <span class="fl">0.5</span>, <span class="fl">0.8</span><span class="op">)</span><span class="op">[</span><span class="va">i</span><span class="op">]</span></span>
<span>  <span class="va">prior_weight</span> <span class="op">&lt;-</span> <span class="fl">1</span> <span class="op">-</span> <span class="va">I</span></span>
<span>  </span>
<span>  <span class="co"># Prior: Gamma(1.5, 0.8)</span></span>
<span>  <span class="va">prior</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/GammaDist.html" class="external-link">dgamma</a></span><span class="op">(</span><span class="va">alpha_grid</span>, <span class="fl">1.5</span>, <span class="fl">0.8</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="co"># "Likelihood peak" centered at alpha = 2.5</span></span>
<span>  <span class="va">likelihood_center</span> <span class="op">&lt;-</span> <span class="fl">2.5</span></span>
<span>  <span class="va">likelihood_width</span> <span class="op">&lt;-</span> <span class="fl">0.5</span> <span class="op">+</span> <span class="fl">2</span> <span class="op">*</span> <span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="va">I</span><span class="op">)</span>  <span class="co"># Wider at low I</span></span>
<span>  <span class="va">likelihood</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">dnorm</a></span><span class="op">(</span><span class="va">alpha_grid</span>, <span class="va">likelihood_center</span>, <span class="va">likelihood_width</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="co"># Posterior is mixture weighted by informativeness</span></span>
<span>  <span class="va">posterior</span> <span class="op">&lt;-</span> <span class="va">prior_weight</span> <span class="op">*</span> <span class="va">prior</span> <span class="op">+</span> <span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="va">prior_weight</span><span class="op">)</span> <span class="op">*</span> </span>
<span>               <span class="op">(</span><span class="va">likelihood</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">max</a></span><span class="op">(</span><span class="va">likelihood</span><span class="op">)</span><span class="op">)</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">max</a></span><span class="op">(</span><span class="va">prior</span><span class="op">)</span></span>
<span>  <span class="va">posterior</span> <span class="op">&lt;-</span> <span class="va">posterior</span> <span class="op">/</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="va">posterior</span><span class="op">)</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/diff.html" class="external-link">diff</a></span><span class="op">(</span><span class="va">alpha_grid</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">rbind</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span>alpha <span class="op">=</span> <span class="va">alpha_grid</span>, density <span class="op">=</span> <span class="va">prior</span>, </span>
<span>               Type <span class="op">=</span> <span class="st">"Prior"</span>, Setting <span class="op">=</span> <span class="va">I_levels</span><span class="op">[</span><span class="va">i</span><span class="op">]</span><span class="op">)</span>,</span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span>alpha <span class="op">=</span> <span class="va">alpha_grid</span>, density <span class="op">=</span> <span class="va">posterior</span>, </span>
<span>               Type <span class="op">=</span> <span class="st">"Posterior"</span>, Setting <span class="op">=</span> <span class="va">I_levels</span><span class="op">[</span><span class="va">i</span><span class="op">]</span><span class="op">)</span></span>
<span>  <span class="op">)</span></span>
<span><span class="op">}</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">concept_data</span><span class="op">$</span><span class="va">Setting</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html" class="external-link">factor</a></span><span class="op">(</span><span class="va">concept_data</span><span class="op">$</span><span class="va">Setting</span>, levels <span class="op">=</span> <span class="va">I_levels</span><span class="op">)</span></span>
<span><span class="va">concept_data</span><span class="op">$</span><span class="va">Type</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html" class="external-link">factor</a></span><span class="op">(</span><span class="va">concept_data</span><span class="op">$</span><span class="va">Type</span>, levels <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"Prior"</span>, <span class="st">"Posterior"</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="fu">ggplot</span><span class="op">(</span><span class="va">concept_data</span>, <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">alpha</span>, y <span class="op">=</span> <span class="va">density</span>, color <span class="op">=</span> <span class="va">Type</span>, linetype <span class="op">=</span> <span class="va">Type</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_line</span><span class="op">(</span>linewidth <span class="op">=</span> <span class="fl">1</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">facet_wrap</span><span class="op">(</span><span class="op">~</span><span class="va">Setting</span>, nrow <span class="op">=</span> <span class="fl">1</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">scale_color_manual</span><span class="op">(</span>values <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"Prior"</span> <span class="op">=</span> <span class="st">"#E41A1C"</span>, <span class="st">"Posterior"</span> <span class="op">=</span> <span class="st">"#377EB8"</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">scale_linetype_manual</span><span class="op">(</span>values <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"Prior"</span> <span class="op">=</span> <span class="st">"dashed"</span>, <span class="st">"Posterior"</span> <span class="op">=</span> <span class="st">"solid"</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">labs</span><span class="op">(</span>x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/expression.html" class="external-link">expression</a></span><span class="op">(</span><span class="va">alpha</span><span class="op">)</span>,</span>
<span>       y <span class="op">=</span> <span class="st">"Density"</span>,</span>
<span>       title <span class="op">=</span> <span class="st">"Prior Influence Varies with Informativeness"</span>,</span>
<span>       subtitle <span class="op">=</span> <span class="st">"In low-I settings, the posterior closely tracks the prior"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme_minimal</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme</span><span class="op">(</span>legend.position <span class="op">=</span> <span class="st">"bottom"</span>,</span>
<span>        legend.title <span class="op">=</span> <span class="fu">element_blank</span><span class="op">(</span><span class="op">)</span>,</span>
<span>        strip.text <span class="op">=</span> <span class="fu">element_text</span><span class="op">(</span>face <span class="op">=</span> <span class="st">"bold"</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<img src="introduction_files/figure-html/informativeness-demo-1.png" class="r-plt" alt="Prior influence across different informativeness levels. In low-information settings (low I), the prior's shape substantially affects the posterior." width="85%"><p class="caption">
Prior influence across different informativeness levels. In
low-information settings (low I), the prior‚Äôs shape substantially
affects the posterior.
</p>
</div>
</div>
</div>
<div class="section level2">
<h2 id="the-k-based-elicitation-philosophy">The K-Based Elicitation Philosophy<a class="anchor" aria-label="anchor" href="#the-k-based-elicitation-philosophy"></a>
</h2>
<div class="section level3">
<h3 id="speaking-the-researchers-language">Speaking the Researcher‚Äôs Language<a class="anchor" aria-label="anchor" href="#speaking-the-researchers-language"></a>
</h3>
<p>The DPprior package is built on a simple insight: while
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ±</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>
is an abstract mathematical parameter, the <em>number of clusters</em>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>K</mi><mi>J</mi></msub><annotation encoding="application/x-tex">K_J</annotation></semantics></math>
is something researchers can often reason about directly.</p>
<p>Consider a researcher analyzing a multisite educational trial with 50
sites. They might not have intuitions about
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ±</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>,
but they can likely answer questions like:</p>
<blockquote>
<p>‚ÄúAmong your 50 sites, roughly how many distinct effect patterns or
subtypes do you expect?‚Äù</p>
</blockquote>
<blockquote>
<p>‚ÄúAre you fairly confident in that expectation, or quite
uncertain?‚Äù</p>
</blockquote>
<p>Lee et al.¬†(2025) operationalized this approach using a chi-square
distribution for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>K</mi><mi>J</mi></msub><annotation encoding="application/x-tex">K_J</annotation></semantics></math>:
if a researcher expects about 5 clusters, specifying
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>K</mi><mi>J</mi></msub><mo>‚àº</mo><msup><mi>œá</mi><mn>2</mn></msup><mrow><mo stretchy="true" form="prefix">(</mo><mn>5</mn><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">K_J \sim \chi^2(5)</annotation></semantics></math>
implies both a mean of 5 and a variance of 10. The package then finds
Gamma parameters
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="true" form="prefix">(</mo><mi>a</mi><mo>,</mo><mi>b</mi><mo stretchy="true" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">(a, b)</annotation></semantics></math>
such that the prior on
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ±</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>
induces a distribution over
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>K</mi><mi>J</mi></msub><annotation encoding="application/x-tex">K_J</annotation></semantics></math>
that matches these moments.</p>
</div>
<div class="section level3">
<h3 id="beyond-cluster-counts-the-weight-dimension">Beyond Cluster Counts: The Weight Dimension<a class="anchor" aria-label="anchor" href="#beyond-cluster-counts-the-weight-dimension"></a>
</h3>
<p>However, <a href="https://doi.org/10.48550/arXiv.2502.00864" class="external-link">Vicentini &amp; Jermyn
(2025)</a> identified an important limitation of approaches that focus
solely on
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>K</mi><mi>J</mi></msub><annotation encoding="application/x-tex">K_J</annotation></semantics></math>:
matching a target cluster count distribution does not guarantee
intuitive behavior for the <em>cluster weights</em>‚Äîthe relative sizes
of the clusters.</p>
<p>Consider a researcher who says ‚ÄúI expect about 5 clusters.‚Äù They
likely imagine something like five roughly comparable groups, not a
situation where one cluster contains 80% of observations while four
others share the remaining 20%. Yet a prior calibrated only to match
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ùîº</mi><mrow><mo stretchy="true" form="prefix">[</mo><msub><mi>K</mi><mi>J</mi></msub><mo stretchy="true" form="postfix">]</mo></mrow><mo>=</mo><mn>5</mn></mrow><annotation encoding="application/x-tex">\mathbb{E}[K_J] = 5</annotation></semantics></math>
might imply substantial probability of such ‚Äúdominant cluster‚Äù
configurations.</p>
<p>This insight motivates the dual-anchor framework in DPprior:
researchers can additionally express beliefs about weight concentration
through questions like:</p>
<blockquote>
<p>‚ÄúHow likely is it that a single cluster would contain more than half
of your sites?‚Äù</p>
</blockquote>
<p>These natural questions translate directly into prior
specifications:</p>
<table class="table">
<thead><tr class="header">
<th>Researcher‚Äôs Answer</th>
<th>Mathematical Translation</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>‚ÄúAbout 5 groups‚Äù</td>
<td>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œº</mi><mi>K</mi></msub><mo>=</mo><mn>5</mn></mrow><annotation encoding="application/x-tex">\mu_K = 5</annotation></semantics></math>
(target mean of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>K</mi><mi>J</mi></msub><annotation encoding="application/x-tex">K_J</annotation></semantics></math>)</td>
</tr>
<tr class="even">
<td>‚ÄúModerately confident‚Äù</td>
<td><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext mathvariant="normal">Var</mtext><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>K</mi><mi>J</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>‚âà</mo><mn>2.5</mn><mo>√ó</mo><msub><mi>Œº</mi><mi>K</mi></msub></mrow><annotation encoding="application/x-tex">\text{Var}(K_J) \approx 2.5 \times \mu_K</annotation></semantics></math></td>
</tr>
<tr class="odd">
<td>‚ÄúVery uncertain‚Äù</td>
<td><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext mathvariant="normal">Var</mtext><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>K</mi><mi>J</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>‚âà</mo><mn>5</mn><mo>√ó</mo><msub><mi>Œº</mi><mi>K</mi></msub></mrow><annotation encoding="application/x-tex">\text{Var}(K_J) \approx 5 \times \mu_K</annotation></semantics></math></td>
</tr>
<tr class="even">
<td>‚ÄúUnlikely one group dominates‚Äù</td>
<td><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>w</mi><mn>1</mn></msub><mo>&gt;</mo><mn>0.5</mn><mo stretchy="true" form="postfix">)</mo></mrow><mo>&lt;</mo><mn>0.3</mn></mrow><annotation encoding="application/x-tex">P(w_1 &gt; 0.5) &lt; 0.3</annotation></semantics></math></td>
</tr>
</tbody>
</table>
</div>
<div class="section level3">
<h3 id="from-moments-to-gamma-hyperparameters">From Moments to Gamma Hyperparameters<a class="anchor" aria-label="anchor" href="#from-moments-to-gamma-hyperparameters"></a>
</h3>
<p>The DPprior package converts these intuitive specifications into
Gamma hyperparameters
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Œ±</mi><mo>‚àº</mo><mtext mathvariant="normal">Gamma</mtext><mrow><mo stretchy="true" form="prefix">(</mo><mi>a</mi><mo>,</mo><mi>b</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\alpha \sim \text{Gamma}(a, b)</annotation></semantics></math>
through a two-step process:</p>
<ol style="list-style-type: decimal">
<li><p><strong>A1 (Closed-form approximation)</strong>: Using the
asymptotic relationship
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>K</mi><mi>J</mi></msub><mo>‚à£</mo><mi>Œ±</mi><mo>‚âà</mo><mtext mathvariant="normal">Poisson</mtext><mrow><mo stretchy="true" form="prefix">(</mo><mi>Œ±</mi><mo>log</mo><mi>J</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">K_J \mid \alpha \approx \text{Poisson}(\alpha \log J)</annotation></semantics></math>,
which under a Gamma prior on
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ±</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>
yields a Negative Binomial marginal for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>K</mi><mi>J</mi></msub><annotation encoding="application/x-tex">K_J</annotation></semantics></math>
(Vicentini &amp; Jermyn, 2025; Zito et al., 2024), we derive initial
closed-form estimates
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>a</mi><mn>0</mn></msub><mo>,</mo><msub><mi>b</mi><mn>0</mn></msub><mo stretchy="true" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">(a_0, b_0)</annotation></semantics></math>.</p></li>
<li><p><strong>A2 (Newton refinement)</strong>: Using exact moments
computed via the Antoniak distribution, we refine
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="true" form="prefix">(</mo><mi>a</mi><mo>,</mo><mi>b</mi><mo stretchy="true" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">(a, b)</annotation></semantics></math>
to precisely match the target
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>Œº</mi><mi>K</mi></msub><mo>,</mo><msubsup><mi>œÉ</mi><mi>K</mi><mn>2</mn></msubsup><mo stretchy="true" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">(\mu_K, \sigma_K^2)</annotation></semantics></math>.</p></li>
</ol>
<p>This approach‚Äîwhich we call <em>Design-Conditional Elicitation
(DCE)</em>‚Äîextends the original DORO method (Dorazio, 2009; Lee et al.,
2025) by replacing computationally expensive grid search with
near-instantaneous closed-form solutions backed by Newton iteration for
guaranteed accuracy. The optional dual-anchor extension further
incorporates weight constraints, addressing the ‚Äúunintended prior‚Äù
problem identified by Vicentini &amp; Jermyn (2025).</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Demonstrate the elicitation workflow</span></span>
<span><span class="va">J</span> <span class="op">&lt;-</span> <span class="fl">50</span></span>
<span><span class="va">mu_K</span> <span class="op">&lt;-</span> <span class="fl">5</span></span>
<span></span>
<span><span class="co"># Method 1: Using confidence levels</span></span>
<span><span class="va">fit_low</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/DPprior_fit.html">DPprior_fit</a></span><span class="op">(</span>J <span class="op">=</span> <span class="va">J</span>, mu_K <span class="op">=</span> <span class="va">mu_K</span>, confidence <span class="op">=</span> <span class="st">"low"</span><span class="op">)</span></span>
<span><span class="co">#&gt; Warning: HIGH DOMINANCE RISK: P(w1 &gt; 0.5) = 56.3% exceeds 40%.</span></span>
<span><span class="co">#&gt;   This may indicate unintended prior behavior (Lee, 2026).</span></span>
<span><span class="co">#&gt;   Consider using DPprior_dual() for weight-constrained elicitation.</span></span>
<span><span class="co">#&gt;   See ?DPprior_diagnostics for interpretation.</span></span>
<span><span class="va">fit_med</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/DPprior_fit.html">DPprior_fit</a></span><span class="op">(</span>J <span class="op">=</span> <span class="va">J</span>, mu_K <span class="op">=</span> <span class="va">mu_K</span>, confidence <span class="op">=</span> <span class="st">"medium"</span><span class="op">)</span></span>
<span><span class="co">#&gt; Warning: HIGH DOMINANCE RISK: P(w1 &gt; 0.5) = 49.7% exceeds 40%.</span></span>
<span><span class="co">#&gt;   This may indicate unintended prior behavior (Lee, 2026).</span></span>
<span><span class="co">#&gt;   Consider using DPprior_dual() for weight-constrained elicitation.</span></span>
<span><span class="co">#&gt;   See ?DPprior_diagnostics for interpretation.</span></span>
<span><span class="va">fit_high</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/DPprior_fit.html">DPprior_fit</a></span><span class="op">(</span>J <span class="op">=</span> <span class="va">J</span>, mu_K <span class="op">=</span> <span class="va">mu_K</span>, confidence <span class="op">=</span> <span class="st">"high"</span><span class="op">)</span></span>
<span><span class="co">#&gt; Warning: HIGH DOMINANCE RISK: P(w1 &gt; 0.5) = 46.5% exceeds 40%.</span></span>
<span><span class="co">#&gt;   This may indicate unintended prior behavior (Lee, 2026).</span></span>
<span><span class="co">#&gt;   Consider using DPprior_dual() for weight-constrained elicitation.</span></span>
<span><span class="co">#&gt;   See ?DPprior_diagnostics for interpretation.</span></span>
<span></span>
<span><span class="co"># Display results</span></span>
<span><span class="va">results</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span></span>
<span>  Confidence <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"Low"</span>, <span class="st">"Medium"</span>, <span class="st">"High"</span><span class="op">)</span>,</span>
<span>  VIF <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">4.0</span>, <span class="fl">2.5</span>, <span class="fl">1.5</span><span class="op">)</span>,</span>
<span>  var_K <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">fit_low</span><span class="op">$</span><span class="va">target</span><span class="op">$</span><span class="va">var_K</span>, <span class="va">fit_med</span><span class="op">$</span><span class="va">target</span><span class="op">$</span><span class="va">var_K</span>, </span>
<span>                  <span class="va">fit_high</span><span class="op">$</span><span class="va">target</span><span class="op">$</span><span class="va">var_K</span><span class="op">)</span>, <span class="fl">2</span><span class="op">)</span>,</span>
<span>  a <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">fit_low</span><span class="op">$</span><span class="va">a</span>, <span class="va">fit_med</span><span class="op">$</span><span class="va">a</span>, <span class="va">fit_high</span><span class="op">$</span><span class="va">a</span><span class="op">)</span>, <span class="fl">3</span><span class="op">)</span>,</span>
<span>  b <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">fit_low</span><span class="op">$</span><span class="va">b</span>, <span class="va">fit_med</span><span class="op">$</span><span class="va">b</span>, <span class="va">fit_high</span><span class="op">$</span><span class="va">b</span><span class="op">)</span>, <span class="fl">3</span><span class="op">)</span>,</span>
<span>  E_alpha <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">fit_low</span><span class="op">$</span><span class="va">a</span><span class="op">/</span><span class="va">fit_low</span><span class="op">$</span><span class="va">b</span>, <span class="va">fit_med</span><span class="op">$</span><span class="va">a</span><span class="op">/</span><span class="va">fit_med</span><span class="op">$</span><span class="va">b</span>, </span>
<span>                    <span class="va">fit_high</span><span class="op">$</span><span class="va">a</span><span class="op">/</span><span class="va">fit_high</span><span class="op">$</span><span class="va">b</span><span class="op">)</span>, <span class="fl">3</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="fu">knitr</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/knitr/man/kable.html" class="external-link">kable</a></span><span class="op">(</span><span class="va">results</span>, </span>
<span>             col.names <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"Confidence"</span>, <span class="st">"VIF"</span>, <span class="st">"Var(K)"</span>, <span class="st">"a"</span>, <span class="st">"b"</span>, <span class="st">"E[Œ±]"</span><span class="op">)</span>,</span>
<span>             caption <span class="op">=</span> <span class="st">"Gamma hyperparameters for different confidence levels (J = 50, Œº_K = 5)"</span><span class="op">)</span></span></code></pre></div>
<table class="table">
<caption>Gamma hyperparameters for different confidence levels (J = 50,
Œº_K = 5)</caption>
<thead><tr class="header">
<th align="left">Confidence</th>
<th align="right">VIF</th>
<th align="right">Var(K)</th>
<th align="right">a</th>
<th align="right">b</th>
<th align="right">E[Œ±]</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">Low</td>
<td align="right">4.0</td>
<td align="right">20</td>
<td align="right">0.518</td>
<td align="right">0.341</td>
<td align="right">1.519</td>
</tr>
<tr class="even">
<td align="left">Medium</td>
<td align="right">2.5</td>
<td align="right">10</td>
<td align="right">1.408</td>
<td align="right">1.077</td>
<td align="right">1.308</td>
</tr>
<tr class="odd">
<td align="left">High</td>
<td align="right">1.5</td>
<td align="right">6</td>
<td align="right">3.568</td>
<td align="right">2.900</td>
<td align="right">1.230</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section level2">
<h2 id="what-this-package-does">What This Package Does<a class="anchor" aria-label="anchor" href="#what-this-package-does"></a>
</h2>
<p>The DPprior package provides three core capabilities:</p>
<div class="section level3">
<h3 id="k-based-elicitation">1. K-Based Elicitation<a class="anchor" aria-label="anchor" href="#k-based-elicitation"></a>
</h3>
<p>Convert intuitive beliefs about cluster counts into principled Gamma
hyperpriors:</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># The main elicitation function</span></span>
<span><span class="va">fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/DPprior_fit.html">DPprior_fit</a></span><span class="op">(</span></span>
<span>  J <span class="op">=</span> <span class="fl">50</span>,              <span class="co"># Number of observations/sites</span></span>
<span>  mu_K <span class="op">=</span> <span class="fl">5</span>,            <span class="co"># Expected number of clusters</span></span>
<span>  confidence <span class="op">=</span> <span class="st">"medium"</span> <span class="co"># Uncertainty about that expectation</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Warning: HIGH DOMINANCE RISK: P(w1 &gt; 0.5) = 49.7% exceeds 40%.</span></span>
<span><span class="co">#&gt;   This may indicate unintended prior behavior (Lee, 2026).</span></span>
<span><span class="co">#&gt;   Consider using DPprior_dual() for weight-constrained elicitation.</span></span>
<span><span class="co">#&gt;   See ?DPprior_diagnostics for interpretation.</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"Elicited prior: Œ± ~ Gamma("</span>, <span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="va">fit</span><span class="op">$</span><span class="va">a</span>, <span class="fl">3</span><span class="op">)</span>, <span class="st">", "</span>, </span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="va">fit</span><span class="op">$</span><span class="va">b</span>, <span class="fl">3</span><span class="op">)</span>, <span class="st">")\n"</span>, sep <span class="op">=</span> <span class="st">""</span><span class="op">)</span></span>
<span><span class="co">#&gt; Elicited prior: Œ± ~ Gamma(1.408, 1.077)</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="dual-anchor-control">2. Dual-Anchor Control<a class="anchor" aria-label="anchor" href="#dual-anchor-control"></a>
</h3>
<p>Go beyond cluster counts to control weight concentration, addressing
the ‚Äúunintended prior‚Äù problem identified by <a href="https://doi.org/10.48550/arXiv.2502.00864" class="external-link">Vicentini &amp; Jermyn
(2025)</a>:</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># First, fit K-only prior</span></span>
<span><span class="va">fit_K</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/DPprior_fit.html">DPprior_fit</a></span><span class="op">(</span>J <span class="op">=</span> <span class="fl">50</span>, mu_K <span class="op">=</span> <span class="fl">5</span>, var_K <span class="op">=</span> <span class="fl">8</span><span class="op">)</span></span>
<span><span class="co">#&gt; Warning: HIGH DOMINANCE RISK: P(w1 &gt; 0.5) = 48.1% exceeds 40%.</span></span>
<span><span class="co">#&gt;   This may indicate unintended prior behavior (Lee, 2026).</span></span>
<span><span class="co">#&gt;   Consider using DPprior_dual() for weight-constrained elicitation.</span></span>
<span><span class="co">#&gt;   See ?DPprior_diagnostics for interpretation.</span></span>
<span></span>
<span><span class="co"># Check weight behavior</span></span>
<span><span class="va">p_w1</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/prob_w1_exceeds.html">prob_w1_exceeds</a></span><span class="op">(</span><span class="fl">0.5</span>, <span class="va">fit_K</span><span class="op">$</span><span class="va">a</span>, <span class="va">fit_K</span><span class="op">$</span><span class="va">b</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"K-only prior: P(w‚ÇÅ &gt; 0.5) ="</span>, <span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="va">p_w1</span>, <span class="fl">3</span><span class="op">)</span>, <span class="st">"\n"</span><span class="op">)</span></span>
<span><span class="co">#&gt; K-only prior: P(w‚ÇÅ &gt; 0.5) = 0.481</span></span>
<span></span>
<span><span class="co"># Apply dual-anchor constraint if weight behavior is undesirable</span></span>
<span><span class="kw">if</span> <span class="op">(</span><span class="va">p_w1</span> <span class="op">&gt;</span> <span class="fl">0.4</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">w1_target</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>prob <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>threshold <span class="op">=</span> <span class="fl">0.5</span>, value <span class="op">=</span> <span class="fl">0.30</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="va">fit_dual</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/DPprior_dual.html">DPprior_dual</a></span><span class="op">(</span><span class="va">fit_K</span>, <span class="va">w1_target</span>, lambda <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span></span>
<span>  <span class="va">p_w1_new</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/prob_w1_exceeds.html">prob_w1_exceeds</a></span><span class="op">(</span><span class="fl">0.5</span>, <span class="va">fit_dual</span><span class="op">$</span><span class="va">a</span>, <span class="va">fit_dual</span><span class="op">$</span><span class="va">b</span><span class="op">)</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"Dual-anchor prior: P(w‚ÇÅ &gt; 0.5) ="</span>, <span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="va">p_w1_new</span>, <span class="fl">3</span><span class="op">)</span>, <span class="st">"\n"</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span><span class="co">#&gt; Dual-anchor prior: P(w‚ÇÅ &gt; 0.5) = 0.438</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="comprehensive-diagnostics">3. Comprehensive Diagnostics<a class="anchor" aria-label="anchor" href="#comprehensive-diagnostics"></a>
</h3>
<p>Verify that your elicited prior behaves as intended across all
relevant dimensions:</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Run diagnostics</span></span>
<span><span class="va">fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/DPprior_fit.html">DPprior_fit</a></span><span class="op">(</span>J <span class="op">=</span> <span class="fl">50</span>, mu_K <span class="op">=</span> <span class="fl">5</span>, var_K <span class="op">=</span> <span class="fl">8</span>, check_diagnostics <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="co">#&gt; Warning: HIGH DOMINANCE RISK: P(w1 &gt; 0.5) = 48.1% exceeds 40%.</span></span>
<span><span class="co">#&gt;   This may indicate unintended prior behavior (Lee, 2026).</span></span>
<span><span class="co">#&gt;   Consider using DPprior_dual() for weight-constrained elicitation.</span></span>
<span><span class="co">#&gt;   See ?DPprior_diagnostics for interpretation.</span></span>
<span></span>
<span><span class="co"># Visualize the complete prior specification</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<img src="introduction_files/figure-html/capability-3-1.png" class="r-plt" alt="DPprior diagnostic dashboard showing the joint behavior of Œ±, K, and w‚ÇÅ under the elicited prior." width="85%"><p class="caption">
DPprior diagnostic dashboard showing the joint behavior of Œ±, K, and w‚ÇÅ
under the elicited prior.
</p>
</div>
<pre><code><span><span class="co">#&gt; TableGrob (2 x 2) "dpprior_dashboard": 4 grobs</span></span>
<span><span class="co">#&gt;   z     cells              name           grob</span></span>
<span><span class="co">#&gt; 1 1 (1-1,1-1) dpprior_dashboard gtable[layout]</span></span>
<span><span class="co">#&gt; 2 2 (2-2,1-1) dpprior_dashboard gtable[layout]</span></span>
<span><span class="co">#&gt; 3 3 (1-1,2-2) dpprior_dashboard gtable[layout]</span></span>
<span><span class="co">#&gt; 4 4 (2-2,2-2) dpprior_dashboard gtable[layout]</span></span></code></pre>
</div>
<div class="section level3">
<h3 id="package-architecture">Package Architecture<a class="anchor" aria-label="anchor" href="#package-architecture"></a>
</h3>
<p>The package is organized into three layers:</p>
<table class="table">
<colgroup>
<col width="22%">
<col width="29%">
<col width="48%">
</colgroup>
<thead><tr class="header">
<th>Layer</th>
<th>Purpose</th>
<th>Key Functions</th>
</tr></thead>
<tbody>
<tr class="odd">
<td><strong>A. Reference Engine</strong></td>
<td>Exact computation of Stirling numbers and conditional
distributions</td>
<td>
<code><a href="../reference/compute_log_stirling.html">compute_log_stirling()</a></code>,
<code><a href="../reference/pmf_K_given_alpha.html">pmf_K_given_alpha()</a></code>
</td>
</tr>
<tr class="even">
<td><strong>B. Elicitation Engine</strong></td>
<td>Mapping algorithms from moments to Gamma parameters</td>
<td>
<code><a href="../reference/DPprior_a1.html">DPprior_a1()</a></code>, <code><a href="../reference/DPprior_a2_newton.html">DPprior_a2_newton()</a></code>,
<code><a href="../reference/DPprior_dual.html">DPprior_dual()</a></code>
</td>
</tr>
<tr class="odd">
<td><strong>C. User Interface</strong></td>
<td>User-friendly wrappers with sensible defaults</td>
<td>
<code><a href="../reference/DPprior_fit.html">DPprior_fit()</a></code>, <code><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot()</a></code>,
<code><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary()</a></code>
</td>
</tr>
</tbody>
</table>
<p>Most users interact only with Layer C, but the underlying layers are
available for advanced applications and research.</p>
</div>
</div>
<div class="section level2">
<h2 id="when-to-use-dpprior">When to Use DPprior<a class="anchor" aria-label="anchor" href="#when-to-use-dpprior"></a>
</h2>
<div class="section level3">
<h3 id="recommended-use-cases">Recommended Use Cases<a class="anchor" aria-label="anchor" href="#recommended-use-cases"></a>
</h3>
<p>The DPprior package is particularly valuable for:</p>
<ul>
<li><p><strong>Multisite randomized trials</strong>: When analyzing
heterogeneity across treatment sites with moderate
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>J</mi><annotation encoding="application/x-tex">J</annotation></semantics></math>
(20‚Äì200 sites)</p></li>
<li><p><strong>Meta-analysis with flexible heterogeneity</strong>: When
standard normal random effects may be too restrictive</p></li>
<li><p><strong>Bayesian nonparametric density estimation</strong>: When
sample sizes are small enough that prior specification matters</p></li>
<li><p><strong>Mixed-effects models with flexible random
effects</strong>: When exploring potential clustering among random
effect distributions</p></li>
</ul>
</div>
<div class="section level3">
<h3 id="when-other-approaches-may-be-more-appropriate">When Other Approaches May Be More Appropriate<a class="anchor" aria-label="anchor" href="#when-other-approaches-may-be-more-appropriate"></a>
</h3>
<p>Consider alternatives when:</p>
<ul>
<li><p><strong>Very large
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>J</mi><annotation encoding="application/x-tex">J</annotation></semantics></math>
or streaming data</strong>: With thousands of observations, the prior on
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ±</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>
becomes less influential. Sample-size-independent (SSI) approaches may
be more natural.</p></li>
<li><p><strong>Highly informative data</strong>: When the likelihood
provides overwhelming evidence about
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ±</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>,
prior specification is less critical.</p></li>
<li><p><strong>Primarily interested in prediction</strong>: DP mixture
models excel at clustering and density estimation; for pure prediction
tasks, other models may be more appropriate.</p></li>
</ul>
</div>
</div>
<div class="section level2">
<h2 id="road-map-to-the-vignettes">Road Map to the Vignettes<a class="anchor" aria-label="anchor" href="#road-map-to-the-vignettes"></a>
</h2>
<p>The DPprior package includes comprehensive documentation organized
into two tracks:</p>
<div class="section level3">
<h3 id="applied-researchers-track">Applied Researchers Track<a class="anchor" aria-label="anchor" href="#applied-researchers-track"></a>
</h3>
<p>For users who want to apply the package effectively:</p>
<table class="table">
<colgroup>
<col width="30%">
<col width="27%">
<col width="42%">
</colgroup>
<thead><tr class="header">
<th>Vignette</th>
<th>Purpose</th>
<th>Reading Time</th>
</tr></thead>
<tbody>
<tr class="odd">
<td><a href="quick-start.html">Quick Start</a></td>
<td>Your first prior in 5 minutes</td>
<td>5 min</td>
</tr>
<tr class="even">
<td><a href="applied-guide.html">Applied Guide</a></td>
<td>Complete elicitation workflow</td>
<td>30-40 min</td>
</tr>
<tr class="odd">
<td><a href="dual-anchor.html">Dual-Anchor Framework</a></td>
<td>Control cluster counts AND weights</td>
<td>20-25 min</td>
</tr>
<tr class="even">
<td><a href="diagnostics.html">Diagnostics</a></td>
<td>Verify your prior behaves as intended</td>
<td>15-20 min</td>
</tr>
<tr class="odd">
<td><a href="case-studies.html">Case Studies</a></td>
<td>Real-world applications</td>
<td>30 min</td>
</tr>
</tbody>
</table>
</div>
<div class="section level3">
<h3 id="methodological-researchers-track">Methodological Researchers Track<a class="anchor" aria-label="anchor" href="#methodological-researchers-track"></a>
</h3>
<p>For users interested in the mathematical foundations:</p>
<table class="table">
<colgroup>
<col width="30%">
<col width="27%">
<col width="42%">
</colgroup>
<thead><tr class="header">
<th>Vignette</th>
<th>Purpose</th>
<th>Reading Time</th>
</tr></thead>
<tbody>
<tr class="odd">
<td><a href="theory-overview.html">Theory Overview</a></td>
<td>Mathematical foundations</td>
<td>45-60 min</td>
</tr>
<tr class="even">
<td><a href="theory-stirling.html">Stirling Numbers</a></td>
<td>Antoniak distribution details</td>
<td>30 min</td>
</tr>
<tr class="odd">
<td><a href="theory-approximations.html">Approximations</a></td>
<td>A1 closed-form theory</td>
<td>30 min</td>
</tr>
<tr class="even">
<td><a href="theory-newton.html">Newton Algorithm</a></td>
<td>A2 exact moment matching</td>
<td>30 min</td>
</tr>
<tr class="odd">
<td><a href="theory-weights.html">Weight Distributions</a></td>
<td>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>w</mi><mn>1</mn></msub><annotation encoding="application/x-tex">w_1</annotation></semantics></math>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>œÅ</mi><annotation encoding="application/x-tex">\rho</annotation></semantics></math>,
and dual-anchor</td>
<td>40 min</td>
</tr>
<tr class="even">
<td><a href="api-reference.html">API Reference</a></td>
<td>Complete function documentation</td>
<td>Reference</td>
</tr>
</tbody>
</table>
</div>
<div class="section level3">
<h3 id="recommended-reading-paths">Recommended Reading Paths<a class="anchor" aria-label="anchor" href="#recommended-reading-paths"></a>
</h3>
<dl>
<dt><strong>‚ÄúI want to get started quickly‚Äù</strong></dt>
<dd>
‚Üí <a href="quick-start.html">Quick Start</a>
</dd>
<dt><strong>‚ÄúI want a systematic introduction‚Äù</strong></dt>
<dd>
‚Üí Quick Start ‚Üí Applied Guide ‚Üí Dual-Anchor ‚Üí Diagnostics
</dd>
<dt><strong>‚ÄúI need to understand the theory‚Äù</strong></dt>
<dd>
‚Üí Theory Overview ‚Üí Stirling Numbers ‚Üí Approximations ‚Üí Newton Algorithm
</dd>
<dt><strong>‚ÄúI need specific application examples‚Äù</strong></dt>
<dd>
‚Üí Case Studies
</dd>
</dl>
</div>
</div>
<div class="section level2">
<h2 id="summary">Summary<a class="anchor" aria-label="anchor" href="#summary"></a>
</h2>
<p>The DPprior package addresses a fundamental challenge in Bayesian
nonparametric modeling: how to translate domain knowledge into a
principled prior on the Dirichlet Process concentration parameter
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ±</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>.
Key features include:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Intuitive elicitation</strong>: Specify priors through
expected cluster counts and weight concentration, rather than abstract
parameters</p></li>
<li><p><strong>Fast computation</strong>: Closed-form approximations
with Newton refinement, eliminating the need for grid search (DCE via
TSMM)</p></li>
<li><p><strong>Comprehensive control</strong>: Dual-anchor framework for
joint control of cluster counts and weight behavior, addressing the
‚Äúunintended prior‚Äù problem identified by Vicentini &amp; Jermyn
(2025)</p></li>
<li><p><strong>Rich diagnostics</strong>: Verification tools to ensure
priors behave as intended across all relevant dimensions‚Äînot just
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>K</mi><mi>J</mi></msub><annotation encoding="application/x-tex">K_J</annotation></semantics></math>
but also
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>w</mi><mn>1</mn></msub><annotation encoding="application/x-tex">w_1</annotation></semantics></math>
and co-clustering probability
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>œÅ</mi><annotation encoding="application/x-tex">\rho</annotation></semantics></math></p></li>
</ol>
<p>The package is especially valuable in <em>low-information
settings</em>‚Äîmultisite trials, meta-analyses, and other applications
where, as Lee et al.¬†(2025) demonstrated, the prior on
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ±</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>
can substantially influence posterior inference on site-specific effects
and their distribution.</p>
</div>
<div class="section level2">
<h2 id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<p>Antoniak, C. E. (1974). Mixtures of Dirichlet processes with
applications to Bayesian nonparametric problems. <em>The Annals of
Statistics</em>, 2(6), 1152‚Äì1174.</p>
<p>Dorazio, R. M. (2009). On selecting a prior for the precision
parameter of Dirichlet process mixture models. <em>Journal of
Statistical Planning and Inference</em>, 139(10), 3384‚Äì3390.</p>
<p>Ferguson, T. S. (1973). A Bayesian analysis of some nonparametric
problems. <em>The Annals of Statistics</em>, 1(2), 209‚Äì230.</p>
<p>Lee, J., Che, J., Rabe-Hesketh, S., Feller, A., &amp; Miratrix, L.
(2025). Improving the estimation of site-specific effects and their
distribution in multisite trials. <em>Journal of Educational and
Behavioral Statistics</em>, 50(5), 731‚Äì764. <a href="https://doi.org/10.3102/10769986241254286" class="external-link uri">https://doi.org/10.3102/10769986241254286</a></p>
<p>Sethuraman, J. (1994). A constructive definition of Dirichlet priors.
<em>Statistica Sinica</em>, 4(2), 639‚Äì650.</p>
<p>Vicentini, C., &amp; Jermyn, I. H. (2025). Prior selection for the
precision parameter of Dirichlet process mixtures.
<em>arXiv:2502.00864</em>. <a href="https://doi.org/10.48550/arXiv.2502.00864" class="external-link uri">https://doi.org/10.48550/arXiv.2502.00864</a></p>
<p>Zito, A., Rigon, T., &amp; Dunson, D. B. (2024). Bayesian
nonparametric modeling of latent partitions via Stirling-gamma priors.
<em>arXiv:2306.02360</em>.</p>
<hr>
<p><em>For questions or feedback about this package, please visit the <a href="https://github.com/joonho112/DPprior" class="external-link">GitHub
repository</a>.</em></p>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by <a href="https://github.com/joonho112" class="external-link">JoonHo Lee</a>.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.2.0.</p>
</div>

    </footer>
</div>





  </body>
</html>
