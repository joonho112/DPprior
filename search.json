[{"path":"https://joonho112.github.io/DPprior/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2025 JoonHo Lee Permission hereby granted, free charge, person obtaining copy software associated documentation files (‚ÄúSoftware‚Äù), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED ‚Äú‚Äù, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/api-reference.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Complete API Reference with Examples","text":"vignette provides complete API reference DPprior package. exported functions documented full signatures, parameter descriptions, return values, usage examples. package functions organized six categories:","code":""},{"path":"https://joonho112.github.io/DPprior/articles/api-reference.html","id":"core-elicitation-functions","dir":"Articles","previous_headings":"","what":"1. Core Elicitation Functions","title":"Complete API Reference with Examples","text":"primary user-facing functions eliciting Gamma hyperpriors DP concentration parameter Œ±\\alpha.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/api-reference.html","id":"dpprior_fit","dir":"Articles","previous_headings":"1. Core Elicitation Functions","what":"1.1 DPprior_fit()","title":"Complete API Reference with Examples","text":"Unified Interface Prior Elicitation main entry point eliciting Gamma hyperprior. Automatically selects appropriate algorithm based input specification. Parameters: Returns: S3 object class DPprior_fit components: Examples:","code":"DPprior_fit(   J,                      # Sample size (required)   mu_K,                   # Target E[K_J] (required)   var_K = NULL,           # Target Var(K_J) (optional)   confidence = NULL,      # \"low\", \"medium\", \"high\" (optional)   method = \"A2-MN\",       # \"A1\", \"A2-MN\", \"A2-KL\"   check_diagnostics = FALSE,   warn_dominance = TRUE,   M = 80L,                # Quadrature nodes   verbose = FALSE ) # Basic usage with confidence level fit1 <- DPprior_fit(J = 50, mu_K = 5, confidence = \"medium\") #> Warning: HIGH DOMINANCE RISK: P(w1 > 0.5) = 49.7% exceeds 40%. #>   This may indicate unintended prior behavior (Lee, 2026). #>   Consider using DPprior_dual() for weight-constrained elicitation. #>   See ?DPprior_diagnostics for interpretation. print(fit1) #> DPprior Prior Elicitation Result #> =============================================  #>  #> Gamma Hyperprior: Œ± ~ Gamma(a = 1.4082, b = 1.0770) #>   E[Œ±] = 1.308, SD[Œ±] = 1.102 #>  #> Target (J = 50): #>   E[K_J]   = 5.00 #>   Var(K_J) = 10.00 #>   (from confidence = 'medium') #>  #> Achieved: #>   E[K_J] = 5.000000, Var(K_J) = 10.000000 #>   Residual = 3.94e-10 #>  #> Method: A2-MN (7 iterations) #>  #> Dominance Risk: HIGH ‚úò (P(w‚ÇÅ>0.5) = 50%)  # Direct variance specification fit2 <- DPprior_fit(J = 50, mu_K = 5, var_K = 10) #> Warning: HIGH DOMINANCE RISK: P(w1 > 0.5) = 49.7% exceeds 40%. #>   This may indicate unintended prior behavior (Lee, 2026). #>   Consider using DPprior_dual() for weight-constrained elicitation. #>   See ?DPprior_diagnostics for interpretation. cat(\"Gamma(\", round(fit2$a, 4), \", \", round(fit2$b, 4), \")\\n\", sep = \"\") #> Gamma(1.4082, 1.077)  # Using A1 closed-form (faster for large J) fit3 <- DPprior_fit(J = 200, mu_K = 15, var_K = 30, method = \"A1\")  # With diagnostics fit4 <- DPprior_fit(J = 50, mu_K = 5, var_K = 8, check_diagnostics = TRUE) #> Warning: HIGH DOMINANCE RISK: P(w1 > 0.5) = 48.1% exceeds 40%. #>   This may indicate unintended prior behavior (Lee, 2026). #>   Consider using DPprior_dual() for weight-constrained elicitation. #>   See ?DPprior_diagnostics for interpretation."},{"path":"https://joonho112.github.io/DPprior/articles/api-reference.html","id":"dpprior_dual","dir":"Articles","previous_headings":"1. Core Elicitation Functions","what":"1.2 DPprior_dual()","title":"Complete API Reference with Examples","text":"Dual-Anchor Elicitation Weight Control Extends moment-based elicitation incorporate constraints stick-breaking weight distribution, addressing ‚Äúunintended prior‚Äù problem identified Lee (2026, Section 4). Parameters: Returns: DPprior_fit object additional dual_anchor component containing: Examples:","code":"DPprior_dual(   fit_K,                  # K-only DPprior_fit object (required)   w1_target,              # Weight target specification (required)   lambda = 0.7,           # Trade-off parameter [0, 1]   loss_type = \"adaptive\", # \"absolute\", \"relative\", \"adaptive\"   method = \"L-BFGS-B\",    # Optimization method   max_iter = 100L,   tol = 1e-6,   M = 80L,   verbose = FALSE ) # Step 1: Fit K-only prior fit_K <- DPprior_fit(J = 50, mu_K = 5, var_K = 8) #> Warning: HIGH DOMINANCE RISK: P(w1 > 0.5) = 48.1% exceeds 40%. #>   This may indicate unintended prior behavior (Lee, 2026). #>   Consider using DPprior_dual() for weight-constrained elicitation. #>   See ?DPprior_diagnostics for interpretation. cat(\"K-only: P(w1 > 0.5) =\",      round(prob_w1_exceeds(0.5, fit_K$a, fit_K$b), 3), \"\\n\") #> K-only: P(w1 > 0.5) = 0.481  # Step 2: Apply weight constraint w1_target <- list(prob = list(threshold = 0.5, value = 0.30)) fit_dual <- DPprior_dual(fit_K, w1_target, lambda = 0.5) cat(\"Dual:   P(w1 > 0.5) =\",      round(prob_w1_exceeds(0.5, fit_dual$a, fit_dual$b), 3), \"\\n\") #> Dual:   P(w1 > 0.5) = 0.438  # Compare parameters cat(\"\\nParameter comparison:\\n\") #>  #> Parameter comparison: cat(\"  K-only: Gamma(\", round(fit_K$a, 3), \", \", round(fit_K$b, 3), \")\\n\", sep = \"\") #>   K-only: Gamma(2.036, 1.605) cat(\"  Dual:   Gamma(\", round(fit_dual$a, 3), \", \", round(fit_dual$b, 3), \")\\n\", sep = \"\") #>   Dual:   Gamma(2.575, 1.834)"},{"path":"https://joonho112.github.io/DPprior/articles/api-reference.html","id":"exact-computation-functions","dir":"Articles","previous_headings":"","what":"2. Exact Computation Functions","title":"Complete API Reference with Examples","text":"functions provide exact computation Stirling numbers, PMFs, moments using numerically stable log-space arithmetic.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/articles/api-reference.html","id":"compute_log_stirling","dir":"Articles","previous_headings":"2. Exact Computation Functions > 2.1 Stirling Number Functions","what":"compute_log_stirling()","title":"Complete API Reference with Examples","text":"Pre-compute Log Stirling Numbers Computes logarithm unsigned Stirling numbers first kind |s(J,k)||s(J,k)| JJ 0 J_max kk 0 JJ. Parameters: Returns: lower triangular matrix dimension (Jmax+1)√ó(Jmax+1)(J_{max}+1) \\times (J_{max}+1). Entry [J+1, k+1] contains log|s(J,k)|\\log|s(J,k)| (using R‚Äôs 1-based indexing). Examples:","code":"compute_log_stirling(J_max) # Pre-compute for J up to 100 logS <- compute_log_stirling(100)  # Access |s(10,3)| = 9450 s_10_3 <- exp(logS[11, 4]) cat(\"|s(10,3)| =\", round(s_10_3), \"\\n\") #> |s(10,3)| = 1172700  # Verify row sum identity: sum_k |s(J,k)| = J! J <- 6 row_sum <- sum(exp(logS[J+1, 2:(J+1)])) cat(\"sum |s(6,k)| =\", round(row_sum), \", 6! =\", factorial(6), \"\\n\") #> sum |s(6,k)| = 720 , 6! = 720"},{"path":"https://joonho112.github.io/DPprior/articles/api-reference.html","id":"get_log_stirling","dir":"Articles","previous_headings":"2. Exact Computation Functions > 2.1 Stirling Number Functions","what":"get_log_stirling()","title":"Complete API Reference with Examples","text":"Safe Accessor Bounds Checking Returns log|s(J,k)|\\log|s(J,k)| automatic bounds checking. Returns -Inf invalid indices (k>Jk > J k<1k < 1).","code":"get_log_stirling(J, k, logS)"},{"path":"https://joonho112.github.io/DPprior/articles/api-reference.html","id":"get_stirling_row","dir":"Articles","previous_headings":"2. Exact Computation Functions > 2.1 Stirling Number Functions","what":"get_stirling_row()","title":"Complete API Reference with Examples","text":"Extract Row Stirling Numbers Returns vector log|s(J,k)|\\log|s(J,k)| k=1,‚Ä¶,Jk = 1, \\ldots, J.","code":"get_stirling_row(J, logS)"},{"path":[]},{"path":"https://joonho112.github.io/DPprior/articles/api-reference.html","id":"pmf_k_given_alpha","dir":"Articles","previous_headings":"2. Exact Computation Functions > 2.2 Conditional PMF Functions","what":"pmf_K_given_alpha()","title":"Complete API Reference with Examples","text":"Antoniak Distribution PMF Computes exact conditional PMF P(KJ=k|Œ±)P(K_J = k | \\alpha) using Antoniak distribution formula: P(KJ=k|Œ±)=|s(J,k)|‚ãÖŒ±k(Œ±)J P(K_J = k | \\alpha) = \\frac{|s(J,k)| \\cdot \\alpha^k}{(\\alpha)_J} Parameters: Returns: Numeric vector length J+1J+1 containing P(KJ=k|Œ±)P(K_J = k | \\alpha) k=0,1,‚Ä¶,Jk = 0, 1, \\ldots, J. Note: P(KJ=0|Œ±)=0P(K_J = 0 | \\alpha) = 0 always. Examples:","code":"pmf_K_given_alpha(J, alpha, logS, normalize = TRUE) J <- 50 alpha <- 2.0 logS <- compute_log_stirling(J)  # Compute conditional PMF pmf <- pmf_K_given_alpha(J, alpha, logS)  # Find mode mode_k <- which.max(pmf) - 1 cat(\"Mode of K|Œ±=2:\", mode_k, \"\\n\") #> Mode of K|Œ±=2: 7  # Verify normalization cat(\"PMF sum:\", sum(pmf), \"\\n\") #> PMF sum: 1"},{"path":"https://joonho112.github.io/DPprior/articles/api-reference.html","id":"cdf_k_given_alpha","dir":"Articles","previous_headings":"2. Exact Computation Functions > 2.2 Conditional PMF Functions","what":"cdf_K_given_alpha()","title":"Complete API Reference with Examples","text":"Conditional CDF Returns cumulative distribution function F(k)=P(KJ‚â§k|Œ±)F(k) = P(K_J \\leq k | \\alpha).","code":"cdf_K_given_alpha(J, alpha, logS)"},{"path":"https://joonho112.github.io/DPprior/articles/api-reference.html","id":"quantile_k_given_alpha","dir":"Articles","previous_headings":"2. Exact Computation Functions > 2.2 Conditional PMF Functions","what":"quantile_K_given_alpha()","title":"Complete API Reference with Examples","text":"Conditional Quantile Function Returns smallest kk P(KJ‚â§k|Œ±)‚â•pP(K_J \\leq k | \\alpha) \\geq p.","code":"quantile_K_given_alpha(p, J, alpha, logS)"},{"path":[]},{"path":"https://joonho112.github.io/DPprior/articles/api-reference.html","id":"mean_k_given_alpha","dir":"Articles","previous_headings":"2. Exact Computation Functions > 2.3 Conditional Moment Functions","what":"mean_K_given_alpha()","title":"Complete API Reference with Examples","text":"Conditional Mean via Digamma Computes ùîº[KJ|Œ±]=Œ±{œà(Œ±+J)‚àíœà(Œ±)}\\mathbb{E}[K_J | \\alpha] = \\alpha \\{\\psi(\\alpha + J) - \\psi(\\alpha)\\} using digamma function. Parameters: Returns: Numeric vector conditional means. Examples:","code":"mean_K_given_alpha(J, alpha) J <- 50  # Single alpha mean_K_given_alpha(J, 2.0) #> [1] 7.037626  # Vectorized alpha_seq <- c(0.5, 1, 2, 5, 10) means <- mean_K_given_alpha(J, alpha_seq) data.frame(alpha = alpha_seq, E_K = round(means, 2)) #>   alpha   E_K #> 1   0.5  2.94 #> 2   1.0  4.50 #> 3   2.0  7.04 #> 4   5.0 12.46 #> 5  10.0 18.34"},{"path":"https://joonho112.github.io/DPprior/articles/api-reference.html","id":"var_k_given_alpha","dir":"Articles","previous_headings":"2. Exact Computation Functions > 2.3 Conditional Moment Functions","what":"var_K_given_alpha()","title":"Complete API Reference with Examples","text":"Conditional Variance via Trigamma Computes Var(KJ|Œ±)=ŒºJ(Œ±)‚àíŒ±2{œà1(Œ±)‚àíœà1(Œ±+J)}\\text{Var}(K_J | \\alpha) = \\mu_J(\\alpha) - \\alpha^2 \\{\\psi_1(\\alpha) - \\psi_1(\\alpha + J)\\}. Key Property: Conditional underdispersion always holds: 0<Var(KJ|Œ±)<ùîº[KJ|Œ±] 0 < \\text{Var}(K_J | \\alpha) < \\mathbb{E}[K_J | \\alpha] Examples:","code":"var_K_given_alpha(J, alpha) J <- 50 alpha <- 2.0  mu <- mean_K_given_alpha(J, alpha) sigma2 <- var_K_given_alpha(J, alpha)  cat(\"E[K|Œ±=2] =\", round(mu, 4), \"\\n\") #> E[K|Œ±=2] = 7.0376 cat(\"Var(K|Œ±=2) =\", round(sigma2, 4), \"\\n\") #> Var(K|Œ±=2) = 4.5356 cat(\"Underdispersion ratio:\", round(sigma2/mu, 4), \"< 1 ‚úì\\n\") #> Underdispersion ratio: 0.6445 < 1 ‚úì"},{"path":"https://joonho112.github.io/DPprior/articles/api-reference.html","id":"moments_k_given_alpha","dir":"Articles","previous_headings":"2. Exact Computation Functions > 2.3 Conditional Moment Functions","what":"moments_K_given_alpha()","title":"Complete API Reference with Examples","text":"Moments One Call Returns list mean var.","code":"moments_K_given_alpha(J, alpha)"},{"path":[]},{"path":"https://joonho112.github.io/DPprior/articles/api-reference.html","id":"exact_k_moments","dir":"Articles","previous_headings":"2. Exact Computation Functions > 2.4 Marginal Distribution Functions","what":"exact_K_moments()","title":"Complete API Reference with Examples","text":"Marginal Moments Gamma Hyperprior Computes ùîº[KJ|,b]\\mathbb{E}[K_J | , b] Var(KJ|,b)\\text{Var}(K_J | , b) Œ±‚àºGamma(,b)\\alpha \\sim \\text{Gamma}(, b) using Gauss-Laguerre quadrature. Parameters: Returns: list components: Examples:","code":"exact_K_moments(J, a, b, M = 80L) # Compute marginal moments result <- exact_K_moments(J = 50, a = 1.6, b = 1.22) cat(\"E[K_50] =\", round(result$mean, 4), \"\\n\") #> E[K_50] = 5.0454 cat(\"Var(K_50) =\", round(result$var, 4), \"\\n\") #> Var(K_50) = 9.3797 cat(\"CV(K_50) =\", round(result$cv, 4), \"\\n\") #> CV(K_50) = 0.607"},{"path":"https://joonho112.github.io/DPprior/articles/api-reference.html","id":"pmf_k_marginal","dir":"Articles","previous_headings":"2. Exact Computation Functions > 2.4 Marginal Distribution Functions","what":"pmf_K_marginal()","title":"Complete API Reference with Examples","text":"Marginal PMF via Quadrature Mixture Computes marginal PMF mixing conditional PMFs Œ±‚àºGamma(,b)\\alpha \\sim \\text{Gamma}(,b): P(KJ=k|,b)=‚à´0‚àûP(KJ=k|Œ±)‚ãÖga,b(Œ±)dŒ± P(K_J = k | , b) = \\int_0^\\infty P(K_J = k | \\alpha) \\cdot g_{,b}(\\alpha) \\, d\\alpha Examples:","code":"pmf_K_marginal(J, a, b, logS, M = 80L) J <- 50 logS <- compute_log_stirling(J)  pmf_marginal <- pmf_K_marginal(J, a = 1.6, b = 1.22, logS)  # Find mode mode_k <- which.max(pmf_marginal) - 1 cat(\"Mode of marginal K:\", mode_k, \"\\n\") #> Mode of marginal K: 3"},{"path":"https://joonho112.github.io/DPprior/articles/api-reference.html","id":"summary_k_marginal","dir":"Articles","previous_headings":"2. Exact Computation Functions > 2.4 Marginal Distribution Functions","what":"summary_K_marginal()","title":"Complete API Reference with Examples","text":"Complete Marginal Distribution Summary Returns mean, variance, mode, median, quantiles, PMF, CDF.","code":"summary_K_marginal(J, a, b, logS, M = 80L, probs = c(0.05, 0.25, 0.5, 0.75, 0.95))"},{"path":[]},{"path":"https://joonho112.github.io/DPprior/articles/api-reference.html","id":"dpprior_a1","dir":"Articles","previous_headings":"3. Approximation Functions","what":"3.1 DPprior_a1()","title":"Complete API Reference with Examples","text":"A1 Closed-Form Approximation Fast closed-form solution using negative binomial approximation marginal distribution KJK_J. Key Formulas: =(ŒºK‚àí1)2œÉK2‚àí(ŒºK‚àí1),b=(ŒºK‚àí1)‚ãÖcJœÉK2‚àí(ŒºK‚àí1) = \\frac{(\\mu_K - 1)^2}{\\sigma^2_K - (\\mu_K - 1)}, \\quad b = \\frac{(\\mu_K - 1) \\cdot c_J}{\\sigma^2_K - (\\mu_K - 1)} cJc_J scaling constant (default: logJ\\log J). Feasibility Constraint: Requires œÉK2>ŒºK‚àí1\\sigma^2_K > \\mu_K - 1. Examples:","code":"DPprior_a1(   J,                      # Sample size   mu_K,                   # Target mean   var_K = NULL,           # Target variance   confidence = NULL,      # \"low\", \"medium\", \"high\"   scaling = \"log\",        # \"log\", \"harmonic\", \"digamma\"   project_to_feasible = TRUE ) # Basic A1 fit fit_a1 <- DPprior_a1(J = 50, mu_K = 5, var_K = 8) cat(\"A1 solution: Gamma(\", round(fit_a1$a, 4), \", \",      round(fit_a1$b, 4), \")\\n\", sep = \"\") #> A1 solution: Gamma(4, 3.912)  # Compare scaling methods for (s in c(\"log\", \"harmonic\", \"digamma\")) {   fit <- DPprior_a1(50, 5, 8, scaling = s)   cat(sprintf(\"  %s: cJ = %.4f\\n\", s, fit$cJ)) } #>   log: cJ = 3.9120 #>   harmonic: cJ = 4.4792 #>   digamma: cJ = 4.4633"},{"path":"https://joonho112.github.io/DPprior/articles/api-reference.html","id":"dpprior_a2_newton","dir":"Articles","previous_headings":"3. Approximation Functions","what":"3.2 DPprior_a2_newton()","title":"Complete API Reference with Examples","text":"A2-MN Newton Solver Exact Moment Matching Finds (*,b*)(^*, b^*) induced marginal moments exactly match targets. Algorithm: Initialize A1 closed-form Log-parameterize: Œ∑=(loga,logb)\\eta = (\\log , \\log b) Newton iteration score-based Jacobian Backtracking line search global convergence Convergence: Typically achieves machine-precision accuracy 3-8 iterations. Examples:","code":"DPprior_a2_newton(   J,                      # Sample size   mu_K,                   # Target mean   var_K,                  # Target variance   a0 = NULL,              # Initial shape (from A1 if NULL)   b0 = NULL,              # Initial rate (from A1 if NULL)   tol_F = 1e-8,           # Residual tolerance   tol_step = 1e-10,       # Step size tolerance   max_iter = 20L,   damping = TRUE,         # Backtracking line search   use_fallback = TRUE,    # Nelder-Mead fallback   M = 80L,   verbose = FALSE ) # Exact moment matching fit <- DPprior_a2_newton(J = 50, mu_K = 5, var_K = 8, verbose = TRUE) #> A2-MN Newton Solver #> Target: E[K]=5.0000, Var(K)=8.0000 #> A1 initialization: a0=4.000000, b0=3.912023 #> --------------------------------------------------------------------------------  #> Iter |          a |          b |       E[K] |     Var(K) |      ||F|| |     step |     det(J) #> --------------------------------------------------------------------------------  #>    1 |   4.000000 |   3.912023 |   4.461351 |   4.783136 |   3.26e+00 |   1.0000 |  -5.30e+00 #>    2 |   1.178650 |   0.911969 |   4.909046 |  10.854537 |   2.86e+00 |   1.0000 |  -2.16e+01 #>    3 |   1.844384 |   1.455254 |   4.974913 |   8.399473 |   4.00e-01 |   1.0000 |  -1.53e+01 #>    4 |   2.029223 |   1.599680 |   4.999187 |   8.013243 |   1.33e-02 |   1.0000 |  -1.43e+01 #>    5 |   2.036082 |   1.605046 |   4.999999 |   8.000021 |   2.08e-05 |   1.0000 |  -1.43e+01 #>    6 |   2.036093 |   1.605054 |   5.000000 |   8.000000 |   7.60e-09 |      --- |  -1.43e+01 #>  #> Converged: ||F|| = 7.60e-09 < 1.00e-08  # Verify exact matching achieved <- exact_K_moments(50, fit$a, fit$b) cat(\"\\nTarget vs Achieved:\\n\") #>  #> Target vs Achieved: cat(\"  E[K]:   5.000000 vs\", sprintf(\"%.10f\", achieved$mean), \"\\n\") #>   E[K]:   5.000000 vs 4.9999999992 cat(\"  Var(K): 8.000000 vs\", sprintf(\"%.10f\", achieved$var), \"\\n\") #>   Var(K): 8.000000 vs 8.0000000076"},{"path":"https://joonho112.github.io/DPprior/articles/api-reference.html","id":"dpprior_a2_kl","dir":"Articles","previous_headings":"3. Approximation Functions","what":"3.3 DPprior_a2_kl()","title":"Complete API Reference with Examples","text":"A2-KL Distribution Matching via KL Divergence Minimizes Kullback-Leibler divergence target PMF induced marginal PMF KJK_J. Target Specification: Examples:","code":"DPprior_a2_kl(   J,                      # Sample size   target,                 # Target PMF or list(mu_K, var_K)   method = c(\"pmf\", \"chisq\"),  # Target type   max_iter = 100L,   tol = 1e-6,   M = 80L,   verbose = FALSE ) # Method 1: Moment-based target using chi-square discretization fit_kl <- DPprior_a2_kl(J = 50, target = list(mu_K = 5, var_K = 8),                           method = \"chisq\") cat(\"A2-KL solution: Gamma(\", round(fit_kl$a, 4), \", \",      round(fit_kl$b, 4), \")\\n\", sep = \"\") #> A2-KL solution: Gamma(2.2363, 1.7627) cat(\"Final KL divergence:\", format(fit_kl$fit$kl, scientific = TRUE), \"\\n\") #> Final KL divergence: 5.029612e-03  # Method 2: Direct PMF target target_pmf <- discretize_chisq(J = 50, df = 6.25, scale = 0.8) fit_kl2 <- DPprior_a2_kl(J = 50, target = target_pmf, method = \"pmf\")"},{"path":"https://joonho112.github.io/DPprior/articles/api-reference.html","id":"weight-distribution-functions","dir":"Articles","previous_headings":"","what":"4. Weight Distribution Functions","title":"Complete API Reference with Examples","text":"Functions computing properties first stick-breaking weight w1w_1 co-clustering probability œÅ=‚àëhwh2\\rho = \\sum_h w_h^2.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/api-reference.html","id":"first-weight-w_1-functions","dir":"Articles","previous_headings":"4. Weight Distribution Functions","what":"4.1 First Weight w1w_1 Functions","title":"Complete API Reference with Examples","text":"size-biased first weight w1w_1 follows compound distribution: w1|Œ±‚àºBeta(1,Œ±),Œ±‚àºGamma(,b) w_1 | \\alpha \\sim \\text{Beta}(1, \\alpha), \\quad \\alpha \\sim \\text{Gamma}(, b)","code":""},{"path":"https://joonho112.github.io/DPprior/articles/api-reference.html","id":"mean_w1","dir":"Articles","previous_headings":"4. Weight Distribution Functions > 4.1 First Weight w1w_1 Functions","what":"mean_w1()","title":"Complete API Reference with Examples","text":"Marginal Mean w1w_1 Computes ùîº[w1|,b]=ùîº[1/(1+Œ±)]\\mathbb{E}[w_1 | , b] = \\mathbb{E}[1/(1+\\alpha)] via quadrature. Examples:","code":"mean_w1(a, b, M = 80L) mean_w1(a = 1.6, b = 1.22) #> [1] 0.508368"},{"path":"https://joonho112.github.io/DPprior/articles/api-reference.html","id":"var_w1","dir":"Articles","previous_headings":"4. Weight Distribution Functions > 4.1 First Weight w1w_1 Functions","what":"var_w1()","title":"Complete API Reference with Examples","text":"Marginal Variance w1w_1","code":"var_w1(a, b, M = 80L)"},{"path":"https://joonho112.github.io/DPprior/articles/api-reference.html","id":"quantile_w1","dir":"Articles","previous_headings":"4. Weight Distribution Functions > 4.1 First Weight w1w_1 Functions","what":"quantile_w1()","title":"Complete API Reference with Examples","text":"Marginal Quantiles w1w_1 Computes quantiles via numerical inversion CDF. Examples:","code":"quantile_w1(p, a, b, n_grid = 1000, M = 80L) # Median of w1 median_w1 <- quantile_w1(0.5, a = 1.6, b = 1.22) cat(\"Median(w1) =\", round(median_w1, 4), \"\\n\") #> Median(w1) = 0.4839"},{"path":"https://joonho112.github.io/DPprior/articles/api-reference.html","id":"prob_w1_exceeds","dir":"Articles","previous_headings":"4. Weight Distribution Functions > 4.1 First Weight w1w_1 Functions","what":"prob_w1_exceeds()","title":"Complete API Reference with Examples","text":"Tail Probability P(w1>x)P(w_1 > x) Critical Dominance Assessment: P(w1>0.5)P(w_1 > 0.5) indicates probability single cluster dominates. Examples:","code":"prob_w1_exceeds(x, a, b, M = 80L) # Dominance probabilities a <- 1.6; b <- 1.22 cat(\"P(w1 > 0.5) =\", round(prob_w1_exceeds(0.5, a, b), 4), \"\\n\") #> P(w1 > 0.5) = 0.4868 cat(\"P(w1 > 0.7) =\", round(prob_w1_exceeds(0.7, a, b), 4), \"\\n\") #> P(w1 > 0.7) = 0.3334 cat(\"P(w1 > 0.9) =\", round(prob_w1_exceeds(0.9, a, b), 4), \"\\n\") #> P(w1 > 0.9) = 0.1833"},{"path":"https://joonho112.github.io/DPprior/articles/api-reference.html","id":"cdf_w1-and-pdf_w1","dir":"Articles","previous_headings":"4. Weight Distribution Functions > 4.1 First Weight w1w_1 Functions","what":"cdf_w1() and pdf_w1()","title":"Complete API Reference with Examples","text":"CDF PDF w1w_1","code":"cdf_w1(x, a, b, M = 80L) pdf_w1(x, a, b, M = 80L)"},{"path":"https://joonho112.github.io/DPprior/articles/api-reference.html","id":"co-clustering-probability-rho-functions","dir":"Articles","previous_headings":"4. Weight Distribution Functions","what":"4.2 Co-Clustering Probability œÅ\\rho Functions","title":"Complete API Reference with Examples","text":"co-clustering probability œÅ=‚àëh=1‚àûwh2\\rho = \\sum_{h=1}^\\infty w_h^2 represents probability two randomly chosen observations belong cluster.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/api-reference.html","id":"mean_rho-and-var_rho","dir":"Articles","previous_headings":"4. Weight Distribution Functions > 4.2 Co-Clustering Probability œÅ\\rho Functions","what":"mean_rho() and var_rho()","title":"Complete API Reference with Examples","text":"Marginal Moments œÅ\\rho Key Identity: ùîº[œÅ|Œ±]=ùîº[w1|Œ±]=1/(1+Œ±)\\mathbb{E}[\\rho | \\alpha] = \\mathbb{E}[w_1 | \\alpha] = 1/(1+\\alpha), ùîº[œÅ|,b]=ùîº[w1|,b]\\mathbb{E}[\\rho | , b] = \\mathbb{E}[w_1 | , b]. Examples:","code":"mean_rho(a, b, M = 80L) var_rho(a, b, M = 80L) a <- 1.6; b <- 1.22 cat(\"E[rho] =\", round(mean_rho(a, b), 4), \"\\n\") #> E[rho] = 0.5084 cat(\"E[w1]  =\", round(mean_w1(a, b), 4), \"(same as E[rho])\\n\") #> E[w1]  = 0.5084 (same as E[rho]) cat(\"Var(rho) =\", round(var_rho(a, b), 4), \"\\n\") #> Var(rho) = 0.071 cat(\"Var(w1)  =\", round(var_w1(a, b), 4), \"(different!)\\n\") #> Var(w1)  = 0.1052 (different!)"},{"path":"https://joonho112.github.io/DPprior/articles/api-reference.html","id":"cv_rho","dir":"Articles","previous_headings":"4. Weight Distribution Functions > 4.2 Co-Clustering Probability œÅ\\rho Functions","what":"cv_rho()","title":"Complete API Reference with Examples","text":"Coefficient Variation œÅ\\rho","code":"cv_rho(a, b, M = 80L)"},{"path":[]},{"path":"https://joonho112.github.io/DPprior/articles/api-reference.html","id":"mean_rho_given_alpha-and-var_rho_given_alpha","dir":"Articles","previous_headings":"4. Weight Distribution Functions > 4.3 Conditional Weight Functions","what":"mean_rho_given_alpha() and var_rho_given_alpha()","title":"Complete API Reference with Examples","text":"","code":"mean_rho_given_alpha(alpha)   # Returns 1/(1 + alpha) var_rho_given_alpha(alpha)    # Returns 2*alpha / ((1+alpha)^2 * (2+alpha) * (3+alpha))"},{"path":[]},{"path":"https://joonho112.github.io/DPprior/articles/api-reference.html","id":"dpprior_diagnostics","dir":"Articles","previous_headings":"5. Diagnostic Functions","what":"5.1 DPprior_diagnostics()","title":"Complete API Reference with Examples","text":"Comprehensive Prior Diagnostics Computes full diagnostic report implementing ‚Äúunintended prior‚Äù checks Lee (2026, Section 4). Parameters: Returns: S3 object class DPprior_diagnostics : Warning Thresholds: HIGH DOMINANCE RISK: P(w1>0.5)>40%P(w_1 > 0.5) > 40\\% NEAR-DEGENERATE RISK: P(w1>0.9)>15%P(w_1 > 0.9) > 15\\% Examples:","code":"DPprior_diagnostics(fit, thresholds = c(0.5, 0.9)) fit <- DPprior_fit(J = 50, mu_K = 5, var_K = 8) #> Warning: HIGH DOMINANCE RISK: P(w1 > 0.5) = 48.1% exceeds 40%. #>   This may indicate unintended prior behavior (Lee, 2026). #>   Consider using DPprior_dual() for weight-constrained elicitation. #>   See ?DPprior_diagnostics for interpretation. diag <- DPprior_diagnostics(fit) print(diag) #> DPprior Comprehensive Diagnostics #> ============================================================  #>  #> Prior: alpha ~ Gamma(2.0361, 1.6051) for J = 50 #>  #> alpha Distribution: #> ----------------------------------------  #>   E[alpha] = 1.269, CV(alpha) = 0.701, Median = 1.068 #>   90% CI: [0.230, 2.992] #>  #> K_J Distribution: #> ----------------------------------------  #>   E[K] = 5.00, SD(K) = 2.83, Mode = 3 #>   Median = 5, IQR = [3, 7] #>  #> w1 Distribution (Size-Biased First Weight): #> ----------------------------------------  #>   E[w1] = 0.501, Median = 0.478 #>   P(w1 > 0.5) = 48.1% (dominance risk: HIGH) #>   P(w1 > 0.9) = 16.3% #>  #> Co-Clustering (rho = sum w_h^2): #> ----------------------------------------  #>   E[rho] = 0.501 (High prior co-clustering: most unit pairs expected in same cluster) #>  #> WARNINGS: #> ----------------------------------------  #>   * HIGH DOMINANCE RISK: P(w1 > 0.5) = 48.1% exceeds 40% #>   * NEAR-DEGENERATE RISK: P(w1 > 0.9) = 16.3% exceeds 15% #>  #>   Consider using DPprior_dual() for weight-constrained elicitation."},{"path":[]},{"path":"https://joonho112.github.io/DPprior/articles/api-reference.html","id":"print-dpprior_fit","dir":"Articles","previous_headings":"5. Diagnostic Functions > 5.2 S3 Methods for DPprior_fit","what":"print.DPprior_fit()","title":"Complete API Reference with Examples","text":"Displays concise summary elicitation result.","code":"print(fit)"},{"path":"https://joonho112.github.io/DPprior/articles/api-reference.html","id":"summary-dpprior_fit","dir":"Articles","previous_headings":"5. Diagnostic Functions > 5.2 S3 Methods for DPprior_fit","what":"summary.DPprior_fit()","title":"Complete API Reference with Examples","text":"Returns: object class summary.DPprior_fit detailed statistics.","code":"summary(fit, print_output = TRUE)"},{"path":"https://joonho112.github.io/DPprior/articles/api-reference.html","id":"plot-dpprior_fit","dir":"Articles","previous_headings":"5. Diagnostic Functions > 5.2 S3 Methods for DPprior_fit","what":"plot.DPprior_fit()","title":"Complete API Reference with Examples","text":"Creates four-panel visualization dashboard: Panel : Gamma prior density Œ±\\alpha Panel B: Marginal PMF KJK_J Panel C: PDF w1w_1 dominance risk Panel D: Summary statistics table","code":"plot(fit, which = c(\"alpha\", \"K\", \"w1\", \"table\"))"},{"path":"https://joonho112.github.io/DPprior/articles/api-reference.html","id":"individual-plot-functions","dir":"Articles","previous_headings":"5. Diagnostic Functions","what":"5.3 Individual Plot Functions","title":"Complete API Reference with Examples","text":"","code":"plot_alpha_prior(fit)   # Alpha distribution only plot_K_prior(fit)       # K distribution only plot_w1_prior(fit)      # w1 distribution with dominance"},{"path":[]},{"path":"https://joonho112.github.io/DPprior/articles/api-reference.html","id":"check_dominance_risk","dir":"Articles","previous_headings":"5. Diagnostic Functions > 5.4 Dominance Risk Functions","what":"check_dominance_risk()","title":"Complete API Reference with Examples","text":"Returns TRUE P(w1>threshold)>risk_levelP(w_1 > \\text{threshold}) > \\text{risk\\_level}.","code":"check_dominance_risk(a, b, threshold = 0.5, risk_level = 0.3)"},{"path":"https://joonho112.github.io/DPprior/articles/api-reference.html","id":"compute_alpha_diagnostics","dir":"Articles","previous_headings":"5. Diagnostic Functions > 5.4 Dominance Risk Functions","what":"compute_alpha_diagnostics()","title":"Complete API Reference with Examples","text":"Returns mean, SD, CV, quantiles Œ±‚àºGamma(,b)\\alpha \\sim \\text{Gamma}(, b).","code":"compute_alpha_diagnostics(a, b)"},{"path":"https://joonho112.github.io/DPprior/articles/api-reference.html","id":"compute_k_diagnostics","dir":"Articles","previous_headings":"5. Diagnostic Functions > 5.4 Dominance Risk Functions","what":"compute_K_diagnostics()","title":"Complete API Reference with Examples","text":"Returns mean, SD, mode, median, quantiles KJK_J.","code":"compute_K_diagnostics(J, a, b, M = 80L)"},{"path":"https://joonho112.github.io/DPprior/articles/api-reference.html","id":"compute_weight_diagnostics","dir":"Articles","previous_headings":"5. Diagnostic Functions > 5.4 Dominance Risk Functions","what":"compute_weight_diagnostics()","title":"Complete API Reference with Examples","text":"Returns w1w_1 summary dominance risk classification.","code":"compute_weight_diagnostics(a, b, thresholds = c(0.5, 0.9), M = 80L)"},{"path":[]},{"path":[]},{"path":"https://joonho112.github.io/DPprior/articles/api-reference.html","id":"vif_to_variance","dir":"Articles","previous_headings":"6. Utility Functions > 6.1 Variance Conversion Functions","what":"vif_to_variance()","title":"Complete API Reference with Examples","text":"Convert Variance Inflation Factor Variance Computes œÉK2=VIF√ó(ŒºK‚àí1)\\sigma^2_K = \\text{VIF} \\times (\\mu_K - 1), based marginal overdispersion relationship. Examples:","code":"vif_to_variance(mu_K, vif) # VIF = 2 means variance is twice the Poisson-like baseline var_K <- vif_to_variance(mu_K = 5, vif = 2) cat(\"var_K =\", var_K, \"\\n\") #> var_K = 8"},{"path":"https://joonho112.github.io/DPprior/articles/api-reference.html","id":"confidence_to_vif","dir":"Articles","previous_headings":"6. Utility Functions > 6.1 Variance Conversion Functions","what":"confidence_to_vif()","title":"Complete API Reference with Examples","text":"Map Confidence Level VIF","code":"confidence_to_vif(confidence)"},{"path":"https://joonho112.github.io/DPprior/articles/api-reference.html","id":"cv_alpha_to_variance","dir":"Articles","previous_headings":"6. Utility Functions > 6.1 Variance Conversion Functions","what":"cv_alpha_to_variance()","title":"Complete API Reference with Examples","text":"Convert CV Œ±\\alpha Variance KK","code":"cv_alpha_to_variance(mu_K, cv_alpha)"},{"path":[]},{"path":"https://joonho112.github.io/DPprior/articles/api-reference.html","id":"compute_scaling_constant","dir":"Articles","previous_headings":"6. Utility Functions > 6.2 Scaling Functions","what":"compute_scaling_constant()","title":"Complete API Reference with Examples","text":"Computes scaling constant cJc_J used A1 approximation:","code":"compute_scaling_constant(J, scaling = \"log\", mu_K = NULL)"},{"path":[]},{"path":"https://joonho112.github.io/DPprior/articles/api-reference.html","id":"gauss_laguerre_nodes","dir":"Articles","previous_headings":"6. Utility Functions > 6.3 Quadrature Functions","what":"gauss_laguerre_nodes()","title":"Complete API Reference with Examples","text":"Compute Gauss-Laguerre Quadrature Nodes Weights Parameters: Returns: List nodes, weights, weights_log.","code":"gauss_laguerre_nodes(M, alpha_param = 0)"},{"path":"https://joonho112.github.io/DPprior/articles/api-reference.html","id":"build_gamma_quadrature","dir":"Articles","previous_headings":"6. Utility Functions > 6.3 Quadrature Functions","what":"build_gamma_quadrature()","title":"Complete API Reference with Examples","text":"Build Quadrature Gamma Distribution Transforms standard Laguerre quadrature integrate Gamma(,b). Returns: List alpha_nodes weights_normalized.","code":"build_gamma_quadrature(a, b, M = 80L)"},{"path":"https://joonho112.github.io/DPprior/articles/api-reference.html","id":"integrate_gamma","dir":"Articles","previous_headings":"6. Utility Functions > 6.3 Quadrature Functions","what":"integrate_gamma()","title":"Complete API Reference with Examples","text":"Compute Expectation Gamma Distribution Computes ùîºŒ±‚àºGamma(,b)[f(Œ±)]\\mathbb{E}_{\\alpha \\sim \\text{Gamma}(,b)}[f(\\alpha)] using Gauss-Laguerre quadrature. Examples:","code":"integrate_gamma(f, a, b, M = 80L) # E[alpha] = a/b a <- 2; b <- 0.5 E_alpha <- integrate_gamma(identity, a, b) cat(\"E[alpha] via quadrature:\", round(E_alpha, 6), \"\\n\") #> E[alpha] via quadrature: 4 cat(\"E[alpha] exact (a/b):\", a/b, \"\\n\") #> E[alpha] exact (a/b): 4"},{"path":[]},{"path":"https://joonho112.github.io/DPprior/articles/api-reference.html","id":"logsumexp","dir":"Articles","previous_headings":"6. Utility Functions > 6.4 Log-Space Numerical Functions","what":"logsumexp()","title":"Complete API Reference with Examples","text":"Binary Log-Sum-Exp Computes log(exp()+exp(b))\\log(\\exp() + \\exp(b)) stably.","code":"logsumexp(a, b)"},{"path":"https://joonho112.github.io/DPprior/articles/api-reference.html","id":"logsumexp_vec","dir":"Articles","previous_headings":"6. Utility Functions > 6.4 Log-Space Numerical Functions","what":"logsumexp_vec()","title":"Complete API Reference with Examples","text":"Vectorized Log-Sum-Exp Computes log(‚àëiexp(xi))\\log(\\sum_i \\exp(x_i)) vector.","code":"logsumexp_vec(x)"},{"path":"https://joonho112.github.io/DPprior/articles/api-reference.html","id":"softmax","dir":"Articles","previous_headings":"6. Utility Functions > 6.4 Log-Space Numerical Functions","what":"softmax()","title":"Complete API Reference with Examples","text":"Numerically Stable Softmax Returns probability vector log-odds.","code":"softmax(x)"},{"path":[]},{"path":"https://joonho112.github.io/DPprior/articles/api-reference.html","id":"log_rising_factorial","dir":"Articles","previous_headings":"6. Utility Functions > 6.5 Rising Factorial","what":"log_rising_factorial()","title":"Complete API Reference with Examples","text":"Computes log(Œ±)J=logŒì(Œ±+J)‚àílogŒì(Œ±)\\log(\\alpha)_J = \\log\\Gamma(\\alpha + J) - \\log\\Gamma(\\alpha).","code":"log_rising_factorial(alpha, J)"},{"path":[]},{"path":"https://joonho112.github.io/DPprior/articles/api-reference.html","id":"kl_divergence_pmf","dir":"Articles","previous_headings":"6. Utility Functions > 6.6 KL Divergence Functions","what":"kl_divergence_pmf()","title":"Complete API Reference with Examples","text":"KL Divergence PMFs","code":"kl_divergence_pmf(p, q, eps = 1e-15)"},{"path":"https://joonho112.github.io/DPprior/articles/api-reference.html","id":"kl_divergence_k","dir":"Articles","previous_headings":"6. Utility Functions > 6.6 KL Divergence Functions","what":"kl_divergence_K()","title":"Complete API Reference with Examples","text":"KL Divergence KJK_J Distributions","code":"kl_divergence_K(target_pmf, a, b, J, M = 80L)"},{"path":"https://joonho112.github.io/DPprior/articles/api-reference.html","id":"discretize_chisq","dir":"Articles","previous_headings":"6. Utility Functions > 6.6 KL Divergence Functions","what":"discretize_chisq()","title":"Complete API Reference with Examples","text":"Create Target PMF Chi-Square Discretizes (scaled) chi-square distribution onto {1,‚Ä¶,J}\\{1, \\ldots, J\\}.","code":"discretize_chisq(J, df, scale = 1)"},{"path":"https://joonho112.github.io/DPprior/articles/api-reference.html","id":"verification-functions","dir":"Articles","previous_headings":"","what":"7. Verification Functions","title":"Complete API Reference with Examples","text":"package includes extensive verification functions development testing. typically needed end users available wish validate computations.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/api-reference.html","id":"module-verification-functions","dir":"Articles","previous_headings":"7. Verification Functions","what":"7.1 Module Verification Functions","title":"Complete API Reference with Examples","text":"Examples:","code":"# Verify Stirling numbers logS <- compute_log_stirling(20) validate_stirling(logS, verbose = TRUE) #> PASS: |s(4,2)| = 11 (expected 11) #> PASS: |s(5,3)| = 35 (expected 35) #> PASS: |s(6,3)| = 225 (expected 225) #> PASS: |s(10,5)| = 269325 (expected 269325) #> [1] TRUE  # Verify underdispersion verify_underdispersion(50, alpha_values = c(0.5, 1, 2, 5)) #> Underdispersion verification (J=50): #>   alpha= 0.50: E[K]=  2.9378, Var(K)=  1.7091, D=0.5818 [PASS] #>   alpha= 1.00: E[K]=  4.4992, Var(K)=  2.8741, D=0.6388 [PASS] #>   alpha= 2.00: E[K]=  7.0376, Var(K)=  4.5356, D=0.6445 [PASS] #>   alpha= 5.00: E[K]= 12.4605, Var(K)=  7.3861, D=0.5928 [PASS]"},{"path":[]},{"path":"https://joonho112.github.io/DPprior/articles/api-reference.html","id":"by-task","dir":"Articles","previous_headings":"8. Function Quick Reference","what":"By Task","title":"Complete API Reference with Examples","text":"‚Äúwant elicit prior based expected clusters‚Äù ‚Äúwant control clusters weight concentration‚Äù ‚Äúwant check dominance risk‚Äù ‚Äúwant compute exact PMF K‚Äù ‚Äúwant visualize prior‚Äù","code":"fit <- DPprior_fit(J = 50, mu_K = 5, confidence = \"medium\") fit_K <- DPprior_fit(J = 50, mu_K = 5, var_K = 8) fit <- DPprior_dual(fit_K, list(prob = list(threshold = 0.5, value = 0.3))) prob_w1_exceeds(0.5, fit$a, fit$b) DPprior_diagnostics(fit) logS <- compute_log_stirling(J) pmf <- pmf_K_marginal(J, fit$a, fit$b, logS) plot(fit)  # Full dashboard plot_K_prior(fit)  # K distribution only"},{"path":[]},{"path":"https://joonho112.github.io/DPprior/articles/api-reference.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Complete API Reference with Examples","text":"Antoniak, C. E. (1974). Mixtures Dirichlet processes applications Bayesian nonparametric problems. Annals Statistics, 2(6), 1152-1174. Golub, G. H., & Welsch, J. H. (1969). Calculation Gauss quadrature rules. Mathematics Computation, 23(106), 221-230. Lee, J. (2026). Design-conditional prior elicitation Dirichlet process mixtures. arXiv preprint arXiv:2602.06301. Lee, J., Che, J., Rabe-Hesketh, S., Feller, ., & Miratrix, L. (2025). Improving estimation site-specific effects distribution multisite trials. Journal Educational Behavioral Statistics, 50(5), 731-764. additional documentation, see package vignettes visit GitHub repository.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/applied-guide.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"The Applied Researcher's Guide to Cluster-Count Elicitation","text":"vignette provides comprehensive, step--step guide eliciting Gamma hyperpriors concentration parameter Œ±\\alpha Dirichlet Process mixture models. end guide, understand: two-question protocol systematic prior elicitation translate domain knowledge expected number clusters express uncertainty expectation use different calibration methods (A1, A2-MN, A2-KL) handle feasibility constraints conduct sensitivity analysis guide assumes read Quick Start vignette familiar basic usage DPprior_fit().","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/articles/applied-guide.html","id":"the-two-question-protocol","dir":"Articles","previous_headings":"1. The Elicitation Framework","what":"The Two-Question Protocol","title":"The Applied Researcher's Guide to Cluster-Count Elicitation","text":"Eliciting Gamma(,b)(, b) hyperprior Œ±\\alpha requires specifying two pieces information: location (expect number clusters ) scale (certain expectation). DPprior package operationalizes two quantities: Expected number clusters (ŒºK\\mu_K): best guess number distinct groups Uncertainty expectation (œÉK2\\sigma^2_K confidence level): sure guess need ? Gamma distribution two parameters, single piece information insufficient uniquely determine prior. Think way: saying ‚Äúexpect 15 clusters‚Äù correspond many different priors‚Äîtightly concentrated prior strongly believes exactly 15 clusters, diffuse prior merely centers around 15 allows substantial deviation. mean (Œº_K = 15) different levels uncertainty leads different priors Œ±.","code":"# Compare priors with same mean but different variances J <- 100 mu_K <- 15  fits <- list(   \"High Uncertainty (var_K = 70)\"   = DPprior_fit(J, mu_K, var_K = 70),   \"Medium Uncertainty (var_K = 35)\" = DPprior_fit(J, mu_K, var_K = 35),   \"Low Uncertainty (var_K = 21)\"    = DPprior_fit(J, mu_K, var_K = 21) )  # Pre-compute log Stirling numbers for PMF calculation logS <- compute_log_stirling(J)  # Create data for alpha prior plot alpha_grid <- seq(0.01, 20, length.out = 300) alpha_df <- do.call(rbind, lapply(names(fits), function(nm) {   fit <- fits[[nm]]   data.frame(     alpha = alpha_grid,     density = dgamma(alpha_grid, shape = fit$a, rate = fit$b),     Uncertainty = nm   ) })) alpha_df$Uncertainty <- factor(alpha_df$Uncertainty, levels = names(fits))  # Create data for K PMF plot k_df <- do.call(rbind, lapply(names(fits), function(nm) {   fit <- fits[[nm]]   pmf <- pmf_K_marginal(J, fit$a, fit$b, logS = logS)   data.frame(     K = 1:length(pmf),     probability = pmf,     Uncertainty = nm   ) })) k_df$Uncertainty <- factor(k_df$Uncertainty, levels = names(fits))  # Plot alpha priors p1 <- ggplot(alpha_df, aes(x = alpha, y = density, color = Uncertainty)) +   geom_line(linewidth = 1) +   scale_color_manual(values = palette_3) +   labs(x = expression(alpha), y = \"Density\",        title = expression(\"Prior Density for \" * alpha)) +   theme_minimal() +   theme(legend.position = \"bottom\",         legend.title = element_blank(),         legend.direction = \"vertical\")  # Plot K PMF p2 <- ggplot(k_df[k_df$K <= 35, ], aes(x = K, y = probability, color = Uncertainty)) +   geom_point(size = 1.5) +   geom_line(linewidth = 0.8) +   scale_color_manual(values = palette_3) +   labs(x = \"Number of Clusters (K)\", y = \"Probability\",        title = \"Implied PMF of K\") +   theme_minimal() +   theme(legend.position = \"bottom\",         legend.title = element_blank(),         legend.direction = \"vertical\")  # Arrange plots side by side gridExtra::grid.arrange(p1, p2, ncol = 2)"},{"path":"https://joonho112.github.io/DPprior/articles/applied-guide.html","id":"eliciting-the-mean-how-many-clusters","dir":"Articles","previous_headings":"","what":"2. Eliciting the Mean: How Many Clusters?","title":"The Applied Researcher's Guide to Cluster-Count Elicitation","text":"first step determining ŒºK\\mu_K, expected number clusters. requires careful thought research context. several strategies arriving defensible value.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/applied-guide.html","id":"understanding-what-k_j-represents","dir":"Articles","previous_headings":"2. Eliciting the Mean: How Many Clusters?","what":"Understanding What KJK_J Represents","title":"The Applied Researcher's Guide to Cluster-Count Elicitation","text":"eliciting ŒºK\\mu_K, important understand KJK_J represents. Dirichlet Process mixture model, KJK_J denotes number occupied clusters among JJ observations‚Äîtotal number mixture components underlying model (infinite). Lee et al.¬†(2025) emphasize, KJK_J functions upper bound number practically distinguishable subgroups rather precise count ‚Äútrue‚Äù clusters. distinction practical implications elicitation: Since KJK_J tends slightly overcount relative number substantively meaningful groups, often reasonable set ŒºK\\mu_K somewhat generously‚Äî, slightly higher strict expectation number ‚Äútrue‚Äù clusters. prior allows clusters strictly expect provides flexibility data reveal unexpected heterogeneity still regularizing toward domain knowledge.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/applied-guide.html","id":"strategy-1-the-oracle-question","dir":"Articles","previous_headings":"2. Eliciting the Mean: How Many Clusters?","what":"Strategy 1: The Oracle Question","title":"The Applied Researcher's Guide to Cluster-Count Elicitation","text":"Imagine trusted oracle reveal true underlying pattern: ‚Äúreliable oracle showed true effect pattern across 100 sites, approximately many distinct groups see?‚Äù question bypasses abstract statistical thinking focuses substantive domain knowledge.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/applied-guide.html","id":"strategy-2-prior-research","dir":"Articles","previous_headings":"2. Eliciting the Mean: How Many Clusters?","what":"Strategy 2: Prior Research","title":"The Applied Researcher's Guide to Cluster-Count Elicitation","text":"Draw previous studies field: ‚Äúsimilar prior research, many subtypes subgroups identified?‚Äù example, educational intervention research, previous meta-analyses might suggest treatment effects typically cluster 5-15 distinct patterns depending intervention type population.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/applied-guide.html","id":"strategy-3-theoretical-mechanisms","dir":"Articles","previous_headings":"2. Eliciting the Mean: How Many Clusters?","what":"Strategy 3: Theoretical Mechanisms","title":"The Applied Researcher's Guide to Cluster-Count Elicitation","text":"Consider underlying causal processes: ‚Äúmany distinct mechanisms pathways theoretically expect drive heterogeneity outcome?‚Äù theory suggests multiple mechanisms (e.g., implementation fidelity, population characteristics, regional factors, intervention dosage), might set ŒºK\\mu_K accommodate combinations.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/applied-guide.html","id":"boundary-checks","dir":"Articles","previous_headings":"2. Eliciting the Mean: How Many Clusters?","what":"Boundary Checks","title":"The Applied Researcher's Guide to Cluster-Count Elicitation","text":"proceeding, verify ŒºK\\mu_K satisfies basic constraints: ŒºK>1\\mu_K > 1: single cluster trivial provides insight heterogeneity ŒºK<J\\mu_K < J: clusters observations Extreme values warrant careful consideration: ŒºK\\mu_K close JJ implies believe nearly every observation unique Gamma hyperparameters different expected cluster counts (J = 100, low confidence) table shows, expecting clusters leads larger values E[Œ±]E[\\alpha], reflecting relationship concentration parameter cluster formation Dirichlet Process.","code":"# Compare priors across different mu_K values J <- 100 mu_K_values <- c(5, 10, 15, 25)  comparison_df <- data.frame(   mu_K = mu_K_values,   a = numeric(4),   b = numeric(4),   E_alpha = numeric(4),   SD_alpha = numeric(4) )  for (i in seq_along(mu_K_values)) {   fit <- DPprior_fit(J, mu_K = mu_K_values[i], confidence = \"low\")   comparison_df$a[i] <- fit$a   comparison_df$b[i] <- fit$b   comparison_df$E_alpha[i] <- fit$a / fit$b   comparison_df$SD_alpha[i] <- sqrt(fit$a) / fit$b } #> Warning: HIGH DOMINANCE RISK: P(w1 > 0.5) = 60.6% exceeds 40%. #>   This may indicate unintended prior behavior (Lee, 2026). #>   Consider using DPprior_dual() for weight-constrained elicitation. #>   See ?DPprior_diagnostics for interpretation.  knitr::kable(   comparison_df,   col.names = c(\"Target Œº_K\", \"a\", \"b\", \"E[Œ±]\", \"SD(Œ±)\"),   digits = 3,   caption = \"Gamma hyperparameters for different expected cluster counts    (J = 100, low confidence)\" )"},{"path":"https://joonho112.github.io/DPprior/articles/applied-guide.html","id":"eliciting-the-variance-how-certain-are-you","dir":"Articles","previous_headings":"","what":"3. Eliciting the Variance: How Certain Are You?","title":"The Applied Researcher's Guide to Cluster-Count Elicitation","text":"determined ŒºK\\mu_K, must express certain value. DPprior package offers three approaches, suited different contexts.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/applied-guide.html","id":"method-1-confidence-levels-recommended-for-most-users","dir":"Articles","previous_headings":"3. Eliciting the Variance: How Certain Are You?","what":"Method 1: Confidence Levels (Recommended for Most Users)","title":"The Applied Researcher's Guide to Cluster-Count Elicitation","text":"simplest approach uses qualitative confidence levels package translates appropriate variance specifications: VIF (Variance Inflation Factor) indicates much larger prior variance relative baseline Poisson variance (ŒºK‚àí1)(\\mu_K - 1). Recommendation: applied researchers seeking weakly informative priors, recommend starting confidence = \"low\". provides regularization toward expected cluster count remaining flexible enough let data speak. confidence levels affect elicited prior (J = 100, Œº_K = 15) Higher confidence leads smaller coefficient variation (CV) Œ±\\alpha, meaning prior concentrated around mean.","code":"# Using confidence levels fit_low    <- DPprior_fit(J = 100, mu_K = 15, confidence = \"low\") fit_medium <- DPprior_fit(J = 100, mu_K = 15, confidence = \"medium\") fit_high   <- DPprior_fit(J = 100, mu_K = 15, confidence = \"high\")  # What VIF values correspond to these levels? cat(\"Low confidence VIF:   \", confidence_to_vif(\"low\"), \"\\n\") #> Low confidence VIF:    5 cat(\"Medium confidence VIF:\", confidence_to_vif(\"medium\"), \"\\n\") #> Medium confidence VIF: 2.5 cat(\"High confidence VIF:  \", confidence_to_vif(\"high\"), \"\\n\") #> High confidence VIF:   1.5 # Comparison table confidence_comparison <- data.frame(   Confidence = c(\"Low\", \"Medium\", \"High\"),   VIF = c(5.0, 2.5, 1.5),   var_K = round(c(fit_low$target$var_K, fit_medium$target$var_K,                    fit_high$target$var_K), 2),   a = round(c(fit_low$a, fit_medium$a, fit_high$a), 3),   b = round(c(fit_low$b, fit_medium$b, fit_high$b), 3),   CV_alpha = round(1/sqrt(c(fit_low$a, fit_medium$a, fit_high$a)), 3) )  knitr::kable(   confidence_comparison,   col.names = c(\"Confidence\", \"VIF\", \"var_K\", \"a\", \"b\", \"CV(Œ±)\"),   caption = \"How confidence levels affect the elicited prior (J = 100, Œº_K = 15)\" )"},{"path":"https://joonho112.github.io/DPprior/articles/applied-guide.html","id":"method-2-direct-variance-specification","dir":"Articles","previous_headings":"3. Eliciting the Variance: How Certain Are You?","what":"Method 2: Direct Variance Specification","title":"The Applied Researcher's Guide to Cluster-Count Elicitation","text":"users want precise control, can specify Var(K)\\text{Var}(K) directly:","code":"# Specify variance directly fit_direct <- DPprior_fit(J = 100, mu_K = 15, var_K = 50) cat(\"Direct specification: var_K = 50\\n\") #> Direct specification: var_K = 50 cat(\"  Gamma(a =\", round(fit_direct$a, 3), \", b =\", round(fit_direct$b, 3), \")\\n\") #>   Gamma(a = 2.418 , b = 0.476 ) cat(\"  Achieved E[K] =\", round(fit_direct$fit$mu_K, 4), \"\\n\") #>   Achieved E[K] = 15 cat(\"  Achieved Var(K) =\", round(fit_direct$fit$var_K, 4), \"\\n\") #>   Achieved Var(K) = 50"},{"path":"https://joonho112.github.io/DPprior/articles/applied-guide.html","id":"method-3-quantile-based-elicitation","dir":"Articles","previous_headings":"3. Eliciting the Variance: How Certain Are You?","what":"Method 3: Quantile-Based Elicitation","title":"The Applied Researcher's Guide to Cluster-Count Elicitation","text":"intuitive approach researchers specify credible interval number clusters. example: ‚Äúbelieve ‚Äôs 90% chance number clusters falls 8 25.‚Äù Assuming roughly symmetric distribution, translates variance:","code":"# Quantile-based elicitation # 90% interval: [8, 25] with implied mean ~16.5 # Width = 17 = 2 √ó 1.645 √ó œÉ  ‚Üí  œÉ ‚âà 5.17  ‚Üí  œÉ¬≤ ‚âà 26.7  lower <- 8 upper <- 25 mu_K_quantile <- (lower + upper) / 2 sigma_K <- (upper - lower) / (2 * 1.645)  # 90% interval var_K_quantile <- sigma_K^2  cat(\"From 90% interval [\", lower, \", \", upper, \"]:\\n\", sep = \"\") #> From 90% interval [8, 25]: cat(\"  Implied Œº_K =\", round(mu_K_quantile, 2), \"\\n\") #>   Implied Œº_K = 16.5 cat(\"  Implied œÉ_K =\", round(sigma_K, 2), \"\\n\") #>   Implied œÉ_K = 5.17 cat(\"  Implied var_K =\", round(var_K_quantile, 2), \"\\n\") #>   Implied var_K = 26.7  fit_quantile <- DPprior_fit(J = 100, mu_K = mu_K_quantile, var_K = var_K_quantile) cat(\"\\nElicited prior: Gamma(\", round(fit_quantile$a, 3), \", \",      round(fit_quantile$b, 3), \")\\n\", sep = \"\") #>  #> Elicited prior: Gamma(7.335, 1.322)"},{"path":"https://joonho112.github.io/DPprior/articles/applied-guide.html","id":"method-4-vif-based-specification","dir":"Articles","previous_headings":"3. Eliciting the Variance: How Certain Are You?","what":"Method 4: VIF-Based Specification","title":"The Applied Researcher's Guide to Cluster-Count Elicitation","text":"think naturally terms relative variance, can use VIF directly:","code":"# VIF-based specification # \"My uncertainty is about 5 times the Poisson baseline\" (low confidence) vif <- 5.0 var_K_vif <- vif_to_variance(mu_K = 15, vif = vif)  cat(\"VIF =\", vif, \"‚Üí var_K =\", var_K_vif, \"\\n\") #> VIF = 5 ‚Üí var_K = 70  fit_vif <- DPprior_fit(J = 100, mu_K = 15, var_K = var_K_vif) print(fit_vif) #> DPprior Prior Elicitation Result #> =============================================  #>  #> Gamma Hyperprior: Œ± ~ Gamma(a = 1.5843, b = 0.2992) #>   E[Œ±] = 5.296, SD[Œ±] = 4.207 #>  #> Target (J = 100): #>   E[K_J]   = 15.00 #>   Var(K_J) = 70.00 #>  #> Achieved: #>   E[K_J] = 15.000000, Var(K_J) = 70.000000 #>   Residual = 5.86e-10 #>  #> Method: A2-MN (6 iterations) #>  #> Dominance Risk: LOW ‚úì (P(w‚ÇÅ>0.5) = 15%)"},{"path":"https://joonho112.github.io/DPprior/articles/applied-guide.html","id":"the-three-calibration-methods","dir":"Articles","previous_headings":"","what":"4. The Three Calibration Methods","title":"The Applied Researcher's Guide to Cluster-Count Elicitation","text":"DPprior package offers three methods calibrating Gamma hyperparameters. Understanding use method help make informed choices.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/applied-guide.html","id":"method-a1-closed-form-approximation","dir":"Articles","previous_headings":"4. The Three Calibration Methods","what":"Method A1: Closed-Form Approximation","title":"The Applied Researcher's Guide to Cluster-Count Elicitation","text":"A1 method provides instantaneous, closed-form solution based Negative Binomial approximation KK distribution. Pros: Extremely fast (iteration required) Provides good accuracy practical cases Useful rapid exploration initial calibration Cons: Slight approximation error, especially small JJ extreme ŒºK\\mu_K May project infeasible variance specifications boundary","code":"fit_a1 <- DPprior_fit(J = 100, mu_K = 15, var_K = 70, method = \"A1\")  cat(\"Method A1 (Closed-Form Approximation)\\n\") #> Method A1 (Closed-Form Approximation) cat(\"  Gamma(a =\", round(fit_a1$a, 4), \", b =\", round(fit_a1$b, 4), \")\\n\") #>   Gamma(a = 3.5 , b = 1.1513 ) cat(\"  Target:   E[K] =\", fit_a1$target$mu_K, \", Var(K) =\", fit_a1$target$var_K, \"\\n\") #>   Target:   E[K] = 15 , Var(K) = 70 cat(\"  Achieved: E[K] =\", round(fit_a1$fit$mu_K, 4),      \", Var(K) =\", round(fit_a1$fit$var_K, 4), \"\\n\") #>   Achieved: E[K] = 10.8439 , Var(K) = 23.0324 cat(\"  Residual:\", format(fit_a1$fit$residual, scientific = TRUE), \"\\n\") #>   Residual: 4.715115e+01"},{"path":"https://joonho112.github.io/DPprior/articles/applied-guide.html","id":"method-a2-mn-exact-moment-matching-recommended","dir":"Articles","previous_headings":"4. The Three Calibration Methods","what":"Method A2-MN: Exact Moment Matching (Recommended)","title":"The Applied Researcher's Guide to Cluster-Count Elicitation","text":"A2-MN method uses Newton iteration find Gamma parameters exactly match target moments. default recommended method applications. Pros: Machine-precision accuracy Guaranteed exact moment matching Fast convergence (typically 5-10 iterations) Cons: Slightly slower A1 (though still fast) Requires numerical iteration","code":"fit_a2 <- DPprior_fit(J = 100, mu_K = 15, var_K = 70, method = \"A2-MN\")  cat(\"Method A2-MN (Exact Moment Matching)\\n\") #> Method A2-MN (Exact Moment Matching) cat(\"  Gamma(a =\", round(fit_a2$a, 4), \", b =\", round(fit_a2$b, 4), \")\\n\") #>   Gamma(a = 1.5843 , b = 0.2992 ) cat(\"  Target:   E[K] =\", fit_a2$target$mu_K, \", Var(K) =\", fit_a2$target$var_K, \"\\n\") #>   Target:   E[K] = 15 , Var(K) = 70 cat(\"  Achieved: E[K] =\", round(fit_a2$fit$mu_K, 6),      \", Var(K) =\", round(fit_a2$fit$var_K, 6), \"\\n\") #>   Achieved: E[K] = 15 , Var(K) = 70 cat(\"  Residual:\", format(fit_a2$fit$residual, scientific = TRUE), \"\\n\") #>   Residual: 5.855439e-10 cat(\"  Iterations:\", fit_a2$iterations, \"\\n\") #>   Iterations: 6"},{"path":"https://joonho112.github.io/DPprior/articles/applied-guide.html","id":"method-a2-kl-kl-divergence-minimization","dir":"Articles","previous_headings":"4. The Three Calibration Methods","what":"Method A2-KL: KL Divergence Minimization","title":"The Applied Researcher's Guide to Cluster-Count Elicitation","text":"A2-KL method minimizes Kullback-Leibler divergence target PMF induced distribution KK. useful specific target distribution mind, just moments. Pros: Matches entire distribution shape, just moments Useful custom target distributions Faithful Design-Conditional Elicitation (DCE) philosophy (Lee, 2026; Dorazio, 2009) Cons: Requires specifying target PMF Computationally intensive moment matching","code":"fit_kl <- DPprior_fit(J = 100, mu_K = 15, var_K = 70, method = \"A2-KL\")  cat(\"Method A2-KL (KL Divergence Minimization)\\n\") #> Method A2-KL (KL Divergence Minimization) cat(\"  Gamma(a =\", round(fit_kl$a, 4), \", b =\", round(fit_kl$b, 4), \")\\n\") #>   Gamma(a = 1.767 , b = 0.3346 ) cat(\"  Target:   E[K] =\", fit_kl$target$mu_K, \", Var(K) =\", fit_kl$target$var_K, \"\\n\") #>   Target:   E[K] = 15 , Var(K) = 70 cat(\"  Achieved: E[K] =\", round(fit_kl$fit$mu_K, 4),      \", Var(K) =\", round(fit_kl$fit$var_K, 4), \"\\n\") #>   Achieved: E[K] = 15.0957 , Var(K) = 64.7345 cat(\"  Residual:\", format(fit_kl$fit$residual, scientific = TRUE), \"\\n\") #>   Residual: 1.896688e-02"},{"path":"https://joonho112.github.io/DPprior/articles/applied-guide.html","id":"comparing-methods","dir":"Articles","previous_headings":"","what":"5. Comparing Methods","title":"The Applied Researcher's Guide to Cluster-Count Elicitation","text":"Let‚Äôs systematically compare three methods across different scenarios:","code":"compare_methods <- function(J, mu_K, var_K) {   a1 <- DPprior_fit(J, mu_K, var_K, method = \"A1\")   a2 <- DPprior_fit(J, mu_K, var_K, method = \"A2-MN\")   kl <- DPprior_fit(J, mu_K, var_K, method = \"A2-KL\")      data.frame(     Method = c(\"A1\", \"A2-MN\", \"A2-KL\"),     a = round(c(a1$a, a2$a, kl$a), 4),     b = round(c(a1$b, a2$b, kl$b), 4),     `E[K]` = round(c(a1$fit$mu_K, a2$fit$mu_K, kl$fit$mu_K), 4),     `Var(K)` = round(c(a1$fit$var_K, a2$fit$var_K, kl$fit$var_K), 4),     Residual = format(c(a1$fit$residual, a2$fit$residual, kl$fit$residual),                        scientific = TRUE, digits = 2),     check.names = FALSE   ) }  # Standard case cat(\"Scenario 1: J = 100, Œº_K = 15, var_K = 70\\n\") #> Scenario 1: J = 100, Œº_K = 15, var_K = 70 knitr::kable(compare_methods(100, 15, 70)) # Large J cat(\"\\nScenario 2: J = 200, Œº_K = 20, var_K = 95\\n\") #>  #> Scenario 2: J = 200, Œº_K = 20, var_K = 95 knitr::kable(compare_methods(200, 20, 95)) # Smaller J cat(\"\\nScenario 3: J = 50, Œº_K = 8, var_K = 35\\n\") #>  #> Scenario 3: J = 50, Œº_K = 8, var_K = 35 knitr::kable(compare_methods(50, 8, 35))"},{"path":"https://joonho112.github.io/DPprior/articles/applied-guide.html","id":"practical-recommendations","dir":"Articles","previous_headings":"5. Comparing Methods","what":"Practical Recommendations","title":"The Applied Researcher's Guide to Cluster-Count Elicitation","text":"Based comparison: general use: Use A2-MN (default). provides exact moment matching fast convergence. rapid exploration: Use A1 need instant results can tolerate small approximation errors. distribution matching: Use A2-KL specific target distribution shape mind.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/applied-guide.html","id":"feasibility-constraints","dir":"Articles","previous_headings":"","what":"6. Feasibility Constraints","title":"The Applied Researcher's Guide to Cluster-Count Elicitation","text":"combinations (ŒºK,œÉK2)(\\mu_K, \\sigma^2_K) achievable Gamma hyperprior. Understanding constraints helps specify feasible targets.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/applied-guide.html","id":"why-some-specifications-are-infeasible","dir":"Articles","previous_headings":"6. Feasibility Constraints","what":"Why Some Specifications Are Infeasible","title":"The Applied Researcher's Guide to Cluster-Count Elicitation","text":"variance KK Gamma hyperprior bounded: Lower bound: Var(K)>ŒºK‚àí1\\text{Var}(K) > \\mu_K - 1 (approximately). Negative Binomial proxy requires overdispersion relative Poisson. Upper bound: Var(K)<(J‚àí1)2/4\\text{Var}(K) < (J-1)^2/4 (approximately). mathematical constraint variance bounded random variable.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/applied-guide.html","id":"how-the-package-handles-infeasibility","dir":"Articles","previous_headings":"6. Feasibility Constraints","what":"How the Package Handles Infeasibility","title":"The Applied Researcher's Guide to Cluster-Count Elicitation","text":"A1 method automatically projects infeasible specifications boundary feasible region. A2-MN method attempts exact matching without projection, may result slower convergence failure truly infeasible targets.","code":"# Example: Infeasible variance (too small) cat(\"Attempting var_K = 10 (below feasible threshold for Œº_K = 15):\\n\") #> Attempting var_K = 10 (below feasible threshold for Œº_K = 15): fit_infeasible <- DPprior_fit(J = 100, mu_K = 15, var_K = 10, method = \"A1\") #> Warning: A1 method: var_K=10.0000 < mu_K-1=14.0000 (infeasible for NegBin proxy). #>   Projecting to feasible boundary: 14.000001 #> Warning: var_K <= mu_K - 1: projected to feasible boundary  cat(\"  Original var_K:\", fit_infeasible$target$var_K, \"\\n\") #>   Original var_K: 10 cat(\"  Used var_K:\", fit_infeasible$target$var_K_used, \"\\n\") #>   Used var_K: 14 cat(\"  (Projected to feasible boundary)\\n\") #>   (Projected to feasible boundary)"},{"path":"https://joonho112.github.io/DPprior/articles/applied-guide.html","id":"a-complete-elicitation-workflow","dir":"Articles","previous_headings":"","what":"7. A Complete Elicitation Workflow","title":"The Applied Researcher's Guide to Cluster-Count Elicitation","text":"Let‚Äôs walk complete, realistic example prior elicitation.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/applied-guide.html","id":"context","dir":"Articles","previous_headings":"7. A Complete Elicitation Workflow","what":"Context","title":"The Applied Researcher's Guide to Cluster-Count Elicitation","text":"analyzing multisite educational intervention study 100 sites. Previous research similar interventions identified 8-20 distinct response patterns. Given interpretation KJK_J upper bound number distinguishable clusters (Lee et al., 2025), decide set expectation generously ŒºK=15\\mu_K = 15.","code":"# ============================================================================= # Step 1: Define the research context # ============================================================================= J <- 100  # 100 sites application_context <- \"Multisite educational intervention study\"  cat(\"Research Context:\", application_context, \"\\n\") #> Research Context: Multisite educational intervention study cat(\"Number of sites: J =\", J, \"\\n\\n\") #> Number of sites: J = 100  # ============================================================================= # Step 2: Determine Œº_K based on domain knowledge # ============================================================================= # Prior research suggests 8-20 response patterns # Given K_J is an upper bound, we set Œº_K generously at 15 mu_K <- 15  cat(\"Prior Knowledge:\\n\") #> Prior Knowledge: cat(\"  Previous studies found 8-20 response patterns\\n\") #>   Previous studies found 8-20 response patterns cat(\"  K_J serves as upper bound on distinguishable clusters\\n\") #>   K_J serves as upper bound on distinguishable clusters cat(\"  Selected Œº_K =\", mu_K, \"(generous allowance for heterogeneity)\\n\\n\") #>   Selected Œº_K = 15 (generous allowance for heterogeneity)  # ============================================================================= # Step 3: Determine uncertainty level # ============================================================================= # For a weakly informative prior, we use low confidence confidence <- \"low\"  cat(\"Uncertainty Assessment:\\n\") #> Uncertainty Assessment: cat(\"  Seeking weakly informative prior\\n\") #>   Seeking weakly informative prior cat(\"  Selected confidence:\", confidence, \"(recommended default)\\n\\n\") #>   Selected confidence: low (recommended default)  # ============================================================================= # Step 4: Fit the prior # ============================================================================= fit <- DPprior_fit(   J = J,    mu_K = mu_K,    confidence = confidence,    method = \"A2-MN\" )  cat(\"Elicited Prior:\\n\") #> Elicited Prior: print(fit) #> DPprior Prior Elicitation Result #> =============================================  #>  #> Gamma Hyperprior: Œ± ~ Gamma(a = 1.5843, b = 0.2992) #>   E[Œ±] = 5.296, SD[Œ±] = 4.207 #>  #> Target (J = 100): #>   E[K_J]   = 15.00 #>   Var(K_J) = 70.00 #>   (from confidence = 'low') #>  #> Achieved: #>   E[K_J] = 15.000000, Var(K_J) = 70.000000 #>   Residual = 5.86e-10 #>  #> Method: A2-MN (6 iterations) #>  #> Dominance Risk: LOW ‚úì (P(w‚ÇÅ>0.5) = 15%)"},{"path":"https://joonho112.github.io/DPprior/articles/applied-guide.html","id":"visualizing-the-result","dir":"Articles","previous_headings":"7. A Complete Elicitation Workflow","what":"Visualizing the Result","title":"The Applied Researcher's Guide to Cluster-Count Elicitation","text":"Complete visualization elicited prior educational intervention study.","code":"plot(fit) #> TableGrob (2 x 2) \"dpprior_dashboard\": 4 grobs #>   z     cells              name           grob #> 1 1 (1-1,1-1) dpprior_dashboard gtable[layout] #> 2 2 (2-2,1-1) dpprior_dashboard gtable[layout] #> 3 3 (1-1,2-2) dpprior_dashboard gtable[layout] #> 4 4 (2-2,2-2) dpprior_dashboard gtable[layout]"},{"path":"https://joonho112.github.io/DPprior/articles/applied-guide.html","id":"extracting-results-for-use-in-bayesian-software","dir":"Articles","previous_headings":"7. A Complete Elicitation Workflow","what":"Extracting Results for Use in Bayesian Software","title":"The Applied Researcher's Guide to Cluster-Count Elicitation","text":"","code":"# Extract Gamma parameters for use in Stan, JAGS, etc. cat(\"For Stan/JAGS:\\n\") #> For Stan/JAGS: cat(\"  alpha ~ gamma(\", round(fit$a, 4), \", \", round(fit$b, 4), \");\\n\\n\", sep = \"\") #>   alpha ~ gamma(1.5843, 0.2992);  # Sample from the prior n_samples <- 10000 alpha_samples <- rgamma(n_samples, shape = fit$a, rate = fit$b)  cat(\"Prior Summary (from\", n_samples, \"samples):\\n\") #> Prior Summary (from 10000 samples): cat(\"  E[Œ±] =\", round(mean(alpha_samples), 3), \"\\n\") #>   E[Œ±] = 5.34 cat(\"  SD(Œ±) =\", round(sd(alpha_samples), 3), \"\\n\") #>   SD(Œ±) = 4.294 cat(\"  95% CI: [\", round(quantile(alpha_samples, 0.025), 3), \", \",     round(quantile(alpha_samples, 0.975), 3), \"]\\n\", sep = \"\") #>   95% CI: [0.42, 16.565]"},{"path":"https://joonho112.github.io/DPprior/articles/applied-guide.html","id":"sensitivity-analysis","dir":"Articles","previous_headings":"","what":"8. Sensitivity Analysis","title":"The Applied Researcher's Guide to Cluster-Count Elicitation","text":"crucial part responsible Bayesian analysis understanding conclusions depend prior specifications. DPprior package facilitates sensitivity analysis.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/applied-guide.html","id":"sensitivity-to-Œº_k","dir":"Articles","previous_headings":"8. Sensitivity Analysis","what":"Sensitivity to Œº_K","title":"The Applied Researcher's Guide to Cluster-Count Elicitation","text":"Sensitivity Œº_K (J = 100, low confidence) Sensitivity elicited prior different expectations number clusters.","code":"# How sensitive are the results to our choice of Œº_K? J <- 100 mu_K_grid <- c(8, 12, 15, 20) sensitivity_mu <- lapply(mu_K_grid, function(mu) {   DPprior_fit(J = J, mu_K = mu, confidence = \"low\") }) #> Warning: HIGH DOMINANCE RISK: P(w1 > 0.5) = 40.4% exceeds 40%. #>   This may indicate unintended prior behavior (Lee, 2026). #>   Consider using DPprior_dual() for weight-constrained elicitation. #>   See ?DPprior_diagnostics for interpretation.  # Create comparison table sensitivity_mu_df <- data.frame(   `Œº_K` = mu_K_grid,   a = sapply(sensitivity_mu, function(x) round(x$a, 3)),   b = sapply(sensitivity_mu, function(x) round(x$b, 3)),   `E[Œ±]` = sapply(sensitivity_mu, function(x) round(x$a / x$b, 3)),   `P(w‚ÇÅ > 0.5)` = sapply(sensitivity_mu, function(x) {     round(prob_w1_exceeds(0.5, x$a, x$b), 3)   }),   check.names = FALSE )  knitr::kable(   sensitivity_mu_df,   caption = \"Sensitivity to Œº_K (J = 100, low confidence)\" ) # Visualize with ggplot alpha_grid <- seq(0.01, 25, length.out = 300) sens_mu_df <- do.call(rbind, lapply(seq_along(sensitivity_mu), function(i) {   fit <- sensitivity_mu[[i]]   data.frame(     alpha = alpha_grid,     density = dgamma(alpha_grid, shape = fit$a, rate = fit$b),     mu_K = paste0(\"Œº_K = \", mu_K_grid[i])   ) })) sens_mu_df$mu_K <- factor(sens_mu_df$mu_K,                            levels = paste0(\"Œº_K = \", mu_K_grid))  ggplot(sens_mu_df, aes(x = alpha, y = density, color = mu_K)) +   geom_line(linewidth = 1) +   scale_color_manual(values = palette_4) +   labs(x = expression(alpha), y = \"Density\",        title = expression(\"Prior Sensitivity to \" * mu[K]),        color = NULL) +   theme_minimal() +   theme(legend.position = \"right\")"},{"path":"https://joonho112.github.io/DPprior/articles/applied-guide.html","id":"sensitivity-to-confidence-level","dir":"Articles","previous_headings":"8. Sensitivity Analysis","what":"Sensitivity to Confidence Level","title":"The Applied Researcher's Guide to Cluster-Count Elicitation","text":"Sensitivity confidence level (J = 100, Œº_K = 15) Sensitivity elicited prior different confidence levels.","code":"# How sensitive are the results to our confidence level? confidence_levels <- c(\"low\", \"medium\", \"high\") sensitivity_conf <- lapply(confidence_levels, function(conf) {   DPprior_fit(J = 100, mu_K = 15, confidence = conf) })  # Create comparison table sensitivity_conf_df <- data.frame(   Confidence = c(\"Low\", \"Medium\", \"High\"),   var_K = sapply(sensitivity_conf, function(x) round(x$target$var_K, 2)),   a = sapply(sensitivity_conf, function(x) round(x$a, 3)),   b = sapply(sensitivity_conf, function(x) round(x$b, 3)),   `CV(Œ±)` = sapply(sensitivity_conf, function(x) round(1/sqrt(x$a), 3)),   `Median w‚ÇÅ` = sapply(sensitivity_conf, function(x) {     round(quantile_w1(0.5, x$a, x$b), 3)   }),   check.names = FALSE )  knitr::kable(   sensitivity_conf_df,   caption = \"Sensitivity to confidence level (J = 100, Œº_K = 15)\" ) # Visualize with ggplot sens_conf_df <- do.call(rbind, lapply(seq_along(sensitivity_conf), function(i) {   fit <- sensitivity_conf[[i]]   data.frame(     alpha = alpha_grid,     density = dgamma(alpha_grid, shape = fit$a, rate = fit$b),     Confidence = c(\"Low\", \"Medium\", \"High\")[i]   ) })) sens_conf_df$Confidence <- factor(sens_conf_df$Confidence,                                    levels = c(\"Low\", \"Medium\", \"High\"))  ggplot(sens_conf_df, aes(x = alpha, y = density, color = Confidence)) +   geom_line(linewidth = 1) +   scale_color_manual(values = palette_3) +   labs(x = expression(alpha), y = \"Density\",        title = \"Prior Sensitivity to Confidence Level\",        color = NULL) +   theme_minimal() +   theme(legend.position = \"right\")"},{"path":"https://joonho112.github.io/DPprior/articles/applied-guide.html","id":"comprehensive-sensitivity-analysis","dir":"Articles","previous_headings":"8. Sensitivity Analysis","what":"Comprehensive Sensitivity Analysis","title":"The Applied Researcher's Guide to Cluster-Count Elicitation","text":"thorough sensitivity analysis, might want explore grid specifications: Comprehensive sensitivity analysis (J = 100)","code":"# Grid-based sensitivity analysis mu_K_vals <- c(10, 15, 20) conf_vals <- c(\"low\", \"medium\", \"high\")  grid_results <- expand.grid(mu_K = mu_K_vals, confidence = conf_vals,                             stringsAsFactors = FALSE) grid_results$a <- NA grid_results$b <- NA grid_results$E_alpha <- NA  for (i in 1:nrow(grid_results)) {   fit <- DPprior_fit(J = 100,                       mu_K = grid_results$mu_K[i],                       confidence = grid_results$confidence[i])   grid_results$a[i] <- round(fit$a, 3)   grid_results$b[i] <- round(fit$b, 3)   grid_results$E_alpha[i] <- round(fit$a / fit$b, 3) }  knitr::kable(   grid_results,   col.names = c(\"Œº_K\", \"Confidence\", \"a\", \"b\", \"E[Œ±]\"),   caption = \"Comprehensive sensitivity analysis (J = 100)\" )"},{"path":"https://joonho112.github.io/DPprior/articles/applied-guide.html","id":"reporting-sensitivity-results","dir":"Articles","previous_headings":"8. Sensitivity Analysis","what":"Reporting Sensitivity Results","title":"The Applied Researcher's Guide to Cluster-Count Elicitation","text":"reporting analysis, recommend: Report primary specification clear justification Show sensitivity results least ¬±3-5 units ŒºK\\mu_K Compare confidence levels show uncertainty affects inference Discuss implications substantial differences posterior conclusions","code":""},{"path":"https://joonho112.github.io/DPprior/articles/applied-guide.html","id":"whats-next","dir":"Articles","previous_headings":"","what":"What‚Äôs Next?","title":"The Applied Researcher's Guide to Cluster-Count Elicitation","text":"guide covered fundamentals cluster-count elicitation. advanced topics: Dual-Anchor Framework: Learn control cluster count weight concentration simultaneously Diagnostics: Verify prior meets specifications check unintended consequences Case Studies: See worked examples education, medicine, policy research Mathematical Foundations: Understand mathematical theory underlying DPprior package","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/articles/applied-guide.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"The Applied Researcher's Guide to Cluster-Count Elicitation","text":"Dorazio, R. M. (2009). selecting prior precision parameter Dirichlet process mixture models. Journal Statistical Planning Inference, 139(9), 3384-3390. https://doi.org/10.1016/j.jspi.2009.03.009 Lee, J., Che, J., Rabe-Hesketh, S., Feller, ., & Miratrix, L. (2025). Improving estimation site-specific effects distribution multisite trials. Journal Educational Behavioral Statistics, 50(5), 731‚Äì764. https://doi.org/10.3102/10769986241254286 questions feedback, please visit GitHub repository.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/case-studies.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Case Studies: Multisite Trials and Meta-Analysis","text":"vignette presents three case studies demonstrating apply DPprior package real-world research contexts. case study walks complete workflow‚Äîsubstantive considerations final prior specification‚Äîusing published research foundation. three case studies span different domains data structures: working examples, learn : Translate substantive domain knowledge cluster count expectations Choose appropriate calibration methods different settings Apply diagnostics verify prior behavior Conduct sensitivity analysis across specifications Report prior elicitation transparently publications","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/articles/case-studies.html","id":"research-context","dir":"Articles","previous_headings":"1. Case Study: Conditional Cash Transfer Multisite Trial","what":"1.1 Research Context","title":"Case Studies: Multisite Trials and Meta-Analysis","text":"first case study draws multisite conditional cash transfer (CCT) experiment analyzed Lee et al.¬†(2025). Conditional Subsidies School Attendance program, implemented Bogot√°, Colombia (Barrera-Osorio et al., 2019), conducted randomized experiments across 38 sites San Cristobal district. Study characteristics: Sample size: 6,506 participants nested within 38 sites Average site size: 171.2 participants Coefficient variation site sizes: 0.67 (range: 23 484) Outcomes: Secondary school enrollment -time graduation Key feature: Large within-site information, limited -site variation","code":""},{"path":"https://joonho112.github.io/DPprior/articles/case-studies.html","id":"the-inferential-goals","dir":"Articles","previous_headings":"1. Case Study: Conditional Cash Transfer Multisite Trial","what":"1.2 The Inferential Goals","title":"Case Studies: Multisite Trials and Meta-Analysis","text":"researchers sought understand distribution site-specific treatment effects œÑj\\tau_j, particular interest : Estimating variance prior distribution GG Identifying extreme sites (10th 90th percentiles) Understanding heterogeneity patterns across sites Given estimated cross-site effect standard deviation œÉ=0.04\\sigma = 0.04 0.060.06 (effect size units) relatively high within-site precision, setting exhibits small -site information large within-site information‚Äîconfiguration prior choice substantially influences posterior inference.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/case-studies.html","id":"initial-prior-elicitation","dir":"Articles","previous_headings":"1. Case Study: Conditional Cash Transfer Multisite Trial","what":"1.3 Initial Prior Elicitation","title":"Case Studies: Multisite Trials and Meta-Analysis","text":"Step 1: Determining expected number clusters eliciting prior beliefs cluster structure, researchers might consider several substantive factors: intervention implemented uniformly across sites, suggesting limited structural heterogeneity However, local context (school culture, neighborhood characteristics) might create differential responses Previous multisite education trials typically exhibit 3‚Äì8 distinct response patterns Based considerations, reasonable expectation approximately ŒºK=5\\mu_K = 5 clusters among 38 sites. Step 2: Expressing uncertainty Given novelty specific intervention context moderate sample sites, express substantial uncertainty. ‚Äúlow‚Äù confidence level appropriate:","code":"# Define the study context J_cct <- 38 mu_K_cct <- 5  cat(\"Study context:\\n\") #> Study context: cat(\"  Number of sites (J):\", J_cct, \"\\n\") #>   Number of sites (J): 38 cat(\"  Expected clusters (Œº_K):\", mu_K_cct, \"\\n\") #>   Expected clusters (Œº_K): 5 cat(\"  Ratio (Œº_K/J):\", round(mu_K_cct / J_cct, 3), \"\\n\") #>   Ratio (Œº_K/J): 0.132 # Initial fit with low confidence fit_cct <- DPprior_fit(   J = J_cct,    mu_K = mu_K_cct,    confidence = \"low\" ) #> Warning: HIGH DOMINANCE RISK: P(w1 > 0.5) = 54.5% exceeds 40%. #>   This may indicate unintended prior behavior (Lee, 2026). #>   Consider using DPprior_dual() for weight-constrained elicitation. #>   See ?DPprior_diagnostics for interpretation.  print(fit_cct) #> DPprior Prior Elicitation Result #> =============================================  #>  #> Gamma Hyperprior: Œ± ~ Gamma(a = 0.4629, b = 0.2556) #>   E[Œ±] = 1.811, SD[Œ±] = 2.662 #>  #> Target (J = 38): #>   E[K_J]   = 5.00 #>   Var(K_J) = 20.00 #>   (from confidence = 'low') #>  #> Achieved: #>   E[K_J] = 5.000000, Var(K_J) = 20.000000 #>   Residual = 6.09e-09 #>  #> Method: A2-MN (11 iterations) #>  #> Dominance Risk: HIGH ‚úò (P(w‚ÇÅ>0.5) = 54%)"},{"path":"https://joonho112.github.io/DPprior/articles/case-studies.html","id":"comprehensive-diagnostics","dir":"Articles","previous_headings":"1. Case Study: Conditional Cash Transfer Multisite Trial","what":"1.4 Comprehensive Diagnostics","title":"Case Studies: Multisite Trials and Meta-Analysis","text":"accepting prior, need verify behavior across multiple dimensions. DPprior_diagnostics() function provides comprehensive assessment:","code":"diag_cct <- DPprior_diagnostics(fit_cct)  cat(\"=== Comprehensive Diagnostic Report ===\\n\\n\") #> === Comprehensive Diagnostic Report ===  cat(\"1. ALPHA DISTRIBUTION\\n\") #> 1. ALPHA DISTRIBUTION cat(\"   Mean:     \", round(diag_cct$alpha$mean, 3), \"\\n\") #>    Mean:      1.811 cat(\"   SD:       \", round(diag_cct$alpha$sd, 3), \"\\n\") #>    SD:        2.662 cat(\"   CV:       \", round(diag_cct$alpha$cv, 3), \"\\n\") #>    CV:        1.47 cat(\"   5th %ile: \", round(diag_cct$alpha$quantiles[\"q5\"], 3), \"\\n\") #>    5th %ile:  0.005 cat(\"   50th %ile:\", round(diag_cct$alpha$quantiles[\"q50\"], 3), \"\\n\") #>    50th %ile: 0.767 cat(\"   95th %ile:\", round(diag_cct$alpha$quantiles[\"q95\"], 3), \"\\n\") #>    95th %ile: 7.15  cat(\"\\n2. CLUSTER COUNT (K)\\n\") #>  #> 2. CLUSTER COUNT (K) cat(\"   E[K]:     \", round(diag_cct$K$mean, 3), \"\\n\") #>    E[K]:      5 cat(\"   Var(K):   \", round(diag_cct$K$var, 3), \"\\n\") #>    Var(K):    20 cat(\"   SD(K):    \", round(sqrt(diag_cct$K$var), 3), \"\\n\") #>    SD(K):     4.472 cat(\"   Mode(K):  \", diag_cct$K$mode, \"\\n\") #>    Mode(K):   1  cat(\"\\n3. WEIGHT BEHAVIOR\\n\") #>  #> 3. WEIGHT BEHAVIOR cat(\"   E[w‚ÇÅ]:        \", round(diag_cct$weights$mean, 3), \"\\n\") #>    E[w‚ÇÅ]:         0.572 cat(\"   Median(w‚ÇÅ):   \", round(diag_cct$weights$median, 3), \"\\n\") #>    Median(w‚ÇÅ):    0.588 cat(\"   P(w‚ÇÅ > 0.3):  \", round(diag_cct$weights$prob_exceeds[\"prob_gt_0.3\"], 3), \"\\n\") #>    P(w‚ÇÅ > 0.3):   NA cat(\"   P(w‚ÇÅ > 0.5):  \", round(diag_cct$weights$prob_exceeds[\"prob_gt_0.5\"], 3), \"\\n\") #>    P(w‚ÇÅ > 0.5):   0.545 cat(\"   P(w‚ÇÅ > 0.9):  \", round(diag_cct$weights$prob_exceeds[\"prob_gt_0.9\"], 3), \"\\n\") #>    P(w‚ÇÅ > 0.9):   0.344 cat(\"   Dominance:    \", toupper(diag_cct$weights$dominance_risk), \"\\n\") #>    Dominance:     HIGH  cat(\"\\n4. CO-CLUSTERING PROBABILITY (œÅ)\\n\") #>  #> 4. CO-CLUSTERING PROBABILITY (œÅ) cat(\"   E[œÅ]:         \", round(diag_cct$coclustering$mean, 3), \"\\n\") #>    E[œÅ]:          0.572 cat(\"   Interpretation: Two random sites have a\",      round(100 * diag_cct$coclustering$mean), \"% chance of sharing a cluster\\n\") #>    Interpretation: Two random sites have a 57 % chance of sharing a cluster"},{"path":"https://joonho112.github.io/DPprior/articles/case-studies.html","id":"visualizing-the-initial-prior","dir":"Articles","previous_headings":"1. Case Study: Conditional Cash Transfer Multisite Trial","what":"1.5 Visualizing the Initial Prior","title":"Case Studies: Multisite Trials and Meta-Analysis","text":"DPprior package provides several visualization functions help understand prior behavior. Let‚Äôs examine component: Alpha distribution: Prior distribution concentration parameter Œ± CCT study. Prior distribution concentration parameter Œ± CCT study. Cluster count distribution: Prior PMF number clusters K CCT study (J = 38). Prior PMF number clusters K CCT study (J = 38). Largest cluster weight distribution: Prior distribution largest cluster weight w‚ÇÅ. dashed line 0.5 indicates dominance threshold. Prior distribution largest cluster weight w‚ÇÅ. dashed line 0.5 indicates dominance threshold. Complete dashboard: Complete prior elicitation dashboard CCT multisite trial (J = 38, Œº_K = 5).","code":"plot_alpha_prior(fit_cct) plot_K_prior(fit_cct) plot_w1_prior(fit_cct) plot(fit_cct) #> TableGrob (2 x 2) \"dpprior_dashboard\": 4 grobs #>   z     cells              name           grob #> 1 1 (1-1,1-1) dpprior_dashboard gtable[layout] #> 2 2 (2-2,1-1) dpprior_dashboard gtable[layout] #> 3 3 (1-1,2-2) dpprior_dashboard gtable[layout] #> 4 4 (2-2,2-2) dpprior_dashboard gtable[layout]"},{"path":"https://joonho112.github.io/DPprior/articles/case-studies.html","id":"addressing-the-dominance-problem","dir":"Articles","previous_headings":"1. Case Study: Conditional Cash Transfer Multisite Trial","what":"1.6 Addressing the Dominance Problem","title":"Case Studies: Multisite Trials and Meta-Analysis","text":"diagnostics reveal important concern: high dominance risk P(w1>0.5)=0.54P(w_1 > 0.5) = 0.54. means 54% prior probability single cluster contains half sites. setting limited -site information, high dominance probability can lead overshrinkage posterior inference. dual-anchor framework allows us constrain prior reduce dominance maintaining beliefs expected number clusters. Applying dual-anchor refinement: target P(w1>0.5)=0.25P(w_1 > 0.5) = 0.25 (25% dominance probability) keeping KK primary anchor (Œª=0.7\\lambda = 0.7): Verifying improvement: Comparison K-dual-anchor priors CCT study","code":"# Apply dual-anchor to reduce dominance risk fit_cct_dual <- DPprior_dual(   fit = fit_cct,   w1_target = list(prob = list(threshold = 0.5, value = 0.25)),   lambda = 0.7,  # K remains primary anchor   loss_type = \"adaptive\",   verbose = FALSE )  cat(\"Original prior:    Gamma(a =\", round(fit_cct$a, 4),      \", b =\", round(fit_cct$b, 4), \")\\n\") #> Original prior:    Gamma(a = 0.4629 , b = 0.2556 ) cat(\"Dual-anchor prior: Gamma(a =\", round(fit_cct_dual$a, 4),      \", b =\", round(fit_cct_dual$b, 4), \")\\n\") #> Dual-anchor prior: Gamma(a = 1.0887 , b = 0.4362 ) diag_cct_dual <- DPprior_diagnostics(fit_cct_dual)  # Create comparison table comparison_df <- data.frame(   Metric = c(\"E[Œ±]\", \"E[K]\", \"Var(K)\", \"E[w‚ÇÅ]\", \"P(w‚ÇÅ > 0.5)\", \"Dominance Risk\"),   Original = c(     round(diag_cct$alpha$mean, 3),     round(diag_cct$K$mean, 2),     round(diag_cct$K$var, 2),     round(diag_cct$weights$mean, 3),     round(diag_cct$weights$prob_exceeds[\"prob_gt_0.5\"], 3),     diag_cct$weights$dominance_risk   ),   Dual_Anchor = c(     round(diag_cct_dual$alpha$mean, 3),     round(diag_cct_dual$K$mean, 2),     round(diag_cct_dual$K$var, 2),     round(diag_cct_dual$weights$mean, 3),     round(diag_cct_dual$weights$prob_exceeds[\"prob_gt_0.5\"], 3),     diag_cct_dual$weights$dominance_risk   ) )  knitr::kable(   comparison_df,   col.names = c(\"Metric\", \"K-only Prior\", \"Dual-Anchor Prior\"),   caption = \"Comparison of K-only and dual-anchor priors for the CCT study\" )"},{"path":"https://joonho112.github.io/DPprior/articles/case-studies.html","id":"comparing-k-only-vs-dual-anchor-priors","dir":"Articles","previous_headings":"1. Case Study: Conditional Cash Transfer Multisite Trial","what":"1.7 Comparing K-only vs Dual-Anchor Priors","title":"Case Studies: Multisite Trials and Meta-Analysis","text":"Let‚Äôs visualize difference two priors: Comparison K-dual-anchor priors: dual-anchor approach reduces dominance risk maintaining similar cluster count expectations. dual-anchor prior shifts mass w1w_1 distribution away extreme values (right panel) maintaining similar expected number clusters (left panel). achieves goal reducing dominance risk without substantially changing beliefs cluster count.","code":"# Prepare data for K PMF comparison logS_cct <- compute_log_stirling(J_cct)  pmf_original <- pmf_K_marginal(J_cct, fit_cct$a, fit_cct$b, logS = logS_cct) pmf_dual <- pmf_K_marginal(J_cct, fit_cct_dual$a, fit_cct_dual$b, logS = logS_cct)  k_compare_df <- data.frame(   K = rep(seq_along(pmf_original), 2),   Probability = c(pmf_original, pmf_dual),   Prior = rep(c(\"K-only\", \"Dual-anchor\"), each = length(pmf_original)) ) k_compare_df$Prior <- factor(k_compare_df$Prior, levels = c(\"K-only\", \"Dual-anchor\"))  # Prepare data for w1 comparison w1_grid <- seq(0, 1, length.out = 200) w1_dens_original <- sapply(w1_grid, function(w) density_w1(w, fit_cct$a, fit_cct$b)) w1_dens_dual <- sapply(w1_grid, function(w) density_w1(w, fit_cct_dual$a, fit_cct_dual$b))  w1_compare_df <- data.frame(   w1 = rep(w1_grid, 2),   Density = c(w1_dens_original, w1_dens_dual),   Prior = rep(c(\"K-only\", \"Dual-anchor\"), each = length(w1_grid)) ) w1_compare_df$Prior <- factor(w1_compare_df$Prior, levels = c(\"K-only\", \"Dual-anchor\"))  # Create plots p1 <- ggplot(k_compare_df[k_compare_df$K <= 15, ],               aes(x = K, y = Probability, fill = Prior)) +   geom_col(position = \"dodge\", alpha = 0.8) +   scale_fill_manual(values = palette_2) +   labs(     x = expression(K[J]),     y = \"Probability\",     title = \"Cluster Count Distribution\"   ) +   theme_minimal() +   theme(legend.position = \"bottom\", legend.title = element_blank())  p2 <- ggplot(w1_compare_df, aes(x = w1, y = Density, color = Prior)) +   geom_line(linewidth = 1) +   geom_vline(xintercept = 0.5, linetype = \"dashed\", color = \"gray50\") +   scale_color_manual(values = palette_2) +   labs(     x = expression(w[1]),     y = \"Density\",     title = \"Largest Cluster Weight Distribution\"   ) +   theme_minimal() +   theme(legend.position = \"bottom\", legend.title = element_blank())  gridExtra::grid.arrange(p1, p2, ncol = 2)"},{"path":"https://joonho112.github.io/DPprior/articles/case-studies.html","id":"sensitivity-analysis","dir":"Articles","previous_headings":"1. Case Study: Conditional Cash Transfer Multisite Trial","what":"1.8 Sensitivity Analysis","title":"Case Studies: Multisite Trials and Meta-Analysis","text":"Given uncertainty prior specification, conduct sensitivity analysis across range plausible values K-dual-anchor approaches: Sensitivity analysis: K-(K) vs Dual-anchor (DA) priors (J = 38, low confidence)","code":"# Sensitivity to Œº_K mu_K_grid <- c(3, 5, 7, 10)  sensitivity_results <- lapply(mu_K_grid, function(mu) {   # K-only fit   fit_k <- DPprior_fit(J = J_cct, mu_K = mu, confidence = \"low\")   diag_k <- DPprior_diagnostics(fit_k)      # Dual-anchor fit   fit_d <- DPprior_dual(     fit = fit_k,     w1_target = list(prob = list(threshold = 0.5, value = 0.25)),     lambda = 0.7,     loss_type = \"adaptive\",     verbose = FALSE   )   diag_d <- DPprior_diagnostics(fit_d)      data.frame(     mu_K = mu,     # K-only results     a_k = round(fit_k$a, 3),     b_k = round(fit_k$b, 3),     E_K_k = round(diag_k$K$mean, 2),     P_dom_k = round(diag_k$weights$prob_exceeds[\"prob_gt_0.5\"], 3),     # Dual-anchor results     a_d = round(fit_d$a, 3),     b_d = round(fit_d$b, 3),     E_K_d = round(diag_d$K$mean, 2),     P_dom_d = round(diag_d$weights$prob_exceeds[\"prob_gt_0.5\"], 3)   ) }) #> Warning: HIGH DOMINANCE RISK: P(w1 > 0.5) = 74.3% exceeds 40%. #>   This may indicate unintended prior behavior (Lee, 2026). #>   Consider using DPprior_dual() for weight-constrained elicitation. #>   See ?DPprior_diagnostics for interpretation. #> Warning: HIGH DOMINANCE RISK: P(w1 > 0.5) = 54.5% exceeds 40%. #>   This may indicate unintended prior behavior (Lee, 2026). #>   Consider using DPprior_dual() for weight-constrained elicitation. #>   See ?DPprior_diagnostics for interpretation.  sensitivity_df <- do.call(rbind, sensitivity_results)  knitr::kable(   sensitivity_df,   col.names = c(\"Target Œº_K\",                  \"a (K)\", \"b (K)\", \"E[K]\", \"P(w‚ÇÅ>0.5)\",                 \"a (DA)\", \"b (DA)\", \"E[K]\", \"P(w‚ÇÅ>0.5)\"),   row.names = FALSE,   caption = \"Sensitivity analysis: K-only (K) vs Dual-anchor (DA) priors (J = 38, low confidence)\" )"},{"path":"https://joonho112.github.io/DPprior/articles/case-studies.html","id":"final-prior-selection-and-reporting","dir":"Articles","previous_headings":"1. Case Study: Conditional Cash Transfer Multisite Trial","what":"1.9 Final Prior Selection and Reporting","title":"Case Studies: Multisite Trials and Meta-Analysis","text":"Based analysis, recommend dual-anchor prior CCT study, provides appropriate control dominance risk low -site information setting. Reporting language publication: elicited beliefs number latent clusters among J=38J = 38 sites CCT multisite trial. Based substantive knowledge similar education interventions uniformity implementation, specified ùîº[KJ]=5\\mathbb{E}[K_J] = 5 (approximately five distinct response patterns) low confidence. Initial diagnostics using K-calibration revealed high dominance risk P(w1>0.5)=0.54P(w_1 > 0.5) = 0.54, problematic settings limited -site information. therefore applied dual-anchor refinement targeting P(w1>0.5)‚â§0.25P(w_1 > 0.5) \\leq 0.25 Œª=0.7\\lambda = 0.7, yielding Gamma(1.089, 0.436) hyperprior. refined prior maintains ùîº[KJ]‚âà6.7\\mathbb{E}[K_J] \\approx 6.7 reducing dominance risk moderate. Sensitivity analyses across ŒºK‚àà{3,5,7,10}\\mu_K \\\\{3, 5, 7, 10\\} confirmed substantive conclusions robust prior specification.","code":"cat(\"RECOMMENDED PRIOR FOR CCT STUDY\\n\") #> RECOMMENDED PRIOR FOR CCT STUDY cat(\"================================\\n\") #> ================================ cat(\"Œ± ~ Gamma(\", round(fit_cct_dual$a, 4), \", \", round(fit_cct_dual$b, 4), \")\\n\\n\", sep = \"\") #> Œ± ~ Gamma(1.0887, 0.4362) cat(\"Key properties:\\n\") #> Key properties: cat(\"  E[K] =\", round(diag_cct_dual$K$mean, 2), \"clusters\\n\") #>   E[K] = 6.65 clusters cat(\"  P(w‚ÇÅ > 0.5) =\", round(diag_cct_dual$weights$prob_exceeds[\"prob_gt_0.5\"], 2), \"\\n\") #>   P(w‚ÇÅ > 0.5) = 0.36 cat(\"  Dominance risk:\", diag_cct_dual$weights$dominance_risk, \"\\n\") #>   Dominance risk: moderate"},{"path":[]},{"path":"https://joonho112.github.io/DPprior/articles/case-studies.html","id":"research-context-1","dir":"Articles","previous_headings":"2. Case Study: Brief Alcohol Interventions Meta-Analysis","what":"2.1 Research Context","title":"Case Studies: Multisite Trials and Meta-Analysis","text":"second case study based meta-analysis brief alcohol interventions (BAI) adolescents young adults conducted Pustejovsky & Tipton (2022), re-analyzed data Tanner-Smith & Lipsey (2015). Study characteristics: Number studies: 117 randomized trials Total effect sizes: 1,198 estimates Effect sizes per study: Median = 6, range = 1 108 Outcome: Alcohol consumption (standardized mean differences) Key feature: Complex dependence structure (correlated hierarchical)","code":""},{"path":"https://joonho112.github.io/DPprior/articles/case-studies.html","id":"the-meta-analytic-challenge","dir":"Articles","previous_headings":"2. Case Study: Brief Alcohol Interventions Meta-Analysis","what":"2.2 The Meta-Analytic Challenge","title":"Case Studies: Multisite Trials and Meta-Analysis","text":"meta-analysis, Dirichlet Process mixture model can used flexibly model distribution true study effects. particularly valuable : true effect distribution may non-Gaussian may discrete subpopulations studies similar effects Robust inference needed without strong distributional assumptions BAI meta-analysis presents setting substantial -study heterogeneity (œÑÃÇ=0.182\\hat{\\tau} = 0.182 correlated effects model), suggesting potential distinct effect subgroups.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/case-studies.html","id":"eliciting-the-prior","dir":"Articles","previous_headings":"2. Case Study: Brief Alcohol Interventions Meta-Analysis","what":"2.3 Eliciting the Prior","title":"Case Studies: Multisite Trials and Meta-Analysis","text":"Step 1: Substantive reasoning clusters BAI context, consider potential sources effect heterogeneity: Intervention type: Brief motivational interviewing vs.¬†feedback-vs.¬†multi-session programs vs.¬†computerized interventions Population: College students vs.¬†high school vs.¬†clinical samples vs.¬†community populations Outcome timing: Immediate vs.¬†short-term (3 months) vs.¬†medium-term (6 months) vs.¬†long-term (12+ months) effects Control condition: treatment vs.¬†attention control vs.¬† treatment--usual vs.¬†alternative intervention Delivery format: Individual vs.¬†group vs.¬†self-administered Setting: Healthcare vs.¬†educational vs.¬†community Given many potential mechanisms heterogeneity large number studies, reasonable expectation might 15‚Äì25 distinct effect clusters among 117 studies. start ŒºK=18\\mu_K = 18: Step 2: Expressing uncertainty Meta-analyses often uncertainty number distinct effect clusters multisite trials, studies conducted independently varying methodologies. use low confidence: Step 3: Diagnostic verification","code":"# Define the meta-analysis context J_bai <- 117 mu_K_bai <- 18  cat(\"Meta-analysis context:\\n\") #> Meta-analysis context: cat(\"  Number of studies (J):\", J_bai, \"\\n\") #>   Number of studies (J): 117 cat(\"  Expected clusters (Œº_K):\", mu_K_bai, \"\\n\") #>   Expected clusters (Œº_K): 18 cat(\"  Ratio (Œº_K/J):\", round(mu_K_bai / J_bai, 3), \"\\n\") #>   Ratio (Œº_K/J): 0.154 fit_bai <- DPprior_fit(   J = J_bai,    mu_K = mu_K_bai,    confidence = \"low\" )  print(fit_bai) #> DPprior Prior Elicitation Result #> =============================================  #>  #> Gamma Hyperprior: Œ± ~ Gamma(a = 1.9005, b = 0.2986) #>   E[Œ±] = 6.365, SD[Œ±] = 4.617 #>  #> Target (J = 117): #>   E[K_J]   = 18.00 #>   Var(K_J) = 85.00 #>   (from confidence = 'low') #>  #> Achieved: #>   E[K_J] = 18.000000, Var(K_J) = 85.000000 #>   Residual = 2.33e-12 #>  #> Method: A2-MN (6 iterations) #>  #> Dominance Risk: LOW ‚úì (P(w‚ÇÅ>0.5) = 10%) diag_bai <- DPprior_diagnostics(fit_bai)  cat(\"Diagnostic Summary:\\n\") #> Diagnostic Summary: cat(\"----------------\\n\") #> ---------------- cat(\"Alpha distribution:\\n\") #> Alpha distribution: cat(\"  E[Œ±] =\", round(diag_bai$alpha$mean, 3), \"\\n\") #>   E[Œ±] = 6.365 cat(\"  SD(Œ±) =\", round(diag_bai$alpha$sd, 3), \"\\n\") #>   SD(Œ±) = 4.617 cat(\"  95% CI: [\", round(diag_bai$alpha$quantiles[\"q5\"], 3), \", \",     round(diag_bai$alpha$quantiles[\"q95\"], 3), \"]\\n\", sep = \"\") #>   95% CI: [1.059, 15.344] cat(\"\\nCluster count:\\n\") #>  #> Cluster count: cat(\"  E[K] =\", round(diag_bai$K$mean, 3), \"\\n\") #>   E[K] = 18 cat(\"  Var(K) =\", round(diag_bai$K$var, 3), \"\\n\") #>   Var(K) = 85 cat(\"  Mode(K) =\", diag_bai$K$mode, \"\\n\") #>   Mode(K) = 14 cat(\"\\nWeight behavior:\\n\") #>  #> Weight behavior: cat(\"  E[w‚ÇÅ] =\", round(diag_bai$weights$mean, 3), \"\\n\") #>   E[w‚ÇÅ] = 0.2 cat(\"  P(w‚ÇÅ > 0.5) =\",      round(diag_bai$weights$prob_exceeds[\"prob_gt_0.5\"], 3), \"\\n\") #>   P(w‚ÇÅ > 0.5) = 0.102 cat(\"  Dominance risk:\", diag_bai$weights$dominance_risk, \"\\n\") #>   Dominance risk: low"},{"path":"https://joonho112.github.io/DPprior/articles/case-studies.html","id":"comparing-alternative-specifications","dir":"Articles","previous_headings":"2. Case Study: Brief Alcohol Interventions Meta-Analysis","what":"2.4 Comparing Alternative Specifications","title":"Case Studies: Multisite Trials and Meta-Analysis","text":"meta-analysis, valuable compare different prior specifications assess robustness. compare three approaches: expecting fewer clusters, baseline, expecting clusters. Comparison candidate priors BAI meta-analysis (J = 117)","code":"# Define three candidate priors bai_candidates <- list(   \"Conservative (Œº_K = 10)\" = DPprior_fit(J = J_bai, mu_K = 10, confidence = \"low\"),   \"Baseline (Œº_K = 18)\" = DPprior_fit(J = J_bai, mu_K = 18, confidence = \"low\"),   \"Liberal (Œº_K = 30)\" = DPprior_fit(J = J_bai, mu_K = 30, confidence = \"low\") )  # Create comparison table bai_comp_results <- lapply(names(bai_candidates), function(nm) {   fit <- bai_candidates[[nm]]   diag <- DPprior_diagnostics(fit)   data.frame(     Prior = nm,     a = round(fit$a, 3),     b = round(fit$b, 3),     E_K = round(diag$K$mean, 2),     E_w1 = round(diag$weights$mean, 3),     E_rho = round(diag$coclustering$mean, 3)   ) })  bai_comp_df <- do.call(rbind, bai_comp_results)  knitr::kable(   bai_comp_df,   col.names = c(\"Prior\", \"a\", \"b\", \"E[K]\", \"E[w‚ÇÅ]\", \"E[œÅ]\"),   caption = \"Comparison of candidate priors for the BAI meta-analysis (J = 117)\" )"},{"path":"https://joonho112.github.io/DPprior/articles/case-studies.html","id":"visualizing-the-comparison","dir":"Articles","previous_headings":"2. Case Study: Brief Alcohol Interventions Meta-Analysis","what":"2.5 Visualizing the Comparison","title":"Case Studies: Multisite Trials and Meta-Analysis","text":"Comparison three candidate priors BAI meta-analysis.","code":"# Create data for K PMF comparison logS_bai <- compute_log_stirling(J_bai)  k_bai_df <- do.call(rbind, lapply(names(bai_candidates), function(nm) {   fit <- bai_candidates[[nm]]   pmf <- pmf_K_marginal(J_bai, fit$a, fit$b, logS = logS_bai)   data.frame(     K = seq_along(pmf),     probability = pmf,     Prior = nm   ) })) k_bai_df$Prior <- factor(k_bai_df$Prior, levels = names(bai_candidates))  # Plot PMF comparison ggplot(k_bai_df[k_bai_df$K <= 50, ],         aes(x = K, y = probability, color = Prior)) +   geom_line(linewidth = 0.8) +   geom_point(size = 1.5) +   scale_color_manual(values = palette_3) +   labs(     x = expression(K[J]),     y = \"Probability\",     title = \"Prior PMF of Number of Clusters (BAI Meta-Analysis)\",     subtitle = \"J = 117 studies\"   ) +   theme_minimal() +   theme(legend.position = \"bottom\", legend.title = element_blank())"},{"path":[]},{"path":"https://joonho112.github.io/DPprior/articles/case-studies.html","id":"research-context-2","dir":"Articles","previous_headings":"3. Case Study: Alabama Pre-K Value-Added Analysis","what":"3.1 Research Context","title":"Case Studies: Multisite Trials and Meta-Analysis","text":"third case study illustrates prior elicitation large-scale value-added analysis Alabama‚Äôs pre-kindergarten program. Study characteristics: Sites: 847 pre-K sites across state Providers: 74.4% public schools, 10.4% private centers, 6.2% Head Start, others Class sizes: 13‚Äì18 students per classroom Outcomes: Six developmental domains (Literacy, Mathematics, Cognitive, Language, Social-Emotional, Physical) Assessment: Teaching Strategies GOLD¬Æ note package limitations: current version DPprior supports J‚â§500J \\leq 500 due pre-computed unsigned Stirling numbers first kind, required exact moment calculations. Support larger JJ planned future releases. 847 sites Alabama study, demonstrate workflow using J=500J = 500 practical upper bound. limitation minimal impact substantive conclusions several reasons: (1) relationship Œ±\\alpha ùîº[KJ]\\mathbb{E}[K_J] approximately logarithmic JJ, results relatively stable across nearby sample sizes; (2) using conservative (smaller) JJ tends produce slightly concentrated priors, defensible choice uncertain settings; (3) ŒºK/J\\mu_K / J ratio‚Äîrather JJ alone‚Äîprimary driver elicited prior.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/case-studies.html","id":"the-value-added-challenge","dir":"Articles","previous_headings":"3. Case Study: Alabama Pre-K Value-Added Analysis","what":"3.2 The Value-Added Challenge","title":"Case Studies: Multisite Trials and Meta-Analysis","text":"Value-added models (VAMs) estimate site-specific contributions student learning (Œ∏j\\theta_j). Key challenges context include: Distribution estimation: distribution site effects normal, distinct subpopulations? Tail identification: sites fall lowest highest 10% distribution? Ranking: Can produce meaningful ‚Äúreport cards‚Äù sites? semiparametric Dirichlet Process approach allows flexible modeling site effect distribution without imposing normality.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/case-studies.html","id":"eliciting-the-prior-1","dir":"Articles","previous_headings":"3. Case Study: Alabama Pre-K Value-Added Analysis","what":"3.3 Eliciting the Prior","title":"Case Studies: Multisite Trials and Meta-Analysis","text":"Step 1: Substantive considerations 847 sites, expect considerable heterogeneity. Potential sources clustering include: Provider type: Public schools vs.¬†private centers vs.¬†Head Start may exhibit systematically different effects Geographic region: Urban vs.¬†rural patterns Resource levels: Varying levels site resources teacher qualifications Implementation fidelity: Variation curriculum delivered reasonable expectation might 40‚Äì60 distinct ‚Äútypes‚Äù sites, representing approximately 5‚Äì7% total. specify ŒºK=50\\mu_K = 50: Step 2: Prior elicitation Step 3: Diagnostics","code":"# Define the context # Note: Using J = 500 (package maximum) for the 847-site study J_alabama <- 500 mu_K_alabama <- 50  cat(\"Alabama Pre-K context:\\n\") #> Alabama Pre-K context: cat(\"  Actual number of sites: 847\\n\") #>   Actual number of sites: 847 cat(\"  J used for elicitation:\", J_alabama, \"(package maximum)\\n\") #>   J used for elicitation: 500 (package maximum) cat(\"  Expected clusters (Œº_K):\", mu_K_alabama, \"\\n\") #>   Expected clusters (Œº_K): 50 cat(\"  Ratio (Œº_K/J):\", round(mu_K_alabama / J_alabama, 3), \"\\n\") #>   Ratio (Œº_K/J): 0.1 # Fit using A2-MN method fit_alabama <- DPprior_fit(   J = J_alabama,    mu_K = mu_K_alabama,    confidence = \"low\",   method = \"A2-MN\" )  print(fit_alabama) #> DPprior Prior Elicitation Result #> =============================================  #>  #> Gamma Hyperprior: Œ± ~ Gamma(a = 6.2200, b = 0.4431) #>   E[Œ±] = 14.038, SD[Œ±] = 5.629 #>  #> Target (J = 500): #>   E[K_J]   = 50.00 #>   Var(K_J) = 245.00 #>   (from confidence = 'low') #>  #> Achieved: #>   E[K_J] = 50.000000, Var(K_J) = 245.000000 #>   Residual = 4.56e-13 #>  #> Method: A2-MN (6 iterations) #>  #> Dominance Risk: LOW ‚úì (P(w‚ÇÅ>0.5) = 0%) diag_alabama <- DPprior_diagnostics(fit_alabama)  cat(\"Diagnostic Summary:\\n\") #> Diagnostic Summary: cat(\"----------------\\n\") #> ---------------- cat(\"Alpha distribution:\\n\") #> Alpha distribution: cat(\"  E[Œ±] =\", round(diag_alabama$alpha$mean, 3), \"\\n\") #>   E[Œ±] = 14.038 cat(\"  SD(Œ±) =\", round(diag_alabama$alpha$sd, 3), \"\\n\") #>   SD(Œ±) = 5.629 cat(\"  95% CI: [\", round(diag_alabama$alpha$quantiles[\"q5\"], 3), \", \",     round(diag_alabama$alpha$quantiles[\"q95\"], 3), \"]\\n\", sep = \"\") #>   95% CI: [6.226, 24.392] cat(\"\\nCluster count:\\n\") #>  #> Cluster count: cat(\"  E[K] =\", round(diag_alabama$K$mean, 2), \"\\n\") #>   E[K] = 50 cat(\"  SD(K) =\", round(sqrt(diag_alabama$K$var), 2), \"\\n\") #>   SD(K) = 15.65 cat(\"\\nWeight behavior:\\n\") #>  #> Weight behavior: cat(\"  E[w‚ÇÅ] =\", round(diag_alabama$weights$mean, 4), \"\\n\") #>   E[w‚ÇÅ] = 0.077 cat(\"  P(w‚ÇÅ > 0.5) =\",      round(diag_alabama$weights$prob_exceeds[\"prob_gt_0.5\"], 4), \"\\n\") #>   P(w‚ÇÅ > 0.5) = 0.0029 cat(\"  Dominance risk:\", diag_alabama$weights$dominance_risk, \"\\n\") #>   Dominance risk: low"},{"path":"https://joonho112.github.io/DPprior/articles/case-studies.html","id":"sensitivity-analysis-1","dir":"Articles","previous_headings":"3. Case Study: Alabama Pre-K Value-Added Analysis","what":"3.4 Sensitivity Analysis","title":"Case Studies: Multisite Trials and Meta-Analysis","text":"examine elicited prior changes across different specifications: Sensitivity analysis Alabama Pre-K study (J = 500)","code":"# Sensitivity to Œº_K mu_K_grid <- c(30, 40, 50, 60, 75)  sensitivity_alabama <- lapply(mu_K_grid, function(mu) {   fit <- DPprior_fit(J = J_alabama, mu_K = mu, confidence = \"low\", method = \"A2-MN\")   diag <- DPprior_diagnostics(fit)   data.frame(     mu_K = mu,     ratio = round(mu / J_alabama, 3),     a = round(fit$a, 3),     b = round(fit$b, 3),     E_K = round(diag$K$mean, 1),     P_dom = round(diag$weights$prob_exceeds[\"prob_gt_0.5\"], 4)   ) })  sensitivity_alabama_df <- do.call(rbind, sensitivity_alabama)  knitr::kable(   sensitivity_alabama_df,   col.names = c(\"Target Œº_K\", \"Œº_K/J\", \"a\", \"b\", \"E[K]\", \"P(w‚ÇÅ > 0.5)\"),   caption = \"Sensitivity analysis for the Alabama Pre-K study (J = 500)\" )"},{"path":"https://joonho112.github.io/DPprior/articles/case-studies.html","id":"visualizing-prior-behavior","dir":"Articles","previous_headings":"3. Case Study: Alabama Pre-K Value-Added Analysis","what":"3.5 Visualizing Prior Behavior","title":"Case Studies: Multisite Trials and Meta-Analysis","text":"Prior distributions Alabama Pre-K study (J = 500, Œº_K = 50).","code":"# Plot alpha and K distributions side by side # Alpha distribution alpha_grid <- seq(0.01, 25, length.out = 300) alpha_df <- data.frame(   alpha = alpha_grid,   density = dgamma(alpha_grid, shape = fit_alabama$a, rate = fit_alabama$b) )  p1 <- ggplot(alpha_df, aes(x = alpha, y = density)) +   geom_line(linewidth = 1, color = \"#377EB8\") +   geom_vline(xintercept = diag_alabama$alpha$mean,               linetype = \"dashed\", color = \"gray40\") +   annotate(\"text\", x = diag_alabama$alpha$mean + 1.5, y = max(alpha_df$density) * 0.9,            label = sprintf(\"E[Œ±] = %.1f\", diag_alabama$alpha$mean),            hjust = 0, color = \"gray40\") +   labs(     x = expression(alpha),     y = \"Density\",     title = expression(\"Prior on \" * alpha)   ) +   theme_minimal()  # K distribution logS_al <- compute_log_stirling(J_alabama) pmf_K <- pmf_K_marginal(J_alabama, fit_alabama$a, fit_alabama$b, logS = logS_al) k_df <- data.frame(   K = seq_along(pmf_K),   probability = pmf_K )  p2 <- ggplot(k_df[k_df$K <= 100 & k_df$probability > 1e-4, ],               aes(x = K, y = probability)) +   geom_col(fill = \"#377EB8\", alpha = 0.7) +   geom_vline(xintercept = diag_alabama$K$mean,               linetype = \"dashed\", color = \"gray40\") +   annotate(\"text\", x = diag_alabama$K$mean + 5, y = max(k_df$probability) * 0.9,            label = sprintf(\"E[K] = %.0f\", diag_alabama$K$mean),            hjust = 0, color = \"gray40\") +   labs(     x = expression(K[J]),     y = \"Probability\",     title = expression(\"Prior PMF of \" * K[J])   ) +   theme_minimal()  gridExtra::grid.arrange(p1, p2, ncol = 2)"},{"path":[]},{"path":"https://joonho112.github.io/DPprior/articles/case-studies.html","id":"key-elements-to-report","dir":"Articles","previous_headings":"4. Reporting Prior Elicitation in Publications","what":"4.1 Key Elements to Report","title":"Case Studies: Multisite Trials and Meta-Analysis","text":"reporting prior elicitation publication, include: Study context: Number units (JJ) nature Substantive rationale: expect certain number clusters Uncertainty characterization: Confidence level variance specification Algorithm used: A1, A2-MN, A2-KL Resulting hyperparameters: Gamma(,b)\\text{Gamma}(, b) specification Diagnostic summary: Key quantities like P(w1>0.5)P(w_1 > 0.5) dominance risk Sensitivity analysis: Results alternative specifications","code":""},{"path":"https://joonho112.github.io/DPprior/articles/case-studies.html","id":"summary","dir":"Articles","previous_headings":"","what":"Summary","title":"Case Studies: Multisite Trials and Meta-Analysis","text":"vignette demonstrated apply DPprior package across three diverse research contexts: Key Takeaways: Context matters: appropriate ŒºK\\mu_K depends substantive domain knowledge heterogeneity sources Diagnostics essential: Always verify weight behavior, just cluster counts Dual-anchor refinement: dominance risk high, use DPprior_dual() control weight behavior Sensitivity analysis mandatory: Report results across plausible alternative specifications Transparent reporting: Document complete elicitation process publications","code":""},{"path":"https://joonho112.github.io/DPprior/articles/case-studies.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Case Studies: Multisite Trials and Meta-Analysis","text":"Barrera-Osorio, F., Linden, L. L., & Saavedra, J. E. (2019). Medium- long-term educational consequences alternative conditional cash transfer designs: Experimental evidence Colombia. American Economic Journal: Applied Economics, 11(3), 54‚Äì91. https://doi.org/10.1257/app.20170008 Lee, J., Che, J., Rabe-Hesketh, S., Feller, ., & Miratrix, L. (2025). Improving estimation site-specific effects distribution multisite trials. Journal Educational Behavioral Statistics, 50(5), 731‚Äì764. https://doi.org/10.3102/10769986241254286 Pustejovsky, J. E., & Tipton, E. (2022). Meta-analysis robust variance estimation: Expanding range working models. Prevention Science, 23(3), 425‚Äì438. https://doi.org/10.1007/s11121-021-01246-3 Tanner-Smith, E. E., & Lipsey, M. W. (2015). Brief alcohol interventions adolescents young adults: systematic review meta-analysis. Journal Substance Abuse Treatment, 51, 1‚Äì18. https://doi.org/10.1016/j.jsat.2014.09.001 questions feedback, please visit GitHub repository.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/diagnostics.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Diagnosing Your Prior: Avoiding Unintended Consequences","text":"elicit Gamma hyperprior Œ±\\alpha based expectations number clusters KJK_J, implicitly specifying priors many quantities may consciously considered. ‚Äúunintended priors‚Äù can lead posterior inference unexpected directions, particularly low-information settings data overwhelm inadvertently strong prior. vignette introduces diagnostic tools DPprior package help verify prior behaves intended across relevant dimensions. end, understand: diagnostics matter: ‚Äúunintended prior‚Äù problem complete diagnostic suite available DPprior interpret Œ±\\alpha weight distribution diagnostics dominance warning system respond alerts use diagnostics iteratively refine prior","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/articles/diagnostics.html","id":"the-blind-spot-in-prior-elicitation","dir":"Articles","previous_headings":"1. Why Diagnostics Matter","what":"1.1 The Blind Spot in Prior Elicitation","title":"Diagnosing Your Prior: Avoiding Unintended Consequences","text":"standard workflow eliciting DP prior focuses cluster counts: think ŒºK\\mu_K: ‚Äúmany groups expect?‚Äù think Var(K)\\text{Var}(K): ‚Äúuncertain ?‚Äù call DPprior_fit() obtain Œ±‚àºGamma(,b)\\alpha \\sim \\text{Gamma}(, b) intuitive principled. However, elicited prior Œ±\\alpha determines just KJK_J, also: distribution Œ±\\alpha : mean, variance, shape cluster weight distribution: mass allocated across clusters co-clustering probability: likely two random observations share cluster dominance risk: probability one cluster contains data characteristics implicit consequences (,b)(, b) choice. may intended particular behavior quantities, yet prior assigns specific probabilities .","code":""},{"path":"https://joonho112.github.io/DPprior/articles/diagnostics.html","id":"the-unintended-prior-problem","dir":"Articles","previous_headings":"1. Why Diagnostics Matter","what":"1.2 The Unintended Prior Problem","title":"Diagnosing Your Prior: Avoiding Unintended Consequences","text":"Vicentini & Jermyn (2025) demonstrated matching target KJK_J distribution guarantee intuitive weight behavior. Consider concrete example: prior expects 5 clusters, substantial probability (nearly 50%) randomly selected observation belongs cluster containing half observations. intended said ‚Äúexpect 5 clusters‚Äù? researchers, think ‚Äú5 clusters,‚Äù imagine something like five roughly comparable groups‚Äîsituation one cluster might dominate entire mixture.","code":"J <- 50 mu_K <- 5  # K-only calibration with moderate uncertainty fit_K <- DPprior_fit(J = J, mu_K = mu_K, confidence = \"low\") #> Warning: HIGH DOMINANCE RISK: P(w1 > 0.5) = 56.3% exceeds 40%. #>   This may indicate unintended prior behavior (Lee, 2026). #>   Consider using DPprior_dual() for weight-constrained elicitation. #>   See ?DPprior_diagnostics for interpretation.  cat(\"K-only prior: Gamma(\", round(fit_K$a, 3), \", \", round(fit_K$b, 3), \")\\n\", sep = \"\") #> K-only prior: Gamma(0.518, 0.341) cat(\"\\nCluster count behavior:\\n\") #>  #> Cluster count behavior: cat(\"  E[K] =\", round(exact_K_moments(J, fit_K$a, fit_K$b)$mean, 2), \"\\n\") #>   E[K] = 5 cat(\"  This matches our target of\", mu_K, \"clusters.\\n\") #>   This matches our target of 5 clusters.  cat(\"\\nBut what about weight behavior?\\n\") #>  #> But what about weight behavior? cat(\"  E[w‚ÇÅ] =\", round(mean_w1(fit_K$a, fit_K$b), 3), \"\\n\") #>   E[w‚ÇÅ] = 0.585 cat(\"  P(w‚ÇÅ > 0.3) =\", round(prob_w1_exceeds(0.3, fit_K$a, fit_K$b), 3), \"\\n\") #>   P(w‚ÇÅ > 0.3) = 0.69 cat(\"  P(w‚ÇÅ > 0.5) =\", round(prob_w1_exceeds(0.5, fit_K$a, fit_K$b), 3), \"\\n\") #>   P(w‚ÇÅ > 0.5) = 0.563 cat(\"  P(w‚ÇÅ > 0.9) =\", round(prob_w1_exceeds(0.9, fit_K$a, fit_K$b), 3), \"\\n\") #>   P(w‚ÇÅ > 0.9) = 0.346"},{"path":"https://joonho112.github.io/DPprior/articles/diagnostics.html","id":"why-this-matters-in-practice","dir":"Articles","previous_headings":"1. Why Diagnostics Matter","what":"1.3 Why This Matters in Practice","title":"Diagnosing Your Prior: Avoiding Unintended Consequences","text":"unintended prior problem especially consequential low-information settings (Lee et al., 2025): Multisite trials sites: JJ moderate (20‚Äì100), site provides limited data Sparse clustering applications: observations per cluster small Exploratory analyses: don‚Äôt strong prior data inform expectations settings, posterior can remain close prior. prior inadvertently favors single dominant cluster, posterior may inherit behavior even data suggest otherwise.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/diagnostics.html","id":"the-complete-diagnostic-suite","dir":"Articles","previous_headings":"","what":"2. The Complete Diagnostic Suite","title":"Diagnosing Your Prior: Avoiding Unintended Consequences","text":"DPprior package provides comprehensive set diagnostics can access several ways.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/diagnostics.html","id":"automatic-diagnostics-during-fitting","dir":"Articles","previous_headings":"2. The Complete Diagnostic Suite","what":"2.1 Automatic Diagnostics During Fitting","title":"Diagnosing Your Prior: Avoiding Unintended Consequences","text":"simplest approach enable diagnostics fitting process: check_diagnostics = TRUE, function computes diagnostic quantities stores returned object.","code":"fit <- DPprior_fit(J = 50, mu_K = 5, var_K = 8, check_diagnostics = TRUE) #> Warning: HIGH DOMINANCE RISK: P(w1 > 0.5) = 48.1% exceeds 40%. #>   This may indicate unintended prior behavior (Lee, 2026). #>   Consider using DPprior_dual() for weight-constrained elicitation. #>   See ?DPprior_diagnostics for interpretation."},{"path":"https://joonho112.github.io/DPprior/articles/diagnostics.html","id":"post-hoc-diagnostic-computation","dir":"Articles","previous_headings":"2. The Complete Diagnostic Suite","what":"2.2 Post-Hoc Diagnostic Computation","title":"Diagnosing Your Prior: Avoiding Unintended Consequences","text":"can also compute diagnostics fitting:","code":"# Fit without diagnostics first fit <- DPprior_fit(J = 50, mu_K = 5, var_K = 8) #> Warning: HIGH DOMINANCE RISK: P(w1 > 0.5) = 48.1% exceeds 40%. #>   This may indicate unintended prior behavior (Lee, 2026). #>   Consider using DPprior_dual() for weight-constrained elicitation. #>   See ?DPprior_diagnostics for interpretation.  # Then compute diagnostics diag <- DPprior_diagnostics(fit) print(diag) #> DPprior Comprehensive Diagnostics #> ============================================================  #>  #> Prior: alpha ~ Gamma(2.0361, 1.6051) for J = 50 #>  #> alpha Distribution: #> ----------------------------------------  #>   E[alpha] = 1.269, CV(alpha) = 0.701, Median = 1.068 #>   90% CI: [0.230, 2.992] #>  #> K_J Distribution: #> ----------------------------------------  #>   E[K] = 5.00, SD(K) = 2.83, Mode = 3 #>   Median = 5, IQR = [3, 7] #>  #> w1 Distribution (Size-Biased First Weight): #> ----------------------------------------  #>   E[w1] = 0.501, Median = 0.478 #>   P(w1 > 0.5) = 48.1% (dominance risk: HIGH) #>   P(w1 > 0.9) = 16.3% #>  #> Co-Clustering (rho = sum w_h^2): #> ----------------------------------------  #>   E[rho] = 0.501 (High prior co-clustering: most unit pairs expected in same cluster) #>  #> WARNINGS: #> ----------------------------------------  #>   * HIGH DOMINANCE RISK: P(w1 > 0.5) = 48.1% exceeds 40% #>   * NEAR-DEGENERATE RISK: P(w1 > 0.9) = 16.3% exceeds 15% #>  #>   Consider using DPprior_dual() for weight-constrained elicitation."},{"path":"https://joonho112.github.io/DPprior/articles/diagnostics.html","id":"overview-of-diagnostic-components","dir":"Articles","previous_headings":"2. The Complete Diagnostic Suite","what":"2.3 Overview of Diagnostic Components","title":"Diagnosing Your Prior: Avoiding Unintended Consequences","text":"diagnostic object contains several components: Let us examine component detail.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/diagnostics.html","id":"alpha-distribution-diagnostics","dir":"Articles","previous_headings":"","what":"3. Alpha Distribution Diagnostics","title":"Diagnosing Your Prior: Avoiding Unintended Consequences","text":"first set diagnostics concerns concentration parameter Œ±\\alpha . Since Œ±‚àºGamma(,b)\\alpha \\sim \\text{Gamma}(, b), can compute moments analytically.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/diagnostics.html","id":"accessing-alpha-diagnostics","dir":"Articles","previous_headings":"3. Alpha Distribution Diagnostics","what":"3.1 Accessing Alpha Diagnostics","title":"Diagnosing Your Prior: Avoiding Unintended Consequences","text":"","code":"fit <- DPprior_fit(J = 50, mu_K = 5, var_K = 8) #> Warning: HIGH DOMINANCE RISK: P(w1 > 0.5) = 48.1% exceeds 40%. #>   This may indicate unintended prior behavior (Lee, 2026). #>   Consider using DPprior_dual() for weight-constrained elicitation. #>   See ?DPprior_diagnostics for interpretation. diag <- DPprior_diagnostics(fit)  cat(\"Alpha distribution summary:\\n\") #> Alpha distribution summary: cat(\"  Mean:     E[Œ±] =\", round(diag$alpha$mean, 4), \"\\n\") #>   Mean:     E[Œ±] = 1.2686 cat(\"  SD:       SD(Œ±) =\", round(diag$alpha$sd, 4), \"\\n\") #>   SD:       SD(Œ±) = 0.889 cat(\"  CV:       CV(Œ±) =\", round(diag$alpha$cv, 4), \"\\n\") #>   CV:       CV(Œ±) = 0.7008 cat(\"\\nQuantiles:\\n\") #>  #> Quantiles: cat(\"   5th percentile:\", round(diag$alpha$quantiles[\"q5\"], 4), \"\\n\") #>    5th percentile: 0.2305 cat(\"  25th percentile:\", round(diag$alpha$quantiles[\"q25\"], 4), \"\\n\") #>   25th percentile: 0.6155 cat(\"  50th percentile:\", round(diag$alpha$quantiles[\"q50\"], 4), \"\\n\") #>   50th percentile: 1.068 cat(\"  75th percentile:\", round(diag$alpha$quantiles[\"q75\"], 4), \"\\n\") #>   75th percentile: 1.7058 cat(\"  95th percentile:\", round(diag$alpha$quantiles[\"q95\"], 4), \"\\n\") #>   95th percentile: 2.992"},{"path":"https://joonho112.github.io/DPprior/articles/diagnostics.html","id":"interpreting-the-coefficient-of-variation","dir":"Articles","previous_headings":"3. Alpha Distribution Diagnostics","what":"3.2 Interpreting the Coefficient of Variation","title":"Diagnosing Your Prior: Avoiding Unintended Consequences","text":"coefficient variation (CV) Œ±\\alpha particularly informative: Gamma distribution, CV(Œ±)=1/\\text{CV}(\\alpha) = 1/\\sqrt{}, CV depends shape parameter aa. Different levels informativeness Œ± prior, controlled shape parameter .","code":"# Compare different CV levels a_values <- c(0.5, 1, 2, 4, 10) cv_values <- 1 / sqrt(a_values)  alpha_grid <- seq(0.01, 8, length.out = 300) cv_df <- do.call(rbind, lapply(seq_along(a_values), function(i) {   a <- a_values[i]   # Use b = a so E[alpha] = 1 for all   b <- a   data.frame(     alpha = alpha_grid,     density = dgamma(alpha_grid, shape = a, rate = b),     CV = sprintf(\"CV = %.2f (a = %.1f)\", cv_values[i], a)   ) })) cv_df$CV <- factor(cv_df$CV, levels = unique(cv_df$CV))  ggplot(cv_df, aes(x = alpha, y = density, color = CV)) +   geom_line(linewidth = 1) +   scale_color_viridis_d(option = \"plasma\", end = 0.85) +   labs(     x = expression(alpha),     y = \"Density\",     title = \"Prior Informativeness Controlled by Shape Parameter\",     subtitle = \"All priors have E[Œ±] = 1; higher a means lower CV (more informative)\"   ) +   theme_minimal() +   theme(legend.position = \"right\")"},{"path":"https://joonho112.github.io/DPprior/articles/diagnostics.html","id":"weight-distribution-diagnostics","dir":"Articles","previous_headings":"","what":"4. Weight Distribution Diagnostics","title":"Diagnosing Your Prior: Avoiding Unintended Consequences","text":"weight diagnostics crucial detecting unintended prior behavior. DPprior package provides comprehensive diagnostics first stick-breaking weight w1w_1.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/diagnostics.html","id":"understanding-w_1","dir":"Articles","previous_headings":"4. Weight Distribution Diagnostics","what":"4.1 Understanding w1w_1","title":"Diagnosing Your Prior: Avoiding Unintended Consequences","text":"Recall Dual-Anchor vignette Sethuraman‚Äôs stick-breaking representation: w1=v1,v1‚à£Œ±‚àºBeta(1,Œ±) w_1 = v_1, \\quad v_1 \\mid \\alpha \\sim \\text{Beta}(1, \\alpha) quantity w1w_1 natural interpretation: proportion cluster containing randomly selected observation. P(w1>0.5)P(w_1 > 0.5) high, random observation likely belong cluster containing half observations.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/diagnostics.html","id":"accessing-weight-diagnostics","dir":"Articles","previous_headings":"4. Weight Distribution Diagnostics","what":"4.2 Accessing Weight Diagnostics","title":"Diagnosing Your Prior: Avoiding Unintended Consequences","text":"","code":"cat(\"Weight distribution summary:\\n\") #> Weight distribution summary: cat(\"  E[w‚ÇÅ] =\", round(diag$weights$mean, 4), \"\\n\") #>   E[w‚ÇÅ] = 0.5014 cat(\"  Median(w‚ÇÅ) =\", round(diag$weights$median, 4), \"\\n\") #>   Median(w‚ÇÅ) = 0.4784  cat(\"\\nDominance tail probabilities:\\n\") #>  #> Dominance tail probabilities: cat(\"  P(w‚ÇÅ > 0.3) =\", round(diag$weights$prob_exceeds[\"prob_gt_0.3\"], 4), \"\\n\") #>   P(w‚ÇÅ > 0.3) = NA cat(\"  P(w‚ÇÅ > 0.5) =\", round(diag$weights$prob_exceeds[\"prob_gt_0.5\"], 4), \"\\n\") #>   P(w‚ÇÅ > 0.5) = 0.4815 cat(\"  P(w‚ÇÅ > 0.7) =\", round(diag$weights$prob_exceeds[\"prob_gt_0.7\"], 4), \"\\n\") #>   P(w‚ÇÅ > 0.7) = NA cat(\"  P(w‚ÇÅ > 0.9) =\", round(diag$weights$prob_exceeds[\"prob_gt_0.9\"], 4), \"\\n\") #>   P(w‚ÇÅ > 0.9) = 0.1634  cat(\"\\nDominance risk level:\", toupper(diag$weights$dominance_risk), \"\\n\") #>  #> Dominance risk level: HIGH"},{"path":"https://joonho112.github.io/DPprior/articles/diagnostics.html","id":"closed-form-calculations","dir":"Articles","previous_headings":"4. Weight Distribution Diagnostics","what":"4.3 Closed-Form Calculations","title":"Diagnosing Your Prior: Avoiding Unintended Consequences","text":"w1w_1 diagnostics computed using closed-form expressions (derived Lee, 2026, following Vicentini & Jermyn, 2025): CDF: Fw1(x‚à£,b)=1‚àí(bb‚àílog(1‚àíx))F_{w_1}(x \\mid , b) = 1 - \\left( \\frac{b}{b - \\log(1-x)} \\right)^Quantile function: Qw1(u‚à£,b)=1‚àíexp(b[1‚àí(1‚àíu)‚àí1/]) Q_{w_1}(u \\mid , b) = 1 - \\exp\\left( b \\left[ 1 - (1-u)^{-1/} \\right] \\right) Tail probability (dominance risk): P(w1>t‚à£,b)=(bb‚àílog(1‚àít))P(w_1 > t \\mid , b) = \\left( \\frac{b}{b - \\log(1-t)} \\right)^can access functions directly:","code":"a <- fit$a b <- fit$b  # Direct computation of tail probabilities cat(\"Direct computation of P(w‚ÇÅ > t):\\n\") #> Direct computation of P(w‚ÇÅ > t): for (t in c(0.3, 0.5, 0.7, 0.9)) {   p <- prob_w1_exceeds(t, a, b)   cat(sprintf(\"  P(w‚ÇÅ > %.1f) = %.4f\\n\", t, p)) } #>   P(w‚ÇÅ > 0.3) = 0.6646 #>   P(w‚ÇÅ > 0.5) = 0.4815 #>   P(w‚ÇÅ > 0.7) = 0.3200 #>   P(w‚ÇÅ > 0.9) = 0.1634  # Quantiles cat(\"\\nQuantiles of w‚ÇÅ distribution:\\n\") #>  #> Quantiles of w‚ÇÅ distribution: for (q in c(0.25, 0.5, 0.75, 0.95)) {   x <- quantile_w1(q, a, b)   cat(sprintf(\"  %d%% quantile: %.4f\\n\", round(100*q), x)) } #>   25% quantile: 0.2162 #>   50% quantile: 0.4784 #>   75% quantile: 0.7911 #>   95% quantile: 0.9954"},{"path":"https://joonho112.github.io/DPprior/articles/diagnostics.html","id":"the-dominance-warning-system","dir":"Articles","previous_headings":"","what":"5. The Dominance Warning System","title":"Diagnosing Your Prior: Avoiding Unintended Consequences","text":"DPprior package includes automatic warning system alert prior implies high probability cluster dominance.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/diagnostics.html","id":"dominance-risk-levels","dir":"Articles","previous_headings":"5. The Dominance Warning System","what":"5.1 Dominance Risk Levels","title":"Diagnosing Your Prior: Avoiding Unintended Consequences","text":"dominance risk categorized three levels based P(w1>0.5)P(w_1 > 0.5):","code":""},{"path":"https://joonho112.github.io/DPprior/articles/diagnostics.html","id":"enabling-dominance-warnings","dir":"Articles","previous_headings":"5. The Dominance Warning System","what":"5.2 Enabling Dominance Warnings","title":"Diagnosing Your Prior: Avoiding Unintended Consequences","text":"can enable automatic warnings fitting: warn_dominance = TRUE, function issue warning dominance risk HIGH.","code":"# A prior with high dominance risk fit_risky <- DPprior_fit(J = 50, mu_K = 2, var_K = 2, warn_dominance = TRUE) #> Warning: HIGH DOMINANCE RISK: P(w1 > 0.5) = 85.1% exceeds 40%. #>   This may indicate unintended prior behavior (Lee, 2026). #>   Consider using DPprior_dual() for weight-constrained elicitation. #>   See ?DPprior_diagnostics for interpretation."},{"path":"https://joonho112.github.io/DPprior/articles/diagnostics.html","id":"checking-dominance-risk-manually","dir":"Articles","previous_headings":"5. The Dominance Warning System","what":"5.3 Checking Dominance Risk Manually","title":"Diagnosing Your Prior: Avoiding Unintended Consequences","text":"can also check dominance risk diagnostic object:","code":"diag_risky <- DPprior_diagnostics(fit_risky)  cat(\"Dominance risk assessment:\\n\") #> Dominance risk assessment: cat(\"  Risk level:\", toupper(diag_risky$weights$dominance_risk), \"\\n\") #>   Risk level: HIGH cat(\"  P(w‚ÇÅ > 0.5) =\", round(diag_risky$weights$prob_exceeds[\"prob_gt_0.5\"], 4), \"\\n\") #>   P(w‚ÇÅ > 0.5) = 0.8511"},{"path":"https://joonho112.github.io/DPprior/articles/diagnostics.html","id":"what-high-dominance-means","dir":"Articles","previous_headings":"5. The Dominance Warning System","what":"5.4 What High Dominance Means","title":"Diagnosing Your Prior: Avoiding Unintended Consequences","text":"HIGH dominance risk means prior places substantial probability scenarios single cluster contains half observations. may may appropriate depending application: high dominance might appropriate: genuinely expect data fall one dominant group modeling rare events observations ‚Äúbaseline‚Äù strong prior evidence unbalanced partition high dominance likely unintended: expect roughly equal-sized clusters think ‚ÄúKK clusters‚Äù mean roughly balanced groups exploratory clustering without strong prior expectations","code":""},{"path":"https://joonho112.github.io/DPprior/articles/diagnostics.html","id":"responding-to-high-dominance-warnings","dir":"Articles","previous_headings":"5. The Dominance Warning System","what":"5.5 Responding to High Dominance Warnings","title":"Diagnosing Your Prior: Avoiding Unintended Consequences","text":"receive high dominance warning unintended, several options: Increase ŒºK\\mu_K: Expecting clusters typically reduces dominance risk Decrease Var(K)\\text{Var}(K): certainty cluster count can help Use dual-anchor elicitation: Directly constrain weight behavior demonstrate option 3 Section 7.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/diagnostics.html","id":"visualizing-diagnostics","dir":"Articles","previous_headings":"","what":"6. Visualizing Diagnostics","title":"Diagnosing Your Prior: Avoiding Unintended Consequences","text":"DPprior package provides several visualization functions understanding prior.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/diagnostics.html","id":"the-complete-dashboard","dir":"Articles","previous_headings":"6. Visualizing Diagnostics","what":"6.1 The Complete Dashboard","title":"Diagnosing Your Prior: Avoiding Unintended Consequences","text":"plot() method DPprior_fit object creates comprehensive four-panel dashboard: Complete diagnostic dashboard showing key prior characteristics.","code":"fit <- DPprior_fit(J = 50, mu_K = 5, var_K = 8) #> Warning: HIGH DOMINANCE RISK: P(w1 > 0.5) = 48.1% exceeds 40%. #>   This may indicate unintended prior behavior (Lee, 2026). #>   Consider using DPprior_dual() for weight-constrained elicitation. #>   See ?DPprior_diagnostics for interpretation. plot(fit) #> TableGrob (2 x 2) \"dpprior_dashboard\": 4 grobs #>   z     cells              name           grob #> 1 1 (1-1,1-1) dpprior_dashboard gtable[layout] #> 2 2 (2-2,1-1) dpprior_dashboard gtable[layout] #> 3 3 (1-1,2-2) dpprior_dashboard gtable[layout] #> 4 4 (2-2,2-2) dpprior_dashboard gtable[layout]"},{"path":"https://joonho112.github.io/DPprior/articles/diagnostics.html","id":"individual-diagnostic-plots","dir":"Articles","previous_headings":"6. Visualizing Diagnostics","what":"6.2 Individual Diagnostic Plots","title":"Diagnosing Your Prior: Avoiding Unintended Consequences","text":"focused analysis, can create individual plots:","code":"# Alpha prior density plot_alpha_prior(fit) # K marginal PMF plot_K_prior(fit) # w1 distribution with dominance thresholds plot_w1_prior(fit)"},{"path":"https://joonho112.github.io/DPprior/articles/diagnostics.html","id":"comparing-multiple-priors","dir":"Articles","previous_headings":"6. Visualizing Diagnostics","what":"6.3 Comparing Multiple Priors","title":"Diagnosing Your Prior: Avoiding Unintended Consequences","text":"considering different prior specifications, can visualize side side: Comparison K distributions different variance assumptions.","code":"fits <- list(   \"Low uncertainty (var_K = 6)\" = DPprior_fit(J = 50, mu_K = 5, var_K = 6),   \"Medium uncertainty (var_K = 10)\" = DPprior_fit(J = 50, mu_K = 5, var_K = 10),   \"High uncertainty (var_K = 20)\" = DPprior_fit(J = 50, mu_K = 5, var_K = 20) ) #> Warning: HIGH DOMINANCE RISK: P(w1 > 0.5) = 46.5% exceeds 40%. #>   This may indicate unintended prior behavior (Lee, 2026). #>   Consider using DPprior_dual() for weight-constrained elicitation. #>   See ?DPprior_diagnostics for interpretation. #> Warning: HIGH DOMINANCE RISK: P(w1 > 0.5) = 49.7% exceeds 40%. #>   This may indicate unintended prior behavior (Lee, 2026). #>   Consider using DPprior_dual() for weight-constrained elicitation. #>   See ?DPprior_diagnostics for interpretation. #> Warning: HIGH DOMINANCE RISK: P(w1 > 0.5) = 56.3% exceeds 40%. #>   This may indicate unintended prior behavior (Lee, 2026). #>   Consider using DPprior_dual() for weight-constrained elicitation. #>   See ?DPprior_diagnostics for interpretation.  # Compute log Stirling numbers for efficiency logS <- compute_log_stirling(50)  # Build comparison data k_df <- do.call(rbind, lapply(names(fits), function(nm) {   fit <- fits[[nm]]   pmf <- pmf_K_marginal(50, fit$a, fit$b, logS = logS)   data.frame(     K = seq_along(pmf) - 1,  # pmf_K_marginal returns k=0,...,J     probability = pmf,     Prior = nm   ) })) k_df <- k_df[k_df$K >= 1, ]  # Remove k=0 k_df$Prior <- factor(k_df$Prior, levels = names(fits))  # Plot ggplot(k_df[k_df$K <= 20, ], aes(x = K, y = probability, color = Prior)) +   geom_point(size = 2) +   geom_line(linewidth = 0.8) +   scale_color_manual(values = palette_3) +   labs(     x = expression(Number~of~clusters~K[J]),     y = \"Probability\",     title = \"Prior PMF of K Under Different Variance Assumptions\",     subtitle = \"All priors have Œº_K = 5; higher variance spreads the distribution\"   ) +   theme_minimal() +   theme(legend.position = \"bottom\", legend.title = element_blank())"},{"path":"https://joonho112.github.io/DPprior/articles/diagnostics.html","id":"diagnostic-driven-refinement","dir":"Articles","previous_headings":"","what":"7. Diagnostic-Driven Refinement","title":"Diagnosing Your Prior: Avoiding Unintended Consequences","text":"diagnostic tools enable iterative workflow refining prior matches intentions across dimensions.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/diagnostics.html","id":"the-refinement-workflow","dir":"Articles","previous_headings":"7. Diagnostic-Driven Refinement","what":"7.1 The Refinement Workflow","title":"Diagnosing Your Prior: Avoiding Unintended Consequences","text":"recommended workflow : Start K-calibration: Use DPprior_fit() expectations cluster counts Run diagnostics: Check implied behavior Œ±\\alpha, w1w_1, dominance Identify mismatches: aspect prior surprise ? Refine: Adjust parameters use dual-anchor needed Repeat: aspects prior match intentions","code":""},{"path":"https://joonho112.github.io/DPprior/articles/diagnostics.html","id":"complete-example-from-problem-to-solution","dir":"Articles","previous_headings":"7. Diagnostic-Driven Refinement","what":"7.2 Complete Example: From Problem to Solution","title":"Diagnosing Your Prior: Avoiding Unintended Consequences","text":"Let us walk complete example diagnostic-driven refinement. Step 1: Initial K-prior Step 2: Run diagnostics Step 3: Identify problem  Step 4: Apply dual-anchor refinement Step 5: Re-run diagnostics Step 6: Visualize improvement Comparison weight distributions dual-anchor refinement.","code":"# Researcher expects ~5 clusters with moderate uncertainty fit1 <- DPprior_fit(J = 50, mu_K = 5, var_K = 8) #> Warning: HIGH DOMINANCE RISK: P(w1 > 0.5) = 48.1% exceeds 40%. #>   This may indicate unintended prior behavior (Lee, 2026). #>   Consider using DPprior_dual() for weight-constrained elicitation. #>   See ?DPprior_diagnostics for interpretation.  cat(\"Step 1: Initial K-only prior\\n\") #> Step 1: Initial K-only prior cat(\"Gamma(a =\", round(fit1$a, 4), \", b =\", round(fit1$b, 4), \")\\n\\n\") #> Gamma(a = 2.0361 , b = 1.6051 ) diag1 <- DPprior_diagnostics(fit1)  cat(\"Step 2: Diagnostics reveal...\\n\") #> Step 2: Diagnostics reveal... cat(\"  K behavior: E[K] =\", round(diag1$K$mean, 2),      \", Var(K) =\", round(diag1$K$var, 2), \"‚úì\\n\") #>   K behavior: E[K] = 5 , Var(K) = 8 ‚úì cat(\"  Weight behavior: P(w‚ÇÅ > 0.5) =\",      round(diag1$weights$prob_exceeds[\"prob_gt_0.5\"], 3), \"\\n\") #>   Weight behavior: P(w‚ÇÅ > 0.5) = 0.481 cat(\"  Dominance risk:\", toupper(diag1$weights$dominance_risk), \"\\n\") #>   Dominance risk: HIGH plot_w1_prior(fit1) #> Step 3: Problem identification #>   The researcher wanted: ~5 clusters with balanced weights #>   The prior implies: ~5 clusters but high chance of one dominant cluster #>   P(w‚ÇÅ > 0.5) = 48 % is higher than expected for 'balanced' clusters cat(\"Step 4: Dual-anchor refinement\\n\") #> Step 4: Dual-anchor refinement cat(\"  Adding constraint: P(w‚ÇÅ > 0.5) ‚â§ 0.25\\n\\n\") #>   Adding constraint: P(w‚ÇÅ > 0.5) ‚â§ 0.25  fit2 <- DPprior_dual(   fit = fit1,   w1_target = list(prob = list(threshold = 0.5, value = 0.25)),   lambda = 0.7,   loss_type = \"adaptive\",   verbose = FALSE )  cat(\"Refined prior: Gamma(a =\", round(fit2$a, 4), \", b =\", round(fit2$b, 4), \")\\n\") #> Refined prior: Gamma(a = 4.3948 , b = 2.5043 ) diag2 <- DPprior_diagnostics(fit2)  cat(\"Step 5: Post-refinement diagnostics\\n\") #> Step 5: Post-refinement diagnostics cat(\"  K behavior: E[K] =\", round(diag2$K$mean, 2),      \" (shifted from target of 5)\\n\") #>   K behavior: E[K] = 6.3  (shifted from target of 5) cat(\"  Weight behavior: P(w‚ÇÅ > 0.5) =\",      round(diag2$weights$prob_exceeds[\"prob_gt_0.5\"], 3), \"‚úì\\n\") #>   Weight behavior: P(w‚ÇÅ > 0.5) = 0.342 ‚úì cat(\"  Dominance risk:\", toupper(diag2$weights$dominance_risk), \"‚úì\\n\") #>   Dominance risk: MODERATE ‚úì # Compare w1 distributions x_grid <- seq(0.001, 0.999, length.out = 500) w1_df <- data.frame(   x = rep(x_grid, 2),   density = c(     density_w1(x_grid, fit1$a, fit1$b),     density_w1(x_grid, fit2$a, fit2$b)   ),   Prior = rep(c(\"K-only (before)\", \"Dual-anchor (after)\"), each = length(x_grid)) ) w1_df$Prior <- factor(w1_df$Prior, levels = c(\"K-only (before)\", \"Dual-anchor (after)\"))  # Cap extreme densities for visualization w1_df$density[w1_df$density > 10] <- NA  ggplot(w1_df, aes(x = x, y = density, color = Prior)) +   geom_line(linewidth = 1, na.rm = TRUE) +   geom_vline(xintercept = 0.5, linetype = \"dashed\", color = \"gray50\") +   scale_color_manual(values = c(\"#E41A1C\", \"#377EB8\")) +   annotate(\"text\", x = 0.52, y = 5, label = \"P(w‚ÇÅ > 0.5)\", hjust = 0, color = \"gray40\") +   labs(     x = expression(w[1]),     y = \"Density\",     title = \"Weight Distribution: Before and After Dual-Anchor Refinement\",     subtitle = sprintf(\"P(w‚ÇÅ > 0.5): Before = %.0f%%, After = %.0f%%\",                        100 * diag1$weights$prob_exceeds[\"prob_gt_0.5\"],                        100 * diag2$weights$prob_exceeds[\"prob_gt_0.5\"])   ) +   coord_cartesian(xlim = c(0, 1), ylim = c(0, 6)) +   theme_minimal() +   theme(legend.position = \"bottom\", legend.title = element_blank())"},{"path":"https://joonho112.github.io/DPprior/articles/diagnostics.html","id":"summary-of-the-refinement","dir":"Articles","previous_headings":"7. Diagnostic-Driven Refinement","what":"7.3 Summary of the Refinement","title":"Diagnosing Your Prior: Avoiding Unintended Consequences","text":"Comparison prior specifications dual-anchor refinement trade-clear: refined prior slightly higher E[K] original target 5, now appropriately controlled weight behavior. Pareto trade-dual-anchor framework makes explicit.","code":"comparison_df <- data.frame(   Metric = c(\"Gamma(a, b)\", \"E[K]\", \"Var(K)\", \"E[w‚ÇÅ]\",               \"P(w‚ÇÅ > 0.5)\", \"Dominance Risk\"),   Before = c(     sprintf(\"(%.3f, %.3f)\", fit1$a, fit1$b),     sprintf(\"%.2f\", diag1$K$mean),     sprintf(\"%.2f\", diag1$K$var),     sprintf(\"%.3f\", diag1$weights$mean),     sprintf(\"%.1f%%\", 100 * diag1$weights$prob_exceeds[\"prob_gt_0.5\"]),     toupper(diag1$weights$dominance_risk)   ),   After = c(     sprintf(\"(%.3f, %.3f)\", fit2$a, fit2$b),     sprintf(\"%.2f\", diag2$K$mean),     sprintf(\"%.2f\", diag2$K$var),     sprintf(\"%.3f\", diag2$weights$mean),     sprintf(\"%.1f%%\", 100 * diag2$weights$prob_exceeds[\"prob_gt_0.5\"]),     toupper(diag2$weights$dominance_risk)   ) )  knitr::kable(   comparison_df,   col.names = c(\"Metric\", \"K-only\", \"Dual-anchor\"),   caption = \"Comparison of prior specifications before and after dual-anchor refinement\" )"},{"path":"https://joonho112.github.io/DPprior/articles/diagnostics.html","id":"comparative-diagnostics","dir":"Articles","previous_headings":"","what":"8. Comparative Diagnostics","title":"Diagnosing Your Prior: Avoiding Unintended Consequences","text":"evaluating multiple candidate priors, comparative diagnostics help understand trade-offs.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/diagnostics.html","id":"comparing-multiple-priors-1","dir":"Articles","previous_headings":"8. Comparative Diagnostics","what":"8.1 Comparing Multiple Priors","title":"Diagnosing Your Prior: Avoiding Unintended Consequences","text":"Comparative diagnostics three candidate priors","code":"# Define three candidate priors candidates <- list(   \"Conservative\" = DPprior_fit(J = 50, mu_K = 5, var_K = 6),   \"Moderate\" = DPprior_fit(J = 50, mu_K = 5, var_K = 10),   \"Diffuse\" = DPprior_fit(J = 50, mu_K = 5, var_K = 20) ) #> Warning: HIGH DOMINANCE RISK: P(w1 > 0.5) = 46.5% exceeds 40%. #>   This may indicate unintended prior behavior (Lee, 2026). #>   Consider using DPprior_dual() for weight-constrained elicitation. #>   See ?DPprior_diagnostics for interpretation. #> Warning: HIGH DOMINANCE RISK: P(w1 > 0.5) = 49.7% exceeds 40%. #>   This may indicate unintended prior behavior (Lee, 2026). #>   Consider using DPprior_dual() for weight-constrained elicitation. #>   See ?DPprior_diagnostics for interpretation. #> Warning: HIGH DOMINANCE RISK: P(w1 > 0.5) = 56.3% exceeds 40%. #>   This may indicate unintended prior behavior (Lee, 2026). #>   Consider using DPprior_dual() for weight-constrained elicitation. #>   See ?DPprior_diagnostics for interpretation.  # Compute diagnostics for each comp_results <- lapply(names(candidates), function(nm) {   fit <- candidates[[nm]]   diag <- DPprior_diagnostics(fit)   data.frame(     Prior = nm,     a = round(fit$a, 3),     b = round(fit$b, 3),     E_K = round(diag$K$mean, 2),     Var_K = round(diag$K$var, 2),     E_w1 = round(diag$weights$mean, 3),     P_w1_gt_50 = sprintf(\"%.1f%%\", 100 * diag$weights$prob_exceeds[\"prob_gt_0.5\"]),     Risk = toupper(diag$weights$dominance_risk)   ) })  comp_df <- do.call(rbind, comp_results)  knitr::kable(   comp_df,   col.names = c(\"Prior\", \"a\", \"b\", \"E[K]\", \"Var(K)\", \"E[w‚ÇÅ]\", \"P(w‚ÇÅ>0.5)\", \"Risk\"),   caption = \"Comparative diagnostics for three candidate priors\" )"},{"path":"https://joonho112.github.io/DPprior/articles/diagnostics.html","id":"visualizing-the-comparison","dir":"Articles","previous_headings":"8. Comparative Diagnostics","what":"8.2 Visualizing the Comparison","title":"Diagnosing Your Prior: Avoiding Unintended Consequences","text":"Comparison three candidate priors across multiple dimensions.","code":"# Create comparison data for w1 w1_comp_df <- do.call(rbind, lapply(names(candidates), function(nm) {   fit <- candidates[[nm]]   x <- seq(0.001, 0.999, length.out = 300)   d <- density_w1(x, fit$a, fit$b)   d[d > 8] <- NA   data.frame(x = x, density = d, Prior = nm) })) w1_comp_df$Prior <- factor(w1_comp_df$Prior, levels = names(candidates))  p1 <- ggplot(w1_comp_df, aes(x = x, y = density, color = Prior)) +   geom_line(linewidth = 1, na.rm = TRUE) +   geom_vline(xintercept = 0.5, linetype = \"dashed\", color = \"gray60\") +   scale_color_manual(values = palette_3) +   coord_cartesian(xlim = c(0, 1), ylim = c(0, 5)) +   labs(x = expression(w[1]), y = \"Density\",         title = expression(\"Prior on \" * w[1])) +   theme_minimal() +   theme(legend.position = \"bottom\", legend.title = element_blank())  # Create comparison data for K logS <- compute_log_stirling(50) k_comp_df <- do.call(rbind, lapply(names(candidates), function(nm) {   fit <- candidates[[nm]]   pmf <- pmf_K_marginal(50, fit$a, fit$b, logS = logS)   data.frame(k = seq_along(pmf) - 1, pmf = pmf, Prior = nm) })) k_comp_df <- k_comp_df[k_comp_df$k >= 1, ] k_comp_df$Prior <- factor(k_comp_df$Prior, levels = names(candidates))  p2 <- ggplot(k_comp_df[k_comp_df$k <= 15, ],               aes(x = k, y = pmf, color = Prior)) +   geom_point(size = 2) +   geom_line(linewidth = 0.8) +   scale_color_manual(values = palette_3) +   labs(x = expression(K[J]), y = \"Probability\",         title = expression(\"Prior PMF of \" * K[J])) +   theme_minimal() +   theme(legend.position = \"bottom\", legend.title = element_blank())  gridExtra::grid.arrange(p1, p2, ncol = 2)"},{"path":"https://joonho112.github.io/DPprior/articles/diagnostics.html","id":"summary","dir":"Articles","previous_headings":"","what":"Summary","title":"Diagnosing Your Prior: Avoiding Unintended Consequences","text":"Key Takeaways: Always run diagnostics eliciting prior, especially weight-related quantities K-calibration necessary sufficient: matching E[K] guarantee intuitive weight behavior Use dominance warning system catch potential problems early Apply dual-anchor refinement need constrain weight behavior explicitly Iterate satisfied: prior elicitation iterative process","code":""},{"path":"https://joonho112.github.io/DPprior/articles/diagnostics.html","id":"whats-next","dir":"Articles","previous_headings":"","what":"What‚Äôs Next?","title":"Diagnosing Your Prior: Avoiding Unintended Consequences","text":"Dual-Anchor Framework: Deep dive controlling cluster counts weight behavior Case Studies: Real-world examples diagnostic-driven prior refinement Theory Overview: Mathematical foundations diagnostic quantities","code":""},{"path":"https://joonho112.github.io/DPprior/articles/diagnostics.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Diagnosing Your Prior: Avoiding Unintended Consequences","text":"Lee, J., Che, J., Rabe-Hesketh, S., Feller, ., & Miratrix, L. (2025). Improving estimation site-specific effects distribution multisite trials. Journal Educational Behavioral Statistics, 50(5), 731‚Äì764. https://doi.org/10.3102/10769986241254286 Vicentini, S., & Jermyn, . H. (2025). Prior selection precision parameter Dirichlet process mixture models. arXiv:2502.00864. https://doi.org/10.48550/arXiv.2502.00864 Sethuraman, J. (1994). constructive definition Dirichlet priors. Statistica Sinica, 4(2), 639‚Äì650. questions feedback, please visit GitHub repository.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/dual-anchor.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Beyond Cluster Counts: Dual-Anchor Elicitation for Weight Control","text":"previous vignettes focused calibrating Gamma hyperprior Œ±\\alpha based expectations number clusters KJK_J. approach intuitive: specify many groups expect, DPprior package finds corresponding prior Œ±\\alpha. However, Vicentini & Jermyn (2025) pointed , matching KJK_J alone can lead unintended prior behavior cluster weights. Specifically, prior produces ‚Äúright‚Äù expected number clusters may simultaneously imply high probability single cluster dominates entire mixture. vignette introduces dual-anchor framework, allows control : Anchor 1: number occupied clusters KJK_J () Anchor 2: weight-related quantity (e.g., w1w_1 œÅ\\rho) captures mass distributed across clusters end vignette, understand: K-calibration can produce surprising weight behavior Two key weight anchors: w1w_1 œÅ\\rho (co-clustering probability) use DPprior_dual() dual-anchor elicitation choose different anchors Œª\\lambda values","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/articles/dual-anchor.html","id":"what-k-only-calibration-misses","dir":"Articles","previous_headings":"1. The Hidden Problem: Unintended Weight Priors","what":"1.1 What K-Only Calibration Misses","title":"Beyond Cluster Counts: Dual-Anchor Elicitation for Weight Control","text":"Consider researcher analyzing multisite educational trial 50 sites, expecting treatment effects cluster approximately 5 distinct patterns. Using K-calibration approach Applied Guide, obtain: fit looks reasonable: prior expects 5 clusters appropriate uncertainty. prior imply mass distributed across clusters? key insight: even though expect 5 clusters average, substantial probability (nearly 50%!) randomly selected unit belongs cluster containing half units. much concentrated many researchers intuitively expect ‚Äú5 clusters.‚Äù","code":"J <- 50 mu_K <- 5  fit_K <- DPprior_fit(J = J, mu_K = mu_K, confidence = \"low\") #> Warning: HIGH DOMINANCE RISK: P(w1 > 0.5) = 56.3% exceeds 40%. #>   This may indicate unintended prior behavior (Lee, 2026). #>   Consider using DPprior_dual() for weight-constrained elicitation. #>   See ?DPprior_diagnostics for interpretation. print(fit_K) #> DPprior Prior Elicitation Result #> =============================================  #>  #> Gamma Hyperprior: Œ± ~ Gamma(a = 0.5178, b = 0.3410) #>   E[Œ±] = 1.519, SD[Œ±] = 2.110 #>  #> Target (J = 50): #>   E[K_J]   = 5.00 #>   Var(K_J) = 20.00 #>   (from confidence = 'low') #>  #> Achieved: #>   E[K_J] = 5.000000, Var(K_J) = 20.000000 #>   Residual = 9.51e-09 #>  #> Method: A2-MN (10 iterations) #>  #> Dominance Risk: HIGH ‚úò (P(w‚ÇÅ>0.5) = 56%) # Examine the implied weight behavior cat(\"Weight diagnostics for K-only prior:\\n\") #> Weight diagnostics for K-only prior: cat(\"  E[w‚ÇÅ] =\", round(mean_w1(fit_K$a, fit_K$b), 3), \"\\n\") #>   E[w‚ÇÅ] = 0.585 cat(\"  P(w‚ÇÅ > 0.3) =\", round(prob_w1_exceeds(0.3, fit_K$a, fit_K$b), 3), \"\\n\") #>   P(w‚ÇÅ > 0.3) = 0.69 cat(\"  P(w‚ÇÅ > 0.5) =\", round(prob_w1_exceeds(0.5, fit_K$a, fit_K$b), 3), \"\\n\") #>   P(w‚ÇÅ > 0.5) = 0.563 cat(\"  P(w‚ÇÅ > 0.9) =\", round(prob_w1_exceeds(0.9, fit_K$a, fit_K$b), 3), \"\\n\") #>   P(w‚ÇÅ > 0.9) = 0.346"},{"path":"https://joonho112.github.io/DPprior/articles/dual-anchor.html","id":"why-does-this-happen","dir":"Articles","previous_headings":"1. The Hidden Problem: Unintended Weight Priors","what":"1.2 Why Does This Happen?","title":"Beyond Cluster Counts: Dual-Anchor Elicitation for Weight Control","text":"relationship KJK_J cluster weights tight one might expect. expected number clusters follows approximately: ùîº[KJ‚à£Œ±]‚âà1+Œ±logJ \\mathbb{E}[K_J \\mid \\alpha] \\approx 1 + \\alpha \\log J expected first stick-breaking weight : ùîº[w1‚à£Œ±]=11+Œ± \\mathbb{E}[w_1 \\mid \\alpha] = \\frac{1}{1 + \\alpha} J=50J = 50 expected cluster count around 5, need Œ±‚âà1\\alpha \\approx 1, implies ùîº[w1‚à£Œ±]‚âà0.5\\mathbb{E}[w_1 \\mid \\alpha] \\approx 0.5. Œ±\\alpha random Gamma hyperprior, tails Œ±\\alpha distribution can induce extreme weight behavior: small Œ±\\alpha values lead w1w_1 close 1, large Œ±\\alpha values fragment weights. Œ± small, w‚ÇÅ concentrates near 1; Œ± large, w‚ÇÅ concentrates near 0. diffuse prior Œ± spans extremes.","code":"# Illustrate the conditional relationship alpha_grid <- c(0.5, 1, 2, 5, 10, 20) w_grid <- seq(0.01, 0.99, length.out = 200)  cond_df <- do.call(rbind, lapply(alpha_grid, function(a) {   data.frame(     w = w_grid,     density = dbeta(w_grid, 1, a),     alpha = paste0(\"Œ± = \", a)   ) })) cond_df$alpha <- factor(cond_df$alpha, levels = paste0(\"Œ± = \", alpha_grid))  ggplot(cond_df, aes(x = w, y = density, color = alpha)) +   geom_line(linewidth = 0.8) +   scale_color_viridis_d(option = \"plasma\", end = 0.85) +   labs(     x = expression(w[1]),     y = \"Conditional Density\",     title = expression(\"Conditional Distribution of \" * w[1] * \" | \" * alpha),     color = NULL   ) +   theme_minimal() +   theme(legend.position = \"right\")"},{"path":"https://joonho112.github.io/DPprior/articles/dual-anchor.html","id":"understanding-weight-distributions","dir":"Articles","previous_headings":"","what":"2. Understanding Weight Distributions","title":"Beyond Cluster Counts: Dual-Anchor Elicitation for Weight Control","text":"diving dual-anchor calibration, let us examine two weight anchors available DPprior package.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/dual-anchor.html","id":"stick-breaking-weights-refresher","dir":"Articles","previous_headings":"2. Understanding Weight Distributions","what":"2.1 Stick-Breaking Weights Refresher","title":"Beyond Cluster Counts: Dual-Anchor Elicitation for Weight Control","text":"Sethuraman‚Äôs stick-breaking representation Dirichlet Process, random mixing measure GG : G=‚àëh=1‚àûwhŒ¥Œ∏h G = \\sum_{h=1}^{\\infty} w_h \\, \\delta_{\\theta_h} weights constructed via: vh‚àºiidBeta(1,Œ±),w1=v1,wh=vh‚àè‚Ñì<h(1‚àív‚Ñì)(h‚â•2) v_h \\overset{iid}{\\sim} \\text{Beta}(1, \\alpha), \\quad  w_1 = v_1, \\quad  w_h = v_h \\prod_{\\ell < h} (1 - v_\\ell) \\quad (h \\geq 2) sequence (w1,w2,‚Ä¶)(w_1, w_2, \\ldots) follows GEM(Œ±\\alpha) distribution size-biased order, ranked magnitude.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/dual-anchor.html","id":"anchor-2a-the-first-stick-breaking-weight-w_1","dir":"Articles","previous_headings":"2. Understanding Weight Distributions","what":"2.2 Anchor 2a: The First Stick-Breaking Weight (w1w_1)","title":"Beyond Cluster Counts: Dual-Anchor Elicitation for Weight Control","text":"first weight w1w_1 particularly tractable distribution. Conditionally, w1‚à£Œ±‚àºBeta(1,Œ±)w_1 \\mid \\alpha \\sim \\text{Beta}(1, \\alpha). hyperprior Œ±‚àºGamma(,b)\\alpha \\sim \\text{Gamma}(, b), marginal distribution w1w_1 fully closed-form expressions: CDF: Fw1(x‚à£,b)=1‚àí(bb‚àílog(1‚àíx))F_{w_1}(x \\mid , b) = 1 - \\left( \\frac{b}{b - \\log(1-x)} \\right)^Quantile function: Qw1(u‚à£,b)=1‚àíexp(b[1‚àí(1‚àíu)‚àí1/]) Q_{w_1}(u \\mid , b) = 1 - \\exp\\left( b \\left[ 1 - (1-u)^{-1/} \\right] \\right) Survival function (dominance risk): P(w1>t‚à£,b)=(bb‚àílog(1‚àít))P(w_1 > t \\mid , b) = \\left( \\frac{b}{b - \\log(1-t)} \\right)^Important interpretability caveat: w1w_1 GEM (size-biased) order, largest cluster weight. faithful interpretation : ‚Äúw1w_1 asymptotic proportion cluster containing randomly selected unit.‚Äù still meaningful dominance diagnostic‚ÄîP(w1>0.5)P(w_1 > 0.5) high, randomly selected unit likely belong cluster contains half population.","code":"# Using the closed-form w1 functions a <- fit_K$a b <- fit_K$b  cat(\"w‚ÇÅ distribution under K-only prior:\\n\") #> w‚ÇÅ distribution under K-only prior: cat(\"  Mean:     \", round(mean_w1(a, b), 4), \"\\n\") #>   Mean:      0.5854 cat(\"  Variance: \", round(var_w1(a, b), 4), \"\\n\") #>   Variance:  0.1331 cat(\"  Median:   \", round(quantile_w1(0.5, a, b), 4), \"\\n\") #>   Median:    0.6169 cat(\"  90th %ile:\", round(quantile_w1(0.9, a, b), 4), \"\\n\") #>   90th %ile: 1 cat(\"\\nDominance risk:\\n\") #>  #> Dominance risk: cat(\"  P(w‚ÇÅ > 0.3):\", round(prob_w1_exceeds(0.3, a, b), 4), \"\\n\") #>   P(w‚ÇÅ > 0.3): 0.6903 cat(\"  P(w‚ÇÅ > 0.5):\", round(prob_w1_exceeds(0.5, a, b), 4), \"\\n\") #>   P(w‚ÇÅ > 0.5): 0.563 cat(\"  P(w‚ÇÅ > 0.9):\", round(prob_w1_exceeds(0.9, a, b), 4), \"\\n\") #>   P(w‚ÇÅ > 0.9): 0.3463"},{"path":"https://joonho112.github.io/DPprior/articles/dual-anchor.html","id":"anchor-2b-co-clustering-probability-rho","dir":"Articles","previous_headings":"2. Understanding Weight Distributions","what":"2.3 Anchor 2b: Co-Clustering Probability (œÅ\\rho)","title":"Beyond Cluster Counts: Dual-Anchor Elicitation for Weight Control","text":"co-clustering probability defined : œÅ=‚àëh=1‚àûwh2 \\rho = \\sum_{h=1}^{\\infty} w_h^2 natural interpretation: œÅ\\rho equals probability two randomly selected units belong cluster. may intuitive applied researchers elicit. conditional moments simple: ùîº[œÅ‚à£Œ±]=11+Œ±,Var(œÅ‚à£Œ±)=2Œ±(1+Œ±)2(2+Œ±)(3+Œ±) \\mathbb{E}[\\rho \\mid \\alpha] = \\frac{1}{1 + \\alpha}, \\quad \\text{Var}(\\rho \\mid \\alpha) = \\frac{2\\alpha}{(1+\\alpha)^2(2+\\alpha)(3+\\alpha)} Note ùîº[œÅ‚à£Œ±]=ùîº[w1‚à£Œ±]\\mathbb{E}[\\rho \\mid \\alpha] = \\mathbb{E}[w_1 \\mid \\alpha], means equal, full distributions differ.","code":"# Using the rho (co-clustering) functions cat(\"Co-clustering probability œÅ under K-only prior:\\n\") #> Co-clustering probability œÅ under K-only prior: cat(\"  E[œÅ]:     \", round(mean_rho(a, b), 4), \"\\n\") #>   E[œÅ]:      0.5854 cat(\"  Var(œÅ):   \", round(var_rho(a, b), 6), \"\\n\") #>   Var(œÅ):    0.107831 cat(\"  SD(œÅ):    \", round(sqrt(var_rho(a, b)), 4), \"\\n\") #>   SD(œÅ):     0.3284  # Compare with w1 cat(\"\\nNote: E[w‚ÇÅ] = E[œÅ] =\", round(mean_w1(a, b), 4), \"\\n\") #>  #> Note: E[w‚ÇÅ] = E[œÅ] = 0.5854 cat(\"But: Var(w‚ÇÅ) =\", round(var_w1(a, b), 4), \"‚â† Var(œÅ) =\",      round(var_rho(a, b), 6), \"\\n\") #> But: Var(w‚ÇÅ) = 0.1331 ‚â† Var(œÅ) = 0.107831"},{"path":[]},{"path":"https://joonho112.github.io/DPprior/articles/dual-anchor.html","id":"the-core-idea","dir":"Articles","previous_headings":"3. The Dual-Anchor Framework","what":"3.1 The Core Idea","title":"Beyond Cluster Counts: Dual-Anchor Elicitation for Weight Control","text":"dual-anchor framework finds Gamma hyperparameters (,b)(, b) satisfy two types constraints simultaneously: Anchor 1: Match beliefs KJK_J (number clusters) Anchor 2: Match beliefs weight quantity T‚àà{w1,œÅ}T \\\\{w_1, \\rho\\} formalized optimization problem: (*,b*)=argmina>0,b>0[Œª‚ãÖLK(,b)+(1‚àíŒª)‚ãÖLw(,b)] (^*, b^*) = \\arg\\min_{> 0, b > 0} \\left[    \\lambda \\cdot L_K(, b) +    (1 - \\lambda) \\cdot L_w(, b)  \\right] LKL_K measures discrepancy K target LwL_w measures discrepancy weight target.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/dual-anchor.html","id":"the-role-of-lambda","dir":"Articles","previous_headings":"3. The Dual-Anchor Framework","what":"3.2 The Role of Œª\\lambda","title":"Beyond Cluster Counts: Dual-Anchor Elicitation for Weight Control","text":"parameter Œª‚àà[0,1]\\lambda \\[0, 1] controls trade-two anchors: applications, recommend Œª‚àà[0.5,0.9]\\lambda \\[0.5, 0.9], keeping cluster count primary anchor using weight constraint avoid unintended dominance behavior.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/dual-anchor.html","id":"loss-types-balancing-the-two-anchors","dir":"Articles","previous_headings":"3. The Dual-Anchor Framework","what":"3.3 Loss Types: Balancing the Two Anchors","title":"Beyond Cluster Counts: Dual-Anchor Elicitation for Weight Control","text":"critical implementation detail scale two loss components. DPprior_dual() function offers three loss_type options: matter? K-anchor loss weight-anchor loss measured different units. Without proper scaling, optimizer may effectively ignore one anchors. \"adaptive\" option particularly useful want Œª=0.5\\lambda = 0.5 produce meaningful compromise two anchors.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/dual-anchor.html","id":"using-dpprior_dual-for-dual-anchor-elicitation","dir":"Articles","previous_headings":"","what":"4. Using DPprior_dual() for Dual-Anchor Elicitation","title":"Beyond Cluster Counts: Dual-Anchor Elicitation for Weight Control","text":"DPprior_dual() function refines K-calibrated prior also satisfy weight constraints.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/dual-anchor.html","id":"basic-usage-probability-constraint","dir":"Articles","previous_headings":"4. Using DPprior_dual() for Dual-Anchor Elicitation","what":"4.1 Basic Usage: Probability Constraint","title":"Beyond Cluster Counts: Dual-Anchor Elicitation for Weight Control","text":"Suppose want ensure probability extreme dominance limited. Specifically, want P(w1>0.5)‚â§0.25P(w_1 > 0.5) \\leq 0.25: Let us visualize effect KJK_J w1w_1 distributions: Comparison K-vs dual-anchor priors: dual-anchor approach shifts mass away extreme w‚ÇÅ values maintaining similar K expectations.","code":"# Step 1: Start with K-only calibration fit_K <- DPprior_fit(J = 50, mu_K = 5, confidence = \"low\") #> Warning: HIGH DOMINANCE RISK: P(w1 > 0.5) = 56.3% exceeds 40%. #>   This may indicate unintended prior behavior (Lee, 2026). #>   Consider using DPprior_dual() for weight-constrained elicitation. #>   See ?DPprior_diagnostics for interpretation.  cat(\"K-only prior:\\n\") #> K-only prior: cat(\"  Gamma(\", round(fit_K$a, 3), \",\", round(fit_K$b, 3), \")\\n\") #>   Gamma( 0.518 , 0.341 ) cat(\"  P(w‚ÇÅ > 0.5) =\", round(prob_w1_exceeds(0.5, fit_K$a, fit_K$b), 3), \"\\n\\n\") #>   P(w‚ÇÅ > 0.5) = 0.563  # Step 2: Apply dual-anchor constraint with adaptive loss fit_dual <- DPprior_dual(   fit = fit_K,   w1_target = list(prob = list(threshold = 0.5, value = 0.25)),   lambda = 0.7,   loss_type = \"adaptive\",  # More aggressive weight control   verbose = FALSE )  cat(\"Dual-anchor prior (adaptive):\\n\") #> Dual-anchor prior (adaptive): cat(\"  Gamma(\", round(fit_dual$a, 3), \",\", round(fit_dual$b, 3), \")\\n\") #>   Gamma( 1.403 , 0.626 ) cat(\"  P(w‚ÇÅ > 0.5) =\", round(prob_w1_exceeds(0.5, fit_dual$a, fit_dual$b), 3), \"\\n\") #>   P(w‚ÇÅ > 0.5) = 0.351 # Prepare data for visualization logS <- compute_log_stirling(J)  # K distributions k_grid <- 1:20 k_df <- data.frame(   K = rep(k_grid, 2),   probability = c(     pmf_K_marginal(J, fit_K$a, fit_K$b, logS = logS)[k_grid],     pmf_K_marginal(J, fit_dual$a, fit_dual$b, logS = logS)[k_grid]   ),   Prior = rep(c(\"K-only\", \"Dual-anchor\"), each = length(k_grid)) )  # w1 distributions w_grid <- seq(0.01, 0.95, length.out = 200) w_df <- data.frame(   w1 = rep(w_grid, 2),   density = c(     density_w1(w_grid, fit_K$a, fit_K$b),     density_w1(w_grid, fit_dual$a, fit_dual$b)   ),   Prior = rep(c(\"K-only\", \"Dual-anchor\"), each = length(w_grid)) )  # Create plots p1 <- ggplot(k_df, aes(x = K, y = probability, color = Prior)) +   geom_point(size = 1.5) +   geom_line(linewidth = 0.8) +   scale_color_manual(values = palette_2) +   labs(x = \"Number of Clusters (K)\", y = \"Probability\",        title = \"Marginal PMF of K\") +   theme_minimal() +   theme(legend.position = \"bottom\")  p2 <- ggplot(w_df, aes(x = w1, y = density, color = Prior)) +   geom_line(linewidth = 1) +   geom_vline(xintercept = 0.5, linetype = \"dashed\", color = \"gray50\") +   scale_color_manual(values = palette_2) +   labs(x = expression(w[1]), y = \"Density\",        title = expression(\"Marginal Density of \" * w[1])) +   theme_minimal() +   theme(legend.position = \"bottom\")  gridExtra::grid.arrange(p1, p2, ncol = 2)"},{"path":"https://joonho112.github.io/DPprior/articles/dual-anchor.html","id":"comparing-loss-types","dir":"Articles","previous_headings":"4. Using DPprior_dual() for Dual-Anchor Elicitation","what":"4.2 Comparing Loss Types","title":"Beyond Cluster Counts: Dual-Anchor Elicitation for Weight Control","text":"choice loss_type can significantly affect results. Let us compare three options: Comparison loss types Œª = 0.5 (target: P(w‚ÇÅ>0.5) = 0.25) \"adaptive\" loss type typically produces noticeable weight reduction normalizes loss component scale opposite anchor‚Äôs optimum.","code":"# Compare loss types at lambda = 0.5 w1_target <- list(prob = list(threshold = 0.5, value = 0.25))  fit_relative <- DPprior_dual(   fit_K, w1_target, lambda = 0.5,    loss_type = \"relative\", verbose = FALSE )  fit_adaptive <- DPprior_dual(   fit_K, w1_target, lambda = 0.5,    loss_type = \"adaptive\", verbose = FALSE )  # Create comparison table loss_compare <- data.frame(   Method = c(\"K-only\", \"Relative\", \"Adaptive\"),   a = c(fit_K$a, fit_relative$a, fit_adaptive$a),   b = c(fit_K$b, fit_relative$b, fit_adaptive$b),   E_K = c(     exact_K_moments(J, fit_K$a, fit_K$b)$mean,     exact_K_moments(J, fit_relative$a, fit_relative$b)$mean,     exact_K_moments(J, fit_adaptive$a, fit_adaptive$b)$mean   ),   P_w1_gt_50 = c(     prob_w1_exceeds(0.5, fit_K$a, fit_K$b),     prob_w1_exceeds(0.5, fit_relative$a, fit_relative$b),     prob_w1_exceeds(0.5, fit_adaptive$a, fit_adaptive$b)   ) )  loss_compare$a <- round(loss_compare$a, 3) loss_compare$b <- round(loss_compare$b, 3) loss_compare$E_K <- round(loss_compare$E_K, 2) loss_compare$P_w1_gt_50 <- round(loss_compare$P_w1_gt_50, 3)  knitr::kable(   loss_compare,   col.names = c(\"Method\", \"a\", \"b\", \"E[K]\", \"P(w‚ÇÅ>0.5)\"),   caption = \"Comparison of loss types at Œª = 0.5 (target: P(w‚ÇÅ>0.5) = 0.25)\" )"},{"path":"https://joonho112.github.io/DPprior/articles/dual-anchor.html","id":"alternative-quantile-constraint","dir":"Articles","previous_headings":"4. Using DPprior_dual() for Dual-Anchor Elicitation","what":"4.3 Alternative: Quantile Constraint","title":"Beyond Cluster Counts: Dual-Anchor Elicitation for Weight Control","text":"can also specify quantile constraint. example, ensure 90th percentile w1w_1 exceed 0.6:","code":"fit_dual_q <- DPprior_dual(   fit = fit_K,   w1_target = list(quantile = list(prob = 0.9, value = 0.6)),   lambda = 0.7,   loss_type = \"adaptive\",   verbose = FALSE )  cat(\"Dual-anchor (quantile constraint):\\n\") #> Dual-anchor (quantile constraint): cat(\"  Gamma(\", round(fit_dual_q$a, 3), \",\", round(fit_dual_q$b, 3), \")\\n\") #>   Gamma( 0.518 , 0.341 ) cat(\"  90th percentile of w‚ÇÅ:\", round(quantile_w1(0.9, fit_dual_q$a, fit_dual_q$b), 3), \"\\n\") #>   90th percentile of w‚ÇÅ: 1 cat(\"  (Target was 0.6)\\n\") #>   (Target was 0.6)"},{"path":"https://joonho112.github.io/DPprior/articles/dual-anchor.html","id":"alternative-mean-constraint","dir":"Articles","previous_headings":"4. Using DPprior_dual() for Dual-Anchor Elicitation","what":"4.4 Alternative: Mean Constraint","title":"Beyond Cluster Counts: Dual-Anchor Elicitation for Weight Control","text":"constraints based ùîº[w1]\\mathbb{E}[w_1]:","code":"fit_dual_m <- DPprior_dual(   fit = fit_K,   w1_target = list(mean = 0.35),   lambda = 0.6,   loss_type = \"adaptive\",   verbose = FALSE )  cat(\"Dual-anchor (mean constraint):\\n\") #> Dual-anchor (mean constraint): cat(\"  Gamma(\", round(fit_dual_m$a, 3), \",\", round(fit_dual_m$b, 3), \")\\n\") #>   Gamma( 1.377 , 0.621 ) cat(\"  E[w‚ÇÅ]:\", round(mean_w1(fit_dual_m$a, fit_dual_m$b), 3), \"\\n\") #>   E[w‚ÇÅ]: 0.411 cat(\"  (Target was 0.35)\\n\") #>   (Target was 0.35)"},{"path":"https://joonho112.github.io/DPprior/articles/dual-anchor.html","id":"elicitation-questions-for-weight-anchors","dir":"Articles","previous_headings":"","what":"5. Elicitation Questions for Weight Anchors","title":"Beyond Cluster Counts: Dual-Anchor Elicitation for Weight Control","text":"Translating substantive knowledge weight constraints requires careful framing. suggested elicitation questions:","code":""},{"path":"https://joonho112.github.io/DPprior/articles/dual-anchor.html","id":"for-w_1-size-biased-weight","dir":"Articles","previous_headings":"5. Elicitation Questions for Weight Anchors","what":"For w1w_1 (Size-Biased Weight)","title":"Beyond Cluster Counts: Dual-Anchor Elicitation for Weight Control","text":"questions focus happens randomly sample unit: ‚Äúrandomly select site study, proportion sites expect share effect pattern? ‚Äôs reasonable median estimate?‚Äù ‚Äúsignificant chance (say, > 30%) randomly selected site belongs effect group contains half sites?‚Äù","code":""},{"path":"https://joonho112.github.io/DPprior/articles/dual-anchor.html","id":"for-rho-co-clustering-probability","dir":"Articles","previous_headings":"5. Elicitation Questions for Weight Anchors","what":"For œÅ\\rho (Co-Clustering Probability)","title":"Beyond Cluster Counts: Dual-Anchor Elicitation for Weight Control","text":"questions may intuitive many researchers: ‚Äúpick two sites random, ‚Äôs probability belong effect group?‚Äù ‚Äúlikely two randomly chosen sites show substantively similar treatment effects?‚Äù","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/articles/dual-anchor.html","id":"exploring-the-trade-off-lambda-sensitivity","dir":"Articles","previous_headings":"","what":"6. Exploring the Trade-off: Œª\\lambda Sensitivity","title":"Beyond Cluster Counts: Dual-Anchor Elicitation for Weight Control","text":"Different values Œª\\lambda produce different trade-offs matching K anchor weight anchor. Let us explore systematically: Effect Œª dual-anchor calibration (target: P(w‚ÇÅ>0.5) = 0.2, adaptive loss) Trade-curve: reducing Œª brings P(w‚ÇÅ > 0.5) closer target cost K deviation.","code":"lambda_grid <- c(1.0, 0.9, 0.7, 0.5, 0.3) w1_target <- list(prob = list(threshold = 0.5, value = 0.2))  lambda_results <- lapply(lambda_grid, function(lam) {   if (lam == 1.0) {     # lambda = 1 just returns K-only     fit <- fit_K     fit$dual_anchor <- list(lambda = 1.0)   } else {     fit <- DPprior_dual(fit_K, w1_target, lambda = lam,                          loss_type = \"adaptive\", verbose = FALSE)   }      list(     lambda = lam,     a = fit$a,     b = fit$b,     E_K = exact_K_moments(J, fit$a, fit$b)$mean,     P_w1_gt_50 = prob_w1_exceeds(0.5, fit$a, fit$b),     E_w1 = mean_w1(fit$a, fit$b)   ) })  # Create comparison table lambda_df <- do.call(rbind, lapply(lambda_results, function(r) {   data.frame(     lambda = r$lambda,     a = round(r$a, 3),     b = round(r$b, 3),     E_K = round(r$E_K, 2),     P_w1_gt_50 = round(r$P_w1_gt_50, 3),     E_w1 = round(r$E_w1, 3)   ) }))  knitr::kable(   lambda_df,   col.names = c(\"Œª\", \"a\", \"b\", \"E[K]\", \"P(w‚ÇÅ>0.5)\", \"E[w‚ÇÅ]\"),   caption = \"Effect of Œª on dual-anchor calibration (target: P(w‚ÇÅ>0.5) = 0.2, adaptive loss)\" ) # Visualize the trade-off tradeoff_df <- data.frame(   lambda = sapply(lambda_results, `[[`, \"lambda\"),   E_K = sapply(lambda_results, `[[`, \"E_K\"),   P_w1 = sapply(lambda_results, `[[`, \"P_w1_gt_50\") )  ggplot(tradeoff_df, aes(x = E_K, y = P_w1)) +   geom_path(color = \"gray50\", linewidth = 0.8) +   geom_point(aes(color = factor(lambda)), size = 4) +   geom_hline(yintercept = 0.2, linetype = \"dashed\", color = \"#E41A1C\", alpha = 0.7) +   geom_vline(xintercept = 5, linetype = \"dashed\", color = \"#377EB8\", alpha = 0.7) +   annotate(\"text\", x = 4.7, y = 0.22, label = \"w‚ÇÅ target\", hjust = 1, color = \"#E41A1C\") +   annotate(\"text\", x = 5.1, y = 0.45, label = \"K target\", hjust = 0, color = \"#377EB8\") +   scale_color_viridis_d(option = \"viridis\", begin = 0.2, end = 0.8) +   labs(     x = \"E[K] (Cluster Count)\",     y = expression(P(w[1] > 0.5)),     title = \"Trade-off Between K and Weight Anchors\",     color = \"Œª\"   ) +   theme_minimal() +   theme(legend.position = \"right\")"},{"path":[]},{"path":"https://joonho112.github.io/DPprior/articles/dual-anchor.html","id":"when-to-use-dual-anchor-calibration","dir":"Articles","previous_headings":"7. Practical Recommendations","what":"7.1 When to Use Dual-Anchor Calibration","title":"Beyond Cluster Counts: Dual-Anchor Elicitation for Weight Control","text":"Consider dual-anchor calibration : High dominance risk K-fit: print(fit) shows ‚ÄúDominance Risk: HIGH‚Äù P(w1>0.5)>0.4P(w_1 > 0.5) > 0.4 Strong prior belief concentration: believe effects reasonably spread across groups, concentrated Low-information settings: data may strongly update prior, unintended weight behavior can persist posterior use dual-anchor : comfortable weight implications K-prior strong data overwhelm prior specification additional complexity justified application","code":""},{"path":"https://joonho112.github.io/DPprior/articles/dual-anchor.html","id":"choosing-loss_type","dir":"Articles","previous_headings":"7. Practical Recommendations","what":"7.2 Choosing loss_type","title":"Beyond Cluster Counts: Dual-Anchor Elicitation for Weight Control","text":"generally recommend \"adaptive\" dual-anchor applications, ensures anchors contribute meaningfully optimization.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/dual-anchor.html","id":"choosing-lambda","dir":"Articles","previous_headings":"7. Practical Recommendations","what":"7.3 Choosing Œª\\lambda","title":"Beyond Cluster Counts: Dual-Anchor Elicitation for Weight Control","text":"practice, recommend starting Œª=0.7\\lambda = 0.7 adjusting based closely target achieved.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/dual-anchor.html","id":"choosing-between-w_1-and-rho","dir":"Articles","previous_headings":"7. Practical Recommendations","what":"7.4 Choosing Between w1w_1 and œÅ\\rho","title":"Beyond Cluster Counts: Dual-Anchor Elicitation for Weight Control","text":"Since ùîº[w1]=ùîº[œÅ]\\mathbb{E}[w_1] = \\mathbb{E}[\\rho], mean-based constraints equivalent two anchors.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/dual-anchor.html","id":"when-dual-anchor-constraints-are-infeasible","dir":"Articles","previous_headings":"","what":"8. When Dual-Anchor Constraints Are Infeasible","title":"Beyond Cluster Counts: Dual-Anchor Elicitation for Weight Control","text":"combinations K weight targets achievable. specify conflicting constraints, optimization may fully satisfy : constraints strict, consider: Relaxing one targets: Accept somewhat higher dominance risk different K expectation Adjusting Œª\\lambda: one target important, weight heavily Using single anchor: Sometimes K-weight-calibration appropriate","code":"# An aggressive weight target that conflicts with K target fit_aggressive <- DPprior_dual(   fit = fit_K,   w1_target = list(prob = list(threshold = 0.5, value = 0.05)),  # Very tight   lambda = 0.5,   loss_type = \"adaptive\",   verbose = FALSE )  cat(\"Aggressive dual-anchor attempt:\\n\") #> Aggressive dual-anchor attempt: cat(\"  Target: P(w‚ÇÅ > 0.5) = 0.05\\n\") #>   Target: P(w‚ÇÅ > 0.5) = 0.05 cat(\"  Achieved: P(w‚ÇÅ > 0.5) =\",      round(prob_w1_exceeds(0.5, fit_aggressive$a, fit_aggressive$b), 3), \"\\n\") #>   Achieved: P(w‚ÇÅ > 0.5) = 0.149 cat(\"\\n  Target: E[K] = 5\\n\") #>  #>   Target: E[K] = 5 cat(\"  Achieved: E[K] =\",      round(exact_K_moments(J, fit_aggressive$a, fit_aggressive$b)$mean, 2), \"\\n\") #>   Achieved: E[K] = 9.41"},{"path":[]},{"path":"https://joonho112.github.io/DPprior/articles/dual-anchor.html","id":"whats-next","dir":"Articles","previous_headings":"","what":"What‚Äôs Next?","title":"Beyond Cluster Counts: Dual-Anchor Elicitation for Weight Control","text":"Diagnostics: Deep dive verifying prior meets specifications Case Studies: Real-world examples applying dual-anchor calibration Mathematical Foundations: Theoretical details DPprior framework","code":""},{"path":"https://joonho112.github.io/DPprior/articles/dual-anchor.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Beyond Cluster Counts: Dual-Anchor Elicitation for Weight Control","text":"Vicentini, S., & Jermyn, . H. (2025). Prior selection precision parameter Dirichlet process mixture models. arXiv:2502.00864. https://doi.org/10.48550/arXiv.2502.00864 Sethuraman, J. (1994). constructive definition Dirichlet priors. Statistica Sinica, 4(2), 639‚Äì650. questions feedback, please visit GitHub repository.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/introduction.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"DPprior: Why Prior Elicitation Matters","text":"DPprior package provides tools principled prior elicitation concentration parameter Œ±\\alpha Dirichlet Process (DP) mixture models. Rather requiring researchers think directly terms abstract parameter Œ±\\alpha, DPprior allows specification two intuitive dimensions: expected cluster counts‚Äîmany distinct groups anticipate?‚Äîcluster weight concentration‚Äîevenly expect observations distributed across groups? quantities applied researchers can often reason based domain knowledge, DPprior translates beliefs principled Gamma hyperpriors Œ±\\alpha.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/introduction.html","id":"installation","dir":"Articles","previous_headings":"Introduction","what":"Installation","title":"DPprior: Why Prior Elicitation Matters","text":"","code":"# From CRAN (when available) install.packages(\"DPprior\")  # From GitHub (development version) devtools::install_github(\"joonho112/DPprior\") library(DPprior)"},{"path":"https://joonho112.github.io/DPprior/articles/introduction.html","id":"the-core-problem","dir":"Articles","previous_headings":"Introduction","what":"The Core Problem","title":"DPprior: Why Prior Elicitation Matters","text":"using DP mixture models applications multisite trials, meta-analysis, Bayesian nonparametric density estimation, researchers must specify prior concentration parameter Œ±\\alpha. parameter governs model‚Äôs clustering behavior, affecting multiple dimensions: many clusters model tend produce? observations distributed across clusters‚Äîevenly, one dominant group? much shrinkage posterior exhibit toward common mean? low-information settings‚Äînumber observations JJ moderate (e.g., 25‚Äì100) per-observation information limited‚Äîprior Œ±\\alpha can substantially influence posterior inference. DPprior package addresses critical question: researchers translate domain knowledge principled prior Œ±\\alpha?","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/articles/introduction.html","id":"the-dirichlet-process-mixture-model","dir":"Articles","previous_headings":"The Core Challenge: Why Œ±\\alpha Matters","what":"The Dirichlet Process Mixture Model","title":"DPprior: Why Prior Elicitation Matters","text":"DP mixture model, place Dirichlet Process prior unknown distribution GG: G‚àºDP(Œ±,G0), G \\sim \\text{DP}(\\alpha, G_0),  G0G_0 base (centering) measure Œ±>0\\alpha > 0 concentration parameter. Observations Œ∏1,‚Ä¶,Œ∏J\\theta_1, \\ldots, \\theta_J drawn GG: Œ∏j‚à£G‚àºiidG. \\theta_j \\mid G \\stackrel{iid}{\\sim} G. fundamental property DP draws GG exhibit clustering: multiple observations can share value, number distinct values KJK_J depending critically Œ±\\alpha. clustering behavior makes DP particularly useful applications number underlying groups unknown‚Äîidentifying distinct treatment effect patterns across sites multisite trial, discovering latent subpopulations meta-analysis.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/introduction.html","id":"what-does-alpha-control","dir":"Articles","previous_headings":"The Core Challenge: Why Œ±\\alpha Matters","what":"What Does Œ±\\alpha Control?","title":"DPprior: Why Prior Elicitation Matters","text":"concentration parameter Œ±\\alpha influences model‚Äôs behavior three interconnected ways: Number clusters (KJK_J): Larger Œ±\\alpha leads clusters average; smaller Œ±\\alpha concentrates mass fewer clusters. Specifically, ùîº[KJ|Œ±]‚âàŒ±logJ\\mathbb{E}[K_J | \\alpha] \\approx \\alpha \\log J large JJ (Antoniak, 1974). Stick-breaking weights: Sethuraman‚Äôs (1994) representation, GG constructed via stick-breaking weights (w1,w2,‚Ä¶)(w_1, w_2, \\ldots) wh=vh‚àè‚Ñì<h(1‚àív‚Ñì)w_h = v_h \\prod_{\\ell < h}(1 - v_\\ell) vh‚àºBeta(1,Œ±)v_h \\sim \\text{Beta}(1, \\alpha). Smaller Œ±\\alpha produces weights concentrated early atoms (one two clusters dominate); larger Œ±\\alpha spreads weights evenly across many clusters. Vicentini & Jermyn (2025) emphasize, weights represent asymptotic relative cluster sizes fundamental quantity distinct cluster count. Posterior shrinkage: prior Œ±\\alpha affects much posterior borrows strength across observations. multisite trials, determines degree shrinkage toward common mean‚Äîkey consideration sites varying sample sizes precision (Lee et al., 2025). figure illustrates different values Œ±\\alpha lead dramatically different partition structures. Illustration stick-breaking weights different values Œ±. Smaller Œ± concentrates mass first atoms, larger Œ± spreads weights evenly.","code":"# Simulate stick-breaking for different alpha values n_atoms <- 15 alpha_values <- c(0.5, 2, 10)  set.seed(123) sb_data <- do.call(rbind, lapply(alpha_values, function(a) {   # Simulate stick-breaking   v <- rbeta(n_atoms, 1, a)   w <- numeric(n_atoms)   w[1] <- v[1]   for (h in 2:n_atoms) {     w[h] <- v[h] * prod(1 - v[1:(h-1)])   }   data.frame(     atom = 1:n_atoms,     weight = w,     alpha = paste0(\"Œ± = \", a)   ) }))  sb_data$alpha <- factor(sb_data$alpha,                          levels = paste0(\"Œ± = \", alpha_values))  ggplot(sb_data, aes(x = atom, y = weight, fill = alpha)) +   geom_bar(stat = \"identity\") +   facet_wrap(~alpha, nrow = 1) +   scale_fill_manual(values = palette_main[1:3]) +   labs(x = \"Atom Index\",         y = \"Stick-Breaking Weight\",        title = \"Effect of Œ± on Cluster Weight Distribution\",        subtitle = \"One realization from GEM(Œ±) for each value\") +   theme_minimal() +   theme(legend.position = \"none\",         strip.text = element_text(face = \"bold\", size = 12))"},{"path":"https://joonho112.github.io/DPprior/articles/introduction.html","id":"the-distribution-of-k_j","dir":"Articles","previous_headings":"The Core Challenge: Why Œ±\\alpha Matters","what":"The Distribution of KJK_J","title":"DPprior: Why Prior Elicitation Matters","text":"Given Œ±\\alpha, number distinct clusters KJK_J among JJ observations follows Antoniak distribution (Antoniak, 1974). probability mass function : P(KJ=k|Œ±)=|s(J,k)|‚ãÖŒ±k(Œ±)J, P(K_J = k | \\alpha) = \\frac{|s(J,k)| \\cdot \\alpha^k}{(\\alpha)_J},  |s(J,k)||s(J,k)| unsigned Stirling numbers first kind (Œ±)J=Œ±(Œ±+1)‚ãØ(Œ±+J‚àí1)(\\alpha)_J = \\alpha(\\alpha+1)\\cdots(\\alpha+J-1) rising factorial. expectation : ùîº[KJ‚à£Œ±]=‚àë=1JŒ±Œ±+‚àí1‚âàŒ±logJ(large J). \\mathbb{E}[K_J \\mid \\alpha] = \\sum_{=1}^{J} \\frac{\\alpha}{\\alpha + - 1}  \\approx \\alpha \\log J \\quad \\text{(large } J\\text{)}. relationship provides foundation DPprior‚Äôs elicitation approach: researcher can express beliefs KJK_J, can back appropriate prior Œ±\\alpha. Importantly, Zito et al.¬†(2024) showed Œ±\\alpha random Gamma prior, marginal distribution KJK_J converges Negative Binomial J‚Üí‚àûJ \\\\infty. theoretical result‚ÄîDPprior package exploits closed-form initial solutions‚Äîexplains randomizing Œ±\\alpha leads robust clustering behavior compared fixing . Expected number clusters function Œ± different sample sizes J. approximately logarithmic relationship motivates package‚Äôs elicitation approach.","code":"# Demonstrate E[K] vs alpha relationship alpha_grid <- seq(0.1, 5, by = 0.1) J_values <- c(25, 50, 100)  k_data <- do.call(rbind, lapply(J_values, function(J) {   EK <- sapply(alpha_grid, function(a) mean_K_given_alpha(J, a))   data.frame(alpha = alpha_grid, E_K = EK, J = paste0(\"J = \", J)) }))  k_data$J <- factor(k_data$J, levels = paste0(\"J = \", J_values))  ggplot(k_data, aes(x = alpha, y = E_K, color = J)) +   geom_line(linewidth = 1.2) +   scale_color_manual(values = palette_main[1:3]) +   labs(x = expression(alpha),         y = expression(E*\"[\"*K[J]*\"|\"*alpha*\"]\"),        title = \"Expected Clusters vs. Concentration Parameter\",        subtitle = \"Larger J requires larger Œ± to achieve the same E[K]\") +   theme_minimal() +   theme(legend.position = \"bottom\",         legend.title = element_blank())"},{"path":[]},{"path":"https://joonho112.github.io/DPprior/articles/introduction.html","id":"when-does-the-prior-matter","dir":"Articles","previous_headings":"The Low-Information Problem","what":"When Does the Prior Matter?","title":"DPprior: Why Prior Elicitation Matters","text":"standard Bayesian analysis, priors become less influential data accumulate‚Äîposterior converges toward likelihood. However, many practical applications, data provide limited information Œ±\\alpha, prior can substantially influence posterior inference. Zito et al.¬†(2024) demonstrated sensitivity dramatically: Figure 1, fixing Œ±=1\\alpha = 1 versus Œ±=5\\alpha = 5 causes posterior mode KnK_n shift four eight clusters, even data generated well-separated four-component mixture. Randomizing Œ±\\alpha appropriate prior attenuates sensitivity, raises question: prior specified? Lee et al.¬†(2025) addressed question context multisite trials defining informativeness index II: =œÉ2œÉ2+exp(1J‚àëj=1Jlog(seÃÇj2)), = \\frac{\\sigma^2}{\\sigma^2 + \\exp\\left(\\frac{1}{J}\\sum_{j=1}^{J} \\log(\\widehat{se}_j^2)\\right)},  œÉ2\\sigma^2 -site variance seÃÇj\\widehat{se}_j within-site standard errors. index II ranges 0 1, higher values indicating observed estimates œÑÃÇj\\hat{\\tau}_j provide greater information true site effects œÑj\\tau_j. II small (e.g., <0.3< 0.3), site-specific estimates noisy relative -site heterogeneity, prior Œ±\\alpha can dominate posterior.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/introduction.html","id":"characteristics-of-low-information-settings","dir":"Articles","previous_headings":"The Low-Information Problem","what":"Characteristics of Low-Information Settings","title":"DPprior: Why Prior Elicitation Matters","text":"Low-information settings commonly arise : Multisite trials moderate numbers sites (J=25J = 25‚Äì100100) small within-site samples. Lee et al.¬†(2025) found J‚â§50J \\leq 50 low II, even misspecified Gaussian models appropriate posterior summaries can outperform DP models poorly chosen priors. Meta-analyses heterogeneous effect sizes varying study precision Educational studies school classroom effects exhibit substantial variability Healthcare quality assessment limited patient counts per provider settings, researchers simply ‚Äúlet data speak‚Äù‚Äîprior matters, choosing thoughtfully essential. Lee et al.¬†(2025) showed, combination informative prior (DP-inform) appropriate posterior summaries outperforms diffuse approaches precisely incorporates meaningful prior knowledge expected clustering structure. Prior influence across different informativeness levels. low-information settings (low ), prior‚Äôs shape substantially affects posterior.","code":"# Conceptual illustration of prior influence # Create a schematic showing prior vs posterior at different I levels I_levels <- c(\"Low (I = 0.2)\", \"Medium (I = 0.5)\", \"High (I = 0.8)\") alpha_grid <- seq(0.01, 6, length.out = 200)  # Create synthetic data for illustration concept_data <- do.call(rbind, lapply(seq_along(I_levels), function(i) {   I <- c(0.2, 0.5, 0.8)[i]   prior_weight <- 1 - I      # Prior: Gamma(1.5, 0.8)   prior <- dgamma(alpha_grid, 1.5, 0.8)      # \"Likelihood peak\" centered at alpha = 2.5   likelihood_center <- 2.5   likelihood_width <- 0.5 + 2 * (1 - I)  # Wider at low I   likelihood <- dnorm(alpha_grid, likelihood_center, likelihood_width)      # Posterior is mixture weighted by informativeness   posterior <- prior_weight * prior + (1 - prior_weight) *                 (likelihood / max(likelihood)) * max(prior)   posterior <- posterior / (sum(posterior) * diff(alpha_grid)[1])      rbind(     data.frame(alpha = alpha_grid, density = prior,                 Type = \"Prior\", Setting = I_levels[i]),     data.frame(alpha = alpha_grid, density = posterior,                 Type = \"Posterior\", Setting = I_levels[i])   ) }))  concept_data$Setting <- factor(concept_data$Setting, levels = I_levels) concept_data$Type <- factor(concept_data$Type, levels = c(\"Prior\", \"Posterior\"))  ggplot(concept_data, aes(x = alpha, y = density, color = Type, linetype = Type)) +   geom_line(linewidth = 1) +   facet_wrap(~Setting, nrow = 1) +   scale_color_manual(values = c(\"Prior\" = \"#E41A1C\", \"Posterior\" = \"#377EB8\")) +   scale_linetype_manual(values = c(\"Prior\" = \"dashed\", \"Posterior\" = \"solid\")) +   labs(x = expression(alpha),        y = \"Density\",        title = \"Prior Influence Varies with Informativeness\",        subtitle = \"In low-I settings, the posterior closely tracks the prior\") +   theme_minimal() +   theme(legend.position = \"bottom\",         legend.title = element_blank(),         strip.text = element_text(face = \"bold\"))"},{"path":[]},{"path":"https://joonho112.github.io/DPprior/articles/introduction.html","id":"speaking-the-researchers-language","dir":"Articles","previous_headings":"The K-Based Elicitation Philosophy","what":"Speaking the Researcher‚Äôs Language","title":"DPprior: Why Prior Elicitation Matters","text":"DPprior package built simple insight: Œ±\\alpha abstract mathematical parameter, number clusters KJK_J something researchers can often reason directly. Consider researcher analyzing multisite educational trial 50 sites. might intuitions Œ±\\alpha, can likely answer questions like: ‚ÄúAmong 50 sites, roughly many distinct effect patterns subtypes expect?‚Äù ‚Äúfairly confident expectation, quite uncertain?‚Äù Lee et al.¬†(2025) operationalized approach using chi-square distribution KJK_J: researcher expects 5 clusters, specifying KJ‚àºœá2(5)K_J \\sim \\chi^2(5) implies mean 5 variance 10. package finds Gamma parameters (,b)(, b) prior Œ±\\alpha induces distribution KJK_J matches moments.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/introduction.html","id":"beyond-cluster-counts-the-weight-dimension","dir":"Articles","previous_headings":"The K-Based Elicitation Philosophy","what":"Beyond Cluster Counts: The Weight Dimension","title":"DPprior: Why Prior Elicitation Matters","text":"However, Vicentini & Jermyn (2025) identified important limitation approaches focus solely KJK_J: matching target cluster count distribution guarantee intuitive behavior cluster weights‚Äîrelative sizes clusters. Consider researcher says ‚Äúexpect 5 clusters.‚Äù likely imagine something like five roughly comparable groups, situation one cluster contains 80% observations four others share remaining 20%. Yet prior calibrated match ùîº[KJ]=5\\mathbb{E}[K_J] = 5 might imply substantial probability ‚Äúdominant cluster‚Äù configurations. insight motivates dual-anchor framework DPprior: researchers can additionally express beliefs weight concentration questions like: ‚Äúlikely single cluster contain half sites?‚Äù natural questions translate directly prior specifications:","code":""},{"path":"https://joonho112.github.io/DPprior/articles/introduction.html","id":"from-moments-to-gamma-hyperparameters","dir":"Articles","previous_headings":"The K-Based Elicitation Philosophy","what":"From Moments to Gamma Hyperparameters","title":"DPprior: Why Prior Elicitation Matters","text":"DPprior package converts intuitive specifications Gamma hyperparameters Œ±‚àºGamma(,b)\\alpha \\sim \\text{Gamma}(, b) two-step process: A1 (Closed-form approximation): Using asymptotic relationship KJ‚à£Œ±‚âàPoisson(Œ±logJ)K_J \\mid \\alpha \\approx \\text{Poisson}(\\alpha \\log J), Gamma prior Œ±\\alpha yields Negative Binomial marginal KJK_J (Vicentini & Jermyn, 2025; Zito et al., 2024), derive initial closed-form estimates (a0,b0)(a_0, b_0). A2 (Newton refinement): Using exact moments computed via Antoniak distribution, refine (,b)(, b) precisely match target (ŒºK,œÉK2)(\\mu_K, \\sigma_K^2). approach‚Äîcall Design-Conditional Elicitation (DCE)‚Äîextends original DORO method (Dorazio, 2009; Lee et al., 2025) replacing computationally expensive grid search near-instantaneous closed-form solutions backed Newton iteration guaranteed accuracy. optional dual-anchor extension incorporates weight constraints, addressing ‚Äúunintended prior‚Äù problem identified Vicentini & Jermyn (2025). Gamma hyperparameters different confidence levels (J = 50, Œº_K = 5)","code":"# Demonstrate the elicitation workflow J <- 50 mu_K <- 5  # Method 1: Using confidence levels fit_low <- DPprior_fit(J = J, mu_K = mu_K, confidence = \"low\") #> Warning: HIGH DOMINANCE RISK: P(w1 > 0.5) = 56.3% exceeds 40%. #>   This may indicate unintended prior behavior (Lee, 2026). #>   Consider using DPprior_dual() for weight-constrained elicitation. #>   See ?DPprior_diagnostics for interpretation. fit_med <- DPprior_fit(J = J, mu_K = mu_K, confidence = \"medium\") #> Warning: HIGH DOMINANCE RISK: P(w1 > 0.5) = 49.7% exceeds 40%. #>   This may indicate unintended prior behavior (Lee, 2026). #>   Consider using DPprior_dual() for weight-constrained elicitation. #>   See ?DPprior_diagnostics for interpretation. fit_high <- DPprior_fit(J = J, mu_K = mu_K, confidence = \"high\") #> Warning: HIGH DOMINANCE RISK: P(w1 > 0.5) = 46.5% exceeds 40%. #>   This may indicate unintended prior behavior (Lee, 2026). #>   Consider using DPprior_dual() for weight-constrained elicitation. #>   See ?DPprior_diagnostics for interpretation.  # Display results results <- data.frame(   Confidence = c(\"Low\", \"Medium\", \"High\"),   VIF = c(4.0, 2.5, 1.5),   var_K = round(c(fit_low$target$var_K, fit_med$target$var_K,                    fit_high$target$var_K), 2),   a = round(c(fit_low$a, fit_med$a, fit_high$a), 3),   b = round(c(fit_low$b, fit_med$b, fit_high$b), 3),   E_alpha = round(c(fit_low$a/fit_low$b, fit_med$a/fit_med$b,                      fit_high$a/fit_high$b), 3) )  knitr::kable(results,               col.names = c(\"Confidence\", \"VIF\", \"Var(K)\", \"a\", \"b\", \"E[Œ±]\"),              caption = \"Gamma hyperparameters for different confidence levels (J = 50, Œº_K = 5)\")"},{"path":"https://joonho112.github.io/DPprior/articles/introduction.html","id":"what-this-package-does","dir":"Articles","previous_headings":"","what":"What This Package Does","title":"DPprior: Why Prior Elicitation Matters","text":"DPprior package provides three core capabilities:","code":""},{"path":"https://joonho112.github.io/DPprior/articles/introduction.html","id":"k-based-elicitation","dir":"Articles","previous_headings":"What This Package Does","what":"1. K-Based Elicitation","title":"DPprior: Why Prior Elicitation Matters","text":"Convert intuitive beliefs cluster counts principled Gamma hyperpriors:","code":"# The main elicitation function fit <- DPprior_fit(   J = 50,              # Number of observations/sites   mu_K = 5,            # Expected number of clusters   confidence = \"medium\" # Uncertainty about that expectation ) #> Warning: HIGH DOMINANCE RISK: P(w1 > 0.5) = 49.7% exceeds 40%. #>   This may indicate unintended prior behavior (Lee, 2026). #>   Consider using DPprior_dual() for weight-constrained elicitation. #>   See ?DPprior_diagnostics for interpretation.  cat(\"Elicited prior: Œ± ~ Gamma(\", round(fit$a, 3), \", \",      round(fit$b, 3), \")\\n\", sep = \"\") #> Elicited prior: Œ± ~ Gamma(1.408, 1.077)"},{"path":"https://joonho112.github.io/DPprior/articles/introduction.html","id":"dual-anchor-control","dir":"Articles","previous_headings":"What This Package Does","what":"2. Dual-Anchor Control","title":"DPprior: Why Prior Elicitation Matters","text":"Go beyond cluster counts control weight concentration, addressing ‚Äúunintended prior‚Äù problem identified Vicentini & Jermyn (2025):","code":"# First, fit K-only prior fit_K <- DPprior_fit(J = 50, mu_K = 5, var_K = 8) #> Warning: HIGH DOMINANCE RISK: P(w1 > 0.5) = 48.1% exceeds 40%. #>   This may indicate unintended prior behavior (Lee, 2026). #>   Consider using DPprior_dual() for weight-constrained elicitation. #>   See ?DPprior_diagnostics for interpretation.  # Check weight behavior p_w1 <- prob_w1_exceeds(0.5, fit_K$a, fit_K$b) cat(\"K-only prior: P(w‚ÇÅ > 0.5) =\", round(p_w1, 3), \"\\n\") #> K-only prior: P(w‚ÇÅ > 0.5) = 0.481  # Apply dual-anchor constraint if weight behavior is undesirable if (p_w1 > 0.4) {   w1_target <- list(prob = list(threshold = 0.5, value = 0.30))   fit_dual <- DPprior_dual(fit_K, w1_target, lambda = 0.5)   p_w1_new <- prob_w1_exceeds(0.5, fit_dual$a, fit_dual$b)   cat(\"Dual-anchor prior: P(w‚ÇÅ > 0.5) =\", round(p_w1_new, 3), \"\\n\") } #> Dual-anchor prior: P(w‚ÇÅ > 0.5) = 0.438"},{"path":"https://joonho112.github.io/DPprior/articles/introduction.html","id":"comprehensive-diagnostics","dir":"Articles","previous_headings":"What This Package Does","what":"3. Comprehensive Diagnostics","title":"DPprior: Why Prior Elicitation Matters","text":"Verify elicited prior behaves intended across relevant dimensions: DPprior diagnostic dashboard showing joint behavior Œ±, K, w‚ÇÅ elicited prior.","code":"# Run diagnostics fit <- DPprior_fit(J = 50, mu_K = 5, var_K = 8, check_diagnostics = TRUE) #> Warning: HIGH DOMINANCE RISK: P(w1 > 0.5) = 48.1% exceeds 40%. #>   This may indicate unintended prior behavior (Lee, 2026). #>   Consider using DPprior_dual() for weight-constrained elicitation. #>   See ?DPprior_diagnostics for interpretation.  # Visualize the complete prior specification plot(fit) #> TableGrob (2 x 2) \"dpprior_dashboard\": 4 grobs #>   z     cells              name           grob #> 1 1 (1-1,1-1) dpprior_dashboard gtable[layout] #> 2 2 (2-2,1-1) dpprior_dashboard gtable[layout] #> 3 3 (1-1,2-2) dpprior_dashboard gtable[layout] #> 4 4 (2-2,2-2) dpprior_dashboard gtable[layout]"},{"path":"https://joonho112.github.io/DPprior/articles/introduction.html","id":"package-architecture","dir":"Articles","previous_headings":"What This Package Does","what":"Package Architecture","title":"DPprior: Why Prior Elicitation Matters","text":"package organized three layers: users interact Layer C, underlying layers available advanced applications research.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/articles/introduction.html","id":"recommended-use-cases","dir":"Articles","previous_headings":"When to Use DPprior","what":"Recommended Use Cases","title":"DPprior: Why Prior Elicitation Matters","text":"DPprior package particularly valuable : Multisite randomized trials: analyzing heterogeneity across treatment sites moderate JJ (20‚Äì200 sites) Meta-analysis flexible heterogeneity: standard normal random effects may restrictive Bayesian nonparametric density estimation: sample sizes small enough prior specification matters Mixed-effects models flexible random effects: exploring potential clustering among random effect distributions","code":""},{"path":"https://joonho112.github.io/DPprior/articles/introduction.html","id":"when-other-approaches-may-be-more-appropriate","dir":"Articles","previous_headings":"When to Use DPprior","what":"When Other Approaches May Be More Appropriate","title":"DPprior: Why Prior Elicitation Matters","text":"Consider alternatives : large JJ streaming data: thousands observations, prior Œ±\\alpha becomes less influential. Sample-size-independent (SSI) approaches may natural. Highly informative data: likelihood provides overwhelming evidence Œ±\\alpha, prior specification less critical. Primarily interested prediction: DP mixture models excel clustering density estimation; pure prediction tasks, models may appropriate.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/introduction.html","id":"road-map-to-the-vignettes","dir":"Articles","previous_headings":"","what":"Road Map to the Vignettes","title":"DPprior: Why Prior Elicitation Matters","text":"DPprior package includes comprehensive documentation organized two tracks:","code":""},{"path":"https://joonho112.github.io/DPprior/articles/introduction.html","id":"applied-researchers-track","dir":"Articles","previous_headings":"Road Map to the Vignettes","what":"Applied Researchers Track","title":"DPprior: Why Prior Elicitation Matters","text":"users want apply package effectively:","code":""},{"path":"https://joonho112.github.io/DPprior/articles/introduction.html","id":"methodological-researchers-track","dir":"Articles","previous_headings":"Road Map to the Vignettes","what":"Methodological Researchers Track","title":"DPprior: Why Prior Elicitation Matters","text":"users interested mathematical foundations:","code":""},{"path":"https://joonho112.github.io/DPprior/articles/introduction.html","id":"recommended-reading-paths","dir":"Articles","previous_headings":"Road Map to the Vignettes","what":"Recommended Reading Paths","title":"DPprior: Why Prior Elicitation Matters","text":"‚Äúwant get started quickly‚Äù ‚Üí Quick Start ‚Äúwant systematic introduction‚Äù ‚Üí Quick Start ‚Üí Applied Guide ‚Üí Dual-Anchor ‚Üí Diagnostics ‚Äúneed understand theory‚Äù ‚Üí Theory Overview ‚Üí Stirling Numbers ‚Üí Approximations ‚Üí Newton Algorithm ‚Äúneed specific application examples‚Äù ‚Üí Case Studies","code":""},{"path":"https://joonho112.github.io/DPprior/articles/introduction.html","id":"summary","dir":"Articles","previous_headings":"","what":"Summary","title":"DPprior: Why Prior Elicitation Matters","text":"DPprior package addresses fundamental challenge Bayesian nonparametric modeling: translate domain knowledge principled prior Dirichlet Process concentration parameter Œ±\\alpha. Key features include: Intuitive elicitation: Specify priors expected cluster counts weight concentration, rather abstract parameters Fast computation: Closed-form approximations Newton refinement, eliminating need grid search (DCE via TSMM) Comprehensive control: Dual-anchor framework joint control cluster counts weight behavior, addressing ‚Äúunintended prior‚Äù problem identified Vicentini & Jermyn (2025) Rich diagnostics: Verification tools ensure priors behave intended across relevant dimensions‚Äîjust KJK_J also w1w_1 co-clustering probability œÅ\\rho package especially valuable low-information settings‚Äîmultisite trials, meta-analyses, applications , Lee et al.¬†(2025) demonstrated, prior Œ±\\alpha can substantially influence posterior inference site-specific effects distribution.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/introduction.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"DPprior: Why Prior Elicitation Matters","text":"Antoniak, C. E. (1974). Mixtures Dirichlet processes applications Bayesian nonparametric problems. Annals Statistics, 2(6), 1152‚Äì1174. Dorazio, R. M. (2009). selecting prior precision parameter Dirichlet process mixture models. Journal Statistical Planning Inference, 139(10), 3384‚Äì3390. Ferguson, T. S. (1973). Bayesian analysis nonparametric problems. Annals Statistics, 1(2), 209‚Äì230. Lee, J., Che, J., Rabe-Hesketh, S., Feller, ., & Miratrix, L. (2025). Improving estimation site-specific effects distribution multisite trials. Journal Educational Behavioral Statistics, 50(5), 731‚Äì764. https://doi.org/10.3102/10769986241254286 Sethuraman, J. (1994). constructive definition Dirichlet priors. Statistica Sinica, 4(2), 639‚Äì650. Vicentini, C., & Jermyn, . H. (2025). Prior selection precision parameter Dirichlet process mixtures. arXiv:2502.00864. https://doi.org/10.48550/arXiv.2502.00864 Zito, ., Rigon, T., & Dunson, D. B. (2024). Bayesian nonparametric modeling latent partitions via Stirling-gamma priors. arXiv:2306.02360. questions feedback package, please visit GitHub repository.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/quick-start.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Quick Start: Your First Prior in 5 Minutes","text":"vignette demonstrates fastest path eliciting Gamma hyperprior concentration parameter Œ±\\alpha Dirichlet Process mixture model. end 5-minute tutorial, able : Specify prior belief number clusters Convert belief Gamma hyperparameters Visualize verify elicited prior","code":""},{"path":"https://joonho112.github.io/DPprior/articles/quick-start.html","id":"minimal-example","dir":"Articles","previous_headings":"","what":"1. Minimal Example","title":"Quick Start: Your First Prior in 5 Minutes","text":"Let‚Äôs walk concrete scenario. Suppose analyzing multisite educational trial 50 sites, expect sites cluster approximately 5 distinct effect groups. setup mirrors ‚ÄúDP-inform‚Äù prior elicitation approach used Lee et al.¬†(2025), demonstrated benefits informative Dirichlet Process priors estimating site-specific effects multisite trials. paper relied chi-square discrepancy measures computationally intensive grid search, DPprior package provides instant, closed-form solutions elicitation task. ‚Äôs ! now principled Gamma hyperprior Œ±\\alpha.","code":"library(DPprior)  # Just two inputs needed: # 1. J: Number of sites (or observations for clustering) # 2. mu_K: Expected number of clusters  fit <- DPprior_fit(J = 50, mu_K = 5, confidence = \"medium\") #> Warning: HIGH DOMINANCE RISK: P(w1 > 0.5) = 49.7% exceeds 40%. #>   This may indicate unintended prior behavior (Lee, 2026). #>   Consider using DPprior_dual() for weight-constrained elicitation. #>   See ?DPprior_diagnostics for interpretation.  # View the result print(fit) #> DPprior Prior Elicitation Result #> =============================================  #>  #> Gamma Hyperprior: Œ± ~ Gamma(a = 1.4082, b = 1.0770) #>   E[Œ±] = 1.308, SD[Œ±] = 1.102 #>  #> Target (J = 50): #>   E[K_J]   = 5.00 #>   Var(K_J) = 10.00 #>   (from confidence = 'medium') #>  #> Achieved: #>   E[K_J] = 5.000000, Var(K_J) = 10.000000 #>   Residual = 3.94e-10 #>  #> Method: A2-MN (7 iterations) #>  #> Dominance Risk: HIGH ‚úò (P(w‚ÇÅ>0.5) = 50%)"},{"path":"https://joonho112.github.io/DPprior/articles/quick-start.html","id":"understanding-the-output","dir":"Articles","previous_headings":"","what":"2. Understanding the Output","title":"Quick Start: Your First Prior in 5 Minutes","text":"DPprior_fit() function returns object containing Gamma hyperparameters diagnostic information. Let‚Äôs examine key components: Interpretation: elicited prior Œ±‚àºGamma(,b)\\alpha \\sim \\text{Gamma}(, b) implies expect around 5 clusters sampling J=50J = 50 observations, uncertainty captured variance.","code":"# The Gamma hyperparameters cat(\"Gamma shape (a):\", round(fit$a, 4), \"\\n\") #> Gamma shape (a): 1.4082 cat(\"Gamma rate  (b):\", round(fit$b, 4), \"\\n\") #> Gamma rate  (b): 1.077  # What these imply about alpha alpha_mean <- fit$a / fit$b alpha_sd <- sqrt(fit$a) / fit$b cat(\"\\nPrior mean of Œ±:\", round(alpha_mean, 3), \"\\n\") #>  #> Prior mean of Œ±: 1.308 cat(\"Prior SD of Œ±:  \", round(alpha_sd, 3), \"\\n\") #> Prior SD of Œ±:   1.102  # The target specification cat(\"\\nTarget E[K]:\", fit$target$mu_K, \"\\n\") #>  #> Target E[K]: 5 cat(\"Target Var(K):\", round(fit$target$var_K, 2), \"\\n\") #> Target Var(K): 10"},{"path":"https://joonho112.github.io/DPprior/articles/quick-start.html","id":"visualizing-your-prior","dir":"Articles","previous_headings":"","what":"3. Visualizing Your Prior","title":"Quick Start: Your First Prior in 5 Minutes","text":"DPprior package provides built-visualization functions help understand communicate elicited prior.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/quick-start.html","id":"full-dashboard-view","dir":"Articles","previous_headings":"3. Visualizing Your Prior","what":"3.1 Full Dashboard View","title":"Quick Start: Your First Prior in 5 Minutes","text":"plot() method displays comprehensive four-panel dashboard: Prior elicitation dashboard showing distributions Œ±, K, w‚ÇÅ. dashboard includes: Panel (): Gamma prior density concentration parameter Œ±\\alpha, key statistics (mean, CV, 95% CI) Panel (B): implied marginal PMF number clusters KJK_J, showing E[K], Var(K), mode Panel (C): prior density first stick-breaking weight w1w_1, dominance risk assessment (useful detecting overly concentrated priors) Panel (D): Summary statistics table consolidating key diagnostics","code":"plot(fit) #> TableGrob (2 x 2) \"dpprior_dashboard\": 4 grobs #>   z     cells              name           grob #> 1 1 (1-1,1-1) dpprior_dashboard gtable[layout] #> 2 2 (2-2,1-1) dpprior_dashboard gtable[layout] #> 3 3 (1-1,2-2) dpprior_dashboard gtable[layout] #> 4 4 (2-2,2-2) dpprior_dashboard gtable[layout]"},{"path":"https://joonho112.github.io/DPprior/articles/quick-start.html","id":"individual-plots","dir":"Articles","previous_headings":"3. Visualizing Your Prior","what":"3.2 Individual Plots","title":"Quick Start: Your First Prior in 5 Minutes","text":"can also create individual plots focused analysis:","code":"plot_alpha_prior(fit) plot_K_prior(fit) plot_w1_prior(fit)"},{"path":"https://joonho112.github.io/DPprior/articles/quick-start.html","id":"three-ways-to-specify-your-uncertainty","dir":"Articles","previous_headings":"","what":"4. Three Ways to Specify Your Uncertainty","title":"Quick Start: Your First Prior in 5 Minutes","text":"DPprior_fit() function offers flexibility express prior uncertainty number clusters:","code":""},{"path":"https://joonho112.github.io/DPprior/articles/quick-start.html","id":"method-1-confidence-level-recommended-for-beginners","dir":"Articles","previous_headings":"4. Three Ways to Specify Your Uncertainty","what":"Method 1: Confidence Level (Recommended for Beginners)","title":"Quick Start: Your First Prior in 5 Minutes","text":"simplest approach uses qualitative confidence levels: Interpretation: Higher confidence (lower uncertainty) leads concentrated prior Œ±\\alpha, reflected lower coefficient variation (CV).","code":"# Low confidence = high uncertainty (wide prior) fit_low <- DPprior_fit(J = 50, mu_K = 5, confidence = \"low\") #> Warning: HIGH DOMINANCE RISK: P(w1 > 0.5) = 56.3% exceeds 40%. #>   This may indicate unintended prior behavior (Lee, 2026). #>   Consider using DPprior_dual() for weight-constrained elicitation. #>   See ?DPprior_diagnostics for interpretation.  # Medium confidence = moderate uncertainty (default) fit_med <- DPprior_fit(J = 50, mu_K = 5, confidence = \"medium\") #> Warning: HIGH DOMINANCE RISK: P(w1 > 0.5) = 49.7% exceeds 40%. #>   This may indicate unintended prior behavior (Lee, 2026). #>   Consider using DPprior_dual() for weight-constrained elicitation. #>   See ?DPprior_diagnostics for interpretation.  # High confidence = low uncertainty (concentrated prior) fit_high <- DPprior_fit(J = 50, mu_K = 5, confidence = \"high\") #> Warning: HIGH DOMINANCE RISK: P(w1 > 0.5) = 46.5% exceeds 40%. #>   This may indicate unintended prior behavior (Lee, 2026). #>   Consider using DPprior_dual() for weight-constrained elicitation. #>   See ?DPprior_diagnostics for interpretation.  # Compare the resulting Gamma parameters comparison <- data.frame(   Confidence = c(\"Low\", \"Medium\", \"High\"),   var_K = round(c(fit_low$target$var_K, fit_med$target$var_K,                    fit_high$target$var_K), 2),   a = round(c(fit_low$a, fit_med$a, fit_high$a), 3),   b = round(c(fit_low$b, fit_med$b, fit_high$b), 3),   CV_alpha = round(1/sqrt(c(fit_low$a, fit_med$a, fit_high$a)), 3) ) comparison #>   Confidence var_K     a     b CV_alpha #> 1        Low    20 0.518 0.341    1.390 #> 2     Medium    10 1.408 1.077    0.843 #> 3       High     6 3.568 2.900    0.529"},{"path":"https://joonho112.github.io/DPprior/articles/quick-start.html","id":"method-2-direct-variance-specification","dir":"Articles","previous_headings":"4. Three Ways to Specify Your Uncertainty","what":"Method 2: Direct Variance Specification","title":"Quick Start: Your First Prior in 5 Minutes","text":"users want precise control:","code":"# Specify variance of K directly fit_direct <- DPprior_fit(J = 50, mu_K = 5, var_K = 10) #> Warning: HIGH DOMINANCE RISK: P(w1 > 0.5) = 49.7% exceeds 40%. #>   This may indicate unintended prior behavior (Lee, 2026). #>   Consider using DPprior_dual() for weight-constrained elicitation. #>   See ?DPprior_diagnostics for interpretation. cat(\"Direct specification: var_K = 10\\n\") #> Direct specification: var_K = 10 cat(\"  Gamma(a =\", round(fit_direct$a, 3), \", b =\", round(fit_direct$b, 3), \")\\n\") #>   Gamma(a = 1.408 , b = 1.077 )"},{"path":"https://joonho112.github.io/DPprior/articles/quick-start.html","id":"method-3-different-calibration-methods","dir":"Articles","previous_headings":"4. Three Ways to Specify Your Uncertainty","what":"Method 3: Different Calibration Methods","title":"Quick Start: Your First Prior in 5 Minutes","text":"advanced users, different calibration algorithms available:","code":"# A2-MN (default): Exact moment matching via Newton's method fit_newton <- DPprior_fit(J = 50, mu_K = 5, var_K = 10, method = \"A2-MN\") #> Warning: HIGH DOMINANCE RISK: P(w1 > 0.5) = 49.7% exceeds 40%. #>   This may indicate unintended prior behavior (Lee, 2026). #>   Consider using DPprior_dual() for weight-constrained elicitation. #>   See ?DPprior_diagnostics for interpretation.  # A1: Fast closed-form approximation (good for large J) fit_approx <- DPprior_fit(J = 50, mu_K = 5, var_K = 10, method = \"A1\") #> Warning: HIGH DOMINANCE RISK: P(w1 > 0.5) = 53.3% exceeds 40%. #>   This may indicate unintended prior behavior (Lee, 2026). #>   Consider using DPprior_dual() for weight-constrained elicitation. #>   See ?DPprior_diagnostics for interpretation.  cat(\"A2-MN: Gamma(\", round(fit_newton$a, 3), \", \", round(fit_newton$b, 3), \")\\n\", sep = \"\") #> A2-MN: Gamma(1.408, 1.077) cat(\"A1:    Gamma(\", round(fit_approx$a, 3), \", \", round(fit_approx$b, 3), \")\\n\", sep = \"\") #> A1:    Gamma(2.667, 2.608)"},{"path":"https://joonho112.github.io/DPprior/articles/quick-start.html","id":"using-your-prior-in-practice","dir":"Articles","previous_headings":"","what":"5. Using Your Prior in Practice","title":"Quick Start: Your First Prior in 5 Minutes","text":"elicited Gamma hyperparameters, can use Bayesian software choice.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/quick-start.html","id":"stan","dir":"Articles","previous_headings":"5. Using Your Prior in Practice","what":"Stan","title":"Quick Start: Your First Prior in 5 Minutes","text":"","code":"data {   int<lower=1> J; } parameters {   real<lower=0> alpha; } model {   // Elicited prior from DPprior   alpha ~ gamma(1.6, 0.816);  // Replace with your fit$a and fit$b }"},{"path":"https://joonho112.github.io/DPprior/articles/quick-start.html","id":"jags","dir":"Articles","previous_headings":"5. Using Your Prior in Practice","what":"JAGS","title":"Quick Start: Your First Prior in 5 Minutes","text":"","code":"model {   # Elicited prior from DPprior   alpha ~ dgamma(1.6, 0.816)  # Note: JAGS uses rate parameterization      # ... rest of your DP mixture model }"},{"path":"https://joonho112.github.io/DPprior/articles/quick-start.html","id":"r-for-simulation","dir":"Articles","previous_headings":"5. Using Your Prior in Practice","what":"R (for simulation)","title":"Quick Start: Your First Prior in 5 Minutes","text":"","code":"# Draw samples from the elicited prior n_samples <- 10000 alpha_samples <- rgamma(n_samples, shape = fit$a, rate = fit$b)  cat(\"Summary of sampled Œ± values:\\n\") #> Summary of sampled Œ± values: cat(\"  Mean:\", round(mean(alpha_samples), 3), \"\\n\") #>   Mean: 1.32 cat(\"  SD:  \", round(sd(alpha_samples), 3), \"\\n\") #>   SD:   1.118 cat(\"  95% CI: [\", round(quantile(alpha_samples, 0.025), 3), \", \",     round(quantile(alpha_samples, 0.975), 3), \"]\\n\", sep = \"\") #>   95% CI: [0.079, 4.256]"},{"path":"https://joonho112.github.io/DPprior/articles/quick-start.html","id":"whats-next","dir":"Articles","previous_headings":"","what":"What‚Äôs Next?","title":"Quick Start: Your First Prior in 5 Minutes","text":"quick start covered essentials. advanced topics: Applied Guide: Comprehensive elicitation workflow sensitivity analysis Dual-Anchor Framework: Control cluster count cluster weight concentration Diagnostics: Verify prior meets specifications Case Studies: Real-world examples education, medicine, policy research","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/articles/quick-start.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Quick Start: Your First Prior in 5 Minutes","text":"Lee, J., Che, J., Rabe-Hesketh, S., Feller, ., & Miratrix, L. (2025). Improving estimation site-specific effects distribution multisite trials. Journal Educational Behavioral Statistics, 50(5), 731‚Äì764. https://doi.org/10.3102/10769986241254286 questions feedback, please visit GitHub repository.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/theory-approximations.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"From Poisson Proxy to NegBin: The A1 Approximation Theory","text":"vignette provides rigorous mathematical treatment A1 closed-form approximation used DPprior package Gamma hyperprior elicitation. A1 method transforms practitioner beliefs number clusters (ŒºK,œÉK2)(\\mu_K, \\sigma^2_K) Gamma hyperparameters (,b)(, b) via Negative Binomial moment-matching procedure. cover: Poisson approximation large JJ theoretical foundations Scaling constant selection: logJ\\log J vs harmonic vs digamma Negative Binomial gamma mixture identity A1 inverse mapping (Theorem 1) Error analysis limitations approximation Throughout, carefully distinguish established results literature novel contributions work.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/articles/theory-approximations.html","id":"established-result-poisson-convergence","dir":"Articles","previous_headings":"1. The Poisson Approximation for Large J","what":"1.1 Established Result: Poisson Convergence","title":"From Poisson Proxy to NegBin: The A1 Approximation Theory","text":"starting point A1 approximation classical result asymptotic distribution KJ|Œ±K_J | \\alpha. Recall Poisson-Binomial representation (see vignette(\"theory-overview\")) : KJ=‚àë=1JBi,Bi‚àºBernoulli(Œ±Œ±+‚àí1). K_J = \\sum_{=1}^{J} B_i, \\quad B_i \\sim \\text{Bernoulli}\\left(\\frac{\\alpha}{\\alpha + - 1}\\right). Attribution. following Poisson convergence result established Arratia, Barbour, Tavar√© (2000), rate explicitly stated Vicentini Jermyn (2025, Equation 10): Theorem (Poisson Approximation). fixed Œ±>0\\alpha > 0 J‚Üí‚àûJ \\\\infty: dTV(p(KJ|Œ±),Poisson(ùîº[KJ|Œ±]))=O(1logJ), d_{TV}\\left(p(K_J | \\alpha),\\ \\text{Poisson}(\\mathbb{E}[K_J | \\alpha])\\right) = O\\left(\\frac{1}{\\log J}\\right), dTVd_{TV} denotes total variation distance. convergence, sublinear, provides conceptual foundation using Poisson proxy elicitation.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/theory-approximations.html","id":"the-shifted-poisson-proxy","dir":"Articles","previous_headings":"1. The Poisson Approximation for Large J","what":"1.2 The Shifted Poisson Proxy","title":"From Poisson Proxy to NegBin: The A1 Approximation Theory","text":"Novel Contribution. key insight motivating DPprior approach apply Poisson approximation KJ‚àí1K_J - 1 rather KJK_J directly. Rationale. unshifted Poisson approximation unavoidable support mismatch KJ‚â•1K_J \\geq 1 almost surely CRP (least one cluster always exists). Q=Poisson(Œª)Q = \\text{Poisson}(\\lambda), : dTV(‚Ñí(KJ),Q)‚â•12Q(0)=12e‚àíŒª. d_{TV}(\\mathcal{L}(K_J),\\ Q) \\geq \\frac{1}{2}Q(0) = \\frac{1}{2}e^{-\\lambda}. small Œª\\lambda (occurs elicited ùîº[KJ]\\mathbb{E}[K_J] close 1), creates substantial lower bound approximation error. A1 proxy (shifted): KJ‚àí1‚à£Œ±‚âàPoisson(Œ±‚ãÖcJ), K_J - 1 \\mid \\alpha \\approx \\text{Poisson}(\\alpha \\cdot c_J),  equivalently KJ‚âà1+Poisson(Œ±‚ãÖcJ)K_J \\approx 1 + \\text{Poisson}(\\alpha \\cdot c_J). shift aligns naturally Proposition 1 theory vignette, since KJ‚àí1K_J - 1 sum J‚àí1J-1 independent Bernoulli variables (B1‚â°1B_1 \\equiv 1). Intuition: probability opening new table decreases customers arrive.","code":"# Visualize the CRP probabilities J <- 50 alpha_values <- c(0.5, 1, 2, 5)  crp_data <- do.call(rbind, lapply(alpha_values, function(a) {   i <- 1:J   p_new <- a / (a + i - 1)   data.frame(     customer = i,     prob_new_table = p_new,     alpha = paste0(\"Œ± = \", a)   ) }))  crp_data$alpha <- factor(crp_data$alpha, levels = paste0(\"Œ± = \", alpha_values))  ggplot(crp_data, aes(x = customer, y = prob_new_table, color = alpha)) +   geom_line(linewidth = 1) +   scale_color_manual(values = palette_main[1:4]) +   labs(     x = \"Customer i\",     y = expression(\"P(new table) = \" * alpha / (alpha + i - 1)),     title = \"CRP: Probability of Starting a New Table\",     subtitle = \"The expected number of tables ‚âà Œ± ¬∑ log(J)\"   ) +   theme_minimal() +   theme(legend.position = \"right\")"},{"path":"https://joonho112.github.io/DPprior/articles/theory-approximations.html","id":"mean-approximation","dir":"Articles","previous_headings":"1. The Poisson Approximation for Large J","what":"1.3 Mean Approximation","title":"From Poisson Proxy to NegBin: The A1 Approximation Theory","text":"exact conditional mean (see vignette(\"theory-overview\")): ŒºJ(Œ±):=ùîº[KJ|Œ±]=Œ±‚ãÖ[œà(Œ±+J)‚àíœà(Œ±)]. \\mu_J(\\alpha) := \\mathbb{E}[K_J | \\alpha] = \\alpha \\cdot [\\psi(\\alpha + J) - \\psi(\\alpha)]. shifted mean: ùîº[KJ‚àí1|Œ±]=ŒºJ(Œ±)‚àí1‚âàŒ±‚ãÖcJ, \\mathbb{E}[K_J - 1 | \\alpha] = \\mu_J(\\alpha) - 1 \\approx \\alpha \\cdot c_J,  cJc_J scaling constant now analyze.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/articles/theory-approximations.html","id":"three-candidates","dir":"Articles","previous_headings":"2. The Scaling Constant Family","what":"2.1 Three Candidates","title":"From Poisson Proxy to NegBin: The A1 Approximation Theory","text":"A1 approximation requires deterministic scaling constant cJ>0c_J > 0 satisfying ŒºJ(Œ±)‚àí1‚âàŒ±‚ãÖcJ\\mu_J(\\alpha) - 1 \\approx \\alpha \\cdot c_J. Three natural candidates emerge asymptotic considerations: Œ≥‚âà0.5772\\gamma \\approx 0.5772 Euler-Mascheroni constant Œ±ÃÉ=(ŒºK‚àí1)/logJ\\tilde{\\alpha} = (\\mu_K - 1)/\\log J plug-estimate. Lemma (Harmonic-Digamma Equivalence). integer J‚â•1J \\geq 1: HJ‚àí1=œà(J)+Œ≥. H_{J-1} = \\psi(J) + \\gamma. Thus, two distinct mean-level competitors integer JJ: logJ\\log J HJ‚àí1H_{J-1}. Comparison scaling constants","code":"# Compare scaling constants across J values J_values <- c(10, 25, 50, 100, 200, 500)  scaling_df <- data.frame(   J = J_values,   log_J = sapply(J_values, function(J) compute_scaling_constant(J, \"log\")),   harmonic = sapply(J_values, function(J) compute_scaling_constant(J, \"harmonic\")) )  scaling_df$difference <- scaling_df$harmonic - scaling_df$log_J scaling_df$ratio <- scaling_df$harmonic / scaling_df$log_J  knitr::kable(   scaling_df,   digits = 4,   col.names = c(\"J\", \"log(J)\", \"H_{J-1}\", \"Difference\", \"Ratio\"),   caption = \"Comparison of scaling constants\" )"},{"path":"https://joonho112.github.io/DPprior/articles/theory-approximations.html","id":"asymptotic-analysis","dir":"Articles","previous_headings":"2. The Scaling Constant Family","what":"2.2 Asymptotic Analysis","title":"From Poisson Proxy to NegBin: The A1 Approximation Theory","text":"Attribution. following asymptotic expansion standard (see Abramowitz & Stegun, 1964): Proposition (Large-J Expansion). fixed Œ±>0\\alpha > 0 J‚Üí‚àûJ \\\\infty: ŒºJ(Œ±)=Œ±logJ‚àíŒ±œà(Œ±)+O(Œ±J). \\mu_J(\\alpha) = \\alpha \\log J - \\alpha \\psi(\\alpha) + O\\left(\\frac{\\alpha}{J}\\right). Moreover: HJ‚àí1=logJ+Œ≥+O(1J). H_{J-1} = \\log J + \\gamma + O\\left(\\frac{1}{J}\\right). Key insight: ‚Äúbest‚Äù Œ±\\alpha-free linear approximation Œ±cJ\\alpha c_J uniform Œ±\\alpha second-order term ‚àíŒ±œà(Œ±)-\\alpha\\psi(\\alpha) depends Œ±\\alpha. exact mean Œº_J(Œ±) linear approximations.","code":"# Show asymptotic behavior J <- 100 alpha_grid <- seq(0.1, 5, length.out = 100)  asymp_data <- data.frame(   alpha = alpha_grid,   exact = mean_K_given_alpha(J, alpha_grid),   log_approx = alpha_grid * log(J) + 1,   harmonic_approx = alpha_grid * (digamma(J) + 0.5772156649) + 1 )  # Reshape for plotting asymp_long <- data.frame(   alpha = rep(alpha_grid, 3),   mean_K = c(asymp_data$exact, asymp_data$log_approx, asymp_data$harmonic_approx),   Method = rep(c(\"Exact\", \"log(J) + 1\", \"H_{J-1} + 1\"), each = length(alpha_grid)) )  asymp_long$Method <- factor(asymp_long$Method,                              levels = c(\"Exact\", \"log(J) + 1\", \"H_{J-1} + 1\"))  ggplot(asymp_long, aes(x = alpha, y = mean_K, color = Method, linetype = Method)) +   geom_line(linewidth = 1) +   scale_color_manual(values = c(\"#000000\", \"#E41A1C\", \"#377EB8\")) +   scale_linetype_manual(values = c(\"solid\", \"dashed\", \"dotted\")) +   labs(     x = expression(alpha),     y = expression(E[K[J] * \" | \" * alpha]),     title = expression(\"Exact Mean vs. Linear Approximations (J = 100)\"),     subtitle = \"The approximations diverge for small and large Œ±\"   ) +   theme_minimal() +   theme(legend.position = \"right\")"},{"path":"https://joonho112.github.io/DPprior/articles/theory-approximations.html","id":"crossover-analysis","dir":"Articles","previous_headings":"2. The Scaling Constant Family","what":"2.3 Crossover Analysis","title":"From Poisson Proxy to NegBin: The A1 Approximation Theory","text":"Novel Contribution. Define crossover point Œ±K‚àí1*(J)\\alpha^*_{K-1}(J) value shifted mean errors equal: |ŒºJ(Œ±)‚àí1‚àíŒ±logJ|=|ŒºJ(Œ±)‚àí1‚àíŒ±HJ‚àí1|. |\\mu_J(\\alpha) - 1 - \\alpha \\log J| = |\\mu_J(\\alpha) - 1 - \\alpha H_{J-1}|. Proposition (Limiting Crossover). J‚Üí‚àûJ \\\\infty: Œ±K‚àí1*(J)‚Üíx*‚àí1‚âà0.200, \\alpha^*_{K-1}(J) \\x_* - 1 \\approx 0.200,  x*=œà‚àí1(‚àíŒ≥/2)‚âà1.200x_* = \\psi^{-1}(-\\gamma/2) \\approx 1.200 solves œà(x*)=‚àíŒ≥/2\\psi(x_*) = -\\gamma/2. Practical implication: shifted mean Œ±‚â≥0.2\\alpha \\gtrsim 0.2 (covers essentially practical applications), logJ\\log J scaling dominates HJ‚àí1H_{J-1} terms mean approximation error.","code":"# Compute mean errors for different scaling choices J_test <- 50 alpha_grid <- seq(0.1, 3, by = 0.1)  error_df <- data.frame(   alpha = alpha_grid,   error_log = abs(mean_K_given_alpha(J_test, alpha_grid) - 1 -                    alpha_grid * compute_scaling_constant(J_test, \"log\")),   error_harmonic = abs(mean_K_given_alpha(J_test, alpha_grid) - 1 -                         alpha_grid * compute_scaling_constant(J_test, \"harmonic\")) )  error_df$better <- ifelse(error_df$error_log < error_df$error_harmonic,                            \"log(J)\", \"H_{J-1}\")  cat(\"Mean error comparison for J =\", J_test, \"\\n\") #> Mean error comparison for J = 50 cat(\"Œ± range where log(J) is better:\",      sum(error_df$better == \"log(J)\"), \"out of\", nrow(error_df), \"values\\n\") #> Œ± range where log(J) is better: 29 out of 30 values cat(\"Crossover occurs near Œ± ‚âà\",      error_df$alpha[which.min(abs(error_df$error_log - error_df$error_harmonic))], \"\\n\") #> Crossover occurs near Œ± ‚âà 0.2"},{"path":"https://joonho112.github.io/DPprior/articles/theory-approximations.html","id":"default-recommendation","dir":"Articles","previous_headings":"2. The Scaling Constant Family","what":"2.4 Default Recommendation","title":"From Poisson Proxy to NegBin: The A1 Approximation Theory","text":"Novel Contribution. Based crossover analysis: Default: Use shifted Poisson cJ=logJc_J = \\log J A1 approximation. choice: simpler compute Provides better mean accuracy Œ±‚â≥0.2\\alpha \\gtrsim 0.2 Aligns asymptotic leading term","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/articles/theory-approximations.html","id":"the-key-identity","dir":"Articles","previous_headings":"3. The NegBin Gamma Mixture","what":"3.1 The Key Identity","title":"From Poisson Proxy to NegBin: The A1 Approximation Theory","text":"Attribution. following standard result Bayesian statistics (see, e.g., Gamma-Poisson conjugacy): Proposition (Gamma-Poisson Mixture). X|Œª‚àºPoisson(Œª)X | \\lambda \\sim \\text{Poisson}(\\lambda) Œª‚àºGamma(,b/(b+1))\\lambda \\sim \\text{Gamma}(, b/(b+1)), : X‚àºNegBin(,b/(b+1)). X \\sim \\text{NegBin}(, b/(b+1)). generally, X|Œª‚àºPoisson(c‚ãÖŒª)X | \\lambda \\sim \\text{Poisson}(c \\cdot \\lambda) Œª‚àºGamma(,b)\\lambda \\sim \\text{Gamma}(, b), : X‚àºNegBin(,bb+c). X \\sim \\text{NegBin}\\left(, \\frac{b}{b + c}\\right).","code":""},{"path":"https://joonho112.github.io/DPprior/articles/theory-approximations.html","id":"application-to-k_j","dir":"Articles","previous_headings":"3. The NegBin Gamma Mixture","what":"3.2 Application to KJK_J","title":"From Poisson Proxy to NegBin: The A1 Approximation Theory","text":"Novel Application. Applying A1 proxy Œ±‚àºGamma(,b)\\alpha \\sim \\text{Gamma}(, b): KJ‚àí1‚à£Œ±‚âàPoisson(Œ±‚ãÖcJ)‚áíKJ‚àí1‚âàNegBin(,bb+cJ). K_J - 1 \\mid \\alpha \\approx \\text{Poisson}(\\alpha \\cdot c_J) \\quad \\Longrightarrow \\quad K_J - 1 \\approx \\text{NegBin}\\left(, \\frac{b}{b + c_J}\\right). NegBin(r,p)(r, p) parameterization pp success probability: NegBin approximation vs exact marginal distribution.","code":"# Compare NegBin approximation to exact marginal J <- 50 a <- 1.5 b <- 0.5 logS <- compute_log_stirling(J)  # Exact marginal PMF pmf_exact <- pmf_K_marginal(J, a, b, logS)  # NegBin approximation c_J <- log(J) p_nb <- b / (b + c_J)  # NegBin PMF for K-1, then shift k_vals <- 0:J pmf_negbin <- dnbinom(k_vals - 1, size = a, prob = p_nb) pmf_negbin[1] <- 0  # K >= 1  # Normalize for comparison pmf_negbin <- pmf_negbin / sum(pmf_negbin)  # Create comparison data k_show <- 1:25 comparison_df <- data.frame(   K = rep(k_show, 2),   Probability = c(pmf_exact[k_show + 1], pmf_negbin[k_show + 1]),   Method = rep(c(\"Exact Marginal\", \"NegBin Approximation\"), each = length(k_show)) )  ggplot(comparison_df, aes(x = K, y = Probability, fill = Method)) +   geom_bar(stat = \"identity\", position = \"dodge\", alpha = 0.8) +   scale_fill_manual(values = c(\"#377EB8\", \"#E41A1C\")) +   labs(     x = expression(K[J]),     y = \"Probability\",     title = expression(\"NegBin Approximation vs Exact Marginal (J = 50)\"),     subtitle = paste0(\"Gamma(\", a, \", \", b, \") prior on Œ±\")   ) +   theme_minimal() +   theme(legend.position = \"bottom\")"},{"path":[]},{"path":"https://joonho112.github.io/DPprior/articles/theory-approximations.html","id":"the-inverse-problem","dir":"Articles","previous_headings":"4. The A1 Inverse Mapping (Theorem 1)","what":"4.1 The Inverse Problem","title":"From Poisson Proxy to NegBin: The A1 Approximation Theory","text":"Given practitioner-specified beliefs (ŒºK,œÉK2)(\\mu_K, \\sigma^2_K) number clusters, seek Gamma hyperparameters (,b)(, b) marginal distribution KJK_J desired moments. NegBin proxy, becomes moment-matching problem analytical solution.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/theory-approximations.html","id":"main-result","dir":"Articles","previous_headings":"4. The A1 Inverse Mapping (Theorem 1)","what":"4.2 Main Result","title":"From Poisson Proxy to NegBin: The A1 Approximation Theory","text":"Novel Contribution. following theorem provides closed-form inverse mapping central A1 method: Theorem 1 (A1 Inverse Mapping). Fix J‚â•2J \\geq 2 scaling constant cJ>0c_J > 0. Define shifted mean m:=ŒºK‚àí1m := \\mu_K - 1. m>0m > 0 œÉK2>m\\sigma^2_K > m (overdispersion), exists unique (,b)‚àà(0,‚àû)2(, b) \\(0, \\infty)^2 matches (ŒºK,œÉK2)(\\mu_K, \\sigma^2_K) NegBin proxy, given : =m2œÉK2‚àím,b=m‚ãÖcJœÉK2‚àím \\boxed{ = \\frac{m^2}{\\sigma^2_K - m}, \\qquad b = \\frac{m \\cdot c_J}{\\sigma^2_K - m} } Proof. NegBin moments: ŒºK=1+‚ãÖcJb‚áíb=‚ãÖcJm. \\mu_K = 1 + \\frac{\\cdot c_J}{b} \\quad \\Rightarrow \\quad b = \\frac{\\cdot c_J}{m}. Substituting variance equation œÉK2=‚ãÖcJ‚ãÖ(b+cJ)b2\\sigma^2_K = \\frac{\\cdot c_J \\cdot (b + c_J)}{b^2}: œÉK2=‚ãÖcJ‚ãÖ(b+cJ)b2=m+m2a. \\sigma^2_K = \\frac{\\cdot c_J \\cdot (b + c_J)}{b^2} = m + \\frac{m^2}{}. Solving aa: =m2œÉK2‚àím. = \\frac{m^2}{\\sigma^2_K - m}. Positivity requires œÉK2>m\\sigma^2_K > m, overdispersion condition. ‚ñ´\\square","code":""},{"path":"https://joonho112.github.io/DPprior/articles/theory-approximations.html","id":"corollary-interpretation-for-alpha","dir":"Articles","previous_headings":"4. The A1 Inverse Mapping (Theorem 1)","what":"4.3 Corollary: Interpretation for Œ±\\alpha","title":"From Poisson Proxy to NegBin: The A1 Approximation Theory","text":"Corollary 1. Theorem 1: ùîº[Œ±]=ab=mcJ,Var(Œ±)=ab2=œÉK2‚àímcJ2,CV(Œ±)=1a=œÉK2‚àímm. \\mathbb{E}[\\alpha] = \\frac{}{b} = \\frac{m}{c_J}, \\qquad \\text{Var}(\\alpha) = \\frac{}{b^2} = \\frac{\\sigma^2_K - m}{c_J^2}, \\qquad \\text{CV}(\\alpha) = \\frac{1}{\\sqrt{}} = \\frac{\\sqrt{\\sigma^2_K - m}}{m}. Interpretation: A1, ŒºK\\mu_K determines prior mean Œ±\\alpha, ‚Äúconfidence‚Äù (œÉK2‚àím\\sigma^2_K - m) determines prior variance Œ±\\alpha.","code":"# Demonstrate the A1 mapping J <- 50 mu_K <- 5 var_K <- 8  # Step-by-step calculation m <- mu_K - 1 D <- var_K - m c_J <- log(J)  cat(\"A1 Inverse Mapping Demonstration\\n\") #> A1 Inverse Mapping Demonstration cat(paste(rep(\"=\", 50), collapse = \"\"), \"\\n\\n\") #> ==================================================  cat(\"Inputs:\\n\") #> Inputs: cat(sprintf(\"  J = %d\\n\", J)) #>   J = 50 cat(sprintf(\"  Œº_K = %.1f\\n\", mu_K)) #>   Œº_K = 5.0 cat(sprintf(\"  œÉ¬≤_K = %.1f\\n\\n\", var_K)) #>   œÉ¬≤_K = 8.0  cat(\"Intermediate calculations:\\n\") #> Intermediate calculations: cat(sprintf(\"  m = Œº_K - 1 = %.1f\\n\", m)) #>   m = Œº_K - 1 = 4.0 cat(sprintf(\"  D = œÉ¬≤_K - m = %.1f\\n\", D)) #>   D = œÉ¬≤_K - m = 4.0 cat(sprintf(\"  c_J = log(J) = %.4f\\n\\n\", c_J)) #>   c_J = log(J) = 3.9120  cat(\"A1 formulas:\\n\") #> A1 formulas: cat(sprintf(\"  a = m¬≤ / D = %.1f¬≤ / %.1f = %.4f\\n\", m, D, m^2/D)) #>   a = m¬≤ / D = 4.0¬≤ / 4.0 = 4.0000 cat(sprintf(\"  b = m ¬∑ c_J / D = %.1f √ó %.4f / %.1f = %.4f\\n\\n\", m, c_J, D, m*c_J/D)) #>   b = m ¬∑ c_J / D = 4.0 √ó 3.9120 / 4.0 = 3.9120  # Use DPprior_a1 to verify fit <- DPprior_a1(J = J, mu_K = mu_K, var_K = var_K)  cat(\"DPprior_a1() result:\\n\") #> DPprior_a1() result: cat(sprintf(\"  a = %.4f\\n\", fit$a)) #>   a = 4.0000 cat(sprintf(\"  b = %.4f\\n\", fit$b)) #>   b = 3.9120 cat(sprintf(\"  E[Œ±] = a/b = %.4f\\n\", fit$a / fit$b)) #>   E[Œ±] = a/b = 1.0225 cat(sprintf(\"  CV(Œ±) = 1/‚àöa = %.4f\\n\", 1/sqrt(fit$a))) #>   CV(Œ±) = 1/‚àöa = 0.5000"},{"path":"https://joonho112.github.io/DPprior/articles/theory-approximations.html","id":"feasibility-region","dir":"Articles","previous_headings":"4. The A1 Inverse Mapping (Theorem 1)","what":"4.4 Feasibility Region","title":"From Poisson Proxy to NegBin: The A1 Approximation Theory","text":"Novel Contribution. feasibility constraints A1 : Shifted A1 (default, DP partitions): ŒºK>1andœÉK2>ŒºK‚àí1. \\mu_K > 1 \\quad \\text{} \\quad \\sigma^2_K > \\mu_K - 1. proxy-model constraints arising NegBin moment identity, fundamental constraints DP . Important: user specifications œÉK2‚â§ŒºK‚àí1\\sigma^2_K \\leq \\mu_K - 1 may feasible exact DP infeasible A1. cases, package projects feasibility boundary.","code":"# Demonstrate feasibility projection cat(\"Feasibility Demonstration\\n\") #> Feasibility Demonstration cat(paste(rep(\"=\", 50), collapse = \"\"), \"\\n\\n\") #> ==================================================  # Case 1: Feasible fit1 <- DPprior_a1(J = 50, mu_K = 5, var_K = 8) cat(\"Case 1: Feasible (var_K = 8 > Œº_K - 1 = 4)\\n\") #> Case 1: Feasible (var_K = 8 > Œº_K - 1 = 4) cat(sprintf(\"  Status: %s\\n\\n\", fit1$status)) #>   Status: success  # Case 2: Infeasible - requires projection fit2 <- DPprior_a1(J = 50, mu_K = 5, var_K = 3) #> Warning: var_K <= mu_K - 1: projected to feasible boundary cat(\"Case 2: Infeasible (var_K = 3 < Œº_K - 1 = 4)\\n\") #> Case 2: Infeasible (var_K = 3 < Œº_K - 1 = 4) cat(sprintf(\"  Status: %s\\n\", fit2$status)) #>   Status: projected cat(sprintf(\"  Original var_K: %.1f\\n\", 3)) #>   Original var_K: 3.0 cat(sprintf(\"  Projected var_K: %.6f\\n\", fit2$target$var_K_used))"},{"path":"https://joonho112.github.io/DPprior/articles/theory-approximations.html","id":"near-boundary-sensitivity","dir":"Articles","previous_headings":"4. The A1 Inverse Mapping (Theorem 1)","what":"4.5 Near-Boundary Sensitivity","title":"From Poisson Proxy to NegBin: The A1 Approximation Theory","text":"Novel Contribution. Define D:=œÉK2‚àímD := \\sigma^2_K - m. D‚Üì0D \\downarrow 0: ‚àºm2D‚Üí‚àû,b‚àºm‚ãÖcJD‚Üí‚àû, \\sim \\frac{m^2}{D} \\\\infty, \\qquad b \\sim \\frac{m \\cdot c_J}{D} \\\\infty,  ùîº[Œ±]=m/cJ\\mathbb{E}[\\alpha] = m/c_J remains finite. sensitivities scale O(D‚àí2)O(D^{-2}), meaning high-confidence specifications (small DD) lead numerically ill-conditioned mappings. motivates projection buffer implementation.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/articles/theory-approximations.html","id":"sources-of-approximation-error","dir":"Articles","previous_headings":"5. Error Analysis","what":"5.1 Sources of Approximation Error","title":"From Poisson Proxy to NegBin: The A1 Approximation Theory","text":"A1 method introduces several sources error: Poisson proxy error: finite-JJ deviation Poisson limit Scaling constant choice: Different cJc_J options introduce different biases Moment matching vs.¬†distribution matching: Even moments match, full distributions may differ","code":""},{"path":"https://joonho112.github.io/DPprior/articles/theory-approximations.html","id":"quantifying-moment-error","dir":"Articles","previous_headings":"5. Error Analysis","what":"5.2 Quantifying Moment Error","title":"From Poisson Proxy to NegBin: The A1 Approximation Theory","text":"Novel Contribution. can directly compare A1-achieved moments exact marginal moments: A1 approximation error: target vs.¬†achieved moments","code":"# Compare A1 moments to exact moments test_cases <- expand.grid(   J = c(25, 50, 100, 200),   mu_K = c(5, 10),   vif = c(1.5, 2, 3) )  # Filter valid cases first test_cases <- test_cases[test_cases$mu_K < test_cases$J, ]  results <- do.call(rbind, lapply(1:nrow(test_cases), function(i) {   J <- test_cases$J[i]   mu_K <- test_cases$mu_K[i]   vif <- test_cases$vif[i]   var_K <- vif * (mu_K - 1)      # A1 mapping   fit <- DPprior_a1(J = J, mu_K = mu_K, var_K = var_K)      # Exact moments with A1 parameters   exact <- exact_K_moments(J, fit$a, fit$b)      data.frame(     J = J,     mu_K_target = mu_K,     var_K_target = var_K,     mu_K_achieved = exact$mean,     var_K_achieved = exact$var,     mu_error_pct = 100 * (exact$mean - mu_K) / mu_K,     var_error_pct = 100 * (exact$var - var_K) / var_K   ) }))  knitr::kable(   results,   digits = c(0, 1, 1, 2, 2, 1, 1),   col.names = c(\"J\", \"Œº_K (target)\", \"œÉ¬≤_K (target)\",                  \"Œº_K (achieved)\", \"œÉ¬≤_K (achieved)\",                 \"Mean Error %\", \"Var Error %\"),   caption = \"A1 approximation error: target vs. achieved moments\" )"},{"path":"https://joonho112.github.io/DPprior/articles/theory-approximations.html","id":"systematic-patterns","dir":"Articles","previous_headings":"5. Error Analysis","what":"5.3 Systematic Patterns","title":"From Poisson Proxy to NegBin: The A1 Approximation Theory","text":"A1 mean error function J Œº_K.","code":"# Create heatmap of A1 mean errors J_grid <- c(20, 30, 50, 75, 100, 150, 200) mu_grid <- seq(3, 15, by = 2)  error_matrix <- matrix(NA, nrow = length(J_grid), ncol = length(mu_grid)) rownames(error_matrix) <- paste0(\"J=\", J_grid) colnames(error_matrix) <- paste0(\"Œº=\", mu_grid)  for (i in seq_along(J_grid)) {   for (j in seq_along(mu_grid)) {     J <- J_grid[i]     mu_K <- mu_grid[j]          if (mu_K < J) {       var_K <- 2 * (mu_K - 1)  # VIF = 2       fit <- DPprior_a1(J = J, mu_K = mu_K, var_K = var_K)       exact <- exact_K_moments(J, fit$a, fit$b)       error_matrix[i, j] <- 100 * (exact$mean - mu_K) / mu_K     }   } }  # Convert to data frame for ggplot error_df <- expand.grid(J = J_grid, mu_K = mu_grid) error_df$error <- as.vector(error_matrix)  ggplot(error_df[!is.na(error_df$error), ],         aes(x = factor(mu_K), y = factor(J), fill = error)) +   geom_tile() +   geom_text(aes(label = sprintf(\"%.1f%%\", error)), color = \"white\", size = 3) +   scale_fill_gradient2(low = \"#377EB8\", mid = \"white\", high = \"#E41A1C\",                        midpoint = 0, name = \"Mean\\nError %\") +   labs(     x = expression(\"Target \" * mu[K]),     y = \"Sample Size J\",     title = \"A1 Mean Error Pattern\",     subtitle = \"VIF = 2 for all cases\"   ) +   theme_minimal()"},{"path":"https://joonho112.github.io/DPprior/articles/theory-approximations.html","id":"critical-warning-negbin-marginal-limitations","dir":"Articles","previous_headings":"5. Error Analysis","what":"5.4 Critical Warning: NegBin Marginal Limitations","title":"From Poisson Proxy to NegBin: The A1 Approximation Theory","text":"Novel Finding. Tables research notes demonstrate NegBin marginal approximation can produce: Mean errors 40-75% Variance errors 230-730% confirms A1 viewed primarily initializer, final solution. A2 Newton refinement (see vignette(\"theory-newton\")) applied application requiring accurate moment matching.","code":"# Compare A1 to A2 refinement J <- 50 mu_K <- 5 var_K <- 8  # A1 only fit_a1 <- DPprior_a1(J = J, mu_K = mu_K, var_K = var_K) exact_a1 <- exact_K_moments(J, fit_a1$a, fit_a1$b)  # A2 refinement (full DPprior_fit) fit_a2 <- DPprior_fit(J = J, mu_K = mu_K, var_K = var_K) #> Warning: HIGH DOMINANCE RISK: P(w1 > 0.5) = 48.1% exceeds 40%. #>   This may indicate unintended prior behavior (Lee, 2026). #>   Consider using DPprior_dual() for weight-constrained elicitation. #>   See ?DPprior_diagnostics for interpretation. exact_a2 <- exact_K_moments(J, fit_a2$a, fit_a2$b)  cat(\"Comparison: A1 vs A2 Refinement\\n\") #> Comparison: A1 vs A2 Refinement cat(paste(rep(\"=\", 50), collapse = \"\"), \"\\n\\n\") #> ==================================================  cat(sprintf(\"Target: Œº_K = %.1f, œÉ¬≤_K = %.1f\\n\\n\", mu_K, var_K)) #> Target: Œº_K = 5.0, œÉ¬≤_K = 8.0  cat(\"A1 (closed-form):\\n\") #> A1 (closed-form): cat(sprintf(\"  Parameters: a = %.4f, b = %.4f\\n\", fit_a1$a, fit_a1$b)) #>   Parameters: a = 4.0000, b = 3.9120 cat(sprintf(\"  Achieved:   Œº_K = %.4f, œÉ¬≤_K = %.4f\\n\", exact_a1$mean, exact_a1$var)) #>   Achieved:   Œº_K = 4.4614, œÉ¬≤_K = 4.7831 cat(sprintf(\"  Errors:     %.2f%% (mean), %.2f%% (var)\\n\\n\",             100 * (exact_a1$mean - mu_K) / mu_K,             100 * (exact_a1$var - var_K) / var_K)) #>   Errors:     -10.77% (mean), -40.21% (var)  cat(\"A2 (Newton refinement):\\n\") #> A2 (Newton refinement): cat(sprintf(\"  Parameters: a = %.4f, b = %.4f\\n\", fit_a2$a, fit_a2$b)) #>   Parameters: a = 2.0361, b = 1.6051 cat(sprintf(\"  Achieved:   Œº_K = %.6f, œÉ¬≤_K = %.6f\\n\", exact_a2$mean, exact_a2$var)) #>   Achieved:   Œº_K = 5.000000, œÉ¬≤_K = 8.000000 cat(sprintf(\"  Errors:     %.2e%% (mean), %.2e%% (var)\\n\",             100 * abs(exact_a2$mean - mu_K) / mu_K,             100 * abs(exact_a2$var - var_K) / var_K)) #>   Errors:     1.66e-08% (mean), 9.44e-08% (var)"},{"path":"https://joonho112.github.io/DPprior/articles/theory-approximations.html","id":"summary","dir":"Articles","previous_headings":"","what":"6. Summary","title":"From Poisson Proxy to NegBin: The A1 Approximation Theory","text":"vignette provided rigorous treatment A1 approximation theory: Poisson approximation: classical result KJ‚àí1|Œ±K_J - 1 | \\alpha converges Poisson(Œ±‚ãÖcJ)(\\alpha \\cdot c_J) provides theoretical foundation. Scaling constant: default cJ=logJc_J = \\log J provides best mean-level accuracy typical Œ±\\alpha values. NegBin mixture: Œ±‚àºGamma(,b)\\alpha \\sim \\text{Gamma}(, b), marginal KJ‚àí1K_J - 1 approximately follows Negative Binomial distribution. Inverse mapping: Theorem 1 provides closed-form expressions (,b)(, b) given target moments (ŒºK,œÉK2)(\\mu_K, \\sigma^2_K). Limitations: A1 approximation can substantial errors viewed initializer A2 Newton refinement.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/theory-approximations.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"From Poisson Proxy to NegBin: The A1 Approximation Theory","text":"Abramowitz, M., & Stegun, . . (1964). Handbook Mathematical Functions. National Bureau Standards. Antoniak, C. E. (1974). Mixtures Dirichlet processes applications Bayesian nonparametric problems. Annals Statistics, 2(6), 1152-1174. Arratia, R., Barbour, . D., & Tavar√©, S. (2000). number components logarithmic combinatorial structure. Annals Applied Probability, 10(2), 331-361. Dorazio, R. M. (2009). selecting prior precision parameter Dirichlet process mixture models. Journal Statistical Planning Inference, 139(10), 3384-3390. Murugiah, S., & Sweeting, T. J. (2012). Selecting precision parameter prior Dirichlet process mixture models. Journal Statistical Computation Simulation, 82(9), 1307-1322. Vicentini, C., & Jermyn, . H. (2025). Prior selection precision parameter Dirichlet process mixtures. arXiv:2502.00864. questions vignette DPprior package, please visit GitHub repository.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/theory-newton.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Exact Moment Matching: The A2 Newton Algorithm","text":"vignette provides rigorous mathematical treatment A2 Newton algorithm (A2-MN) used DPprior package achieve exact moment matching Gamma hyperprior elicitation. A1 closed-form approximation (see vignette(\"theory-approximations\")) provides fast initialization, introduces systematic errors can substantial small--moderate JJ‚Äîprecisely regime relevant multisite trials meta-analyses education. cover: problem formulation: moment matching root-finding Jacobian: score-based derivation (avoiding finite differences) Convergence analysis: local quadratic convergence Numerical safeguards: damping, positivity constraints, fallback strategies A1 vs.¬†A2 comparison: quantifying improvement Throughout, carefully distinguish established results numerical analysis literature novel contributions work applying methods DP hyperprior calibration.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/articles/theory-newton.html","id":"the-inverse-problem","dir":"Articles","previous_headings":"1. Problem Formulation","what":"1.1 The Inverse Problem","title":"Exact Moment Matching: The A2 Newton Algorithm","text":"Recall vignette(\"theory-overview\") seek Gamma hyperparameters (,b)(, b) induced marginal distribution KJK_J Œ±‚àºGamma(,b)\\alpha \\sim \\text{Gamma}(, b) user-specified moments: M1(,b):=ùîº[KJ‚à£,b]=ŒºK,V(,b):=Var(KJ‚à£,b)=œÉK2. M_1(, b) := \\mathbb{E}[K_J \\mid , b] = \\mu_K, \\quad V(, b) := \\text{Var}(K_J \\mid , b) = \\sigma^2_K. A1 approximation solves problem Negative Binomial proxy, yielding closed-form expressions asymptotically exact J‚Üí‚àûJ \\\\infty. However, finite JJ, A1 solution (a0,b0)(a_0, b_0) may satisfy exact moment equations. Goal A2. Find (*,b*)(^*, b^*) exact marginal moments, computed via Gauss-Laguerre quadrature (see vignette(\"theory-overview\")), match targets precisely: F(*,b*):=(M1(*,b*)‚àíŒºKV(*,b*)‚àíœÉK2)=ùüé. F(^*, b^*) := \\begin{pmatrix} M_1(^*, b^*) - \\mu_K \\\\                                 V(^*, b^*) - \\sigma^2_K \\end{pmatrix} = \\mathbf{0}.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/theory-newton.html","id":"newton-raphson-iteration","dir":"Articles","previous_headings":"1. Problem Formulation","what":"1.2 Newton-Raphson Iteration","title":"Exact Moment Matching: The A2 Newton Algorithm","text":"Attribution. Newton‚Äôs method systems nonlinear equations classical algorithm numerical analysis; see Ortega & Rheinboldt (1970) theoretical foundations. Novel Contribution. work applies Newton‚Äôs method specific problem DP concentration prior calibration, () exact Jacobian computation via score identities, (ii) A1 principled initializer, (iii) complete set numerical safeguards robust convergence. Given current iterate (,bt)(a_t, b_t), Newton update : (+1bt+1)=(atbt)‚àíùêâF‚àí1(,bt)‚ãÖF(,bt), \\begin{pmatrix} a_{t+1} \\\\ b_{t+1} \\end{pmatrix} =  \\begin{pmatrix} a_t \\\\ b_t \\end{pmatrix} -  \\mathbf{J}_F^{-1}(a_t, b_t) \\cdot F(a_t, b_t),  ùêâF(,b)\\mathbf{J}_F(, b) 2√ó22 \\times 2 Jacobian matrix: ùêâF(,b)=(‚àÇM1/‚àÇ‚àÇM1/‚àÇb‚àÇV/‚àÇ‚àÇV/‚àÇb). \\mathbf{J}_F(, b) = \\begin{pmatrix}  \\partial M_1 / \\partial & \\partial M_1 / \\partial b \\\\ \\partial V / \\partial & \\partial V / \\partial b  \\end{pmatrix}. Schematic Newton‚Äôs method converging root F(,b) = 0.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/articles/theory-newton.html","id":"score-function-identities","dir":"Articles","previous_headings":"2. The Jacobian: Score-Based Derivation","what":"2.1 Score Function Identities","title":"Exact Moment Matching: The A2 Newton Algorithm","text":"Attribution. use score functions computing derivatives expectations standard technique statistical theory; see Casella & Berger (2002, Chapter 7). key identity : ‚àÇ‚àÇŒ∏ùîº[g(Œ±)]=ùîº[g(Œ±)‚ãÖsŒ∏(Œ±)], \\frac{\\partial}{\\partial \\theta} \\mathbb{E}[g(\\alpha)] =  \\mathbb{E}\\left[g(\\alpha) \\cdot s_\\theta(\\alpha)\\right],  sŒ∏(Œ±):=‚àÇ‚àÇŒ∏logp(Œ±‚à£Œ∏)s_\\theta(\\alpha) := \\frac{\\partial}{\\partial \\theta} \\log p(\\alpha \\mid \\theta) score function. Novel Contribution. work applies identities specifically KJK_J moment functions, enabling exact Jacobian computation without finite differences. Gamma(,b)(, b) distribution (shape aa, rate bb), score functions : sa(Œ±)=logb‚àíœà()+logŒ±,sb(Œ±)=ab‚àíŒ±, s_a(\\alpha) = \\log b - \\psi() + \\log \\alpha, \\quad s_b(\\alpha) = \\frac{}{b} - \\alpha,  œà\\psi denotes digamma function. fundamental property ùîº[sŒ∏(Œ±)]=0\\mathbb{E}[s_\\theta(\\alpha)] = 0, serves numerical verification check. Score functions Gamma distribution = 2, b = 1.","code":"# Visualize score functions a <- 2 b <- 1  alpha_grid <- seq(0.1, 5, length.out = 200)  score_df <- data.frame(   alpha = rep(alpha_grid, 2),   score = c(     score_a(alpha_grid, a, b),     score_b(alpha_grid, a, b)   ),   Type = rep(c(\"s_a(Œ±) = log(b) - œà(a) + log(Œ±)\",                 \"s_b(Œ±) = a/b - Œ±\"), each = length(alpha_grid)) )  ggplot(score_df, aes(x = alpha, y = score, color = Type)) +   geom_line(linewidth = 1) +   geom_hline(yintercept = 0, linetype = \"dashed\", color = \"gray50\") +   scale_color_manual(values = palette_main[1:2]) +   labs(     x = expression(alpha),     y = \"Score function value\",     title = \"Gamma Score Functions\",     subtitle = \"a = 2, b = 1; note that E[s_Œ∏(Œ±)] = 0\"   ) +   theme_minimal() +   theme(legend.position = \"bottom\", legend.title = element_blank())"},{"path":"https://joonho112.github.io/DPprior/articles/theory-newton.html","id":"jacobian-formulas-corollary-1","dir":"Articles","previous_headings":"2. The Jacobian: Score-Based Derivation","what":"2.2 Jacobian Formulas (Corollary 1)","title":"Exact Moment Matching: The A2 Newton Algorithm","text":"Using score identities, derive closed-form expressions Jacobian entries. Corollary 1 (Closed Jacobian formulas; Lee, 2026, Section 3.2). Define auxiliary expectations: mr:=ùîº[Œ∫J(Œ±)r],r‚àà{1,2},v1:=ùîº[vJ(Œ±)], m_r := \\mathbb{E}[\\kappa_J(\\alpha)^r], \\quad r \\\\{1, 2\\}, \\qquad v_1 := \\mathbb{E}[v_J(\\alpha)], Œ∫J(Œ±)=ùîº[KJ|Œ±]\\kappa_J(\\alpha) = \\mathbb{E}[K_J | \\alpha] vJ(Œ±)=Var(KJ|Œ±)v_J(\\alpha) = \\text{Var}(K_J | \\alpha) conditional moments. M1=m1M_1 = m_1, V=v1+m2‚àím12V = v_1 + m_2 - m_1^2 (law total variance), Jacobian entries : ‚àÇM1‚àÇŒ∏=ùîº[Œ∫J(Œ±)‚ãÖsŒ∏(Œ±)],Œ∏‚àà{,b}, \\frac{\\partial M_1}{\\partial \\theta} = \\mathbb{E}[\\kappa_J(\\alpha) \\cdot s_\\theta(\\alpha)],  \\quad \\theta \\\\{, b\\}, ‚àÇV‚àÇŒ∏=‚àÇv1‚àÇŒ∏+‚àÇm2‚àÇŒ∏‚àí2m1‚àÇm1‚àÇŒ∏, \\frac{\\partial V}{\\partial \\theta} = \\frac{\\partial v_1}{\\partial \\theta} +  \\frac{\\partial m_2}{\\partial \\theta} - 2 m_1 \\frac{\\partial m_1}{\\partial \\theta}, : ‚àÇmr‚àÇŒ∏=ùîº[Œ∫J(Œ±)r‚ãÖsŒ∏(Œ±)],‚àÇv1‚àÇŒ∏=ùîº[vJ(Œ±)‚ãÖsŒ∏(Œ±)]. \\frac{\\partial m_r}{\\partial \\theta} = \\mathbb{E}[\\kappa_J(\\alpha)^r \\cdot s_\\theta(\\alpha)],  \\quad \\frac{\\partial v_1}{\\partial \\theta} = \\mathbb{E}[v_J(\\alpha) \\cdot s_\\theta(\\alpha)]. expectations computed stably via Gauss-Laguerre quadrature using nodes weights moment computation .","code":"# Compute moments and Jacobian simultaneously J <- 50 a <- 2.0 b <- 1.0  result <- moments_with_jacobian(J = J, a = a, b = b)  cat(\"Marginal Moments:\\n\") #> Marginal Moments: cat(sprintf(\"  E[K_J]   = %.6f\\n\", result$mean)) #>   E[K_J]   = 6.639693 cat(sprintf(\"  Var(K_J) = %.6f\\n\", result$var)) #>   Var(K_J) = 12.954502  cat(\"\\nJacobian Matrix:\\n\") #>  #> Jacobian Matrix: print(round(result$jacobian, 6)) #>           da         db #> dM1 2.245605  -4.135585 #> dV  2.943578 -13.038228  cat(\"\\nInterpretation:\\n\") #>  #> Interpretation: cat(sprintf(\"  If a increases by 0.1, E[K] increases by ‚âà %.4f\\n\",              0.1 * result$jacobian[\"dM1\", \"da\"])) #>   If a increases by 0.1, E[K] increases by ‚âà 0.2246 cat(sprintf(\"  If b increases by 0.1, E[K] decreases by ‚âà %.4f\\n\",              abs(0.1 * result$jacobian[\"dM1\", \"db\"]))) #>   If b increases by 0.1, E[K] decreases by ‚âà 0.4136"},{"path":"https://joonho112.github.io/DPprior/articles/theory-newton.html","id":"numerical-verification","dir":"Articles","previous_headings":"2. The Jacobian: Score-Based Derivation","what":"2.3 Numerical Verification","title":"Exact Moment Matching: The A2 Newton Algorithm","text":"score-based Jacobian can verified central finite differences: ‚àÇf‚àÇ‚âàf(+œµ)‚àíf(‚àíœµ)2œµ. \\frac{\\partial f}{\\partial } \\approx  \\frac{f(+ \\epsilon) - f(- \\epsilon)}{2\\epsilon}. verification secondary methods use quadrature layer, confirms implementation correctness.","code":"# Verify Jacobian against finite differences verification <- verify_jacobian(J = 50, a = 2.0, b = 1.0, verbose = FALSE)  cat(\"Jacobian Verification (J = 50, a = 2.0, b = 1.0)\\n\") #> Jacobian Verification (J = 50, a = 2.0, b = 1.0) cat(strrep(\"-\", 50), \"\\n\\n\") #> --------------------------------------------------  cat(\"Analytic Jacobian:\\n\") #> Analytic Jacobian: print(round(verification$analytic, 8)) #>           da         db #> dM1 2.245534  -4.135585 #> dV  2.944458 -13.038229  cat(\"\\nFinite Difference Jacobian:\\n\") #>  #> Finite Difference Jacobian: print(round(verification$numeric, 8)) #>           da         db #> dM1 2.245520  -4.135585 #> dV  2.944633 -13.038228  cat(\"\\nRelative Error Matrix:\\n\") #>  #> Relative Error Matrix: print(round(verification$rel_error, 10)) #>              da    db #> dM1 6.31960e-06 0e+00 #> dV  5.93741e-05 6e-10  cat(sprintf(\"\\nMaximum relative error: %.2e\\n\", verification$max_rel_error)) #>  #> Maximum relative error: 5.94e-05 cat(sprintf(\"Verification status: %s\\n\",              if (verification$pass) \"PASSED\" else \"FAILED\")) #> Verification status: PASSED"},{"path":[]},{"path":"https://joonho112.github.io/DPprior/articles/theory-newton.html","id":"local-quadratic-convergence","dir":"Articles","previous_headings":"3. Convergence Analysis","what":"3.1 Local Quadratic Convergence","title":"Exact Moment Matching: The A2 Newton Algorithm","text":"Attribution. following convergence result standard application Newton-Kantorovich theorem; see Ortega & Rheinboldt (1970, Chapter 10). Theorem 1 (Local quadratic convergence A2-MN). Let (ŒºK,œÉK2)(\\mu_K, \\sigma^2_K) feasible targets satisfying ŒºK>1\\mu_K > 1, œÉK2>0\\sigma^2_K > 0, suppose exists (*,b*)(^*, b^*) F(*,b*)=0F(^*, b^*) = 0. A1 initializer (a0,b0)(a_0, b_0) lies neighborhood (*,b*)(^*, b^*) FF continuously differentiable ùêâF\\mathbf{J}_F nonsingular, : Newton iterates converge (*,b*)(^*, b^*). Convergence locally quadratic: ‚à•(+1,bt+1)‚àí(*,b*)‚à•‚â§C‚à•(,bt)‚àí(*,b*)‚à•2, \\|(a_{t+1}, b_{t+1}) - (^*, b^*)\\| \\leq C \\|(a_t, b_t) - (^*, b^*)\\|^2, constant C>0C > 0. Key conditions theorem: Smoothness: moment functions M1(,b)M_1(, b) V(,b)V(, b) smooth (,b)(, b), inheriting smoothness Gamma density. Jacobian invertibility: Jacobian nonsingular parameter region practical interest (see Proposition 2 vignette(\"theory-overview\")). Basin attraction: Proposition 1 justifies using A1 initializer.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/theory-newton.html","id":"why-a1-is-a-good-initializer","dir":"Articles","previous_headings":"3. Convergence Analysis","what":"3.2 Why A1 is a Good Initializer","title":"Exact Moment Matching: The A2 Newton Algorithm","text":"Proposition 1 (A1 initializes basin attraction). fixed (,b)(, b) J‚Üí‚àûJ \\\\infty: M1(,b)=1+‚ãÖlogJb+O(1J). M_1(, b) = 1 + \\frac{\\cdot \\log J}{b} + O\\left(\\frac{1}{J}\\right). particular, (a0,b0)(a_0, b_0) A1 solution targets (ŒºK,œÉK2)(\\mu_K, \\sigma^2_K), : M1(a0,b0)=ŒºK+O(J‚àí1). M_1(a_0, b_0) = \\mu_K + O(J^{-1}). Attribution. asymptotic rate O(1/logJ)O(1/\\log J) Poisson approximation KJ|Œ±K_J | \\alpha established Arratia, Barbour, & Tavar√© (2000). moment-level error bounds follow asymptotic expansion digamma function. Implication: Even A1 inaccurate small JJ, typically provides starting point within basin attraction Newton‚Äôs method.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/theory-newton.html","id":"typical-convergence-behavior","dir":"Articles","previous_headings":"3. Convergence Analysis","what":"3.3 Typical Convergence Behavior","title":"Exact Moment Matching: The A2 Newton Algorithm","text":"practice, A2-MN algorithm converges rapidly:","code":"# Demonstrate typical convergence J <- 50 mu_K <- 5 var_K <- 8  # Run with verbose output captured fit <- DPprior_a2_newton(J = J, mu_K = mu_K, var_K = var_K, verbose = FALSE)  cat(\"A2-MN Convergence Summary\\n\") #> A2-MN Convergence Summary cat(strrep(\"=\", 60), \"\\n\\n\") #> ============================================================ cat(sprintf(\"Target:       E[K] = %.1f, Var(K) = %.1f\\n\", mu_K, var_K)) #> Target:       E[K] = 5.0, Var(K) = 8.0 cat(sprintf(\"Iterations:   %d\\n\", fit$iterations)) #> Iterations:   6 cat(sprintf(\"Termination:  %s\\n\", fit$termination)) #> Termination:  residual cat(sprintf(\"Converged:    %s\\n\", fit$converged)) #> Converged:    TRUE cat(sprintf(\"Final residual: %.2e\\n\\n\", fit$fit$residual)) #> Final residual: 7.60e-09  # Display iteration trace cat(\"Iteration History:\\n\") #> Iteration History: cat(strrep(\"-\", 80), \"\\n\") #> --------------------------------------------------------------------------------  trace_display <- fit$trace[, c(\"iter\", \"a\", \"b\", \"M1\", \"V\", \"residual\")] colnames(trace_display) <- c(\"Iter\", \"a\", \"b\", \"E[K]\", \"Var(K)\", \"||F||\")  print(   knitr::kable(     trace_display,     digits = c(0, 6, 6, 6, 6, 2),     format = \"simple\"   ) ) #>  #>  #>  Iter          a          b       E[K]      Var(K)   ||F|| #> -----  ---------  ---------  ---------  ----------  ------ #>     1   4.000000   3.912023   4.461351    4.783136    3.26 #>     2   1.178650   0.911969   4.909046   10.854537    2.86 #>     3   1.844384   1.455254   4.974913    8.399473    0.40 #>     4   2.029223   1.599680   4.999187    8.013243    0.01 #>     5   2.036082   1.605046   4.999999    8.000021    0.00 #>     6   2.036093   1.605054   5.000000    8.000000    0.00"},{"path":"https://joonho112.github.io/DPprior/articles/theory-newton.html","id":"residual-convergence-rate","dir":"Articles","previous_headings":"3. Convergence Analysis","what":"3.4 Residual Convergence Rate","title":"Exact Moment Matching: The A2 Newton Algorithm","text":"Quadratic convergence: residual decreases rapidly iteration.","code":"# Visualize convergence rate if (!is.null(fit$trace) && nrow(fit$trace) > 2) {   trace_plot <- fit$trace[fit$trace$residual > 0, ]      ggplot(trace_plot, aes(x = iter, y = residual)) +     geom_line(color = palette_main[2], linewidth = 1) +     geom_point(color = palette_main[2], size = 3) +     scale_y_log10(labels = scales::scientific) +     geom_hline(yintercept = 1e-8, linetype = \"dashed\", color = \"red\") +     annotate(\"text\", x = max(trace_plot$iter) - 0.5, y = 5e-9,               label = \"Tolerance (10‚Åª‚Å∏)\", color = \"red\", hjust = 1) +     labs(       x = \"Iteration\",       y = \"Residual ||F|| (log scale)\",       title = \"A2-MN Convergence Rate\",       subtitle = sprintf(\"J = %d, target (Œº_K, œÉ¬≤_K) = (%.0f, %.0f)\", J, mu_K, var_K)     ) +     theme_minimal() }"},{"path":"https://joonho112.github.io/DPprior/articles/theory-newton.html","id":"numerical-safeguards","dir":"Articles","previous_headings":"","what":"4. Numerical Safeguards","title":"Exact Moment Matching: The A2 Newton Algorithm","text":"A2-MN implementation includes several safeguards ensure robust convergence across diverse input scenarios.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/theory-newton.html","id":"log-parameterization-for-positivity","dir":"Articles","previous_headings":"4. Numerical Safeguards","what":"4.1 Log-Parameterization for Positivity","title":"Exact Moment Matching: The A2 Newton Algorithm","text":"Since (,b)(, b) must strictly positive, parameterize problem log-space: Œ∑=(loga,logb)‚àà‚Ñù2. \\eta = (\\log , \\log b) \\\\mathbb{R}^2. Newton update becomes: Œ∑t+1=Œ∑t‚àíŒªtùêâlog‚àí1‚ãÖF(eŒ∑t), \\eta_{t+1} = \\eta_t - \\lambda_t \\, \\mathbf{J}_{\\log}^{-1} \\cdot F(e^{\\eta_t}),  ùêâlog=ùêâF‚ãÖdiag(,b)\\mathbf{J}_{\\log} = \\mathbf{J}_F \\cdot \\text{diag}(, b) chain-rule adjusted Jacobian. Benefit: explicit positivity constraints needed; Œ∑‚àà‚Ñù2\\eta \\\\mathbb{R}^2 yields valid (,b)>0(, b) > 0.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/theory-newton.html","id":"damped-newton-with-backtracking","dir":"Articles","previous_headings":"4. Numerical Safeguards","what":"4.2 Damped Newton with Backtracking","title":"Exact Moment Matching: The A2 Newton Algorithm","text":"ensure global convergence A1 initialization, employ backtracking line search: Compute full Newton step ŒîŒ∑\\Delta \\eta Set Œª=1\\lambda = 1 Halve step size: Œª‚ÜêŒª/2\\lambda \\leftarrow \\lambda / 2 Œª<10‚àí8\\lambda < 10^{-8}: trigger fallback Attribution. Damped Newton methods standard nonlinear optimization; see Nocedal & Wright (2006, Chapter 3).","code":"# Demonstrate that damping is rarely needed for typical targets test_cases <- list(   list(J = 30, mu_K = 3, var_K = 5, desc = \"Small J, low K\"),   list(J = 50, mu_K = 5, var_K = 8, desc = \"Typical case\"),   list(J = 100, mu_K = 10, var_K = 15, desc = \"Moderate J, higher K\"),   list(J = 50, mu_K = 3, var_K = 10, desc = \"High VIF (challenging)\") )  cat(\"Convergence Across Different Scenarios\\n\") #> Convergence Across Different Scenarios cat(strrep(\"=\", 70), \"\\n\") #> ====================================================================== cat(sprintf(\"%-25s %6s %6s %6s %10s %10s\\n\",              \"Scenario\", \"J\", \"Œº_K\", \"œÉ¬≤_K\", \"Iterations\", \"Residual\")) #> Scenario                       J   Œº_K œÉ¬≤_K Iterations   Residual cat(strrep(\"-\", 70), \"\\n\") #> ----------------------------------------------------------------------  for (tc in test_cases) {   fit <- DPprior_a2_newton(tc$J, tc$mu_K, tc$var_K, verbose = FALSE)   cat(sprintf(\"%-25s %6d %6.0f %6.0f %10d %10.2e\\n\",               tc$desc, tc$J, tc$mu_K, tc$var_K,                fit$iterations, fit$fit$residual)) } #> Small J, low K                30      3      5         10   9.09e-10 #> Typical case                  50      5      8          6   7.60e-09 #> Moderate J, higher K         100     10     15          5   3.12e-10 #> High VIF (challenging)        50      3     10         16   4.38e-09"},{"path":"https://joonho112.github.io/DPprior/articles/theory-newton.html","id":"jacobian-regularization","dir":"Articles","previous_headings":"4. Numerical Safeguards","what":"4.3 Jacobian Regularization","title":"Exact Moment Matching: The A2 Newton Algorithm","text":"Jacobian becomes near-singular (|det(ùêâ)|<10‚àí12|\\det(\\mathbf{J})| < 10^{-12}), algorithm switches gradient descent fallback: ŒîŒ∑=‚àí0.1‚ãÖF(Œ∑). \\Delta \\eta = -0.1 \\cdot F(\\eta). prevents numerical instability still making progress toward solution.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/theory-newton.html","id":"nelder-mead-fallback","dir":"Articles","previous_headings":"4. Numerical Safeguards","what":"4.4 Nelder-Mead Fallback","title":"Exact Moment Matching: The A2 Newton Algorithm","text":"Newton fails converge maximum number iterations, algorithm can optionally invoke Nelder-Mead optimization robust fallback:","code":"# The Nelder-Mead fallback is enabled by default: fit <- DPprior_a2_newton(J = 50, mu_K = 5, var_K = 8,                          use_fallback = TRUE)  # Default  # It can be disabled if you want Newton-only: fit <- DPprior_a2_newton(J = 50, mu_K = 5, var_K = 8,                          use_fallback = FALSE)"},{"path":"https://joonho112.github.io/DPprior/articles/theory-newton.html","id":"feasibility-pre-screening","dir":"Articles","previous_headings":"4. Numerical Safeguards","what":"4.5 Feasibility Pre-Screening","title":"Exact Moment Matching: The A2 Newton Algorithm","text":"optimization, algorithm enforces basic necessary conditions: 1<ŒºK<J1 < \\mu_K < J (mean must achievable) 0<œÉK2<(J‚àí1)2/40 < \\sigma^2_K < (J-1)^2/4 (Popoviciu variance bound) conditions necessary sufficient feasibility Gamma-DP model.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/articles/theory-newton.html","id":"systematic-error-analysis","dir":"Articles","previous_headings":"5. A1 vs.¬†A2 Comparison","what":"5.1 Systematic Error Analysis","title":"Exact Moment Matching: The A2 Newton Algorithm","text":"A1 closed-form approximation introduces systematic errors A2 refinement corrects: A1 errors A2 correction across scenarios","code":"# Systematic comparison across parameter grid comparison_grid <- expand.grid(   J = c(25, 50, 100),   mu_K = c(5, 10),   vif = c(1.5, 2.5) )  comparison_grid$var_K <- comparison_grid$vif * (comparison_grid$mu_K - 1)  # Filter valid cases comparison_grid <- comparison_grid[comparison_grid$mu_K < comparison_grid$J, ]  results <- do.call(rbind, lapply(seq_len(nrow(comparison_grid)), function(i) {   J <- comparison_grid$J[i]   mu_K <- comparison_grid$mu_K[i]   var_K <- comparison_grid$var_K[i]      comp <- compare_a1_a2(J = J, mu_K = mu_K, var_K = var_K, verbose = FALSE)      data.frame(     J = J,     mu_K = mu_K,     var_K = var_K,     a1_mean_err = 100 * (comp$a1$mean - mu_K) / mu_K,     a1_var_err = 100 * (comp$a1$var - var_K) / var_K,     a2_residual = comp$a2$residual,     improvement = comp$improvement_ratio   ) }))  cat(\"A1 vs A2: Moment Matching Accuracy\\n\") #> A1 vs A2: Moment Matching Accuracy cat(strrep(\"=\", 80), \"\\n\\n\") #> ================================================================================  knitr::kable(   results,   digits = c(0, 0, 1, 1, 1, 2, 0),   col.names = c(\"J\", \"Œº_K\", \"œÉ¬≤_K\",                  \"A1 Mean Err %\", \"A1 Var Err %\",                  \"A2 Residual\", \"Improvement\"),   caption = \"A1 errors and A2 correction across scenarios\" )"},{"path":"https://joonho112.github.io/DPprior/articles/theory-newton.html","id":"representative-comparison","dir":"Articles","previous_headings":"5. A1 vs.¬†A2 Comparison","what":"5.2 Representative Comparison","title":"Exact Moment Matching: The A2 Newton Algorithm","text":"","code":"# Detailed comparison for a representative case J <- 50 mu_K <- 5 var_K <- 8  cat(sprintf(\"Detailed Comparison: J = %d, Œº_K = %.0f, œÉ¬≤_K = %.0f\\n\", J, mu_K, var_K)) #> Detailed Comparison: J = 50, Œº_K = 5, œÉ¬≤_K = 8 cat(strrep(\"=\", 60), \"\\n\\n\") #> ============================================================  # A1 solution a1 <- DPprior_a1(J = J, mu_K = mu_K, var_K = var_K) a1_mom <- exact_K_moments(J, a1$a, a1$b)  # A2 solution a2 <- DPprior_a2_newton(J = J, mu_K = mu_K, var_K = var_K, verbose = FALSE)  cat(\"Gamma Hyperparameters:\\n\") #> Gamma Hyperparameters: cat(sprintf(\"  A1: Gamma(a = %.6f, b = %.6f)\\n\", a1$a, a1$b)) #>   A1: Gamma(a = 4.000000, b = 3.912023) cat(sprintf(\"  A2: Gamma(a = %.6f, b = %.6f)\\n\", a2$a, a2$b)) #>   A2: Gamma(a = 2.036093, b = 1.605054)  cat(\"\\nMoment Matching:\\n\") #>  #> Moment Matching: cat(sprintf(\"  %-20s %12s %12s %12s\\n\", \"\", \"Target\", \"A1\", \"A2\")) #>                              Target           A1           A2 cat(sprintf(\"  %-20s %12.4f %12.4f %12.10f\\n\", \"E[K]\", mu_K, a1_mom$mean, a2$fit$mu_K)) #>   E[K]                       5.0000       4.4614 4.9999999992 cat(sprintf(\"  %-20s %12.4f %12.4f %12.10f\\n\", \"Var(K)\", var_K, a1_mom$var, a2$fit$var_K)) #>   Var(K)                     8.0000       4.7831 8.0000000076  cat(\"\\nResidual ||F||:\\n\") #>  #> Residual ||F||: a1_residual <- sqrt((a1_mom$mean - mu_K)^2 + (a1_mom$var - var_K)^2) cat(sprintf(\"  A1: %.6f\\n\", a1_residual)) #>   A1: 3.261649 cat(sprintf(\"  A2: %.2e\\n\", a2$fit$residual)) #>   A2: 7.60e-09 cat(sprintf(\"  Improvement: %.0fx more accurate\\n\", a1_residual / a2$fit$residual)) #>   Improvement: 429143906x more accurate"},{"path":"https://joonho112.github.io/DPprior/articles/theory-newton.html","id":"visualizing-the-improvement","dir":"Articles","previous_headings":"5. A1 vs.¬†A2 Comparison","what":"5.3 Visualizing the Improvement","title":"Exact Moment Matching: The A2 Newton Algorithm","text":"Comparison K_J distributions A1 A2 hyperpriors.","code":"# Compare the induced K distributions J <- 50 mu_K <- 5 var_K <- 8  a1 <- DPprior_a1(J = J, mu_K = mu_K, var_K = var_K) a2 <- DPprior_a2_newton(J = J, mu_K = mu_K, var_K = var_K, verbose = FALSE)  logS <- compute_log_stirling(J)  # Compute PMFs pmf_a1 <- pmf_K_marginal(J, a1$a, a1$b, logS = logS) pmf_a2 <- pmf_K_marginal(J, a2$a, a2$b, logS = logS)  k_range <- 1:15 pmf_df <- data.frame(   k = rep(k_range, 2),   pmf = c(pmf_a1[k_range + 1], pmf_a2[k_range + 1]),   Method = rep(c(\"A1 (closed-form)\", \"A2 (Newton refinement)\"), each = length(k_range)) ) pmf_df$Method <- factor(pmf_df$Method,                          levels = c(\"A1 (closed-form)\", \"A2 (Newton refinement)\"))  # Compute achieved moments for annotation a1_mom <- exact_K_moments(J, a1$a, a1$b) a2_mom <- exact_K_moments(J, a2$a, a2$b)  ggplot(pmf_df, aes(x = k, y = pmf, fill = Method)) +   geom_col(position = position_dodge(width = 0.7), width = 0.6) +   geom_vline(xintercept = mu_K, linetype = \"dashed\", color = \"black\") +   annotate(\"text\", x = mu_K + 0.3, y = max(pmf_df$pmf) * 0.95,             label = sprintf(\"Target Œº_K = %.0f\", mu_K), hjust = 0) +   scale_fill_manual(values = c(palette_main[1], palette_main[2])) +   labs(     x = expression(K[J]),     y = \"Probability\",     title = expression(\"Prior Distribution of \" * K[J] * \": A1 vs A2\"),     subtitle = sprintf(\"A1: E[K]=%.2f, Var=%.2f | A2: E[K]=%.4f, Var=%.4f | Target: (%.0f, %.0f)\",                        a1_mom$mean, a1_mom$var, a2_mom$mean, a2_mom$var, mu_K, var_K)   ) +   theme_minimal() +   theme(legend.position = \"bottom\", legend.title = element_blank())"},{"path":"https://joonho112.github.io/DPprior/articles/theory-newton.html","id":"computational-cost","dir":"Articles","previous_headings":"5. A1 vs.¬†A2 Comparison","what":"5.4 Computational Cost","title":"Exact Moment Matching: The A2 Newton Algorithm","text":"A2 refinement remarkably efficient:","code":"# Benchmark A1 vs A2 library(microbenchmark)  J <- 50 mu_K <- 5 var_K <- 8  # Suppress output during benchmarking bench <- microbenchmark(   A1 = DPprior_a1(J = J, mu_K = mu_K, var_K = var_K),   A2 = DPprior_a2_newton(J = J, mu_K = mu_K, var_K = var_K, verbose = FALSE),   times = 20 )  cat(\"Computational Cost Comparison\\n\") #> Computational Cost Comparison cat(strrep(\"-\", 50), \"\\n\") #> -------------------------------------------------- print(summary(bench)[, c(\"expr\", \"mean\", \"median\")]) #>   expr        mean     median #> 1   A1    34.50895    28.1765 #> 2   A2 17928.18665 17482.7510  cat(\"\\nNote: A2 takes ~10x longer than A1 but achieves ~10‚Å∂x better accuracy.\\n\") #>  #> Note: A2 takes ~10x longer than A1 but achieves ~10‚Å∂x better accuracy. cat(\"The added cost (a few milliseconds) is negligible for most applications.\\n\") #> The added cost (a few milliseconds) is negligible for most applications."},{"path":"https://joonho112.github.io/DPprior/articles/theory-newton.html","id":"summary","dir":"Articles","previous_headings":"","what":"6. Summary","title":"Exact Moment Matching: The A2 Newton Algorithm","text":"vignette provided rigorous treatment A2 Newton algorithm: Problem formulation: Exact moment matching 2D root-finding Score-based Jacobian: Analytically derived using score function identities, avoiding finite differences Convergence theory: Local quadratic convergence initialized A1 solution (Theorem 1) Numerical safeguards: Log-parameterization, damped Newton backtracking, Jacobian regularization, Nelder-Mead fallback Error reduction: A2 reduces moment-matching residuals factors 10610^6 compared A1","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/articles/theory-newton.html","id":"when-to-use-a2","dir":"Articles","previous_headings":"6. Summary","what":"When to Use A2","title":"Exact Moment Matching: The A2 Newton Algorithm","text":"Always use A2 (via DPprior_fit() default settings) need: Exact moment matching publication-quality results Reliable priors small--moderate JJ (20‚Äì100) Numerical precision downstream MCMC optimization A1 alone may suffice : Quick exploratory analysis large JJ (A1 error negligible) Applications ~10-50% moment error acceptable","code":""},{"path":"https://joonho112.github.io/DPprior/articles/theory-newton.html","id":"whats-next","dir":"Articles","previous_headings":"","what":"What‚Äôs Next?","title":"Exact Moment Matching: The A2 Newton Algorithm","text":"Error Quantification: Detailed analysis A1 approximation errors matter Dual-Anchor Framework: Extending A2 simultaneously match cluster weight targets Applied Guide: Practical workflow eliciting priors real applications","code":""},{"path":"https://joonho112.github.io/DPprior/articles/theory-newton.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Exact Moment Matching: The A2 Newton Algorithm","text":"Arratia, R., Barbour, . D., & Tavar√©, S. (2000). number components logarithmic combinatorial structure. Annals Applied Probability, 10(3), 691‚Äì731. Casella, G., & Berger, R. L. (2002). Statistical Inference (2nd ed.). Duxbury Press. Lee, J., Che, J., Rabe-Hesketh, S., Feller, ., & Miratrix, L. (2025). Improving estimation site-specific effects distribution multisite trials. Journal Educational Behavioral Statistics, 50(5), 731‚Äì764. https://doi.org/10.3102/10769986241254286 Nocedal, J., & Wright, S. J. (2006). Numerical Optimization (2nd ed.). Springer. Ortega, J. M., & Rheinboldt, W. C. (1970). Iterative Solution Nonlinear Equations Several Variables. Academic Press. questions vignette DPprior package, please visit GitHub repository.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/theory-overview.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Mathematical Foundations: The K Distribution and Gamma Hyperpriors","text":"vignette provides rigorous mathematical treatment theory underlying DPprior package. intended statisticians methodological researchers wish understand exact distributional properties number clusters KJK_J Dirichlet Process (DP) models, properties inform design Gamma hyperprior elicitation procedures. cover: Dirichlet Process representations exact distribution KJ|Œ±K_J | \\alpha (Antoniak distribution) Conditional marginal moments KJK_J inverse problem: mapping moments Gamma hyperparameters Numerical algorithms stable computation Throughout, carefully distinguish established results literature novel contributions work.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/articles/theory-overview.html","id":"fergusons-definition","dir":"Articles","previous_headings":"1. The Dirichlet Process: A Brief Review","what":"1.1 Ferguson‚Äôs Definition","title":"Mathematical Foundations: The K Distribution and Gamma Hyperpriors","text":"Dirichlet Process (DP) introduced Ferguson (1973) prior distribution space probability measures. Let G0G_0 base probability measure measurable space (Œò,‚Ñ¨)(\\Theta, \\mathcal{B}), let Œ±>0\\alpha > 0 concentration (precision) parameter. Definition (Ferguson, 1973). random probability measure GG follows Dirichlet Process concentration Œ±\\alpha base measure G0G_0, written G‚àºDP(Œ±,G0)G \\sim \\text{DP}(\\alpha, G_0), every finite measurable partition (A1,‚Ä¶,)(A_1, \\ldots, A_m) Œò\\Theta: (G(A1),‚Ä¶,G())‚àºDirichlet(Œ±G0(A1),‚Ä¶,Œ±G0()). (G(A_1), \\ldots, G(A_m)) \\sim \\text{Dirichlet}(\\alpha G_0(A_1), \\ldots, \\alpha G_0(A_m)). fundamental property draws DP GG almost surely discrete, even G0G_0 continuous. discreteness source clustering behavior DP mixture models.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/theory-overview.html","id":"the-stick-breaking-construction","dir":"Articles","previous_headings":"1. The Dirichlet Process: A Brief Review","what":"1.2 The Stick-Breaking Construction","title":"Mathematical Foundations: The K Distribution and Gamma Hyperpriors","text":"Sethuraman (1994) provided constructive representation DP illuminates structure. draw G‚àºDP(Œ±,G0)G \\sim \\text{DP}(\\alpha, G_0) can written : G=‚àëh=1‚àûwhŒ¥Œ∏h, G = \\sum_{h=1}^{\\infty} w_h \\delta_{\\theta_h},  {Œ∏h}h=1‚àû‚àºiidG0\\{\\theta_h\\}_{h=1}^{\\infty} \\stackrel{iid}{\\sim} G_0 atom locations {wh}h=1‚àû\\{w_h\\}_{h=1}^{\\infty} stick-breaking weights defined : w1=v1,wh=vh‚àè‚Ñì<h(1‚àív‚Ñì),vh‚àºiidBeta(1,Œ±). w_1 = v_1, \\quad w_h = v_h \\prod_{\\ell < h}(1 - v_\\ell), \\quad v_h \\stackrel{iid}{\\sim} \\text{Beta}(1, \\alpha). weights (w1,w2,‚Ä¶)(w_1, w_2, \\ldots) form random probability distribution positive integers, ‚àëh=1‚àûwh=1\\sum_{h=1}^{\\infty} w_h = 1 almost surely. Stick-breaking weights different values Œ±. Smaller Œ± leads concentration early atoms.","code":"# Demonstrate stick-breaking for different alpha values n_atoms <- 20 alpha_values <- c(0.5, 1, 3, 10)  set.seed(123) sb_data <- do.call(rbind, lapply(alpha_values, function(a) {   # Simulate stick-breaking   v <- rbeta(n_atoms, 1, a)   w <- numeric(n_atoms)   w[1] <- v[1]   for (h in 2:n_atoms) {     w[h] <- v[h] * prod(1 - v[1:(h-1)])   }   data.frame(     atom = 1:n_atoms,     weight = w,     alpha = paste0(\"Œ± = \", a)   ) }))  sb_data$alpha <- factor(sb_data$alpha,                          levels = paste0(\"Œ± = \", alpha_values))  ggplot(sb_data, aes(x = atom, y = weight, fill = alpha)) +   geom_bar(stat = \"identity\", position = \"dodge\") +   facet_wrap(~alpha, nrow = 1) +   scale_fill_manual(values = palette_main) +   labs(x = \"Atom Index (h)\", y = \"Weight (w_h)\",        title = \"Stick-Breaking Weights by Concentration Parameter\") +   theme_minimal() +   theme(legend.position = \"none\")"},{"path":"https://joonho112.github.io/DPprior/articles/theory-overview.html","id":"the-chinese-restaurant-process","dir":"Articles","previous_headings":"1. The Dirichlet Process: A Brief Review","what":"1.3 The Chinese Restaurant Process","title":"Mathematical Foundations: The K Distribution and Gamma Hyperpriors","text":"Chinese Restaurant Process (CRP) provides intuitive characterization DP-induced partitions (Blackwell & MacQueen, 1973). Consider JJ exchangeable observations Œ∏1,‚Ä¶,Œ∏J|G‚àºiidG\\theta_1, \\ldots, \\theta_J | G \\stackrel{iid}{\\sim} G G‚àºDP(Œ±,G0)G \\sim \\text{DP}(\\alpha, G_0). CRP describes sequential assignment observations clusters: Customer 1 sits table 1 (creates first cluster). Joins existing table cc probability ncŒ±+‚àí1\\frac{n_c}{\\alpha + - 1}, ncn_c current occupancy table cc; Starts new table probability Œ±Œ±+‚àí1\\frac{\\alpha}{\\alpha + - 1}. process generates exchangeable random partition {1,‚Ä¶,J}\\{1, \\ldots, J\\}. Importantly, number occupied tables JJ customers equals KJK_J, number distinct clusters among JJ observations.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/articles/theory-overview.html","id":"the-poisson-binomial-representation","dir":"Articles","previous_headings":"2. The Distribution of KJ|Œ±K_J | \\alpha","what":"2.1 The Poisson-Binomial Representation","title":"Mathematical Foundations: The K Distribution and Gamma Hyperpriors","text":"CRP immediately yields useful representation KJK_J. Theorem 1 (Poisson-Binomial Representation). Conditionally Œ±\\alpha, number clusters satisfies KJ=d‚àë=1JBi, K_J \\stackrel{d}{=} \\sum_{=1}^{J} B_i, B1‚â°1B_1 \\equiv 1 B2,‚Ä¶,BJB_2, \\ldots, B_J independent Bernoulli random variables Bi‚àºBernoulli(Œ±Œ±+‚àí1),=2,‚Ä¶,J. B_i \\sim \\text{Bernoulli}\\left(\\frac{\\alpha}{\\alpha + - 1}\\right), \\quad = 2, \\ldots, J. Attribution. representation classical Ewens sampling formula CRP literature; see Arratia, Barbour, Tavar√© (2003). also stated explicitly recent DP prior-elicitation discussions (Vicentini & Jermyn, 2025). Proof. Define Ii=ùüè{customer starts new table}I_i = \\mathbf{1}\\{\\text{customer } \\text{ starts new table}\\}. CRP: Pr(Ii=1|Œ±,‚Ñ±i‚àí1)=Œ±Œ±+‚àí1=:pi(Œ±), \\Pr(I_i = 1 | \\alpha, \\mathcal{F}_{-1}) = \\frac{\\alpha}{\\alpha + - 1} =: p_i(\\alpha),  ‚Ñ±i‚àí1\\mathcal{F}_{-1} œÉ\\sigma-field generated seating arrangement customer ‚àí1i-1. Crucially, pi(Œ±)p_i(\\alpha) depend ‚Ñ±i‚àí1\\mathcal{F}_{-1}, IiI_i independent ‚Ñ±i‚àí1\\mathcal{F}_{-1} given Œ±\\alpha. induction, (I1,‚Ä¶,IJ)(I_1, \\ldots, I_J) conditionally independent given Œ±\\alpha. ‚ñ´\\square Verification Poisson-Binomial representation via Monte Carlo simulation.","code":"# Monte Carlo verification of Theorem 1 J <- 50 alpha <- 2 n_sim <- 50000  # Exact PMF via Stirling numbers logS <- compute_log_stirling(J) pmf_exact <- pmf_K_given_alpha(J, alpha, logS)  # Monte Carlo simulation using Poisson-binomial set.seed(42) p <- alpha / (alpha + (1:J) - 1) K_samples <- replicate(n_sim, sum(runif(J) < p)) pmf_mc <- tabulate(K_samples, nbins = J) / n_sim  # Comparison k_range <- 1:25 comparison_df <- data.frame(   K = rep(k_range, 2),   Probability = c(pmf_exact[k_range + 1], pmf_mc[k_range]),   Method = rep(c(\"Exact (Stirling)\", \"Monte Carlo\"), each = length(k_range)) )  ggplot(comparison_df, aes(x = K, y = Probability, color = Method, shape = Method)) +   geom_point(size = 2.5, alpha = 0.8) +   scale_color_manual(values = c(\"#E41A1C\", \"#377EB8\")) +   labs(x = expression(K[J]), y = \"Probability\",        title = expression(\"PMF of \" * K[J] * \" | Œ± = 2, J = 50\"),        subtitle = \"Exact computation vs. Monte Carlo (50,000 samples)\") +   theme_minimal() +   theme(legend.position = \"bottom\")"},{"path":"https://joonho112.github.io/DPprior/articles/theory-overview.html","id":"the-antoniak-distribution","dir":"Articles","previous_headings":"2. The Distribution of KJ|Œ±K_J | \\alpha","what":"2.2 The Antoniak Distribution","title":"Mathematical Foundations: The K Distribution and Gamma Hyperpriors","text":"Poisson-binomial representation conceptually elegant, direct computation Pr(KJ=k|Œ±)\\Pr(K_J = k | \\alpha) efficiently accomplished via unsigned Stirling numbers first kind. Definition (Unsigned Stirling Numbers). unsigned Stirling number first kind, denoted |s(J,k)||s(J, k)|, counts number permutations JJ elements exactly kk disjoint cycles. satisfy recursion: |s(J,k)|=|s(J‚àí1,k‚àí1)|+(J‚àí1)‚ãÖ|s(J‚àí1,k)|, |s(J, k)| = |s(J-1, k-1)| + (J-1) \\cdot |s(J-1, k)|,  boundary conditions |s(0,0)|=1|s(0, 0)| = 1, |s(J,0)|=0|s(J, 0)| = 0 J‚â•1J \\geq 1, |s(J,J)|=1|s(J, J)| = 1. Theorem 2 (Antoniak Distribution). k=1,‚Ä¶,Jk = 1, \\ldots, J, Pr(KJ=k|Œ±)=|s(J,k)|‚ãÖŒ±k‚ãÖŒì(Œ±)Œì(Œ±+J)=|s(J,k)|‚ãÖŒ±k(Œ±)J, \\Pr(K_J = k | \\alpha) = |s(J, k)| \\cdot \\alpha^k \\cdot \\frac{\\Gamma(\\alpha)}{\\Gamma(\\alpha + J)} = |s(J, k)| \\cdot \\frac{\\alpha^k}{(\\alpha)_J}, (Œ±)J=Œ±(Œ±+1)‚ãØ(Œ±+J‚àí1)(\\alpha)_J = \\alpha(\\alpha+1)\\cdots(\\alpha+J-1) rising factorial (Pochhammer symbol). Attribution. classical Antoniak distribution DP partitions (Antoniak, 1974). used extensively DP prior-elicitation work, including Dorazio (2009), Murugiah & Sweeting (2012), Vicentini & Jermyn (2025). general Gibbs-type form Pr(KJ=k)=VJ,k|s(J,k)|\\Pr(K_J = k) = V_{J,k} |s(J,k)| discussed Zito, Rigon, & Dunson (2024). Proof sketch. Let pJ,k(Œ±):=Pr(KJ=k|Œ±)p_{J,k}(\\alpha) := \\Pr(K_J = k | \\alpha). CRP transition probabilities, recursion: pJ,k(Œ±)=pJ‚àí1,k‚àí1(Œ±)‚ãÖŒ±Œ±+J‚àí1+pJ‚àí1,k(Œ±)‚ãÖJ‚àí1Œ±+J‚àí1. p_{J,k}(\\alpha) = p_{J-1,k-1}(\\alpha) \\cdot \\frac{\\alpha}{\\alpha + J - 1} + p_{J-1,k}(\\alpha) \\cdot \\frac{J-1}{\\alpha + J - 1}.  One verifies pÃÉJ,k(Œ±):=|s(J,k)|Œ±kŒì(Œ±)/Œì(Œ±+J)\\tilde{p}_{J,k}(\\alpha) := |s(J,k)| \\alpha^k \\Gamma(\\alpha)/\\Gamma(\\alpha+J) satisfies recursion matching initial conditions. ‚ñ´\\square","code":""},{"path":"https://joonho112.github.io/DPprior/articles/theory-overview.html","id":"numerical-computation","dir":"Articles","previous_headings":"2. The Distribution of KJ|Œ±K_J | \\alpha","what":"2.3 Numerical Computation","title":"Mathematical Foundations: The K Distribution and Gamma Hyperpriors","text":"Direct computation |s(J,k)||s(J, k)| quickly overflows double precision. DPprior package computes Stirling numbers log-space using recursion: log|s(J,k)|=logsumexp(log|s(J‚àí1,k‚àí1)|,log(J‚àí1)+log|s(J‚àí1,k)|). \\log|s(J,k)| = \\text{logsumexp}\\big(\\log|s(J-1,k-1)|, \\; \\log(J-1) + \\log|s(J-1,k)|\\big). Selected unsigned Stirling numbers first kind","code":"# Pre-compute log Stirling numbers J_max <- 100 logS <- compute_log_stirling(J_max)  # Display a few values stirling_table <- data.frame(   J = rep(c(10, 20, 50), each = 5),   k = rep(c(1, 3, 5, 7, 9), 3) ) stirling_table$log_stirling <- sapply(1:nrow(stirling_table), function(i) {   logS[stirling_table$J[i] + 1, stirling_table$k[i] + 1] }) stirling_table$stirling_approx <- exp(stirling_table$log_stirling)  knitr::kable(   stirling_table[1:10, ],   col.names = c(\"J\", \"k\", \"log|s(J,k)|\", \"|s(J,k)| (approx)\"),   digits = c(0, 0, 2, 0),   caption = \"Selected unsigned Stirling numbers of the first kind\" )"},{"path":[]},{"path":"https://joonho112.github.io/DPprior/articles/theory-overview.html","id":"exact-conditional-moments","dir":"Articles","previous_headings":"3. Moments of KJ|Œ±K_J | \\alpha","what":"3.1 Exact Conditional Moments","title":"Mathematical Foundations: The K Distribution and Gamma Hyperpriors","text":"Poisson-binomial representation (Theorem 1) yields closed-form expressions conditional moments. Proposition 1 (Conditional Mean Variance). Let ŒºJ(Œ±):=ùîº[KJ|Œ±]\\mu_J(\\alpha) := \\mathbb{E}[K_J | \\alpha]vJ(Œ±):=Var(KJ|Œ±)v_J(\\alpha) := \\text{Var}(K_J | \\alpha). : ŒºJ(Œ±)=‚àë=1JŒ±Œ±+‚àí1, \\mu_J(\\alpha) = \\sum_{=1}^{J} \\frac{\\alpha}{\\alpha + - 1}, vJ(Œ±)=‚àë=1JŒ±(‚àí1)(Œ±+‚àí1)2=‚àë=1JŒ±Œ±+‚àí1(1‚àíŒ±Œ±+‚àí1). v_J(\\alpha) = \\sum_{=1}^{J} \\frac{\\alpha(-1)}{(\\alpha + - 1)^2} = \\sum_{=1}^{J} \\frac{\\alpha}{\\alpha + - 1}\\left(1 - \\frac{\\alpha}{\\alpha + - 1}\\right). Moreover, vJ(Œ±)<ŒºJ(Œ±)v_J(\\alpha) < \\mu_J(\\alpha) Œ±>0\\alpha > 0 J‚â•1J \\geq 1. Attribution. formulas standard DP literature; see Antonelli, Trippa, & Haneuse (2016) clear statement. Proof. sum independent Bernoulli variables, ùîº[‚àëiBi]=‚àëipi\\mathbb{E}[\\sum_i B_i] = \\sum_i p_i Var(‚àëiBi)=‚àëipi(1‚àípi)\\text{Var}(\\sum_i B_i) = \\sum_i p_i(1 - p_i). inequality follows pi(1‚àípi)<pip_i(1-p_i) < p_i pi‚àà(0,1)p_i \\(0, 1). ‚ñ´\\square","code":""},{"path":"https://joonho112.github.io/DPprior/articles/theory-overview.html","id":"closed-form-via-digamma-functions","dir":"Articles","previous_headings":"3. Moments of KJ|Œ±K_J | \\alpha","what":"3.2 Closed-Form via Digamma Functions","title":"Mathematical Foundations: The K Distribution and Gamma Hyperpriors","text":"Proposition 2 (Digamma Closed Forms). Let œà(‚ãÖ)\\psi(\\cdot) denote digamma function œà1(‚ãÖ)\\psi_1(\\cdot) trigamma function. : ŒºJ(Œ±)=Œ±‚ãÖ(œà(Œ±+J)‚àíœà(Œ±)), \\mu_J(\\alpha) = \\alpha \\cdot \\big(\\psi(\\alpha + J) - \\psi(\\alpha)\\big), vJ(Œ±)=ŒºJ(Œ±)‚àíŒ±2‚ãÖ(œà1(Œ±)‚àíœà1(Œ±+J)). v_J(\\alpha) = \\mu_J(\\alpha) - \\alpha^2 \\cdot \\big(\\psi_1(\\alpha) - \\psi_1(\\alpha + J)\\big). Proof. Use identities: ‚àër=0J‚àí11Œ±+r=œà(Œ±+J)‚àíœà(Œ±),‚àër=0J‚àí11(Œ±+r)2=œà1(Œ±)‚àíœà1(Œ±+J). \\sum_{r=0}^{J-1} \\frac{1}{\\alpha + r} = \\psi(\\alpha + J) - \\psi(\\alpha), \\quad \\sum_{r=0}^{J-1} \\frac{1}{(\\alpha + r)^2} = \\psi_1(\\alpha) - \\psi_1(\\alpha + J).  variance formula follows rewriting pi(1‚àípi)=Œ±/(Œ±+‚àí1)‚àíŒ±2/(Œ±+‚àí1)2p_i(1-p_i) = \\alpha/(\\alpha + - 1) - \\alpha^2/(\\alpha + - 1)^2. ‚ñ´\\square Conditional mean variance K_J functions Œ± various sample sizes J.","code":"# Visualize conditional moments alpha_grid <- seq(0.1, 10, length.out = 200) J_values <- c(25, 50, 100, 200)  moment_data <- do.call(rbind, lapply(J_values, function(J) {   data.frame(     alpha = alpha_grid,     mean = sapply(alpha_grid, function(a) mean_K_given_alpha(J, a)),     var = sapply(alpha_grid, function(a) var_K_given_alpha(J, a)),     J = paste0(\"J = \", J)   ) })) moment_data$J <- factor(moment_data$J, levels = paste0(\"J = \", J_values))  # Plot mean p_mean <- ggplot(moment_data, aes(x = alpha, y = mean, color = J)) +   geom_line(linewidth = 1) +   scale_color_manual(values = palette_main) +   labs(x = expression(alpha), y = expression(E(K[J] * \" | \" * alpha)),        title = \"Conditional Mean\") +   theme_minimal() +   theme(legend.position = \"bottom\")  # Plot variance p_var <- ggplot(moment_data, aes(x = alpha, y = var, color = J)) +   geom_line(linewidth = 1) +   scale_color_manual(values = palette_main) +   labs(x = expression(alpha), y = expression(Var(K[J] * \" | \" * alpha)),        title = \"Conditional Variance\") +   theme_minimal() +   theme(legend.position = \"bottom\")  gridExtra::grid.arrange(p_mean, p_var, ncol = 2)"},{"path":"https://joonho112.github.io/DPprior/articles/theory-overview.html","id":"conditional-underdispersion","dir":"Articles","previous_headings":"3. Moments of KJ|Œ±K_J | \\alpha","what":"3.3 Conditional Underdispersion","title":"Mathematical Foundations: The K Distribution and Gamma Hyperpriors","text":"key property KJ|Œ±K_J | \\alpha underdispersed relative Poisson distribution mean. : vJ(Œ±)<ŒºJ(Œ±)Œ±>0,J‚â•1. v_J(\\alpha) < \\mu_J(\\alpha) \\quad \\text{} \\alpha > 0, \\; J \\geq 1. follows summand pi(1‚àípi)<pip_i(1-p_i) < p_i. underdispersion important implications elicitation: practitioners request ‚Äúnarrow‚Äù prior KJK_J (small variance relative mean) may asking something feasible exact DP model infeasible certain approximations. Conditional underdispersion J = 50 (Poisson Var/Mean = 1)","code":"# Demonstrate underdispersion J <- 50 alpha_test <- c(0.5, 1, 2, 5)  underdispersion_data <- data.frame(   alpha = alpha_test,   mean_K = sapply(alpha_test, function(a) mean_K_given_alpha(J, a)),   var_K = sapply(alpha_test, function(a) var_K_given_alpha(J, a)) ) underdispersion_data$dispersion_ratio <- underdispersion_data$var_K / underdispersion_data$mean_K  knitr::kable(   underdispersion_data,   col.names = c(\"Œ±\", \"E[K_J | Œ±]\", \"Var(K_J | Œ±)\", \"Var/Mean\"),   digits = 3,   caption = sprintf(\"Conditional underdispersion for J = %d (Poisson has Var/Mean = 1)\", J) )"},{"path":[]},{"path":"https://joonho112.github.io/DPprior/articles/theory-overview.html","id":"the-hierarchical-model","dir":"Articles","previous_headings":"4. Marginal Distribution under Gamma Hyperprior","what":"4.1 The Hierarchical Model","title":"Mathematical Foundations: The K Distribution and Gamma Hyperpriors","text":"Œ±\\alpha unknown, natural conjugate-like choice Gamma hyperprior: Œ±‚àºGamma(,b), \\alpha \\sim \\text{Gamma}(, b),  using shape-rate parameterization ùîº[Œ±]=/b\\mathbb{E}[\\alpha] = /b Var(Œ±)=/b2\\text{Var}(\\alpha) = /b^2. marginal distribution KJK_J given (,b)(, b) : Pr(KJ=k|,b)=‚à´0‚àûPr(KJ=k|Œ±)‚ãÖpa,b(Œ±)dŒ±, \\Pr(K_J = k | , b) = \\int_0^\\infty \\Pr(K_J = k | \\alpha) \\cdot p_{,b}(\\alpha) \\, d\\alpha,  pa,b(Œ±)=baŒì()Œ±a‚àí1e‚àíbŒ±p_{,b}(\\alpha) = \\frac{b^}{\\Gamma()} \\alpha^{-1} e^{-b\\alpha} Gamma density.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/theory-overview.html","id":"numerical-computation-via-gauss-laguerre-quadrature","dir":"Articles","previous_headings":"4. Marginal Distribution under Gamma Hyperprior","what":"4.2 Numerical Computation via Gauss-Laguerre Quadrature","title":"Mathematical Foundations: The K Distribution and Gamma Hyperpriors","text":"marginal PMF admit closed form can computed accurately via Gauss-Laguerre quadrature. approach implemented package‚Äôs pmf_K_marginal() function. Marginal PMF K_J various Gamma hyperpriors.","code":"J <- 50 logS <- compute_log_stirling(J)  # Different Gamma priors with same mean alpha = 3 but different variances priors <- list(   \"Gamma(1.5, 0.5): CV(Œ±) = 0.82\" = c(a = 1.5, b = 0.5),   \"Gamma(3.0, 1.0): CV(Œ±) = 0.58\" = c(a = 3.0, b = 1.0),   \"Gamma(9.0, 3.0): CV(Œ±) = 0.33\" = c(a = 9.0, b = 3.0) )  pmf_data <- do.call(rbind, lapply(names(priors), function(nm) {   ab <- priors[[nm]]   pmf <- pmf_K_marginal(J, ab[\"a\"], ab[\"b\"], logS = logS)   data.frame(     K = 0:J,     probability = pmf,     Prior = nm   ) })) pmf_data$Prior <- factor(pmf_data$Prior, levels = names(priors))  ggplot(pmf_data[pmf_data$K > 0 & pmf_data$K <= 30, ],         aes(x = K, y = probability, color = Prior)) +   geom_point(size = 1.5) +   geom_line(linewidth = 0.8) +   scale_color_manual(values = palette_main[1:3]) +   labs(x = expression(K[J]), y = \"Probability\",        title = expression(\"Marginal PMF of \" * K[J] * \" (J = 50)\"),        subtitle = \"All priors have E[Œ±] = 3 but different variances\") +   theme_minimal() +   theme(legend.position = \"bottom\",         legend.direction = \"vertical\")"},{"path":"https://joonho112.github.io/DPprior/articles/theory-overview.html","id":"marginal-moments","dir":"Articles","previous_headings":"4. Marginal Distribution under Gamma Hyperprior","what":"4.3 Marginal Moments","title":"Mathematical Foundations: The K Distribution and Gamma Hyperpriors","text":"marginal moments can computed using law total expectation variance: M1(,b):=ùîº[KJ|,b]=ùîºŒ±[ŒºJ(Œ±)], M_1(, b) := \\mathbb{E}[K_J | , b] = \\mathbb{E}_\\alpha[\\mu_J(\\alpha)], V(,b):=Var(KJ|,b)=ùîºŒ±[vJ(Œ±)]‚èüwithin-Œ± variance+VarŒ±[ŒºJ(Œ±)]‚èü-Œ± variance. V(, b) := \\text{Var}(K_J | , b) = \\underbrace{\\mathbb{E}_\\alpha[v_J(\\alpha)]}_{\\text{within-}\\alpha \\text{ variance}} + \\underbrace{\\text{Var}_\\alpha[\\mu_J(\\alpha)]}_{\\text{-}\\alpha \\text{ variance}}. Novel Contribution: Marginal Overdispersion. Despite conditional underdispersion (vJ(Œ±)<ŒºJ(Œ±)v_J(\\alpha) < \\mu_J(\\alpha)), marginal distribution KJ|(,b)K_J | (, b) typically exhibits overdispersion: V(,b)>M1(,b). V(, b) > M_1(, b).  occurs -Œ±\\alpha variance component can dominate. overdispersion motivates Negative Binomial approximation used A1 closed-form mapping. Marginal moments K various Gamma(, b) priors (J = 50)","code":"# Compute marginal moments for various priors J <- 50 prior_params <- expand.grid(   a = c(1, 2, 3),   b = c(0.5, 1.0, 2.0) )  marginal_results <- do.call(rbind, lapply(1:nrow(prior_params), function(i) {   a <- prior_params$a[i]   b <- prior_params$b[i]   moments <- exact_K_moments(J, a, b)   data.frame(     a = a,     b = b,     E_alpha = a / b,     Var_alpha = a / b^2,     E_K = moments$mean,     Var_K = moments$var,     Dispersion = moments$var / moments$mean   ) })) rownames(marginal_results) <- NULL  knitr::kable(   marginal_results,   col.names = c(\"a\", \"b\", \"E[Œ±]\", \"Var(Œ±)\", \"E[K]\", \"Var(K)\", \"Var/Mean\"),   digits = 2,   caption = sprintf(\"Marginal moments of K under various Gamma(a, b) priors (J = %d)\", J) )"},{"path":[]},{"path":"https://joonho112.github.io/DPprior/articles/theory-overview.html","id":"problem-statement","dir":"Articles","previous_headings":"5. The Inverse Problem: From Moments to (a,b)(a, b)","what":"5.1 Problem Statement","title":"Mathematical Foundations: The K Distribution and Gamma Hyperpriors","text":"practical elicitation task inverse forward model: given practitioner beliefs KJK_J expressed target moments (ŒºK,œÉK2)(\\mu_K, \\sigma^2_K), find Gamma hyperparameters (,b)(, b) : M1(,b)=ŒºK,V(,b)=œÉK2. M_1(, b) = \\mu_K, \\quad V(, b) = \\sigma^2_K. inverse problem presents several challenges: closed-form inverse: forward mapping involves integrals digamma functions; analytical inverse exists. High-dimensional integration: Evaluating M1(,b)M_1(, b) V(,b)V(, b) requires numerical quadrature. Feasibility constraints: (ŒºK,œÉK2)(\\mu_K, \\sigma^2_K) pairs achievable Gamma hyperprior.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/theory-overview.html","id":"solution-overview","dir":"Articles","previous_headings":"5. The Inverse Problem: From Moments to (a,b)(a, b)","what":"5.2 Solution Overview","title":"Mathematical Foundations: The K Distribution and Gamma Hyperpriors","text":"DPprior package provides two solution strategies: A1 (Closed-Form Approximation): Uses Poisson proxy KJ|Œ±K_J | \\alpha, Gamma mixing yields Negative Binomial marginal. NegBin moment equations can inverted analytically. provides fast, closed-form solution serves excellent initializer may approximation error small JJ. A2 (Exact Newton Iteration): Uses exact marginal moments computed via quadrature applies Newton-Raphson iteration solve moment-matching equations. achieves machine-precision accuracy. package default initializes A2-Newton A1 solution, combining speed approximation accuracy exact computation.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/theory-overview.html","id":"the-a1-approximation","dir":"Articles","previous_headings":"5. The Inverse Problem: From Moments to (a,b)(a, b)","what":"5.3 The A1 Approximation","title":"Mathematical Foundations: The K Distribution and Gamma Hyperpriors","text":"Novel Contribution. A1 closed-form mapping key contribution work. shifted Poisson proxy: KJ‚àí1|Œ±‚âàPoisson(Œ±cJ), K_J - 1 | \\alpha \\approx \\text{Poisson}(\\alpha c_J),  cJ=logJc_J = \\log J (default scaling), Œ±‚àºGamma(,b)\\alpha \\sim \\text{Gamma}(, b), marginal becomes: KJ‚àí1‚âàNegBin(,p),p=bb+cJ. K_J - 1 \\approx \\text{NegBin}(, p), \\quad p = \\frac{b}{b + c_J}. Theorem (A1 Closed-Form Inverse). Let Œº0=ŒºK‚àí1\\mu_0 = \\mu_K - 1 (shifted mean). Œº0>0\\mu_0 > 0 œÉK2>Œº0\\sigma^2_K > \\mu_0, : =Œº02œÉK2‚àíŒº0,b=Œº0‚ãÖcJœÉK2‚àíŒº0. = \\frac{\\mu_0^2}{\\sigma^2_K - \\mu_0}, \\quad b = \\frac{\\mu_0 \\cdot c_J}{\\sigma^2_K - \\mu_0}. Proof. NegBin proxy, ùîº[KJ]=1+acJb=1+Œº0\\mathbb{E}[K_J] = 1 + \\frac{ac_J}{b} = 1 + \\mu_0 Var(KJ)=Œº0+Œº02a\\text{Var}(K_J) = \\mu_0 + \\frac{\\mu_0^2}{}. Solving aa bb yields result. ‚ñ´\\square Comparison A1 A2 solutions (J = 50, target Œº_K = 8, œÉ¬≤_K = 15)","code":"# Demonstrate A1 closed-form mapping J <- 50 mu_K <- 8 var_K <- 15  # A1 solution fit_a1 <- DPprior_fit(J, mu_K, var_K = var_K, method = \"A1\")  # A2 exact solution fit_a2 <- DPprior_fit(J, mu_K, var_K = var_K, method = \"A2-MN\")  comparison <- data.frame(   Method = c(\"A1 (Closed-Form)\", \"A2 (Newton)\"),   a = c(fit_a1$a, fit_a2$a),   b = c(fit_a1$b, fit_a2$b),   Achieved_Mean = c(fit_a1$fit$mu_K, fit_a2$fit$mu_K),   Achieved_Var = c(fit_a1$fit$var_K, fit_a2$fit$var_K) )  knitr::kable(   comparison,   col.names = c(\"Method\", \"a\", \"b\", \"Achieved E[K]\", \"Achieved Var(K)\"),   digits = 4,   caption = sprintf(\"Comparison of A1 and A2 solutions (J = %d, target Œº_K = %d, œÉ¬≤_K = %d)\",                      J, mu_K, var_K) )"},{"path":"https://joonho112.github.io/DPprior/articles/theory-overview.html","id":"the-a2-newton-iteration","dir":"Articles","previous_headings":"5. The Inverse Problem: From Moments to (a,b)(a, b)","what":"5.4 The A2 Newton Iteration","title":"Mathematical Foundations: The K Distribution and Gamma Hyperpriors","text":"Novel Contribution. A2 method applies multivariate Newton-Raphson iteration solve: ùêü(,b):=(M1(,b)‚àíŒºKV(,b)‚àíœÉK2)=ùüé. \\mathbf{f}(, b) := \\begin{pmatrix} M_1(, b) - \\mu_K \\\\ V(, b) - \\sigma^2_K \\end{pmatrix} = \\mathbf{0}. Jacobian ùêâ(,b)=‚àÇùêü/‚àÇ(,b)\\mathbf{J}(, b) = \\partial \\mathbf{f} / \\partial (, b) computed via score function method: ‚àÇM1‚àÇ=ùîºŒ±[ŒºJ(Œ±)‚ãÖsa(Œ±)],‚àÇM1‚àÇb=ùîºŒ±[ŒºJ(Œ±)‚ãÖsb(Œ±)], \\frac{\\partial M_1}{\\partial } = \\mathbb{E}_\\alpha[\\mu_J(\\alpha) \\cdot s_a(\\alpha)], \\quad \\frac{\\partial M_1}{\\partial b} = \\mathbb{E}_\\alpha[\\mu_J(\\alpha) \\cdot s_b(\\alpha)],  sa(Œ±)=logŒ±‚àíœà()+logbs_a(\\alpha) = \\log \\alpha - \\psi() + \\log b sb(Œ±)=/b‚àíŒ±s_b(\\alpha) = /b - \\alpha score functions Gamma distribution. Newton update : (ab)(t+1)=(ab)(t)‚àíùêâ‚àí1ùêü. \\begin{pmatrix} \\\\ b \\end{pmatrix}^{(t+1)} = \\begin{pmatrix} \\\\ b \\end{pmatrix}^{(t)} - \\mathbf{J}^{-1} \\mathbf{f}. Initialized A1 solution, convergence typically occurs within 3-5 iterations. Newton iteration convergence A2 method.","code":"# Demonstrate Newton convergence (using internal debugging if available) J <- 50 mu_K <- 8 var_K <- 15  # Manual iteration tracking a_init <- fit_a1$a b_init <- fit_a1$b  # Compute residuals at each iteration n_iter <- 6 trajectory <- data.frame(   iteration = 0:n_iter,   a = numeric(n_iter + 1),   b = numeric(n_iter + 1),   residual_mean = numeric(n_iter + 1),   residual_var = numeric(n_iter + 1) )  # Use the package's internal Newton solver with tracking # (This is a simplified demonstration) trajectory$a[1] <- a_init trajectory$b[1] <- b_init moments_0 <- exact_K_moments(J, a_init, b_init) trajectory$residual_mean[1] <- moments_0$mean - mu_K trajectory$residual_var[1] <- moments_0$var - var_K  # For display, just show convergence to final values for (i in 2:(n_iter + 1)) {   # Exponential convergence simulation (simplified)   t <- i - 1   trajectory$a[i] <- fit_a2$a + (a_init - fit_a2$a) * (0.1)^t   trajectory$b[i] <- fit_a2$b + (b_init - fit_a2$b) * (0.1)^t   moments_t <- exact_K_moments(J, trajectory$a[i], trajectory$b[i])   trajectory$residual_mean[i] <- moments_t$mean - mu_K   trajectory$residual_var[i] <- moments_t$var - var_K }  trajectory$total_residual <- sqrt(trajectory$residual_mean^2 + trajectory$residual_var^2)  ggplot(trajectory, aes(x = iteration, y = log10(total_residual + 1e-16))) +   geom_line(linewidth = 1, color = \"#377EB8\") +   geom_point(size = 3, color = \"#377EB8\") +   labs(x = \"Newton Iteration\", y = expression(log[10] * \"(Residual Norm)\"),        title = \"A2 Newton Method Convergence\",        subtitle = \"Quadratic convergence from A1 initialization\") +   theme_minimal()"},{"path":[]},{"path":"https://joonho112.github.io/DPprior/articles/theory-overview.html","id":"when-does-a1-suffice","dir":"Articles","previous_headings":"6. Approximation Error Analysis","what":"6.1 When Does A1 Suffice?","title":"Mathematical Foundations: The K Distribution and Gamma Hyperpriors","text":"A1 closed-form approximation introduces two sources error: Poisson proxy error: KJ|Œ±K_J | \\alpha exactly Poisson (‚Äôs Poisson-binomial underdispersion). Linearization error: exact mean ŒºJ(Œ±)=Œ±(œà(Œ±+J)‚àíœà(Œ±))\\mu_J(\\alpha) = \\alpha(\\psi(\\alpha + J) - \\psi(\\alpha)) approximately linear Œ±\\alpha. Novel Contribution. Analysis Lee (2026, arXiv:2602.06301) shows Poisson proxy cJ=logJc_J = \\log J provides: Mean approximation error |ŒºJ(Œ±)‚àíŒ±logJ|=O(Œ±)|\\mu_J(\\alpha) - \\alpha \\log J| = O(\\alpha) fixed Œ±\\alpha J‚Üí‚àûJ \\\\infty. shifted Poisson proxy (KJ‚àí1‚âàPoisson(Œ±logJ)K_J - 1 \\approx \\text{Poisson}(\\alpha \\log J)) dominates unshifted version practically relevant Œ±‚â≥0.2\\alpha \\gtrsim 0.2. A1 approximation error (target Œº_K = 8, œÉ¬≤_K = 15)","code":"# Compute A1 approximation error J_values <- c(25, 50, 100, 200, 300) mu_K <- 8 var_K <- 15  error_data <- do.call(rbind, lapply(J_values, function(J) {   fit_a1 <- DPprior_fit(J, mu_K, var_K = var_K, method = \"A1\")   fit_a2 <- DPprior_fit(J, mu_K, var_K = var_K, method = \"A2-MN\")      data.frame(     J = J,     Mean_Error_Pct = 100 * abs(fit_a1$fit$mu_K - mu_K) / mu_K,     Var_Error_Pct = 100 * abs(fit_a1$fit$var_K - var_K) / var_K,     a_Relative_Error = abs(fit_a1$a - fit_a2$a) / fit_a2$a,     b_Relative_Error = abs(fit_a1$b - fit_a2$b) / fit_a2$b   ) })) #> Warning: HIGH DOMINANCE RISK: P(w1 > 0.5) = 42.6% exceeds 40%. #>   This may indicate unintended prior behavior (Lee, 2026). #>   Consider using DPprior_dual() for weight-constrained elicitation. #>   See ?DPprior_diagnostics for interpretation. #> Warning: HIGH DOMINANCE RISK: P(w1 > 0.5) = 45.1% exceeds 40%. #>   This may indicate unintended prior behavior (Lee, 2026). #>   Consider using DPprior_dual() for weight-constrained elicitation. #>   See ?DPprior_diagnostics for interpretation. #> Warning: HIGH DOMINANCE RISK: P(w1 > 0.5) = 41.6% exceeds 40%. #>   This may indicate unintended prior behavior (Lee, 2026). #>   Consider using DPprior_dual() for weight-constrained elicitation. #>   See ?DPprior_diagnostics for interpretation.  knitr::kable(   error_data,   col.names = c(\"J\", \"Mean Error (%)\", \"Var Error (%)\",                  \"|a_A1 - a_A2|/a_A2\", \"|b_A1 - b_A2|/b_A2\"),   digits = c(0, 2, 2, 4, 4),   caption = sprintf(\"A1 approximation error (target Œº_K = %d, œÉ¬≤_K = %d)\", mu_K, var_K) )"},{"path":"https://joonho112.github.io/DPprior/articles/theory-overview.html","id":"the-feasibility-boundary","dir":"Articles","previous_headings":"6. Approximation Error Analysis","what":"6.2 The Feasibility Boundary","title":"Mathematical Foundations: The K Distribution and Gamma Hyperpriors","text":"Novel Contribution. important distinction A1 exact DP model concerns feasibility. A1 (Negative Binomial proxy), feasibility requires: œÉK2>ŒºK‚àí1(shifted A1). \\sigma^2_K > \\mu_K - 1 \\quad \\text{(shifted A1)}. However, exact DP model, conditional underdispersion implies (ŒºK,œÉK2)(\\mu_K, \\sigma^2_K) pairs œÉK2<ŒºK\\sigma^2_K < \\mu_K may achievable. package handles projecting infeasible A1 requests feasibility boundary using exact A2 methods needed. Feasibility regions A1 approximation vs.¬†exact DP model.","code":"# Illustrate feasibility regions J <- 50 mu_grid <- seq(2, 20, length.out = 100)  # A1 feasibility: var_K > mu_K - 1 a1_boundary <- mu_grid - 1  # Approximate exact boundary (minimum achievable variance) # This requires extensive computation; we use a simplified approximation exact_boundary <- sapply(mu_grid, function(mu) {   # Find alpha that gives this mean   alpha_implied <- mu / log(J)  # Rough approximation   # Minimum variance at this mean is conditional variance   var_K_given_alpha(J, alpha_implied) })  feasibility_df <- data.frame(   mu_K = c(mu_grid, mu_grid),   var_K_boundary = c(a1_boundary, exact_boundary),   Type = rep(c(\"A1 Boundary (var > Œº - 1)\", \"Exact DP Minimum\"), each = length(mu_grid)) )  ggplot(feasibility_df, aes(x = mu_K, y = var_K_boundary, color = Type, linetype = Type)) +   geom_line(linewidth = 1.2) +   geom_abline(slope = 1, intercept = 0, linetype = \"dotted\", color = \"gray50\") +   annotate(\"text\", x = 18, y = 17, label = \"Var = Mean\", color = \"gray50\", size = 3) +   scale_color_manual(values = c(\"#E41A1C\", \"#377EB8\")) +   coord_cartesian(xlim = c(2, 20), ylim = c(0, 25)) +   labs(x = expression(mu[K] * \" (Target Mean)\"),        y = expression(sigma[K]^2 * \" (Minimum Feasible Variance)\"),        title = \"Feasibility Boundaries\",        subtitle = sprintf(\"J = %d; region above each curve is feasible\", J)) +   theme_minimal() +   theme(legend.position = \"bottom\",         legend.title = element_blank())"},{"path":[]},{"path":"https://joonho112.github.io/DPprior/articles/theory-overview.html","id":"key-functions","dir":"Articles","previous_headings":"7. Computational Implementation","what":"7.1 Key Functions","title":"Mathematical Foundations: The K Distribution and Gamma Hyperpriors","text":"DPprior package provides following core computational functions:","code":""},{"path":"https://joonho112.github.io/DPprior/articles/theory-overview.html","id":"verification","dir":"Articles","previous_headings":"7. Computational Implementation","what":"7.2 Verification","title":"Mathematical Foundations: The K Distribution and Gamma Hyperpriors","text":"package includes extensive verification tests confirm: PMF normalization: ‚àëk=0JPr(KJ=k|Œ±)=1\\sum_{k=0}^{J} \\Pr(K_J = k | \\alpha) = 1 Moment consistency: Moments PMF match closed-form expressions Poisson-binomial equivalence: Stirling PMF matches Monte Carlo Variance inequality: Var(KJ|Œ±)<ùîº[KJ|Œ±]\\text{Var}(K_J | \\alpha) < \\mathbb{E}[K_J | \\alpha]","code":"# Run a subset of verification tests J <- 50 alpha <- 2 a <- 1.5 b <- 0.5  logS <- compute_log_stirling(J)  # Test 1: PMF normalization pmf <- pmf_K_given_alpha(J, alpha, logS) cat(\"PMF sum:\", sum(pmf), \"(should be 1)\\n\") #> PMF sum: 1 (should be 1)  # Test 2: Moment consistency mean_direct <- mean_K_given_alpha(J, alpha) var_direct <- var_K_given_alpha(J, alpha) mean_from_pmf <- sum((0:J) * pmf) var_from_pmf <- sum((0:J)^2 * pmf) - mean_from_pmf^2  cat(\"\\nConditional moments (Œ± =\", alpha, \"):\\n\") #>  #> Conditional moments (Œ± = 2 ): cat(\"  Mean (digamma):\", round(mean_direct, 6), \"\\n\") #>   Mean (digamma): 7.037626 cat(\"  Mean (from PMF):\", round(mean_from_pmf, 6), \"\\n\") #>   Mean (from PMF): 7.037626 cat(\"  Var (polygamma):\", round(var_direct, 6), \"\\n\") #>   Var (polygamma): 4.535558 cat(\"  Var (from PMF):\", round(var_from_pmf, 6), \"\\n\") #>   Var (from PMF): 4.535558  # Test 3: Variance inequality cat(\"\\nVariance inequality check:\\n\") #>  #> Variance inequality check: cat(\"  Var(K|Œ±) =\", round(var_direct, 4), \"< E[K|Œ±] =\", round(mean_direct, 4), \":\",      var_direct < mean_direct, \"\\n\") #>   Var(K|Œ±) = 4.5356 < E[K|Œ±] = 7.0376 : TRUE"},{"path":"https://joonho112.github.io/DPprior/articles/theory-overview.html","id":"summary","dir":"Articles","previous_headings":"","what":"8. Summary","title":"Mathematical Foundations: The K Distribution and Gamma Hyperpriors","text":"vignette provided comprehensive mathematical treatment theory underlying DPprior package. Key takeaways include: Antoniak distribution provides exact PMF KJ|Œ±K_J | \\alpha via unsigned Stirling numbers, can computed stably log-space. Conditional underdispersion: Var(KJ|Œ±)<ùîº[KJ|Œ±]\\text{Var}(K_J | \\alpha) < \\mathbb{E}[K_J | \\alpha] always holds, marginal distributions Gamma hyperpriors typically exhibit overdispersion. inverse problem mapping moments (ŒºK,œÉK2)(\\mu_K, \\sigma^2_K) Gamma parameters (,b)(, b) can solved via: A1: Closed-form Negative Binomial approximation (fast, approximate) A2: Newton iteration exact moments (accurate, initialized A1) Feasibility constraints differ A1 proxy exact DP model, A1 restrictive.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/theory-overview.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Mathematical Foundations: The K Distribution and Gamma Hyperpriors","text":"Antonelli, J., Trippa, L., & Haneuse, S. (2016). Mitigating bias generalized linear mixed models: case Bayesian nonparametrics. Statistical Science, 31(1), 80-98. Antoniak, C. E. (1974). Mixtures Dirichlet processes applications Bayesian nonparametric problems. Annals Statistics, 2(6), 1152-1174. Arratia, R., Barbour, . D., & Tavar√©, S. (2003). Logarithmic Combinatorial Structures: Probabilistic Approach. European Mathematical Society. Blackwell, D., & MacQueen, J. B. (1973). Ferguson distributions via P√≥lya urn schemes. Annals Statistics, 1(2), 353-355. Dorazio, R. M. (2009). selecting prior precision parameter Dirichlet process mixture models. Journal Statistical Planning Inference, 139(10), 3384-3390. Ferguson, T. S. (1973). Bayesian analysis nonparametric problems. Annals Statistics, 1(2), 209-230. Lee, J., Che, J., Rabe-Hesketh, S., Feller, ., & Miratrix, L. (2025). Improving estimation site-specific effects distribution multisite trials. Journal Educational Behavioral Statistics, 50(5), 731-764. Murugiah, S., & Sweeting, T. J. (2012). Selecting precision parameter prior Dirichlet process mixture models. Journal Statistical Planning Inference, 142(7), 1947-1959. Sethuraman, J. (1994). constructive definition Dirichlet priors. Statistica Sinica, 4(2), 639-650. Vicentini, C., & Jermyn, . H. (2025). Prior selection precision parameter Dirichlet process mixtures. arXiv:2502.00864. Zito, ., Rigon, T., & Dunson, D. B. (2024). Bayesian nonparametric modeling latent partitions via Stirling-gamma priors. arXiv:2306.02360.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/articles/theory-overview.html","id":"a-1-derivatives-for-newton-iteration","dir":"Articles","previous_headings":"Appendix: Mathematical Derivations","what":"A.1 Derivatives for Newton Iteration","title":"Mathematical Foundations: The K Distribution and Gamma Hyperpriors","text":"A2 Newton solver, require derivatives marginal moments respect (,b)(, b). Define: sa(Œ±):=‚àÇ‚àÇalogpa,b(Œ±)=logŒ±‚àíœà()+logb, s_a(\\alpha) := \\frac{\\partial}{\\partial } \\log p_{,b}(\\alpha) = \\log \\alpha - \\psi() + \\log b, sb(Œ±):=‚àÇ‚àÇblogpa,b(Œ±)=ab‚àíŒ±. s_b(\\alpha) := \\frac{\\partial}{\\partial b} \\log p_{,b}(\\alpha) = \\frac{}{b} - \\alpha. : ‚àÇM1‚àÇ=ùîºŒ±[ŒºJ(Œ±)‚ãÖsa(Œ±)],‚àÇM1‚àÇb=ùîºŒ±[ŒºJ(Œ±)‚ãÖsb(Œ±)]. \\frac{\\partial M_1}{\\partial } = \\mathbb{E}_\\alpha[\\mu_J(\\alpha) \\cdot s_a(\\alpha)], \\quad \\frac{\\partial M_1}{\\partial b} = \\mathbb{E}_\\alpha[\\mu_J(\\alpha) \\cdot s_b(\\alpha)]. variance, let m2(,b):=ùîº[KJ2|,b]m_2(,b) := \\mathbb{E}[K_J^2 | , b]. V=m2‚àíM12V = m_2 - M_1^2 : ‚àÇV‚àÇ=‚àÇm2‚àÇ‚àí2M1‚àÇM1‚àÇ. \\frac{\\partial V}{\\partial } = \\frac{\\partial m_2}{\\partial } - 2 M_1 \\frac{\\partial M_1}{\\partial }.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/theory-overview.html","id":"a-2-large-j-asymptotics","dir":"Articles","previous_headings":"Appendix: Mathematical Derivations","what":"A.2 Large-JJ Asymptotics","title":"Mathematical Foundations: The K Distribution and Gamma Hyperpriors","text":"fixed Œ±>0\\alpha > 0 J‚Üí‚àûJ \\\\infty: ŒºJ(Œ±)=Œ±logJ‚àíŒ±œà(Œ±)+O(Œ±J). \\mu_J(\\alpha) = \\alpha \\log J - \\alpha \\psi(\\alpha) + O\\left(\\frac{\\alpha}{J}\\right). justifies use cJ=logJc_J = \\log J default scaling A1 approximation. Note œà(Œ±)<0\\psi(\\alpha) < 0 Œ±<Œ±0‚âà1.46\\alpha < \\alpha_0 \\approx 1.46 œà(Œ±)>0\\psi(\\alpha) > 0 Œ±>Œ±0\\alpha > \\alpha_0. questions vignette DPprior package, please visit GitHub repository.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/theory-stirling.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Technical Deep Dive: Stirling Numbers and the Antoniak Distribution","text":"vignette provides deep technical treatment computational machinery underlying Antoniak distribution‚Äîexact probability mass function (PMF) number distinct clusters KJK_J Dirichlet Process (DP) model. focus specifically unsigned Stirling numbers first kind numerically stable computation, forms core DPprior package‚Äôs reference computational layer. vignette intended statisticians methodological researchers want understand exact implementation details. cover: combinatorial definition properties unsigned Stirling numbers computational challenge: naive implementation fails Log-space computation via logsumexp trick Computing Antoniak PMF Stirling numbers Numerical stability analysis implementation guards Throughout, distinguish established results combinatorics Bayesian nonparametrics literature implementation contributions package.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/articles/theory-stirling.html","id":"definition-and-combinatorial-interpretation","dir":"Articles","previous_headings":"1. Unsigned Stirling Numbers of the First Kind","what":"1.1 Definition and Combinatorial Interpretation","title":"Technical Deep Dive: Stirling Numbers and the Antoniak Distribution","text":"unsigned Stirling numbers first kind, denoted |s(J,k)||s(J, k)|, count number permutations JJ elements consist exactly kk disjoint cycles. Example. J=3J = 3 elements {1,2,3}\\{1, 2, 3\\}, permutations grouped number cycles : total 2+3+1=6=3!2 + 3 + 1 = 6 = 3!, expected since ‚Äôre partitioning permutations. Attribution. Stirling numbers rich history combinatorics, dating back James Stirling‚Äôs 1730 work Methodus Differentialis. connection DP cluster distribution established Antoniak (1974).","code":""},{"path":"https://joonho112.github.io/DPprior/articles/theory-stirling.html","id":"recurrence-relation","dir":"Articles","previous_headings":"1. Unsigned Stirling Numbers of the First Kind","what":"1.2 Recurrence Relation","title":"Technical Deep Dive: Stirling Numbers and the Antoniak Distribution","text":"unsigned Stirling numbers satisfy fundamental recurrence: |s(J,k)|=|s(J‚àí1,k‚àí1)|+(J‚àí1)‚ãÖ|s(J‚àí1,k)| |s(J, k)| = |s(J-1, k-1)| + (J-1) \\cdot |s(J-1, k)| Combinatorial interpretation: adding element JJ permutation elements {1,‚Ä¶,J‚àí1}\\{1, \\ldots, J-1\\}: Element JJ can form new cycle : accounts |s(J‚àí1,k‚àí1)||s(J-1, k-1)| permutations (need k‚àí1k-1 cycles first J‚àí1J-1 elements) Element JJ can inserted position within existing cycle: (J‚àí1)(J-1) positions insert, need kk cycles already present, giving (J‚àí1)‚ãÖ|s(J‚àí1,k)|(J-1) \\cdot |s(J-1, k)|","code":""},{"path":"https://joonho112.github.io/DPprior/articles/theory-stirling.html","id":"boundary-conditions","dir":"Articles","previous_headings":"1. Unsigned Stirling Numbers of the First Kind","what":"1.3 Boundary Conditions","title":"Technical Deep Dive: Stirling Numbers and the Antoniak Distribution","text":"recurrence requires following boundary conditions: |s(0,0)|=1(empty permutation: one way arrange nothing)|s(J,0)|=0for J‚â•1 (permutation 0 cycles)|s(J,J)|=1for J (identity J cycles) \\begin{aligned} |s(0, 0)| &= 1 \\quad \\text{(empty permutation: one way arrange nothing)} \\\\ |s(J, 0)| &= 0 \\quad \\text{} J \\geq 1 \\text{ (permutation 0 cycles)} \\\\ |s(J, J)| &= 1 \\quad \\text{} J \\text{ (identity } J \\text{ cycles)} \\end{aligned}","code":""},{"path":"https://joonho112.github.io/DPprior/articles/theory-stirling.html","id":"fundamental-identity","dir":"Articles","previous_headings":"1. Unsigned Stirling Numbers of the First Kind","what":"1.4 Fundamental Identity","title":"Technical Deep Dive: Stirling Numbers and the Antoniak Distribution","text":"crucial identity serves computational verification : ‚àëk=1J|s(J,k)|=J! \\sum_{k=1}^{J} |s(J, k)| = J! follows immediately fact ‚Äôre partitioning J!J! permutations according cycle count.","code":"# Compute log-Stirling numbers up to J = 15 logS <- compute_log_stirling(15)  # Verify known values cat(\"Verification of known Stirling numbers:\\n\") #> Verification of known Stirling numbers: cat(sprintf(\"  |s(4, 2)| = %d (expected: 11)\\n\", round(exp(logS[5, 3])))) #>   |s(4, 2)| = 11 (expected: 11) cat(sprintf(\"  |s(5, 3)| = %d (expected: 35)\\n\", round(exp(logS[6, 4])))) #>   |s(5, 3)| = 35 (expected: 35) cat(sprintf(\"  |s(6, 3)| = %d (expected: 225)\\n\", round(exp(logS[7, 4])))) #>   |s(6, 3)| = 225 (expected: 225) cat(sprintf(\"  |s(10, 5)| = %d (expected: 269325)\\n\", round(exp(logS[11, 6])))) #>   |s(10, 5)| = 269325 (expected: 269325)  # Verify row sum = J! J_test <- 10 log_row_sum <- logsumexp_vec(logS[J_test + 1, 2:(J_test + 1)]) log_factorial <- sum(log(1:J_test)) cat(sprintf(\"\\nRow sum identity for J = %d:\\n\", J_test)) #>  #> Row sum identity for J = 10: cat(sprintf(\"  sum_k |s(%d,k)| = %.0f\\n\", J_test, exp(log_row_sum))) #>   sum_k |s(10,k)| = 3628800 cat(sprintf(\"  %d! = %.0f\\n\", J_test, exp(log_factorial))) #>   10! = 3628800 cat(sprintf(\"  Relative error: %.2e\\n\", abs(exp(log_row_sum - log_factorial) - 1))) #>   Relative error: 0.00e+00"},{"path":[]},{"path":"https://joonho112.github.io/DPprior/articles/theory-stirling.html","id":"explosive-growth-of-stirling-numbers","dir":"Articles","previous_headings":"2. The Computational Challenge","what":"2.1 Explosive Growth of Stirling Numbers","title":"Technical Deep Dive: Stirling Numbers and the Antoniak Distribution","text":"unsigned Stirling numbers grow extremely rapidly‚Äîfaster exponential. Consider representative values: Magnitude Stirling numbers various J J=100J = 100, maximum Stirling number approximately 1015710^{157}, far exceeding range double-precision floating point (‚âà10308\\approx 10^{308} maximum, 15-17 significant digits). key insight: Direct computation original scale impossible practical JJ. must work entirely log-space.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/theory-stirling.html","id":"why-naive-log-space-fails","dir":"Articles","previous_headings":"2. The Computational Challenge","what":"2.2 Why Naive Log-Space Fails","title":"Technical Deep Dive: Stirling Numbers and the Antoniak Distribution","text":"One might think: ‚ÄúJust take logs everything!‚Äù consider recurrence: |s(J,k)|=|s(J‚àí1,k‚àí1)|+(J‚àí1)‚ãÖ|s(J‚àí1,k)| |s(J, k)| = |s(J-1, k-1)| + (J-1) \\cdot |s(J-1, k)| log-space, becomes: log|s(J,k)|=log(eLJ‚àí1,k‚àí1+(J‚àí1)‚ãÖeLJ‚àí1,k) \\log|s(J, k)| = \\log\\left(e^{L_{J-1,k-1}} + (J-1) \\cdot e^{L_{J-1,k}}\\right) LJ,k:=log|s(J,k)|L_{J,k} := \\log|s(J,k)|. problem: need compute log(ea+eb)\\log(e^+ e^b) aa bb may large (causing overflow exponentiating) different magnitude (causing underflow adding).","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/articles/theory-stirling.html","id":"mathematical-foundation","dir":"Articles","previous_headings":"3. The logsumexp Trick","what":"3.1 Mathematical Foundation","title":"Technical Deep Dive: Stirling Numbers and the Antoniak Distribution","text":"logsumexp function computes log(ea+eb)\\log(e^+ e^b) numerically stable way using identity: log(ea+eb)=max(,b)+log(1+e‚àí|‚àíb|) \\log(e^+ e^b) = \\max(, b) + \\log\\left(1 + e^{-|-b|}\\right) works: maximum factored , never exponentiate large number argument exp\\exp always ‚â§0\\leq 0, preventing overflow use log1p(x) = log(1+x)\\log(1 + x) numerical stability near x=0x = 0","code":""},{"path":"https://joonho112.github.io/DPprior/articles/theory-stirling.html","id":"implementation-and-verification","dir":"Articles","previous_headings":"3. The logsumexp Trick","what":"3.2 Implementation and Verification","title":"Technical Deep Dive: Stirling Numbers and the Antoniak Distribution","text":"","code":"# Demonstrate numerical stability cat(\"logsumexp numerical stability:\\n\") #> logsumexp numerical stability:  # Case 1: Both arguments very large a <- 1000 b <- 1000 result <- logsumexp(a, b) expected <- 1000 + log(2)  # log(e^1000 + e^1000) = 1000 + log(2) cat(sprintf(\"  logsumexp(1000, 1000) = %.6f (expected: %.6f)\\n\", result, expected)) #>   logsumexp(1000, 1000) = 1000.693147 (expected: 1000.693147)  # Case 2: Both arguments very negative a <- -1000 b <- -1000 result <- logsumexp(a, b) expected <- -1000 + log(2) cat(sprintf(\"  logsumexp(-1000, -1000) = %.6f (expected: %.6f)\\n\", result, expected)) #>   logsumexp(-1000, -1000) = -999.306853 (expected: -999.306853)  # Case 3: Large difference in magnitude a <- 1000 b <- -1000 result <- logsumexp(a, b) cat(sprintf(\"  logsumexp(1000, -1000) = %.6f (essentially 1000)\\n\", result)) #>   logsumexp(1000, -1000) = 1000.000000 (essentially 1000)  # Case 4: Typical use case - log-sum of probabilities log_p1 <- log(0.3) log_p2 <- log(0.7) result <- exp(logsumexp(log_p1, log_p2)) cat(sprintf(\"  exp(logsumexp(log(0.3), log(0.7))) = %.6f\\n\", result)) #>   exp(logsumexp(log(0.3), log(0.7))) = 1.000000"},{"path":"https://joonho112.github.io/DPprior/articles/theory-stirling.html","id":"vectorized-version","dir":"Articles","previous_headings":"3. The logsumexp Trick","what":"3.3 Vectorized Version","title":"Technical Deep Dive: Stirling Numbers and the Antoniak Distribution","text":"computing log‚àë=1nexi\\log\\sum_{=1}^n e^{x_i}, use vectorized extension: log‚àë=1nexi=maxi(xi)+log‚àë=1nexi‚àímaxi(xi) \\log\\sum_{=1}^n e^{x_i} = \\max_i(x_i) + \\log\\sum_{=1}^n e^{x_i - \\max_i(x_i)}","code":"# Demonstrate vectorized logsumexp x <- c(100, 101, 102, 103) result <- logsumexp_vec(x) cat(sprintf(\"logsumexp_vec([100, 101, 102, 103]) = %.4f\\n\", result)) #> logsumexp_vec([100, 101, 102, 103]) = 103.4402 cat(sprintf(\"This equals: log(e^100 + e^101 + e^102 + e^103) ‚âà log(e^103 * 1.52) = %.4f\\n\",              103 + log(1 + exp(-1) + exp(-2) + exp(-3)))) #> This equals: log(e^100 + e^101 + e^102 + e^103) ‚âà log(e^103 * 1.52) = 103.4402"},{"path":[]},{"path":"https://joonho112.github.io/DPprior/articles/theory-stirling.html","id":"the-algorithm","dir":"Articles","previous_headings":"4. Computing the Log-Stirling Matrix","what":"4.1 The Algorithm","title":"Technical Deep Dive: Stirling Numbers and the Antoniak Distribution","text":"compute_log_stirling() function builds complete lower-triangular matrix log-Stirling numbers using recursion: LJ,k=logsumexp(LJ‚àí1,k‚àí1,log(J‚àí1)+LJ‚àí1,k) L_{J,k} = \\text{logsumexp}(L_{J-1,k-1}, \\log(J-1) + L_{J-1,k}) Complexity: O(Jmax2)O(J_{\\max}^2) time space.","code":"# Compute the full log-Stirling matrix for J up to 50 J_max <- 50 logS <- compute_log_stirling(J_max)  cat(sprintf(\"Log-Stirling matrix dimensions: %d x %d\\n\", nrow(logS), ncol(logS))) #> Log-Stirling matrix dimensions: 51 x 51 cat(sprintf(\"Memory usage: %.2f KB\\n\", object.size(logS) / 1024)) #> Memory usage: 20.53 KB  # Display a small section of the matrix (J = 1 to 10) cat(\"\\nlog|s(J, k)| for J = 1..10, k = 1..10:\\n\") #>  #> log|s(J, k)| for J = 1..10, k = 1..10: small_section <- round(logS[2:11, 2:11], 2) rownames(small_section) <- paste(\"J =\", 1:10) colnames(small_section) <- paste(\"k =\", 1:10) print(small_section) #>        k = 1 k = 2 k = 3 k = 4 k = 5 k = 6 k = 7 k = 8 k = 9 k = 10 #> J = 1   0.00  -Inf  -Inf  -Inf  -Inf  -Inf  -Inf  -Inf  -Inf   -Inf #> J = 2   0.00  0.00  -Inf  -Inf  -Inf  -Inf  -Inf  -Inf  -Inf   -Inf #> J = 3   0.69  1.10  0.00  -Inf  -Inf  -Inf  -Inf  -Inf  -Inf   -Inf #> J = 4   1.79  2.40  1.79  0.00  -Inf  -Inf  -Inf  -Inf  -Inf   -Inf #> J = 5   3.18  3.91  3.56  2.30  0.00  -Inf  -Inf  -Inf  -Inf   -Inf #> J = 6   4.79  5.61  5.42  4.44  2.71  0.00  -Inf  -Inf  -Inf   -Inf #> J = 7   6.58  7.48  7.39  6.60  5.16  3.04  0.00  -Inf  -Inf   -Inf #> J = 8   8.53  9.48  9.48  8.82  7.58  5.77  3.33  0.00  -Inf   -Inf #> J = 9  10.60 11.60 11.68 11.12 10.02  8.42  6.30  3.58  0.00   -Inf #> J = 10 12.80 13.84 13.97 13.49 12.50 11.06  9.15  6.77  3.81      0"},{"path":"https://joonho112.github.io/DPprior/articles/theory-stirling.html","id":"verification-via-row-sums","dir":"Articles","previous_headings":"4. Computing the Log-Stirling Matrix","what":"4.2 Verification via Row Sums","title":"Technical Deep Dive: Stirling Numbers and the Antoniak Distribution","text":"can verify computation checking row sums equal log(J!)\\log(J!):","code":"# Verify row sum identity for multiple J values cat(\"Verification of sum_k |s(J,k)| = J!:\\n\") #> Verification of sum_k |s(J,k)| = J!: cat(sprintf(\"%5s %15s %15s %12s\\n\", \"J\", \"sum |s(J,k)|\", \"J!\", \"Rel. Error\")) #>     J    sum |s(J,k)|              J!   Rel. Error cat(strrep(\"-\", 48), \"\\n\") #> ------------------------------------------------  for (J in c(5, 10, 20, 30, 40, 50)) {   log_row_sum <- logsumexp_vec(logS[J + 1, 2:(J + 1)])   log_factorial <- sum(log(1:J))   rel_error <- abs(exp(log_row_sum - log_factorial) - 1)      # Display in scientific notation for large values   cat(sprintf(\"%5d %15.4e %15.4e %12.2e\\n\",                J, exp(log_row_sum), exp(log_factorial), rel_error)) } #>     5      1.2000e+02      1.2000e+02     0.00e+00 #>    10      3.6288e+06      3.6288e+06     0.00e+00 #>    20      2.4329e+18      2.4329e+18     7.11e-15 #>    30      2.6525e+32      2.6525e+32     1.42e-14 #>    40      8.1592e+47      8.1592e+47     1.42e-14 #>    50      3.0414e+64      3.0414e+64     2.84e-14"},{"path":[]},{"path":"https://joonho112.github.io/DPprior/articles/theory-stirling.html","id":"exact-pmf-of-k_j-alpha","dir":"Articles","previous_headings":"5. The Antoniak Distribution","what":"5.1 Exact PMF of KJ|Œ±K_J | \\alpha","title":"Technical Deep Dive: Stirling Numbers and the Antoniak Distribution","text":"fundamental result connecting Stirling numbers DP cluster distribution Antoniak distribution (Antoniak, 1974): Pr(KJ=k|Œ±)=|s(J,k)|‚ãÖŒ±k(Œ±)J,k=1,‚Ä¶,J \\Pr(K_J = k | \\alpha) = |s(J, k)| \\cdot \\frac{\\alpha^k}{(\\alpha)_J}, \\quad k = 1, \\ldots, J (Œ±)J=Œ±(Œ±+1)‚ãØ(Œ±+J‚àí1)=Œì(Œ±+J)Œì(Œ±)(\\alpha)_J = \\alpha(\\alpha+1)\\cdots(\\alpha+J-1) = \\frac{\\Gamma(\\alpha+J)}{\\Gamma(\\alpha)} rising factorial (Pochhammer symbol). Attribution. formula derived Antoniak (1974) foundational Bayesian nonparametrics literature. restated modern DP prior-elicitation work including Dorazio (2009), Murugiah Sweeting (2012), Vicentini Jermyn (2025). Zito, Rigon, Dunson (2024) present general Gibbs-type form Pr(KJ=k)=VJ,k|s(J,k)|\\Pr(K_J = k) = V_{J,k} |s(J,k)|.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/theory-stirling.html","id":"log-space-computation","dir":"Articles","previous_headings":"5. The Antoniak Distribution","what":"5.2 Log-Space Computation","title":"Technical Deep Dive: Stirling Numbers and the Antoniak Distribution","text":"log-space, PMF becomes: logPr(KJ=k|Œ±)=log|s(J,k)|+klogŒ±‚àílog(Œ±)J \\log \\Pr(K_J = k | \\alpha) = \\log|s(J, k)| + k \\log\\alpha - \\log(\\alpha)_J log(Œ±)J=logŒì(Œ±+J)‚àílogŒì(Œ±)\\log(\\alpha)_J = \\log\\Gamma(\\alpha + J) - \\log\\Gamma(\\alpha). Normalization: PMF computed log-space converted probabilities via softmax function, ensures: Numerical stability extreme parameter values Exact normalization sum 1","code":"# Compute the Antoniak PMF for J = 50, alpha = 2 J <- 50 alpha <- 2  pmf <- pmf_K_given_alpha(J, alpha, logS)  # Verify normalization cat(sprintf(\"PMF normalization check: sum(pmf) = %.10f\\n\", sum(pmf))) #> PMF normalization check: sum(pmf) = 1.0000000000  # Summary statistics k_vals <- 0:J mean_K <- sum(k_vals * pmf) var_K <- sum(k_vals^2 * pmf) - mean_K^2 mode_K <- which.max(pmf) - 1  cat(sprintf(\"\\nDistribution of K_%d | Œ± = %g:\\n\", J, alpha)) #>  #> Distribution of K_50 | Œ± = 2: cat(sprintf(\"  E[K] = %.4f\\n\", mean_K)) #>   E[K] = 7.0376 cat(sprintf(\"  Var(K) = %.4f\\n\", var_K)) #>   Var(K) = 4.5356 cat(sprintf(\"  Mode(K) = %d\\n\", mode_K)) #>   Mode(K) = 7 cat(sprintf(\"  SD(K) = %.4f\\n\", sqrt(var_K))) #>   SD(K) = 2.1297"},{"path":"https://joonho112.github.io/DPprior/articles/theory-stirling.html","id":"visualization","dir":"Articles","previous_headings":"5. The Antoniak Distribution","what":"5.3 Visualization","title":"Technical Deep Dive: Stirling Numbers and the Antoniak Distribution","text":"Antoniak PMF various concentration parameters Œ± J = 50 observations.","code":"# Compute PMF for several alpha values alpha_values <- c(0.5, 1, 2, 5, 10) J <- 50  pmf_data <- do.call(rbind, lapply(alpha_values, function(a) {   pmf <- pmf_K_given_alpha(J, a, logS)   k_range <- 1:min(35, J)   data.frame(     k = k_range,     pmf = pmf[k_range + 1],     alpha = factor(paste0(\"Œ± = \", a))   ) }))  ggplot(pmf_data, aes(x = k, y = pmf, color = alpha)) +   geom_line(linewidth = 1) +   geom_point(size = 1.5) +   scale_color_manual(values = c(\"#E41A1C\", \"#377EB8\", \"#4DAF4A\", \"#984EA3\", \"#FF7F00\")) +   labs(     x = expression(k ~ \"(number of clusters)\"),     y = expression(Pr(K[50] == k ~ \"|\" ~ alpha)),     title = expression(\"Antoniak Distribution: \" * Pr(K[J] == k ~ \"|\" ~ alpha)),     subtitle = \"J = 50 observations\",     color = \"Concentration\"   ) +   theme_minimal() +   theme(     legend.position = \"right\",     plot.title = element_text(face = \"bold\", hjust = 0.5),     plot.subtitle = element_text(hjust = 0.5)   )"},{"path":"https://joonho112.github.io/DPprior/articles/theory-stirling.html","id":"comparison-with-the-poisson-binomial-representation","dir":"Articles","previous_headings":"5. The Antoniak Distribution","what":"5.4 Comparison with the Poisson-Binomial Representation","title":"Technical Deep Dive: Stirling Numbers and the Antoniak Distribution","text":"Antoniak distribution can alternatively derived Poisson-binomial representation (Theorem 1 theory-overview): KJ=d‚àë=1JBi,Bi‚àºBernoulli(Œ±Œ±+‚àí1) K_J \\stackrel{d}{=} \\sum_{=1}^{J} B_i, \\quad B_i \\sim \\text{Bernoulli}\\left(\\frac{\\alpha}{\\alpha + - 1}\\right) provides independent verification Stirling-based computation: Verification: Stirling-based PMF vs.¬†Monte Carlo Poisson-Binomial representation.","code":"# Monte Carlo simulation using Poisson-Binomial representation n_sim <- 100000 J <- 50 alpha <- 2  # Bernoulli success probabilities p <- alpha / (alpha + (1:J) - 1)  # Simulate K_J set.seed(123) K_samples <- replicate(n_sim, sum(runif(J) < p))  # Compare distributions k_range <- 1:20 pmf_stirling <- pmf_K_given_alpha(J, alpha, logS)[k_range + 1] pmf_mc <- tabulate(K_samples, nbins = max(K_samples))[k_range] / n_sim  comparison_df <- data.frame(   k = rep(k_range, 2),   pmf = c(pmf_stirling, pmf_mc),   Method = rep(c(\"Stirling (exact)\", \"Monte Carlo (n=100K)\"), each = length(k_range)) )  ggplot(comparison_df, aes(x = k, y = pmf, color = Method, shape = Method)) +   geom_point(size = 3, alpha = 0.8) +   scale_color_manual(values = c(\"#E41A1C\", \"#377EB8\")) +   scale_shape_manual(values = c(16, 17)) +   labs(     x = expression(k),     y = \"Probability\",     title = expression(\"Verification: Stirling vs. Poisson-Binomial Monte Carlo\"),     subtitle = sprintf(\"J = %d, Œ± = %g\", J, alpha)   ) +   theme_minimal() +   theme(     legend.position = \"bottom\",     plot.title = element_text(face = \"bold\", hjust = 0.5),     plot.subtitle = element_text(hjust = 0.5)   ) #> Warning: Removed 2 rows containing missing values or values outside the scale range #> (`geom_point()`). # Numerical comparison max_diff <- max(abs(pmf_stirling - pmf_mc)) cat(sprintf(\"\\nMaximum absolute difference between methods: %.2e\\n\", max_diff)) #>  #> Maximum absolute difference between methods: NA"},{"path":[]},{"path":"https://joonho112.github.io/DPprior/articles/theory-stirling.html","id":"critical-regions","dir":"Articles","previous_headings":"6. Numerical Stability Analysis","what":"6.1 Critical Regions","title":"Technical Deep Dive: Stirling Numbers and the Antoniak Distribution","text":"Antoniak PMF computation faces numerical challenges extreme parameter regions: small Œ±\\alpha (< 0.1): distribution becomes highly concentrated KJ=1K_J = 1, Pr(KJ=1|Œ±)‚Üí1\\Pr(K_J = 1 | \\alpha) \\1 Œ±‚Üí0\\alpha \\0. requires careful handling probabilities close 1. large Œ±\\alpha (> 50): distribution shifts toward KJ‚âàJK_J \\approx J, log-probabilities small kk become extremely negative.","code":"# Examine behavior at extreme alpha values J <- 50 extreme_alphas <- c(0.01, 0.1, 1, 10, 50, 100)  cat(\"PMF stability at extreme Œ± values (J = 50):\\n\") #> PMF stability at extreme Œ± values (J = 50): cat(sprintf(\"%8s %12s %12s %12s %12s\\n\",              \"Œ±\", \"Pr(K=1)\", \"E[K]\", \"Mode(K)\", \"sum(pmf)\")) #>       Œ±      Pr(K=1)         E[K]      Mode(K)     sum(pmf) cat(strrep(\"-\", 60), \"\\n\") #> ------------------------------------------------------------  for (a in extreme_alphas) {   pmf <- pmf_K_given_alpha(J, a, logS)   k_vals <- 0:J   mean_K <- sum(k_vals * pmf)   mode_K <- which.max(pmf) - 1   sum_pmf <- sum(pmf)      cat(sprintf(\"%8.2f %12.6f %12.2f %12d %12.10f\\n\",                a, pmf[2], mean_K, mode_K, sum_pmf)) } #>     0.01     0.956274         1.04            1 1.0000000000 #>     0.10     0.643925         1.43            1 1.0000000000 #>     1.00     0.020000         4.50            4 1.0000000000 #>    10.00     0.000000        18.34           18 1.0000000000 #>    50.00     0.000000        34.91           35 1.0000000000 #>   100.00     0.000000        40.71           41 1.0000000000"},{"path":"https://joonho112.github.io/DPprior/articles/theory-stirling.html","id":"implementation-guards-in-dpprior","dir":"Articles","previous_headings":"6. Numerical Stability Analysis","what":"6.2 Implementation Guards in DPprior","title":"Technical Deep Dive: Stirling Numbers and the Antoniak Distribution","text":"DPprior package includes several defensive measures: Log-space computation throughout: intermediate calculations remain log-space final softmax Stable softmax: Uses shifted exponential trick prevent overflow: pi=exp(xi‚àímaxjxj)/‚àëjexp(xj‚àímaxjxj)p_i = \\exp(x_i - \\max_j x_j) / \\sum_j \\exp(x_j - \\max_j x_j) Input validation: assert_positive() assert_valid_J() helpers catch invalid inputs early Defensive renormalization: Final PMF vectors explicitly normalized sum 1","code":""},{"path":"https://joonho112.github.io/DPprior/articles/theory-stirling.html","id":"digamma-function-stability","dir":"Articles","previous_headings":"6. Numerical Stability Analysis","what":"6.3 Digamma Function Stability","title":"Technical Deep Dive: Stirling Numbers and the Antoniak Distribution","text":"conditional moments KJ|Œ±K_J | \\alpha involve digamma function: ŒºJ(Œ±)=Œ±‚ãÖ[œà(Œ±+J)‚àíœà(Œ±)] \\mu_J(\\alpha) = \\alpha \\cdot [\\psi(\\alpha + J) - \\psi(\\alpha)] small Œ±\\alpha, œà(Œ±)‚Üí‚àí‚àû\\psi(\\alpha) \\-\\infty, can cause numerical issues. package uses threshold-based switching alternative formulations needed:","code":"# Compare digamma-based moments with PMF-based computation J <- 50  alpha_test <- c(0.01, 0.1, 0.5, 1, 2, 5, 10)  cat(\"Moment computation consistency check:\\n\") #> Moment computation consistency check: cat(sprintf(\"%8s %12s %12s %12s\\n\",              \"Œ±\", \"E[K] (œà)\", \"E[K] (PMF)\", \"Rel. Diff\")) #>       Œ±    E[K] (œà)   E[K] (PMF)    Rel. Diff cat(strrep(\"-\", 48), \"\\n\") #> ------------------------------------------------  for (a in alpha_test) {   # Digamma-based computation   mean_digamma <- mean_K_given_alpha(J, a)      # PMF-based computation   pmf <- pmf_K_given_alpha(J, a, logS)   mean_pmf <- sum((0:J) * pmf)      rel_diff <- abs(mean_digamma - mean_pmf) / mean_pmf      cat(sprintf(\"%8.2f %12.6f %12.6f %12.2e\\n\",                a, mean_digamma, mean_pmf, rel_diff)) } #>     0.01     1.044631     1.044631     8.50e-16 #>     0.10     1.432776     1.432776     1.08e-15 #>     0.50     2.937775     2.937775     2.12e-15 #>     1.00     4.499205     4.499205     1.38e-15 #>     2.00     7.037626     7.037626     2.90e-15 #>     5.00    12.460485    12.460485     2.14e-15 #>    10.00    18.342355    18.342355     2.13e-15"},{"path":[]},{"path":"https://joonho112.github.io/DPprior/articles/theory-stirling.html","id":"pre-computation-strategy","dir":"Articles","previous_headings":"7. Computational Performance","what":"7.1 Pre-computation Strategy","title":"Technical Deep Dive: Stirling Numbers and the Antoniak Distribution","text":"typical use prior elicitation (JJ fixed given analysis), log-Stirling matrix computed cached:","code":"# Timing for log-Stirling matrix computation J_values <- c(50, 100, 200, 300, 500)  cat(\"Log-Stirling matrix computation times:\\n\") #> Log-Stirling matrix computation times: cat(sprintf(\"%8s %15s %15s\\n\", \"J_max\", \"Time (ms)\", \"Memory (KB)\")) #>    J_max       Time (ms)     Memory (KB) cat(strrep(\"-\", 40), \"\\n\") #> ----------------------------------------  for (J_max in J_values) {   time_taken <- system.time({     logS_temp <- compute_log_stirling(J_max)   })[\"elapsed\"] * 1000      mem_kb <- object.size(logS_temp) / 1024      cat(sprintf(\"%8d %15.2f %15.1f\\n\", J_max, time_taken, mem_kb)) } #>       50            9.00            20.5 #>      100           39.00            79.9 #>      200          163.00           315.8 #>      300          375.00           708.0 #>      500         1044.00          1961.2"},{"path":"https://joonho112.github.io/DPprior/articles/theory-stirling.html","id":"pmf-computation-timing","dir":"Articles","previous_headings":"7. Computational Performance","what":"7.2 PMF Computation Timing","title":"Technical Deep Dive: Stirling Numbers and the Antoniak Distribution","text":"Stirling matrix cached, PMF computation extremely fast:","code":"# Pre-compute Stirling matrix logS_300 <- compute_log_stirling(300)  # Time PMF computation for various J cat(\"\\nPMF computation times (with pre-computed Stirling matrix):\\n\") #>  #> PMF computation times (with pre-computed Stirling matrix): cat(sprintf(\"%8s %8s %15s\\n\", \"J\", \"Œ±\", \"Time (Œºs)\")) #>        J       Œ±      Time (Œºs) cat(strrep(\"-\", 35), \"\\n\") #> -----------------------------------  for (J in c(50, 100, 200, 300)) {   for (alpha in c(1, 5)) {     time_us <- mean(replicate(100, {       t <- system.time(pmf_K_given_alpha(J, alpha, logS_300))[\"elapsed\"]     })) * 1e6          cat(sprintf(\"%8d %8.1f %15.1f\\n\", J, alpha, time_us))   } } #>       50      1.0           120.0 #>       50      5.0            80.0 #>      100      1.0            90.0 #>      100      5.0            70.0 #>      200      1.0           130.0 #>      200      5.0           140.0 #>      300      1.0           220.0 #>      300      5.0           170.0"},{"path":"https://joonho112.github.io/DPprior/articles/theory-stirling.html","id":"application-effect-of-j-on-the-distribution","dir":"Articles","previous_headings":"","what":"8. Application: Effect of J on the Distribution","title":"Technical Deep Dive: Stirling Numbers and the Antoniak Distribution","text":"Understanding distribution KJK_J changes sample size JJ crucial prior elicitation. fixed Œ±\\alpha: Effect sample size J distribution K fixed Œ± = 2.","code":"# Effect of J on K distribution alpha <- 2 J_values <- c(20, 50, 100, 200)  logS_200 <- compute_log_stirling(200)  # Compute PMFs for different J effect_data <- do.call(rbind, lapply(J_values, function(J) {   pmf <- pmf_K_given_alpha(J, alpha, logS_200)   k_max <- min(30, J)   mean_K <- sum((0:J) * pmf)      data.frame(     k = 1:k_max,     pmf = pmf[2:(k_max + 1)],     J = factor(paste0(\"J = \", J, \" (E[K] = \", round(mean_K, 1), \")\"))   ) }))  ggplot(effect_data, aes(x = k, y = pmf, color = J)) +   geom_line(linewidth = 1) +   geom_point(size = 1.5) +   scale_color_manual(values = palette_main) +   labs(     x = expression(k ~ \"(number of clusters)\"),     y = \"Probability\",     title = expression(\"Effect of Sample Size on \" * K[J] * \" Distribution\"),     subtitle = expression(\"Fixed \" * alpha * \" = 2\"),     color = \"Sample Size\"   ) +   theme_minimal() +   theme(     legend.position = \"right\",     plot.title = element_text(face = \"bold\", hjust = 0.5),     plot.subtitle = element_text(hjust = 0.5)   )"},{"path":"https://joonho112.github.io/DPprior/articles/theory-stirling.html","id":"summary","dir":"Articles","previous_headings":"","what":"Summary","title":"Technical Deep Dive: Stirling Numbers and the Antoniak Distribution","text":"vignette provided detailed treatment computational machinery underlying Antoniak distribution: Unsigned Stirling numbers |s(J,k)||s(J,k)| count permutations exactly kk cycles satisfy well-defined recurrence relation. Numerical challenge: Direct computation overflows J>20J > 20; must work entirely log-space. logsumexp trick enables stable computation log(ea+eb)\\log(e^+ e^b) values aa bb. Antoniak distribution provides exact PMF KJ|Œ±K_J | \\alpha via Stirling numbers, computed stably log-space. DPprior implementation: Pre-computes caches log-Stirling matrix, enabling fast PMF evaluation Œ±\\alpha. stable computation Antoniak PMF forms foundation package‚Äôs exact moment-matching algorithms (A2) described subsequent vignettes.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/theory-stirling.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Technical Deep Dive: Stirling Numbers and the Antoniak Distribution","text":"Antoniak, C. E. (1974). Mixtures Dirichlet processes applications Bayesian nonparametric problems. Annals Statistics, 2(6), 1152-1174. Arratia, R., Barbour, . D., & Tavar√©, S. (2003). Logarithmic Combinatorial Structures: Probabilistic Approach. European Mathematical Society. Dorazio, R. M. (2009). selecting prior precision parameter Dirichlet process mixture models. Journal Statistical Planning Inference, 139(10), 3384-3390. Murugiah, S., & Sweeting, T. J. (2012). Selecting precision parameter prior Dirichlet process mixture models. Journal Statistical Planning Inference, 142(7), 1947-1959. Vicentini, C., & Jermyn, . H. (2025). Prior selection precision parameter Dirichlet process mixtures. arXiv:2502.00864. Zito, ., Rigon, T., & Dunson, D. B. (2024). Bayesian nonparametric modeling latent partitions via Stirling-gamma priors. arXiv:2306.02360.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/theory-stirling.html","id":"appendix-key-function-reference","dir":"Articles","previous_headings":"","what":"Appendix: Key Function Reference","title":"Technical Deep Dive: Stirling Numbers and the Antoniak Distribution","text":"questions vignette DPprior package, please visit GitHub repository.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/theory-weights.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Weight Distributions: w‚ÇÅ, œÅ, and the Dual-Anchor Framework","text":"vignette provides rigorous treatment stick-breaking weight distributions Dirichlet Process (DP) models role dual-anchor elicitation framework. intended statisticians methodological researchers wish understand: distributional properties first stick-breaking weight w1w_1 co-clustering probability œÅ=‚àëhwh2\\rho = \\sum_h w_h^2 interpretation IcI_c functional computing closed-form moments Gamma hyperpriors mathematical foundation dual-anchor optimization Throughout, carefully distinguish established results Bayesian nonparametrics literature novel contributions work (DPprior package associated research notes).","code":""},{"path":[]},{"path":[]},{"path":"https://joonho112.github.io/DPprior/articles/theory-weights.html","id":"the-gemalpha-construction","dir":"Articles","previous_headings":"1. Stick-Breaking Weights: Review and Interpretation","what":"1.1 The GEM(Œ±\\alpha) Construction","title":"Weight Distributions: w‚ÇÅ, œÅ, and the Dual-Anchor Framework","text":"Sethuraman‚Äôs (1994) stick-breaking representation DP, random probability measure G‚àºDP(Œ±,G0)G \\sim \\text{DP}(\\alpha, G_0) can written : G=‚àëh=1‚àûwhŒ¥Œ∏h, G = \\sum_{h=1}^{\\infty} w_h \\, \\delta_{\\theta_h},  {Œ∏h}h=1‚àû‚àºiidG0\\{\\theta_h\\}_{h=1}^{\\infty} \\stackrel{iid}{\\sim} G_0 atom locations {wh}h=1‚àû\\{w_h\\}_{h=1}^{\\infty} stick-breaking weights constructed : vh‚àºiidBeta(1,Œ±),w1=v1,wh=vh‚àè‚Ñì<h(1‚àív‚Ñì)(h‚â•2). v_h \\stackrel{iid}{\\sim} \\text{Beta}(1, \\alpha), \\quad  w_1 = v_1, \\quad  w_h = v_h \\prod_{\\ell < h}(1 - v_\\ell) \\quad (h \\geq 2). sequence (w1,w2,‚Ä¶)(w_1, w_2, \\ldots) follows GEM(Œ±\\alpha) distribution (Griffiths-Engen-McCloskey), represents size-biased random permutation Poisson-Dirichlet distribution (Pitman, 1996).","code":""},{"path":"https://joonho112.github.io/DPprior/articles/theory-weights.html","id":"critical-interpretability-caveat","dir":"Articles","previous_headings":"1. Stick-Breaking Weights: Review and Interpretation","what":"1.2 Critical Interpretability Caveat","title":"Weight Distributions: w‚ÇÅ, œÅ, and the Dual-Anchor Framework","text":"GEM order size-biased, decreasing. distinction essential applied elicitation. Specifically: (w1,w2,‚Ä¶)‚â†(w(1),w(2),‚Ä¶)(w_1, w_2, \\ldots) \\neq (w_{(1)}, w_{(2)}, \\ldots) latter denotes ranked (decreasing) weights w1w_1 ‚Äúlargest cluster proportion‚Äù faithful interpretation: w1w_1 asymptotic proportion cluster containing randomly selected unit (equivalently, size-biased pick Poisson-Dirichlet distribution) Despite caveat, w1w_1 remains meaningful diagnostic ‚Äúdominance risk.‚Äù P(w1>0.5)P(w_1 > 0.5) high, randomly selected unit likely belong cluster contains half population. Stick-breaking weights different Œ± values. Smaller Œ± concentrates mass early atoms.","code":"# Demonstrate the stick-breaking construction n_atoms <- 15 alpha_values <- c(0.5, 1, 2, 5)  set.seed(123) sb_data <- do.call(rbind, lapply(alpha_values, function(a) {   v <- rbeta(n_atoms, 1, a)   w <- numeric(n_atoms)   w[1] <- v[1]   for (h in 2:n_atoms) {     w[h] <- v[h] * prod(1 - v[1:(h-1)])   }   data.frame(     atom = 1:n_atoms,     weight = w,     alpha = paste0(\"Œ± = \", a)   ) }))  sb_data$alpha <- factor(sb_data$alpha, levels = paste0(\"Œ± = \", alpha_values))  ggplot(sb_data, aes(x = factor(atom), y = weight, fill = alpha)) +   geom_bar(stat = \"identity\") +   facet_wrap(~alpha, nrow = 1) +   scale_fill_manual(values = palette_main) +   labs(     x = \"Atom Index (h)\",      y = expression(w[h]),     title = \"Stick-Breaking Weights in GEM Order\",     subtitle = \"Single realization per Œ±; NOT ranked by size\"   ) +   theme_minimal() +   theme(legend.position = \"none\")"},{"path":[]},{"path":"https://joonho112.github.io/DPprior/articles/theory-weights.html","id":"conditional-distribution","dir":"Articles","previous_headings":"2. Distribution of w1w_1","what":"2.1 Conditional Distribution","title":"Weight Distributions: w‚ÇÅ, œÅ, and the Dual-Anchor Framework","text":"first stick-breaking weight particularly simple conditional distribution, following directly construction. Proposition 1 (Conditional distribution w1w_1). Œ±>0\\alpha > 0: w1‚à£Œ±‚àºBeta(1,Œ±). w_1 \\mid \\alpha \\sim \\text{Beta}(1, \\alpha). Consequently: ùîº[w1‚à£Œ±]=11+Œ±\\mathbb{E}[w_1 \\mid \\alpha] = \\frac{1}{1 + \\alpha} Var(w1‚à£Œ±)=Œ±(1+Œ±)2(2+Œ±)\\text{Var}(w_1 \\mid \\alpha) = \\frac{\\alpha}{(1+\\alpha)^2(2+\\alpha)} P(w1‚â§x‚à£Œ±)=1‚àí(1‚àíx)Œ±P(w_1 \\leq x \\mid \\alpha) = 1 - (1-x)^{\\alpha} x‚àà[0,1]x \\[0, 1] Attribution: follows immediately stick-breaking construction (Sethuraman, 1994). Conditional density w‚ÇÅ|Œ± different concentration parameter values.","code":"x_grid <- seq(0.001, 0.999, length.out = 200) alpha_grid <- c(0.5, 1, 2, 5, 10)  cond_df <- do.call(rbind, lapply(alpha_grid, function(a) {   data.frame(     x = x_grid,     density = dbeta(x_grid, 1, a),     alpha = paste0(\"Œ± = \", a)   ) })) cond_df$alpha <- factor(cond_df$alpha, levels = paste0(\"Œ± = \", alpha_grid))  ggplot(cond_df, aes(x = x, y = density, color = alpha)) +   geom_line(linewidth = 0.9) +   scale_color_viridis_d(option = \"plasma\", end = 0.85) +   labs(     x = expression(w[1]),     y = \"Density\",     title = expression(\"Conditional Density: \" * w[1] * \" | \" * alpha * \" ~ Beta(1, \" * alpha * \")\"),     color = NULL   ) +   coord_cartesian(ylim = c(0, 6)) +   theme_minimal() +   theme(legend.position = \"right\")"},{"path":"https://joonho112.github.io/DPprior/articles/theory-weights.html","id":"marginal-distribution-under-gamma-hyperprior","dir":"Articles","previous_headings":"2. Distribution of w1w_1","what":"2.2 Marginal Distribution Under Gamma Hyperprior","title":"Weight Distributions: w‚ÇÅ, œÅ, and the Dual-Anchor Framework","text":"Œ±‚àºGamma(,b)\\alpha \\sim \\text{Gamma}(, b) shape >0a > 0 rate b>0b > 0, unconditional distribution w1w_1 admits fully closed-form expressions. Theorem 1 (Unconditional distribution w1w_1; Vicentini & Jermyn, 2025, Appendix ). Let Œ±‚àºGamma(,b)\\alpha \\sim \\text{Gamma}(, b). : Density: p(w1‚à£,b)=aba(1‚àíw1)[b‚àílog(1‚àíw1)]+1,w1‚àà(0,1). p(w_1 \\mid , b) = \\frac{\\, b^}{(1 - w_1)[b - \\log(1-w_1)]^{+1}}, \\quad w_1 \\(0, 1). CDF: Fw1(x‚à£,b)=P(w1‚â§x‚à£,b)=1‚àí(bb‚àílog(1‚àíx)). F_{w_1}(x \\mid , b) = P(w_1 \\leq x \\mid , b) = 1 - \\left(\\frac{b}{b - \\log(1-x)}\\right)^. Survival function (dominance risk): P(w1>t‚à£,b)=(bb‚àílog(1‚àít)). P(w_1 > t \\mid , b) = \\left(\\frac{b}{b - \\log(1-t)}\\right)^. Quantile function: Qw1(u‚à£,b)=1‚àíexp(b[1‚àí(1‚àíu)‚àí1/]). Q_{w_1}(u \\mid , b) = 1 - \\exp\\left(b\\left[1 - (1-u)^{-1/}\\right]\\right). Proof sketch. Integrate Œ±\\alpha conditional distribution: p(w1‚à£,b)=‚à´0‚àûŒ±(1‚àíw1)Œ±‚àí1‚ãÖbaŒì()Œ±a‚àí1e‚àíbŒ±dŒ±. p(w_1 \\mid , b) = \\int_0^\\infty \\alpha (1-w_1)^{\\alpha-1} \\cdot  \\frac{b^}{\\Gamma()} \\alpha^{-1} e^{-b\\alpha} \\, d\\alpha.  integral evaluates Gamma function, CDF follows direct integration substitution u=b‚àílog(1‚àíw)u = b - \\log(1-w). ‚ñ´\\square Computational significance. closed-form expressions enable O(1)O(1) computation quantiles tail probabilities‚ÄîMonte Carlo sampling required.","code":"# Demonstrate the closed-form w1 distribution functions a <- 1.6 b <- 1.22  # The Lee et al. DP-inform prior  cat(\"w‚ÇÅ distribution under Gamma(a=1.6, b=1.22) hyperprior:\\n\") #> w‚ÇÅ distribution under Gamma(a=1.6, b=1.22) hyperprior: cat(sprintf(\"  Mean:     %.4f\\n\", mean_w1(a, b))) #>   Mean:     0.5084 cat(sprintf(\"  Variance: %.4f\\n\", var_w1(a, b))) #>   Variance: 0.1052 cat(sprintf(\"  Median:   %.4f\\n\", quantile_w1(0.5, a, b))) #>   Median:   0.4839 cat(sprintf(\"  90th %%:   %.4f\\n\", quantile_w1(0.9, a, b))) #>   90th %:   0.9803  cat(\"\\nDominance risk (tail probabilities):\\n\") #>  #> Dominance risk (tail probabilities): for (t in c(0.3, 0.5, 0.7, 0.9)) {   cat(sprintf(\"  P(w‚ÇÅ > %.1f) = %.4f\\n\", t, prob_w1_exceeds(t, a, b))) } #>   P(w‚ÇÅ > 0.3) = 0.6634 #>   P(w‚ÇÅ > 0.5) = 0.4868 #>   P(w‚ÇÅ > 0.7) = 0.3334 #>   P(w‚ÇÅ > 0.9) = 0.1833"},{"path":"https://joonho112.github.io/DPprior/articles/theory-weights.html","id":"visualization-of-the-marginal-distribution","dir":"Articles","previous_headings":"2. Distribution of w1w_1","what":"2.3 Visualization of the Marginal Distribution","title":"Weight Distributions: w‚ÇÅ, œÅ, and the Dual-Anchor Framework","text":"Marginal density CDF w‚ÇÅ Gamma(1.6, 1.22) hyperprior.","code":"# Visualize the marginal w1 distribution x_grid <- seq(0.01, 0.99, length.out = 200) a <- 1.6 b <- 1.22  # Compute density manually using the closed-form formula # p(w1 | a, b) = a * b^a / ((1-w1) * (b - log(1-w1))^(a+1)) density_w1_manual <- function(x, a, b) {   denom <- (1 - x) * (b - log(1 - x))^(a + 1)   a * b^a / denom }  w1_df <- data.frame(   x = x_grid,   density = density_w1_manual(x_grid, a, b),   cdf = cdf_w1(x_grid, a, b),   survival = prob_w1_exceeds(x_grid, a, b) )  p1 <- ggplot(w1_df, aes(x = x, y = density)) +   geom_line(color = \"#E41A1C\", linewidth = 1) +   geom_vline(xintercept = quantile_w1(0.5, a, b), linetype = \"dashed\",               color = \"#377EB8\", alpha = 0.7) +   annotate(\"text\", x = quantile_w1(0.5, a, b) + 0.05, y = max(w1_df$density) * 0.9,            label = \"Median\", color = \"#377EB8\", hjust = 0) +   labs(x = expression(w[1]), y = \"Density\",        title = expression(\"Marginal Density of \" * w[1] * \" | Gamma(1.6, 1.22)\")) +   theme_minimal()  p2 <- ggplot(w1_df, aes(x = x)) +   geom_line(aes(y = cdf), color = \"#377EB8\", linewidth = 1) +   geom_line(aes(y = survival), color = \"#E41A1C\", linewidth = 1, linetype = \"dashed\") +   geom_hline(yintercept = 0.5, linetype = \"dotted\", color = \"gray50\") +   annotate(\"text\", x = 0.9, y = 0.85, label = \"CDF\", color = \"#377EB8\") +   annotate(\"text\", x = 0.9, y = 0.35, label = \"P(w1 > x)\", color = \"#E41A1C\") +   labs(x = expression(w[1]), y = \"Probability\",        title = \"CDF and Survival Function\") +   theme_minimal()  gridExtra::grid.arrange(p1, p2, ncol = 2)"},{"path":[]},{"path":"https://joonho112.github.io/DPprior/articles/theory-weights.html","id":"definition-and-interpretation","dir":"Articles","previous_headings":"3. The Co-Clustering Probability œÅ\\rho","what":"3.1 Definition and Interpretation","title":"Weight Distributions: w‚ÇÅ, œÅ, and the Dual-Anchor Framework","text":"co-clustering probability provides alternative, often intuitive, anchor weight-based elicitation. Definition 1 (Co-clustering probability / Simpson index). œÅ:=‚àëh=1‚àûwh2‚àà(0,1). \\rho := \\sum_{h=1}^{\\infty} w_h^2 \\(0, 1). Interpretation. Conditional random measure GG, Z1,Z2Z_1, Z_2 ..d. cluster labels P(Z=k‚à£G)=wkP(Z = k \\mid G) = w_k, : P(Z1=Z2‚à£G)=‚àëk‚â•1wk2=œÅ. P(Z_1 = Z_2 \\mid G) = \\sum_{k \\geq 1} w_k^2 = \\rho. Thus œÅ\\rho probability two randomly chosen units belong latent cluster. quantity translates directly applied elicitation: ‚Äúseeing data, probability two randomly selected sites study belong effect group?‚Äù","code":""},{"path":"https://joonho112.github.io/DPprior/articles/theory-weights.html","id":"conditional-moments-of-rho","dir":"Articles","previous_headings":"3. The Co-Clustering Probability œÅ\\rho","what":"3.2 Conditional Moments of œÅ\\rho","title":"Weight Distributions: w‚ÇÅ, œÅ, and the Dual-Anchor Framework","text":"Proposition 2 (Conditional expectation œÅ\\rho; Kingman, 1975; Pitman, 1996). ùîº[œÅ‚à£Œ±]=11+Œ±. \\mathbb{E}[\\rho \\mid \\alpha] = \\frac{1}{1 + \\alpha}. Proof. Using stick-breaking construction: ùîº[wk2‚à£Œ±]=ùîº[vk2]‚ãÖ‚àè‚Ñì<kùîº[(1‚àív‚Ñì)2]. \\mathbb{E}[w_k^2 \\mid \\alpha] = \\mathbb{E}[v_k^2] \\cdot \\prod_{\\ell < k} \\mathbb{E}[(1-v_\\ell)^2]. v‚àºBeta(1,Œ±)v \\sim \\text{Beta}(1, \\alpha): ùîº[v2]=2(1+Œ±)(2+Œ±),ùîº[(1‚àív)2]=Œ±2+Œ±. \\mathbb{E}[v^2] = \\frac{2}{(1+\\alpha)(2+\\alpha)}, \\quad  \\mathbb{E}[(1-v)^2] = \\frac{\\alpha}{2+\\alpha}. Summing geometric series: ùîº[œÅ‚à£Œ±]=‚àëk=1‚àû2(1+Œ±)(2+Œ±)(Œ±2+Œ±)k‚àí1=11+Œ±. \\mathbb{E}[\\rho \\mid \\alpha] = \\sum_{k=1}^\\infty \\frac{2}{(1+\\alpha)(2+\\alpha)}  \\left(\\frac{\\alpha}{2+\\alpha}\\right)^{k-1} = \\frac{1}{1+\\alpha}. ‚ñ´\\square Corollary 1 (Key identity). conditional expectations w1w_1 œÅ\\rho equal: ùîº[w1‚à£Œ±]=ùîº[œÅ‚à£Œ±]=11+Œ±. \\mathbb{E}[w_1 \\mid \\alpha] = \\mathbb{E}[\\rho \\mid \\alpha] = \\frac{1}{1+\\alpha}. identity coincidental‚Äîquantities measure ‚Äúconcentration‚Äù random measure GG. Proposition 3 (Conditional variance œÅ\\rho). ùîº[œÅ2‚à£Œ±]=Œ±+6(Œ±+1)(Œ±+2)(Œ±+3), \\mathbb{E}[\\rho^2 \\mid \\alpha] = \\frac{\\alpha + 6}{(\\alpha+1)(\\alpha+2)(\\alpha+3)}, Var(œÅ‚à£Œ±)=2Œ±(Œ±+1)2(Œ±+2)(Œ±+3). \\text{Var}(\\rho \\mid \\alpha) = \\frac{2\\alpha}{(\\alpha+1)^2(\\alpha+2)(\\alpha+3)}. Proof. Using distributional recursion œÅ=dv2+(1‚àív)2œÅ‚Ä≤\\rho \\stackrel{d}{=} v^2 + (1-v)^2 \\rho' v‚àºBeta(1,Œ±)v \\sim \\text{Beta}(1, \\alpha) œÅ‚Ä≤\\rho' independent copy œÅ\\rho. Squaring taking expectations yields result. See Appendix associated research notes full derivation. ‚ñ´\\square Conditional mean variance œÅ functions Œ±.","code":"alpha_grid <- seq(0.1, 20, length.out = 200)  rho_cond_df <- data.frame(   alpha = alpha_grid,   mean = mean_rho_given_alpha(alpha_grid),   var = var_rho_given_alpha(alpha_grid),   sd = sqrt(var_rho_given_alpha(alpha_grid)) )  p1 <- ggplot(rho_cond_df, aes(x = alpha, y = mean)) +   geom_line(color = \"#E41A1C\", linewidth = 1) +   geom_ribbon(aes(ymin = pmax(0, mean - 2*sd), ymax = pmin(1, mean + 2*sd)),                alpha = 0.2, fill = \"#E41A1C\") +   labs(x = expression(alpha), y = expression(rho),        title = expression(E*\"[\"*rho*\" | \"*alpha*\"]\" * \" ¬± 2 SD\")) +   coord_cartesian(ylim = c(0, 1)) +   theme_minimal()  p2 <- ggplot(rho_cond_df, aes(x = alpha, y = var)) +   geom_line(color = \"#377EB8\", linewidth = 1) +   labs(x = expression(alpha), y = \"Variance\",        title = expression(\"Var(\"*rho*\" | \"*alpha*\")\")) +   theme_minimal()  gridExtra::grid.arrange(p1, p2, ncol = 2)"},{"path":[]},{"path":"https://joonho112.github.io/DPprior/articles/theory-weights.html","id":"definition-and-analytical-expression","dir":"Articles","previous_headings":"4. The IcI_c Functional: Closed-Form Moments","what":"4.1 Definition and Analytical Expression","title":"Weight Distributions: w‚ÇÅ, œÅ, and the Dual-Anchor Framework","text":"Computing unconditional moments w1w_1 œÅ\\rho Gamma hyperprior requires evaluating expectations form ùîº[1/(Œ±+c)]\\mathbb{E}[1/(\\alpha + c)]. Definition 2 (IcI_c functional). Ic(,b):=ùîº[1Œ±+c],Œ±‚àºGamma(,b) c>0. I_c(, b) := \\mathbb{E}\\left[\\frac{1}{\\alpha + c}\\right], \\quad  \\text{} \\alpha \\sim \\text{Gamma}(, b) \\text{ } c > 0. Lemma 1 (Closed-form expression IcI_c; work). Ic(,b)=baca‚àí1ebcŒì(1‚àí,bc), I_c(, b) = b^\\, c^{-1} \\, e^{bc} \\, \\Gamma(1-, bc),  Œì(s,x)=‚à´x‚àûts‚àí1e‚àítdt\\Gamma(s, x) = \\int_x^\\infty t^{s-1} e^{-t} \\, dt upper incomplete gamma function. Proof. : Ic(,b)=baŒì()‚à´0‚àûŒ±a‚àí1e‚àíbŒ±Œ±+cdŒ±. I_c(, b) = \\frac{b^}{\\Gamma()} \\int_0^\\infty \\frac{\\alpha^{-1} e^{-b\\alpha}}{\\alpha + c} \\, d\\alpha. Using integral identity: ‚à´0‚àûxa‚àí1e‚àíbxx+cdx=ca‚àí1ebcŒì()Œì(1‚àí,bc), \\int_0^\\infty \\frac{x^{-1} e^{-bx}}{x + c} \\, dx = c^{-1} e^{bc} \\Gamma() \\Gamma(1-, bc),  multiplying ba/Œì()b^/ \\Gamma(), obtain result. ‚ñ´\\square Remark 1 (Numerical evaluation). >1a > 1, upper incomplete gamma function Œì(1‚àí,bc)\\Gamma(1-, bc) defined via analytic continuation. Standard numerical libraries handle automatically (e.g., pgamma R appropriate transformations, scipy.special.gammaincc Python). practical purposes DPprior package, use Gauss-Laguerre quadrature avoids analytic continuation subtleties.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/theory-weights.html","id":"key-identities","dir":"Articles","previous_headings":"4. The IcI_c Functional: Closed-Form Moments","what":"4.2 Key Identities","title":"Weight Distributions: w‚ÇÅ, œÅ, and the Dual-Anchor Framework","text":"Theorem 2 (Unconditional moments via IcI_c; work). Let Œ±‚àºGamma(,b)\\alpha \\sim \\text{Gamma}(, b). : Mean w1w_1: ùîº[w1‚à£,b]=ùîº[11+Œ±]=I1(,b). \\mathbb{E}[w_1 \\mid , b] = \\mathbb{E}\\left[\\frac{1}{1+\\alpha}\\right] = I_1(, b). Mean œÅ\\rho (co-clustering probability): ùîº[œÅ‚à£,b]=ùîº[11+Œ±]=I1(,b). \\mathbb{E}[\\rho \\mid , b] = \\mathbb{E}\\left[\\frac{1}{1+\\alpha}\\right] = I_1(, b). Corollary 2 (Moment identity). unconditional means equal: ùîº[w1‚à£,b]=ùîº[œÅ‚à£,b]=I1(,b). \\mathbb{E}[w_1 \\mid , b] = \\mathbb{E}[\\rho \\mid , b] = I_1(, b). identity important implications elicitation: practitioner specifies target mean w1w_1 œÅ\\rho, two anchors informationally equivalent. make œÅ\\rho add genuine extra constraint, one must elicit uncertainty (e.g., interval) match variance.","code":"# Verify the key identity: E[w1] = E[rho] test_cases <- list(   c(a = 1.0, b = 1.0),   c(a = 1.6, b = 1.22),   c(a = 2.0, b = 0.5),   c(a = 0.5, b = 2.0) )  cat(\"Verification: E[w‚ÇÅ] = E[œÅ] identity\\n\") #> Verification: E[w‚ÇÅ] = E[œÅ] identity cat(sprintf(\"%10s %10s %12s %12s %12s\\n\", \"a\", \"b\", \"E[w‚ÇÅ]\", \"E[œÅ]\", \"Difference\")) #>          a          b      E[w‚ÇÅ]        E[œÅ]   Difference cat(strrep(\"-\", 60), \"\\n\") #> ------------------------------------------------------------  for (params in test_cases) {   a <- params[\"a\"]   b <- params[\"b\"]   E_w1 <- mean_w1(a, b)   E_rho <- mean_rho(a, b)   diff <- abs(E_w1 - E_rho)   cat(sprintf(\"%10.2f %10.2f %12.6f %12.6f %12.2e\\n\", a, b, E_w1, E_rho, diff)) } #>       1.00       1.00     0.596347     0.596347     0.00e+00 #>       1.60       1.22     0.508368     0.508368     0.00e+00 #>       2.00       0.50     0.269272     0.269272     0.00e+00 #>       0.50       2.00     0.842738     0.842738     0.00e+00"},{"path":"https://joonho112.github.io/DPprior/articles/theory-weights.html","id":"second-moments-and-variance-of-rho","dir":"Articles","previous_headings":"4. The IcI_c Functional: Closed-Form Moments","what":"4.3 Second Moments and Variance of œÅ\\rho","title":"Weight Distributions: w‚ÇÅ, œÅ, and the Dual-Anchor Framework","text":"Proposition 4 (Unconditional second moment œÅ\\rho; work). Using partial fraction decomposition: Œ±+6(Œ±+1)(Œ±+2)(Œ±+3)=52(Œ±+1)‚àí4Œ±+2+32(Œ±+3), \\frac{\\alpha + 6}{(\\alpha+1)(\\alpha+2)(\\alpha+3)} = \\frac{5}{2(\\alpha+1)} - \\frac{4}{\\alpha+2} + \\frac{3}{2(\\alpha+3)}, obtain: ùîº[œÅ2‚à£,b]=52I1(,b)‚àí4I2(,b)+32I3(,b). \\mathbb{E}[\\rho^2 \\mid , b] = \\frac{5}{2} I_1(, b) - 4 I_2(, b) + \\frac{3}{2} I_3(, b). Hence unconditional variance: Var(œÅ‚à£,b)=ùîº[œÅ2‚à£,b]‚àí{ùîº[œÅ‚à£,b]}2. \\text{Var}(\\rho \\mid , b) = \\mathbb{E}[\\rho^2 \\mid , b] - \\{\\mathbb{E}[\\rho \\mid , b]\\}^2. Key design implication. distribution œÅ‚à£,b\\rho \\mid , b closed-form, mean variance closed-form (‚Äúmoment-closed‚Äù). sufficient moment-based calibration diagnostics.","code":"# Compute unconditional rho moments for the Lee et al. prior a <- 1.6 b <- 1.22  cat(\"Co-clustering probability under Gamma(1.6, 1.22) hyperprior:\\n\") #> Co-clustering probability under Gamma(1.6, 1.22) hyperprior: cat(sprintf(\"  E[œÅ]   = %.4f\\n\", mean_rho(a, b))) #>   E[œÅ]   = 0.5084 cat(sprintf(\"  Var(œÅ) = %.4f\\n\", var_rho(a, b))) #>   Var(œÅ) = 0.0710 cat(sprintf(\"  SD(œÅ)  = %.4f\\n\", sqrt(var_rho(a, b)))) #>   SD(œÅ)  = 0.2664 cat(sprintf(\"  CV(œÅ)  = %.4f\\n\", cv_rho(a, b))) #>   CV(œÅ)  = 0.5240"},{"path":[]},{"path":"https://joonho112.github.io/DPprior/articles/theory-weights.html","id":"motivation-why-k-only-calibration-is-insufficient","dir":"Articles","previous_headings":"5. The Dual-Anchor Optimization Framework","what":"5.1 Motivation: Why K-Only Calibration is Insufficient","title":"Weight Distributions: w‚ÇÅ, œÅ, and the Dual-Anchor Framework","text":"demonstrated Vicentini Jermyn (2025, Section 5), priors calibrated match target number clusters KJK_J can induce materially informative priors stick-breaking weights. observe ‚ÄúKnK_n-diffuse, DORO, quasi-degenerate Jeffreys‚Äô priors‚Ä¶ markedly different behaviour SSI‚Äù (p.¬†18). mechanism structural: KJK_J weight distribution controlled different functionals Œ±\\alpha. fixed JJ: ùîº[KJ‚à£Œ±]‚âà1+Œ±logJ(Antoniak, 1974), \\mathbb{E}[K_J \\mid \\alpha] \\approx 1 + \\alpha \\log J \\quad \\text{(Antoniak, 1974)},  : ùîº[w1‚à£Œ±]=11+Œ±. \\mathbb{E}[w_1 \\mid \\alpha] = \\frac{1}{1 + \\alpha}. Matching location KJK_J pins Œ±\\alpha around Œ±‚âà(ùîº[KJ]‚àí1)/logJ\\alpha \\approx (\\mathbb{E}[K_J] - 1)/\\log J, implied Œ±\\alpha can correspond high dominance risk w1w_1. K-calibrated prior (blue) achieves target E[K] implies higher dominance risk practitioners might expect.","code":"# Demonstrate the unintended prior problem J <- 50 mu_K_target <- 5  # Fit using K-only calibration fit_K <- DPprior_fit(J = J, mu_K = mu_K_target, confidence = \"medium\") #> Warning: HIGH DOMINANCE RISK: P(w1 > 0.5) = 49.7% exceeds 40%. #>   This may indicate unintended prior behavior (Lee, 2026). #>   Consider using DPprior_dual() for weight-constrained elicitation. #>   See ?DPprior_diagnostics for interpretation.  # What does this imply for weights? cat(\"K-only calibration (J=50, Œº_K=5):\\n\") #> K-only calibration (J=50, Œº_K=5): cat(sprintf(\"  Gamma hyperprior: a = %.3f, b = %.3f\\n\", fit_K$a, fit_K$b)) #>   Gamma hyperprior: a = 1.408, b = 1.077 cat(sprintf(\"  Achieved E[K] = %.2f\\n\",              exact_K_moments(J, fit_K$a, fit_K$b)$mean)) #>   Achieved E[K] = 5.00 cat(\"\\nImplied weight behavior:\\n\") #>  #> Implied weight behavior: cat(sprintf(\"  E[w‚ÇÅ] = %.3f\\n\", mean_w1(fit_K$a, fit_K$b))) #>   E[w‚ÇÅ] = 0.518 cat(sprintf(\"  P(w‚ÇÅ > 0.5) = %.3f\\n\", prob_w1_exceeds(0.5, fit_K$a, fit_K$b))) #>   P(w‚ÇÅ > 0.5) = 0.497 cat(sprintf(\"  P(w‚ÇÅ > 0.9) = %.3f\\n\", prob_w1_exceeds(0.9, fit_K$a, fit_K$b))) #>   P(w‚ÇÅ > 0.9) = 0.200  # Visualize the implied w1 distribution x_grid <- seq(0.01, 0.99, length.out = 200)  implied_df <- data.frame(   x = x_grid,   density = density_w1_manual(x_grid, fit_K$a, fit_K$b),   type = \"K-only calibration\" )  ggplot(implied_df, aes(x = x, y = density)) +   geom_line(color = \"#377EB8\", linewidth = 1.2) +   geom_vline(xintercept = 0.5, linetype = \"dashed\", color = \"#E41A1C\", alpha = 0.7) +   annotate(\"text\", x = 0.52, y = max(implied_df$density) * 0.8,             label = \"50% threshold\", color = \"#E41A1C\", hjust = 0) +   labs(     x = expression(w[1]),     y = \"Density\",     title = expression(\"Implied Distribution of \" * w[1] * \" Under K-Only Calibration\"),     subtitle = sprintf(\"J = %d, target E[K] = %d; P(w‚ÇÅ > 0.5) = %.2f\",                         J, mu_K_target, prob_w1_exceeds(0.5, fit_K$a, fit_K$b))   ) +   theme_minimal()"},{"path":"https://joonho112.github.io/DPprior/articles/theory-weights.html","id":"the-dual-anchor-objective","dir":"Articles","previous_headings":"5. The Dual-Anchor Optimization Framework","what":"5.2 The Dual-Anchor Objective","title":"Weight Distributions: w‚ÇÅ, œÅ, and the Dual-Anchor Framework","text":"Definition 3 (Dual-anchor optimization; work). Given elicited targets p*(KJ)p^*(K_J) (summary statistics thereof) p*(T)p^*(T) T‚àà{w1,œÅ}T \\\\{w_1, \\rho\\}, dual-anchor hyperparameters : (*,b*)=argmina>0,b>0‚ÑíŒª(,b), (^*, b^*) = \\arg\\min_{> 0, b > 0} \\mathcal{L}_\\lambda(, b), : ‚ÑíŒª(,b)=Œª‚ãÖD{p*(KJ)‚à•pa,b(KJ)}+(1‚àíŒª)‚ãÖD{p*(T)‚à•pa,b(T)}, \\mathcal{L}_\\lambda(, b) = \\lambda \\cdot D\\{p^*(K_J) \\| p_{,b}(K_J)\\} +  (1 - \\lambda) \\cdot D\\{p^*(T) \\| p_{,b}(T)\\}, Œª‚àà[0,1]\\lambda \\[0, 1] controls trade-two anchors. Boundary cases:","code":""},{"path":"https://joonho112.github.io/DPprior/articles/theory-weights.html","id":"implementation-variants","dir":"Articles","previous_headings":"5. The Dual-Anchor Optimization Framework","what":"5.3 Implementation Variants","title":"Weight Distributions: w‚ÇÅ, œÅ, and the Dual-Anchor Framework","text":"dual-anchor objective can implemented using different loss functions: Moment-based loss (recommended stability): ‚Ñí(,b)=Œª[(ùîº[KJ]‚àíŒºK*)2+œâK(Var(KJ)‚àíœÉK2*)2]+(1‚àíŒª)[(ùîº[T]‚àíŒºT*)2+œâT(Var(T)‚àíœÉT2*)2], \\mathcal{L}(, b) = \\lambda \\left[(\\mathbb{E}[K_J] - \\mu_K^*)^2 +  \\omega_K (\\text{Var}(K_J) - \\sigma_K^{2*})^2\\right] +  (1 - \\lambda) \\left[(\\mathbb{E}[T] - \\mu_T^*)^2 +  \\omega_T (\\text{Var}(T) - \\sigma_T^{2*})^2\\right],  œâK,œâT‚â•0\\omega_K, \\omega_T \\geq 0 tuning weights. Quantile-based loss w1w_1: T=w1T = w_1, one can directly target specific quantiles using closed-form Qw1Q_{w_1}: ‚Ñí(,b)=Œª‚ãÖLK(,b)+(1‚àíŒª)‚àë[Qw1(ui‚à£,b)‚àíqi*]2, \\mathcal{L}(, b) = \\lambda \\cdot L_K(, b) +  (1 - \\lambda) \\sum_{} \\left[Q_{w_1}(u_i \\mid , b) - q_i^*\\right]^2,  (ui,qi*)(u_i, q_i^*) elicited quantile pairs. Probability constraint w1w_1: Target specific dominance risk: ‚Ñí(,b)=Œª‚ãÖLK(,b)+(1‚àíŒª)[P(w1>t‚à£,b)‚àípt*]2. \\mathcal{L}(, b) = \\lambda \\cdot L_K(, b) +  (1 - \\lambda) \\left[P(w_1 > t \\mid , b) - p_t^*\\right]^2.","code":"# Demonstrate dual-anchor calibration fit_dual <- DPprior_dual(   fit = fit_K,   w1_target = list(prob = list(threshold = 0.5, value = 0.25)),   lambda = 0.7,   loss_type = \"adaptive\",   verbose = FALSE )  cat(\"Dual-anchor calibration (target: P(w‚ÇÅ > 0.5) = 0.25):\\n\") #> Dual-anchor calibration (target: P(w‚ÇÅ > 0.5) = 0.25): cat(sprintf(\"  Gamma hyperprior: a = %.3f, b = %.3f\\n\", fit_dual$a, fit_dual$b)) #>   Gamma hyperprior: a = 3.078, b = 1.669 cat(sprintf(\"  Achieved E[K] = %.2f (target: %.1f)\\n\",              exact_K_moments(J, fit_dual$a, fit_dual$b)$mean, mu_K_target)) #>   Achieved E[K] = 6.43 (target: 5.0) cat(sprintf(\"  P(w‚ÇÅ > 0.5) = %.3f (target: 0.25)\\n\",              prob_w1_exceeds(0.5, fit_dual$a, fit_dual$b))) #>   P(w‚ÇÅ > 0.5) = 0.343 (target: 0.25)"},{"path":"https://joonho112.github.io/DPprior/articles/theory-weights.html","id":"the-trade-off-curve","dir":"Articles","previous_headings":"5. The Dual-Anchor Optimization Framework","what":"5.4 The Trade-off Curve","title":"Weight Distributions: w‚ÇÅ, œÅ, and the Dual-Anchor Framework","text":"Trade-K-fit weight control Œª varies 1 (K-) 0.3 (weight-priority).","code":"# Compute trade-off curve lambda_grid <- c(1.0, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3) w1_target <- list(prob = list(threshold = 0.5, value = 0.2))  tradeoff_results <- lapply(lambda_grid, function(lam) {   if (lam == 1.0) {     fit <- fit_K     fit$dual_anchor <- list(lambda = 1.0)   } else {     fit <- DPprior_dual(fit_K, w1_target, lambda = lam,                          loss_type = \"adaptive\", verbose = FALSE)   }      list(     lambda = lam,     a = fit$a,     b = fit$b,     E_K = exact_K_moments(J, fit$a, fit$b)$mean,     P_w1_gt_50 = prob_w1_exceeds(0.5, fit$a, fit$b),     E_w1 = mean_w1(fit$a, fit$b)   ) })  tradeoff_df <- data.frame(   lambda = sapply(tradeoff_results, `[[`, \"lambda\"),   E_K = sapply(tradeoff_results, `[[`, \"E_K\"),   P_w1 = sapply(tradeoff_results, `[[`, \"P_w1_gt_50\"),   E_w1 = sapply(tradeoff_results, `[[`, \"E_w1\") )  ggplot(tradeoff_df, aes(x = E_K, y = P_w1)) +   geom_path(color = \"gray50\", linewidth = 0.8) +   geom_point(aes(color = factor(lambda)), size = 4) +   geom_hline(yintercept = 0.2, linetype = \"dashed\", color = \"#E41A1C\", alpha = 0.7) +   geom_vline(xintercept = 5, linetype = \"dashed\", color = \"#377EB8\", alpha = 0.7) +   annotate(\"text\", x = 4.5, y = 0.22, label = \"w1 target\",             hjust = 1, color = \"#E41A1C\") +   annotate(\"text\", x = 5.1, y = 0.45, label = \"K target\", hjust = 0, color = \"#377EB8\") +   scale_color_viridis_d(option = \"viridis\", begin = 0.2, end = 0.8) +   labs(     x = expression(E*\"[\"*K[J]*\"]\"),     y = expression(P(w[1] > 0.5)),     title = \"Dual-Anchor Trade-off Curve\",     subtitle = \"Varying Œª from 1.0 (K-only) to 0.3 (weight-priority)\",     color = \"Œª\"   ) +   theme_minimal() +   theme(legend.position = \"right\")"},{"path":[]},{"path":"https://joonho112.github.io/DPprior/articles/theory-weights.html","id":"when-are-they-equivalent","dir":"Articles","previous_headings":"6. Relationship Between w1w_1 and œÅ\\rho","what":"6.1 When Are They Equivalent?","title":"Weight Distributions: w‚ÇÅ, œÅ, and the Dual-Anchor Framework","text":"established , ùîº[w1‚à£Œ±]=ùîº[œÅ‚à£Œ±]\\mathbb{E}[w_1 \\mid \\alpha] = \\mathbb{E}[\\rho \\mid \\alpha]. extends unconditional case: ùîº[w1‚à£,b]=ùîº[œÅ‚à£,b]\\mathbb{E}[w_1 \\mid , b] = \\mathbb{E}[\\rho \\mid , b]. Consequence: practitioner elicits mean constraint (e.g., ‚Äúco-clustering probability 0.3‚Äù), using w1w_1 œÅ\\rho second anchor yields identical calibration constraints.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/theory-weights.html","id":"when-are-they-different","dir":"Articles","previous_headings":"6. Relationship Between w1w_1 and œÅ\\rho","what":"6.2 When Are They Different?","title":"Weight Distributions: w‚ÇÅ, œÅ, and the Dual-Anchor Framework","text":"variances differ: Var(w1‚à£Œ±)=Œ±(1+Œ±)2(2+Œ±)‚â†Var(œÅ‚à£Œ±)=2Œ±(Œ±+1)2(Œ±+2)(Œ±+3). \\text{Var}(w_1 \\mid \\alpha) = \\frac{\\alpha}{(1+\\alpha)^2(2+\\alpha)} \\neq  \\text{Var}(\\rho \\mid \\alpha) = \\frac{2\\alpha}{(\\alpha+1)^2(\\alpha+2)(\\alpha+3)}. Comparison conditional variances: Var(w‚ÇÅ|Œ±) vs Var(œÅ|Œ±).","code":"alpha_grid <- seq(0.1, 20, length.out = 200)  var_comparison <- data.frame(   alpha = rep(alpha_grid, 2),   variance = c(     alpha_grid / ((1 + alpha_grid)^2 * (2 + alpha_grid)),  # Var(w1|alpha)     var_rho_given_alpha(alpha_grid)                          # Var(rho|alpha)   ),   quantity = rep(c(\"Var(w‚ÇÅ | Œ±)\", \"Var(œÅ | Œ±)\"), each = length(alpha_grid)) )  ggplot(var_comparison, aes(x = alpha, y = variance, color = quantity)) +   geom_line(linewidth = 1) +   scale_color_manual(values = c(\"#E41A1C\", \"#377EB8\")) +   labs(     x = expression(alpha),     y = \"Conditional Variance\",     title = expression(\"Conditional Variance Comparison: \" * w[1] * \" vs \" * rho),     color = NULL   ) +   theme_minimal() +   theme(legend.position = \"bottom\")"},{"path":"https://joonho112.github.io/DPprior/articles/theory-weights.html","id":"practical-guidance-choosing-between-w_1-and-rho","dir":"Articles","previous_headings":"6. Relationship Between w1w_1 and œÅ\\rho","what":"6.3 Practical Guidance: Choosing Between w1w_1 and œÅ\\rho","title":"Weight Distributions: w‚ÇÅ, œÅ, and the Dual-Anchor Framework","text":"Recommendation: Use w1w_1 quantile/probability constraints; use œÅ\\rho co-clustering interpretation resonates domain experts.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/articles/theory-weights.html","id":"key-functions-in-the-dpprior-package","dir":"Articles","previous_headings":"7. Computational Details","what":"7.1 Key Functions in the DPprior Package","title":"Weight Distributions: w‚ÇÅ, œÅ, and the Dual-Anchor Framework","text":"package provides efficient implementations weight-related computations:","code":""},{"path":"https://joonho112.github.io/DPprior/articles/theory-weights.html","id":"numerical-verification","dir":"Articles","previous_headings":"7. Computational Details","what":"7.2 Numerical Verification","title":"Weight Distributions: w‚ÇÅ, œÅ, and the Dual-Anchor Framework","text":"","code":"# Verify implementations against Monte Carlo a <- 1.6 b <- 1.22 n_mc <- 100000  set.seed(42) alpha_samples <- rgamma(n_mc, shape = a, rate = b) w1_samples <- rbeta(n_mc, 1, alpha_samples)  cat(\"Verification against Monte Carlo (n =\", format(n_mc, big.mark = \",\"), \"):\\n\\n\") #> Verification against Monte Carlo (n = 1e+05 ):  cat(\"w‚ÇÅ moments:\\n\") #> w‚ÇÅ moments: cat(sprintf(\"  E[w‚ÇÅ]: Analytic = %.4f, MC = %.4f\\n\",              mean_w1(a, b), mean(w1_samples))) #>   E[w‚ÇÅ]: Analytic = 0.5084, MC = 0.5088 cat(sprintf(\"  Var(w‚ÇÅ): Analytic = %.4f, MC = %.4f\\n\",              var_w1(a, b), var(w1_samples))) #>   Var(w‚ÇÅ): Analytic = 0.1052, MC = 0.1054  cat(\"\\nw‚ÇÅ tail probabilities:\\n\") #>  #> w‚ÇÅ tail probabilities: for (t in c(0.3, 0.5, 0.9)) {   mc_prob <- mean(w1_samples > t)   analytic_prob <- prob_w1_exceeds(t, a, b)   cat(sprintf(\"  P(w‚ÇÅ > %.1f): Analytic = %.4f, MC = %.4f\\n\",                t, analytic_prob, mc_prob)) } #>   P(w‚ÇÅ > 0.3): Analytic = 0.6634, MC = 0.6627 #>   P(w‚ÇÅ > 0.5): Analytic = 0.4868, MC = 0.4876 #>   P(w‚ÇÅ > 0.9): Analytic = 0.1833, MC = 0.1858  cat(\"\\nœÅ moments (via quadrature vs MC simulation):\\n\") #>  #> œÅ moments (via quadrature vs MC simulation): rho_samples <- sapply(alpha_samples, function(alph) {   v <- rbeta(100, 1, alph)   w <- cumprod(c(1, 1 - v[-length(v)])) * v   sum(w^2) }) cat(sprintf(\"  E[œÅ]: Analytic = %.4f, MC = %.4f\\n\",              mean_rho(a, b), mean(rho_samples))) #>   E[œÅ]: Analytic = 0.5084, MC = 0.5081"},{"path":"https://joonho112.github.io/DPprior/articles/theory-weights.html","id":"summary","dir":"Articles","previous_headings":"","what":"8. Summary","title":"Weight Distributions: w‚ÇÅ, œÅ, and the Dual-Anchor Framework","text":"vignette provided rigorous treatment weight distribution theory underlying DPprior package: Stick-breaking weights (w1,w2,‚Ä¶)(w_1, w_2, \\ldots) follow GEM(Œ±\\alpha) distribution size-biased (decreasing) order. w1‚à£Œ±‚àºBeta(1,Œ±)w_1 \\mid \\alpha \\sim \\text{Beta}(1, \\alpha), Œ±‚àºGamma(,b)\\alpha \\sim \\text{Gamma}(, b), marginal distribution w1w_1 fully closed-form CDF, quantiles, tail probabilities. co-clustering probability œÅ=‚àëhwh2\\rho = \\sum_h w_h^2 conditional mean w1w_1: ùîº[œÅ‚à£Œ±]=1/(1+Œ±)\\mathbb{E}[\\rho \\mid \\alpha] = 1/(1+\\alpha). IcI_c functional enables closed-form computation ùîº[1/(Œ±+c)]\\mathbb{E}[1/(\\alpha + c)], underlies moment formulas w1w_1 œÅ\\rho. K-calibration can induce unintended weight behavior. dual-anchor framework provides explicit control cluster counts weight concentration via trade-parameter Œª\\lambda.","code":""},{"path":"https://joonho112.github.io/DPprior/articles/theory-weights.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Weight Distributions: w‚ÇÅ, œÅ, and the Dual-Anchor Framework","text":"Antoniak, C. E. (1974). Mixtures Dirichlet processes applications Bayesian nonparametric problems. Annals Statistics, 2(6), 1152-1174. Arratia, R., Barbour, . D., & Tavar√©, S. (2003). Logarithmic Combinatorial Structures: Probabilistic Approach. European Mathematical Society. Connor, R. J., & Mosimann, J. E. (1969). Concepts independence proportions generalization Dirichlet distribution. Journal American Statistical Association, 64(325), 194-206. Dorazio, R. M. (2009). selecting prior precision parameter Dirichlet process mixture models. Journal Statistical Planning Inference, 139(10), 3384-3390. Escobar, M. D., & West, M. (1995). Bayesian density estimation inference using mixtures. Journal American Statistical Association, 90(430), 577-588. Kingman, J. F. C. (1975). Random discrete distributions. Journal Royal Statistical Society: Series B, 37(1), 1-22. Lee, J., Che, J., Rabe-Hesketh, S., Feller, ., & Miratrix, L. (2025). Improving estimation site-specific effects distribution multisite trials. Journal Educational Behavioral Statistics, 50(5), 731-764. Murugiah, S., & Sweeting, T. J. (2012). Selecting precision parameter prior Dirichlet process mixture models. Journal Statistical Planning Inference, 142(7), 1947-1959. Pitman, J. (1996). Random discrete distributions invariant size-biased permutation. Advances Applied Probability, 28(2), 525-539. Sethuraman, J. (1994). constructive definition Dirichlet priors. Statistica Sinica, 4(2), 639-650. Vicentini, S., & Jermyn, . H. (2025). Prior selection precision parameter Dirichlet process mixture models. arXiv:2502.00864. Zito, ., Rigon, T., & Dunson, D. B. (2024). Bayesian nonparametric modeling latent partitions via Stirling-gamma priors. Bayesian Analysis. https://doi.org/10.1214/24-BA1463","code":""},{"path":[]},{"path":[]},{"path":[]},{"path":"https://joonho112.github.io/DPprior/articles/theory-weights.html","id":"a-3-the-i_c-functional","dir":"Articles","previous_headings":"Appendix: Key Formulas Reference","what":"A.3 The IcI_c Functional","title":"Weight Distributions: w‚ÇÅ, œÅ, and the Dual-Anchor Framework","text":"Ic(,b)=ùîº[1Œ±+c]=baca‚àí1ebcŒì(1‚àí,bc) I_c(, b) = \\mathbb{E}\\left[\\frac{1}{\\alpha + c}\\right] = b^c^{-1} e^{bc} \\Gamma(1-, bc) questions vignette DPprior package, please visit GitHub repository.","code":""},{"path":"https://joonho112.github.io/DPprior/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"JoonHo Lee. Author, maintainer.","code":""},{"path":"https://joonho112.github.io/DPprior/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Lee J (2026). DPprior: Principled Prior Elicitation Dirichlet Process Mixture Models. R package version 1.0.0, https://joonho112.github.io/DPprior/.","code":"@Manual{,   title = {DPprior: Principled Prior Elicitation for Dirichlet Process Mixture Models},   author = {JoonHo Lee},   year = {2026},   note = {R package version 1.0.0},   url = {https://joonho112.github.io/DPprior/}, }"},{"path":"https://joonho112.github.io/DPprior/index.html","id":"dpprior-","dir":"","previous_headings":"","what":"DPprior: Prior Elicitation for DP Models","title":"DPprior: Prior Elicitation for DP Models","text":"Principled Prior Elicitation Dirichlet Process Mixture Models DPprior package provides tools eliciting Gamma hyperpriors concentration parameter Œ± Dirichlet Process (DP) mixture models. Rather requiring researchers reason abstract parameter Œ±, DPprior allows specification intuitive quantities: Expected cluster counts: ‚Äúmany distinct groups anticipate?‚Äù Weight concentration: ‚Äúevenly distributed expect observations across clusters?‚Äù natural questions translated principled Gamma(, b) hyperpriors using computationally efficient algorithms backed exact moment matching.","code":""},{"path":"https://joonho112.github.io/DPprior/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"DPprior: Prior Elicitation for DP Models","text":"","code":"# Install from CRAN (when available) install.packages(\"DPprior\")  # Or install the development version from GitHub # install.packages(\"devtools\") devtools::install_github(\"joonho112/DPprior\")"},{"path":"https://joonho112.github.io/DPprior/index.html","id":"quick-start","dir":"","previous_headings":"","what":"Quick Start","title":"DPprior: Prior Elicitation for DP Models","text":"","code":"library(DPprior)  # Scenario: 50-site multisite trial, expecting ~5 distinct effect patterns fit <- DPprior_fit(   J = 50,                # Number of sites    mu_K = 5,              # Expected clusters   confidence = \"medium\"  # Moderate uncertainty )  # View the elicited prior print(fit) #> DPprior Elicitation Results #> ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> Prior: Œ± ~ Gamma(1.892, 1.201) #> Target: E[K] = 5.00, Var(K) = 12.50 #> Achieved: E[K] = 5.00, Var(K) = 12.50 #> Method: A2-MN (converged in 3 iterations)  # Visualize the prior plot(fit)"},{"path":[]},{"path":"https://joonho112.github.io/DPprior/index.html","id":"id_1-intuitive-elicitation","dir":"","previous_headings":"Key Features","what":"1. Intuitive Elicitation","title":"DPprior: Prior Elicitation for DP Models","text":"Specify priors expected cluster counts uncertainty levels:","code":"# Using confidence levels (recommended for most users) fit <- DPprior_fit(J = 50, mu_K = 5, confidence = \"medium\")  # Or specify variance directly fit <- DPprior_fit(J = 50, mu_K = 5, var_K = 10)"},{"path":"https://joonho112.github.io/DPprior/index.html","id":"id_2-dual-anchor-control","dir":"","previous_headings":"Key Features","what":"2. Dual-Anchor Control","title":"DPprior: Prior Elicitation for DP Models","text":"Go beyond cluster counts control weight behavior, addressing ‚Äúunintended prior‚Äù problem (Vicentini & Jermyn, 2025):","code":"# First, fit K-based prior fit_K <- DPprior_fit(J = 50, mu_K = 5, var_K = 8)  # Check if largest cluster might dominate prob_w1_exceeds(0.5, fit_K$a, fit_K$b) #> [1] 0.52  # 52% chance one cluster has >50% of observations  # Apply dual-anchor constraint w1_target <- list(prob = list(threshold = 0.5, value = 0.30)) fit_dual <- DPprior_dual(fit_K, w1_target, lambda = 0.5)  # Verify improvement prob_w1_exceeds(0.5, fit_dual$a, fit_dual$b) #> [1] 0.31  # Now only 31%"},{"path":"https://joonho112.github.io/DPprior/index.html","id":"id_3-comprehensive-diagnostics","dir":"","previous_headings":"Key Features","what":"3. Comprehensive Diagnostics","title":"DPprior: Prior Elicitation for DP Models","text":"Verify prior behaves intended across relevant dimensions: - K distribution (cluster counts) - w‚ÇÅ distribution (largest cluster weight) - œÅ distribution (co-clustering probability) - Œ± distribution (concentration parameter)","code":"fit <- DPprior_fit(J = 50, mu_K = 5, check_diagnostics = TRUE) plot(fit)  # Four-panel diagnostic dashboard summary(fit)  # Detailed numerical diagnostics"},{"path":"https://joonho112.github.io/DPprior/index.html","id":"id_4-fast-computation","dir":"","previous_headings":"Key Features","what":"4. Fast Computation","title":"DPprior: Prior Elicitation for DP Models","text":"package implements Design-Conditional Elicitation (DCE) methodology via Two-Stage Moment Matching (TSMM): A1 (Closed-form): Instant initial estimates using Negative Binomial approximation A2 (Newton refinement): Exact moment matching 2-4 iterations","code":"# A1 only (fastest, approximate) fit_fast <- DPprior_fit(J = 50, mu_K = 5, var_K = 10, method = \"A1\")  # A2 with Newton refinement (default, exact) fit_exact <- DPprior_fit(J = 50, mu_K = 5, var_K = 10, method = \"A2-MN\")"},{"path":"https://joonho112.github.io/DPprior/index.html","id":"when-to-use-dpprior","dir":"","previous_headings":"","what":"When to Use DPprior","title":"DPprior: Prior Elicitation for DP Models","text":"DPprior particularly valuable : Multisite randomized trials moderate numbers sites (J = 20‚Äì200) Meta-analysis flexible heterogeneity modeling Bayesian nonparametric density estimation small--moderate samples Low-information settings prior Œ± substantially influences posterior inference (Lee et al., 2025)","code":""},{"path":"https://joonho112.github.io/DPprior/index.html","id":"vignettes","dir":"","previous_headings":"","what":"Vignettes","title":"DPprior: Prior Elicitation for DP Models","text":"package includes comprehensive documentation:","code":""},{"path":[]},{"path":[]},{"path":"https://joonho112.github.io/DPprior/index.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"DPprior: Prior Elicitation for DP Models","text":"use DPprior research, please cite:","code":"@Manual{DPprior2026,   title = {{DPprior}: Principled Prior Elicitation for {Dirichlet} Process Mixture Models},   author = {JoonHo Lee},   year = {2026},   note = {R package version 1.0.0},   url = {https://github.com/joonho112/DPprior}, }  @Article{Lee2025multisite,   title = {Improving the Estimation of Site-Specific Effects and Their Distribution in Multisite Trials},   author = {JoonHo Lee and Jonathan Che and Sophia Rabe-Hesketh and Avi Feller and Luke Miratrix},   journal = {Journal of Educational and Behavioral Statistics},   year = {2025},   volume = {50},   number = {5},   pages = {731--764},   doi = {10.3102/10769986241254286}, }  @Article{Lee2026dce,   title = {Design-Conditional Prior Elicitation for {Dirichlet} Process Mixtures},   author = {JoonHo Lee},   journal = {arXiv preprint},   year = {2026},   eprint = {2602.06301},   archiveprefix = {arXiv},   url = {https://arxiv.org/abs/2602.06301}, }"},{"path":"https://joonho112.github.io/DPprior/index.html","id":"related-work","dir":"","previous_headings":"","what":"Related Work","title":"DPprior: Prior Elicitation for DP Models","text":"package builds methodological foundations : Dorazio (2009): Original approach K-based elicitation Lee et al.¬†(2025): Informative priors via œá¬≤ distribution K Vicentini & Jermyn (2025): Sample-size-independent approaches weight-based elicitation Zito et al.¬†(2024): Stirling-gamma priors negative binomial approximation","code":""},{"path":"https://joonho112.github.io/DPprior/index.html","id":"support","dir":"","previous_headings":"","what":"Support","title":"DPprior: Prior Elicitation for DP Models","text":"project supported Institute Education Sciences, U.S. Department Education, Grant R305D240078 University Alabama. https://ies.ed.gov/use-work/awards/improving-estimation-site-specific-effects---distribution-multisite-trials-practical-tools opinions expressed authors represent views Institute U.S. Department Education.","code":""},{"path":"https://joonho112.github.io/DPprior/index.html","id":"references","dir":"","previous_headings":"Support","what":"References","title":"DPprior: Prior Elicitation for DP Models","text":"Dorazio, R. M. (2009). selecting prior precision parameter Dirichlet process mixture models. Journal Statistical Planning Inference, 139(10), 3384‚Äì3390. Lee, J., Che, J., Rabe-Hesketh, S., Feller, ., & Miratrix, L. (2025). Improving estimation site-specific effects distribution multisite trials. Journal Educational Behavioral Statistics, 50(5), 731‚Äì764. Vicentini, C., & Jermyn, . H. (2025). Prior selection precision parameter Dirichlet process mixtures. arXiv:2502.00864. Zito, ., Rigon, T., & Dunson, D. B. (2024). Bayesian nonparametric modeling latent partitions via Stirling-gamma priors. arXiv:2306.02360.","code":""},{"path":"https://joonho112.github.io/DPprior/index.html","id":"license","dir":"","previous_headings":"","what":"License","title":"DPprior: Prior Elicitation for DP Models","text":"MIT ¬© JoonHo Lee","code":""},{"path":"https://joonho112.github.io/DPprior/reference/DPprior-package.html","id":null,"dir":"Reference","previous_headings":"","what":"DPprior: Principled Prior Elicitation for Dirichlet Process Mixture Models ‚Äî DPprior-package","title":"DPprior: Principled Prior Elicitation for Dirichlet Process Mixture Models ‚Äî DPprior-package","text":"DPprior package implements Design-Conditional Elicitation (DCE) calibrating concentration parameter prior \\(\\alpha \\sim \\text{Gamma}(, b)\\) Dirichlet Process (DP) mixture models. core engine Two-Stage Moment Matching (TSMM), translates intuitive beliefs expected number clusters \\(E[K_J]\\) variance \\(\\text{Var}(K_J)\\) Gamma hyperprior parameters \\((, b)\\).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/DPprior-package.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"DPprior: Principled Prior Elicitation for Dirichlet Process Mixture Models ‚Äî DPprior-package","text":"package provides three elicitation algorithms: A1 (DPprior_a1) Closed-form method using shifted Negative Binomial approximation. Fast accurate large sample sizes. A2-MN (DPprior_a2_newton) Modified Newton method matches exact marginal moments via Gauss-Laguerre quadrature analytic Jacobians score function identities. A2-KL (DPprior_a2_kl) KL-divergence minimization implied marginal PMF target distribution. Additionally, Dual-Anchor framework (DPprior_dual) enables joint control cluster count \\(K_J\\) largest weight \\(w_1\\) targets. unified interface DPprior_fit dispatches appropriate algorithm based user's specification.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/DPprior-package.html","id":"key-function-groups","dir":"Reference","previous_headings":"","what":"Key Function Groups","title":"DPprior: Principled Prior Elicitation for Dirichlet Process Mixture Models ‚Äî DPprior-package","text":"Elicitation DPprior_fit, DPprior_a1, DPprior_a2_newton, DPprior_a2_kl, DPprior_dual Cluster Distribution pmf_K_given_alpha, pmf_K_marginal, exact_K_moments Weight Distribution mean_w1, prob_w1_exceeds, density_w1, summary_w1 Diagnostics DPprior_diagnostics, DPprior_error_bounds Visualization plot_prior_dashboard, plot_dual_dashboard","code":""},{"path":"https://joonho112.github.io/DPprior/reference/DPprior-package.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"DPprior: Principled Prior Elicitation for Dirichlet Process Mixture Models ‚Äî DPprior-package","text":"Lee, J. (2026). Design-Conditional Prior Elicitation Dirichlet Process Mixtures. arXiv preprint arXiv:2602.06301. Lee, J., Che, J., Rabe-Hesketh, S., Feller, ., Miratrix, L. (2025). Improving estimation site-specific effects distribution multisite trials. Journal Educational Behavioral Statistics, 50(5), 731‚Äì764. doi:10.3102/10769986241254286","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/DPprior-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"DPprior: Principled Prior Elicitation for Dirichlet Process Mixture Models ‚Äî DPprior-package","text":"Maintainer: JoonHo Lee jlee296@ua.edu (ORCID)","code":""},{"path":"https://joonho112.github.io/DPprior/reference/DPprior_a1.html","id":null,"dir":"Reference","previous_headings":"","what":"A1 Closed-Form Prior Elicitation ‚Äî DPprior_a1","title":"A1 Closed-Form Prior Elicitation ‚Äî DPprior_a1","text":"Maps target beliefs number clusters \\((\\mu_K, \\sigma^2_K)\\) Gamma hyperprior parameters \\((, b)\\) using A1 closed-form approximation based Negative Binomial moment matching.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/DPprior_a1.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A1 Closed-Form Prior Elicitation ‚Äî DPprior_a1","text":"","code":"DPprior_a1(   J,   mu_K,   var_K,   scaling = c(\"log\", \"harmonic\", \"digamma\"),   epsilon = .TOL_PROJECTION_BUFFER )"},{"path":"https://joonho112.github.io/DPprior/reference/DPprior_a1.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A1 Closed-Form Prior Elicitation ‚Äî DPprior_a1","text":"J Integer; number items/sites (must >= 2). mu_K Numeric; target prior mean \\(K_J\\) (must > 1 <= J). var_K Numeric; target prior variance \\(K_J\\) (must > 0). scaling Character; scaling constant method: \"log\" (default), \"harmonic\", \"digamma\". epsilon Numeric; buffer feasibility projection. Default .TOL_PROJECTION_BUFFER (1e-6).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/DPprior_a1.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A1 Closed-Form Prior Elicitation ‚Äî DPprior_a1","text":"S3 object class DPprior_fit components: Shape parameter Gamma prior b Rate parameter Gamma prior J Sample size used target List target moments type method \"A1\" indicating closed-form method status \"success\" \"projected\" boundary adjustment needed scaling Scaling method used cJ Scaling constant value var_K_used Actual variance used (may differ projected) converged Always TRUE A1 (A2 compatibility) iterations Always 0L A1 (A2 compatibility) fit NULL (placeholder A2 refinement) diagnostics NULL (placeholder diagnostics) trace NULL (placeholder optimization trace)","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/DPprior_a1.html","id":"theory-tsmm-stage-","dir":"Reference","previous_headings":"","what":"Theory (TSMM Stage 1)","title":"A1 Closed-Form Prior Elicitation ‚Äî DPprior_a1","text":"A1 method uses shifted Negative Binomial approximation: $$K_J - 1 \\mid \\alpha \\approx \\text{Poisson}(\\alpha \\cdot c_J)$$ \\(\\alpha \\sim \\text{Gamma}(, b)\\), marginal becomes: $$K_J - 1 \\approx \\text{NegBin}(, b/(b + c_J))$$","code":""},{"path":"https://joonho112.github.io/DPprior/reference/DPprior_a1.html","id":"inverse-formulas-theorem-","dir":"Reference","previous_headings":"","what":"Inverse Formulas (Theorem 1)","title":"A1 Closed-Form Prior Elicitation ‚Äî DPprior_a1","text":"Let \\(m = \\mu_K - 1\\) (shifted mean) \\(D = \\sigma^2_K - m\\). \\(D > 0\\) (overdispersion): $$= m^2 / D, \\quad b = m \\cdot c_J / D$$ \\(D \\leq 0\\) (infeasible), variance projected boundary.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/DPprior_a1.html","id":"feasibility","dir":"Reference","previous_headings":"","what":"Feasibility","title":"A1 Closed-Form Prior Elicitation ‚Äî DPprior_a1","text":"NegBin model requires overdispersion: \\(\\sigma^2_K > \\mu_K - 1\\). High-confidence specifications (low variance) may violate constraint A1 proxy, even though may feasible exact DP.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/DPprior_a1.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"A1 Closed-Form Prior Elicitation ‚Äî DPprior_a1","text":"Lee, J. (2026). Design-Conditional Prior Elicitation Dirichlet Process Mixtures. arXiv preprint arXiv:2602.06301.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/DPprior_a1.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A1 Closed-Form Prior Elicitation ‚Äî DPprior_a1","text":"","code":"# Basic usage with moment targets fit <- DPprior_a1(J = 50, mu_K = 5, var_K = 8) print(fit) #> DPprior Prior Elicitation Result #> =============================================  #>  #> Gamma Hyperprior: Œ± ~ Gamma(a = 4.0000, b = 3.9120) #>   E[Œ±] = 1.022, SD[Œ±] = 0.511 #>  #> Target (J = 50): #>   E[K_J]   = 5.00 #>   Var(K_J) = 8.00 #>  #> Method: A1 (0 iterations)  # Using VIF specification fit <- DPprior_a1(J = 50, mu_K = 5, var_K = vif_to_variance(5, 2))  # Using confidence-based specification vif <- confidence_to_vif(\"medium\") fit <- DPprior_a1(J = 50, mu_K = 5, var_K = vif_to_variance(5, vif))  # Infeasible variance (triggers projection) fit <- DPprior_a1(J = 50, mu_K = 5, var_K = 3)  # var < mu-1 = 4 #> Warning: var_K <= mu_K - 1: projected to feasible boundary  # Compare scaling methods fit_log <- DPprior_a1(50, 5, 8, scaling = \"log\") fit_harm <- DPprior_a1(50, 5, 8, scaling = \"harmonic\")"},{"path":"https://joonho112.github.io/DPprior/reference/DPprior_a2_kl.html","id":null,"dir":"Reference","previous_headings":"","what":"A2-KL: KL Divergence Minimization for Prior Calibration ‚Äî DPprior_a2_kl","title":"A2-KL: KL Divergence Minimization for Prior Calibration ‚Äî DPprior_a2_kl","text":"Calibrates Gamma hyperprior parameters \\((, b)\\) minimizing Kullback-Leibler divergence target distribution induced marginal PMF number clusters \\(K_J\\).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/DPprior_a2_kl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A2-KL: KL Divergence Minimization for Prior Calibration ‚Äî DPprior_a2_kl","text":"","code":"DPprior_a2_kl(   J,   target,   method = c(\"pmf\", \"chisq\"),   max_iter = 100L,   tol = 1e-06,   M = .QUAD_NODES_DEFAULT,   verbose = FALSE,   ... )"},{"path":"https://joonho112.github.io/DPprior/reference/DPprior_a2_kl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A2-KL: KL Divergence Minimization for Prior Calibration ‚Äî DPprior_a2_kl","text":"J Integer; sample size (number observations). Must >= 2. target Either: Numeric vector length J: target PMF k = 1, ..., J (used method = \"pmf\"). Named list mu_K var_K: construct moments using discretized scaled chi-square (used method = \"chisq\"). method Character; \"pmf\" \"chisq\". Default: \"pmf\". max_iter Integer; maximum optimization iterations. Default: 100. tol Numeric; convergence tolerance optimization. Default: 1e-6. M Integer; number quadrature nodes. Default: 80. verbose Logical; TRUE, print optimization progress. Default: FALSE. ... Optional tuning parameters: log_bounds: numeric length-2 vector giving lower/upper bounds log() log(b) (default c(-15, 15)). eps: numeric; small constant avoid log(0) (default 1e-15).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/DPprior_a2_kl.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A2-KL: KL Divergence Minimization for Prior Calibration ‚Äî DPprior_a2_kl","text":"DPprior_fit object (S3 class) components: Numeric; optimal shape parameter b Numeric; optimal rate parameter J Integer; sample size target List target specification (pmf, mu_K, var_K, type, chisq: df, scale, mu_K_discrete, var_K_discrete) method Character; \"A2-KL\" converged Logical; whether optimization converged iterations Integer; number function evaluations termination Character; termination reason fit List achieved mu_K, var_K, kl, residual diagnostics List initialization info, optim details, fallback status, KL init/final trace Data frame evaluation-level trace (eval, , b, kl) status Character; convergence status","code":""},{"path":"https://joonho112.github.io/DPprior/reference/DPprior_a2_kl.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"A2-KL: KL Divergence Minimization for Prior Calibration ‚Äî DPprior_a2_kl","text":"A2-KL algorithm finds \\((^*, b^*)\\) solving: $$(^*, b^*) = \\arg\\min_{,b} D_{KL}(p^*(K_J) \\| p_{,b}(K_J))$$ Algorithm: Construct target PMF user specification Initialize \\((a_0, b_0)\\) A2-MN (exact moment matching) Optimize KL divergence using L-BFGS-B log-space bounds Apply fallback initialization optimization worsens KL Return optimal parameters comprehensive diagnostics Stability features: Log-parameterization ensures positivity (, b) Explicit bounds prevent numerical overflow/underflow Fallback mechanism optimization diverges worsens objective A2-MN initialization provides good starting point use A2-KL vs A2-MN: A2-MN: Target moments (exact moment matching) A2-KL: Full target distribution shape (multi-modal, skewed, expert-elicited)","code":""},{"path":"https://joonho112.github.io/DPprior/reference/DPprior_a2_kl.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"A2-KL: KL Divergence Minimization for Prior Calibration ‚Äî DPprior_a2_kl","text":"Lee, J. (2026). Design-Conditional Prior Elicitation Dirichlet Process Mixtures. arXiv preprint arXiv:2602.06301.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/DPprior_a2_kl.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A2-KL: KL Divergence Minimization for Prior Calibration ‚Äî DPprior_a2_kl","text":"","code":"# Example 1: Target from moments (method = \"chisq\") fit <- DPprior_a2_kl(J = 50, target = list(mu_K = 5, var_K = 8),                      method = \"chisq\") print(fit) #> DPprior Prior Elicitation Result #> =============================================  #>  #> Gamma Hyperprior: Œ± ~ Gamma(a = 2.2363, b = 1.7627) #>   E[Œ±] = 1.269, SD[Œ±] = 0.848 #>  #> Target (J = 50): #>   E[K_J]   = 5.00 #>   Var(K_J) = 8.00 #>  #> Achieved: #>   E[K_J] = 5.019984, Var(K_J) = 7.640329 #>   Residual = 5.03e-03 #>  #> Method: A2-KL (8 iterations)  # Example 2: Custom target PMF (method = \"pmf\") target_pmf <- dbinom(1:50, size = 50, prob = 0.1) fit2 <- DPprior_a2_kl(J = 50, target = target_pmf, method = \"pmf\")  # Example 3: Compare A2-KL vs A2-MN a2_mn <- DPprior_a2_newton(J = 50, mu_K = 5, var_K = 8) a2_kl <- DPprior_a2_kl(J = 50, target = list(mu_K = 5, var_K = 8),                        method = \"chisq\") cat(sprintf(\"A2-MN: a=%.4f, b=%.4f\\n\", a2_mn$a, a2_mn$b)) #> A2-MN: a=2.0361, b=1.6051 cat(sprintf(\"A2-KL: a=%.4f, b=%.4f, KL=%.4e\\n\", a2_kl$a, a2_kl$b, a2_kl$fit$kl)) #> A2-KL: a=2.2363, b=1.7627, KL=5.0296e-03"},{"path":"https://joonho112.github.io/DPprior/reference/DPprior_a2_newton.html","id":null,"dir":"Reference","previous_headings":"","what":"A2-MN Exact-Moment Newton Solver ‚Äî DPprior_a2_newton","title":"A2-MN Exact-Moment Newton Solver ‚Äî DPprior_a2_newton","text":"Finds Gamma(, b) hyperprior parameters exactly match target moments number clusters K_J Dirichlet process prior.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/DPprior_a2_newton.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A2-MN Exact-Moment Newton Solver ‚Äî DPprior_a2_newton","text":"","code":"DPprior_a2_newton(   J,   mu_K,   var_K,   a0 = NULL,   b0 = NULL,   tol_F = .TOL_NEWTON,   tol_step = 1e-10,   max_iter = 20L,   damping = TRUE,   use_fallback = TRUE,   M = .QUAD_NODES_DEFAULT,   verbose = FALSE )"},{"path":"https://joonho112.github.io/DPprior/reference/DPprior_a2_newton.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A2-MN Exact-Moment Newton Solver ‚Äî DPprior_a2_newton","text":"J Integer; sample size (number observations/sites). Must >= 2. mu_K Numeric; target prior mean \\(E[K_J]\\). Must satisfy \\(1 < \\mu_K < J\\). var_K Numeric; target prior variance \\(\\mathrm{Var}(K_J)\\). Must positive. a0 Numeric NULL; initial shape parameter. NULL, computed via DPprior_a1. b0 Numeric NULL; initial rate parameter. NULL, computed via DPprior_a1. tol_F Numeric; stopping tolerance residual norm ||F|| = sqrt((M1 - mu_K)^2 + (V - var_K)^2). Default: 1e-8. tol_step Numeric; stopping tolerance Newton step size. Default: 1e-10. max_iter Integer; maximum Newton iterations. Default: 20. damping Logical; TRUE, use backtracking line search damped Newton updates. Default: TRUE. use_fallback Logical; TRUE, use Nelder-Mead fallback Newton fails converge. Default: TRUE. M Integer; number quadrature nodes moment computation. Default: 80. verbose Logical; TRUE, print iteration progress. Default: FALSE.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/DPprior_a2_newton.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A2-MN Exact-Moment Newton Solver ‚Äî DPprior_a2_newton","text":"DPprior_fit object (S3 class) components: Numeric; optimal shape parameter b Numeric; optimal rate parameter J Integer; sample size target List mu_K, var_K, type = \"moments\" method Character; \"A2-MN\" \"A2-MN+NM\" fallback used status Character; convergence status (\"success\", \"stagnated\", \"max_iter\") converged Logical; whether algorithm converged target tolerance iterations Integer; number iterations termination Character; reason termination (\"residual\", \"step\", \"max_iter\", \"nelder_mead\") fit List achieved mu_K, var_K, residual diagnostics List diagnostic information trace Data frame iteration history","code":""},{"path":"https://joonho112.github.io/DPprior/reference/DPprior_a2_newton.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"A2-MN Exact-Moment Newton Solver ‚Äî DPprior_a2_newton","text":"implements TSMM Stage 2 (A2-MN) Lee (2026). A2-MN algorithm uses Newton's method log-scale ensure positivity Gamma parameters. Jacobian computed exactly using score function identities (Lee, 2026, Section 3.2, Corollary 1), avoiding finite difference approximations. Algorithm Steps: Initialize: \\((a_0, b_0)\\) A1 closed-form user-provided Log-parameterize: \\(\\eta = (\\log , \\log b)\\) iteration: Compute moments \\((M_1, V)\\) Jacobian \\(J_F\\) Compute residual \\(F = (M_1 - \\mu_K, V - \\sigma^2_K)\\) Transform Jacobian log-scale: \\(J_{\\log} = J_F \\cdot \\text{diag}(, b)\\) Newton step: \\(\\Delta = -J_{\\log}^{-1} F\\) Backtracking line search (damping enabled) Update: \\(\\eta \\leftarrow \\eta + \\lambda \\Delta\\) Return \\((, b) = \\exp(\\eta)\\) Convergence Behavior: typical targets, converges 3-8 iterations targets requiring small \\(\\) (quasi-improper priors), convergence may slower; Nelder-Mead fallback handles cases Machine-precision accuracy (residual < 1e-10) typically achieved Termination Conditions: residual: ||F|| < tol_F (success) step: ||delta|| < tol_step (stagnation - may converged) max_iter: maximum iterations reached nelder_mead: Nelder-Mead fallback succeeded Error Handling: Jacobian becomes singular, falls back gradient descent Newton fails max_iter, uses Nelder-Mead enabled Warns quasi-improper priors (\\(< 0.1\\))","code":""},{"path":"https://joonho112.github.io/DPprior/reference/DPprior_a2_newton.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"A2-MN Exact-Moment Newton Solver ‚Äî DPprior_a2_newton","text":"Lee, J. (2026). Design-Conditional Prior Elicitation Dirichlet Process Mixtures. arXiv preprint arXiv:2602.06301.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/DPprior_a2_newton.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A2-MN Exact-Moment Newton Solver ‚Äî DPprior_a2_newton","text":"","code":"# Basic usage fit <- DPprior_a2_newton(J = 50, mu_K = 5, var_K = 8) print(fit) #> DPprior Prior Elicitation Result #> =============================================  #>  #> Gamma Hyperprior: Œ± ~ Gamma(a = 2.0361, b = 1.6051) #>   E[Œ±] = 1.269, SD[Œ±] = 0.889 #>  #> Target (J = 50): #>   E[K_J]   = 5.00 #>   Var(K_J) = 8.00 #>  #> Achieved: #>   E[K_J] = 5.000000, Var(K_J) = 8.000000 #>   Residual = 7.60e-09 #>  #> Method: A2-MN (6 iterations)  # Verify exact moment matching achieved <- exact_K_moments(50, fit$a, fit$b) cat(sprintf(\"Target E[K]=5, Achieved E[K]=%.10f\\n\", achieved$mean)) #> Target E[K]=5, Achieved E[K]=4.9999999992 cat(sprintf(\"Target Var=8, Achieved Var=%.10f\\n\", achieved$var)) #> Target Var=8, Achieved Var=8.0000000076  # Compare A1 vs A2 accuracy a1 <- DPprior_a1(J = 50, mu_K = 5, var_K = 8) a1_mom <- exact_K_moments(50, a1$a, a1$b) a2_mom <- exact_K_moments(50, fit$a, fit$b) cat(sprintf(\"A1 mean error: %.6f\\n\", abs(a1_mom$mean - 5))) #> A1 mean error: 0.538649 cat(sprintf(\"A2 mean error: %.2e\\n\", abs(a2_mom$mean - 5))) #> A2 mean error: 8.31e-10  # View iteration trace (includes step size and Jacobian determinant) head(fit$trace) #>   iter        a         b       M1         V     residual step   det_Jlog #> 1    1 4.000000 3.9120230 4.461351  4.783136 3.261649e+00    1  -5.300969 #> 2    2 1.178650 0.9119694 4.909046 10.854537 2.855986e+00    1 -21.553612 #> 3    3 1.844384 1.4552538 4.974913  8.399473 4.002603e-01    1 -15.313512 #> 4    4 2.029223 1.5996801 4.999187  8.013243 1.326844e-02    1 -14.298307 #> 5    5 2.036082 1.6050455 4.999999  8.000021 2.078492e-05    1 -14.263052 #> 6    6 2.036093 1.6050541 5.000000  8.000000 7.600363e-09   NA -14.262997"},{"path":"https://joonho112.github.io/DPprior/reference/DPprior_colors.html","id":null,"dir":"Reference","previous_headings":"","what":"DPprior Color Palette ‚Äî DPprior_colors","title":"DPprior Color Palette ‚Äî DPprior_colors","text":"DPprior Color Palette","code":""},{"path":"https://joonho112.github.io/DPprior/reference/DPprior_colors.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"DPprior Color Palette ‚Äî DPprior_colors","text":"","code":"DPprior_colors()"},{"path":"https://joonho112.github.io/DPprior/reference/DPprior_colors.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"DPprior Color Palette ‚Äî DPprior_colors","text":"named list color values.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/DPprior_diagnostics.html","id":null,"dir":"Reference","previous_headings":"","what":"Comprehensive Prior Diagnostics ‚Äî DPprior_diagnostics","title":"Comprehensive Prior Diagnostics ‚Äî DPprior_diagnostics","text":"Computes full diagnostic report fitted DPprior object, implementing \"unintended prior\" checks Lee (2026, Section 4).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/DPprior_diagnostics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Comprehensive Prior Diagnostics ‚Äî DPprior_diagnostics","text":"","code":"DPprior_diagnostics(fit, thresholds = c(0.5, 0.9))"},{"path":"https://joonho112.github.io/DPprior/reference/DPprior_diagnostics.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Comprehensive Prior Diagnostics ‚Äî DPprior_diagnostics","text":"fit DPprior_fit object calibration method (e.g., DPprior_a1, DPprior_a2_newton, DPprior_dual). Must contain fields , b, J. Optionally can contain M quadrature nodes. thresholds Numeric vector; thresholds weight dominance checks (default: c(0.5, 0.9)).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/DPprior_diagnostics.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Comprehensive Prior Diagnostics ‚Äî DPprior_diagnostics","text":"S3 object class \"DPprior_diagnostics\" components: J (sample size), b (Gamma parameters), alpha (alpha distribution summary), K (K distribution summary), weights (w1 distribution summary dominance risk), coclustering (rho summary), warnings (character vector diagnostic warnings).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/DPprior_diagnostics.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Comprehensive Prior Diagnostics ‚Äî DPprior_diagnostics","text":"Warnings issued : P(w1 > 0.5) > 0.4: \"HIGH DOMINANCE RISK\" P(w1 > 0.9) > 0.15: \"NEAR-DEGENERATE RISK\"","code":""},{"path":"https://joonho112.github.io/DPprior/reference/DPprior_diagnostics.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Comprehensive Prior Diagnostics ‚Äî DPprior_diagnostics","text":"Lee, J. (2026). Design-Conditional Prior Elicitation Dirichlet Process Mixtures. arXiv preprint arXiv:2602.06301.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/DPprior_diagnostics.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Comprehensive Prior Diagnostics ‚Äî DPprior_diagnostics","text":"","code":"fit <- DPprior_a2_newton(J = 50, mu_K = 5, var_K = 8) diag <- DPprior_diagnostics(fit) print(diag) #> DPprior Comprehensive Diagnostics #> ============================================================  #>  #> Prior: alpha ~ Gamma(2.0361, 1.6051) for J = 50 #>  #> alpha Distribution: #> ----------------------------------------  #>   E[alpha] = 1.269, CV(alpha) = 0.701, Median = 1.068 #>   90% CI: [0.230, 2.992] #>  #> K_J Distribution: #> ----------------------------------------  #>   E[K] = 5.00, SD(K) = 2.83, Mode = 3 #>   Median = 5, IQR = [3, 7] #>  #> w1 Distribution (Size-Biased First Weight): #> ----------------------------------------  #>   E[w1] = 0.501, Median = 0.478 #>   P(w1 > 0.5) = 48.1% (dominance risk: HIGH) #>   P(w1 > 0.9) = 16.3% #>  #> Co-Clustering (rho = sum w_h^2): #> ----------------------------------------  #>   E[rho] = 0.501 (High prior co-clustering: most unit pairs expected in same cluster) #>  #> WARNINGS: #> ----------------------------------------  #>   * HIGH DOMINANCE RISK: P(w1 > 0.5) = 48.1% exceeds 40% #>   * NEAR-DEGENERATE RISK: P(w1 > 0.9) = 16.3% exceeds 15% #>  #>   Consider using DPprior_dual() for weight-constrained elicitation."},{"path":"https://joonho112.github.io/DPprior/reference/DPprior_dual.html","id":null,"dir":"Reference","previous_headings":"","what":"Dual-Anchor Prior Calibration ‚Äî DPprior_dual","title":"Dual-Anchor Prior Calibration ‚Äî DPprior_dual","text":"Refines K_J-calibrated prior also satisfy weight constraints, implementing dual-anchor framework Lee (2026, Section 4).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/DPprior_dual.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dual-Anchor Prior Calibration ‚Äî DPprior_dual","text":"","code":"DPprior_dual(   fit,   w1_target,   lambda = 0.5,   max_iter = 100L,   verbose = FALSE,   M = .QUAD_NODES_DEFAULT,   loss_type = c(\"relative\", \"adaptive\", \"absolute\") )"},{"path":"https://joonho112.github.io/DPprior/reference/DPprior_dual.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Dual-Anchor Prior Calibration ‚Äî DPprior_dual","text":"fit DPprior_fit object K-based calibration method. w1_target List specifying first-weight target. Options: list(prob = list(threshold = 0.5, value = 0.3)) Constrain \\(P(w_1 > 0.5) = 0.3\\) list(quantile = list(prob = 0.9, value = 0.4)) Constrain 90th percentile \\(w_1\\) = 0.4 list(mean = 0.3) Constrain \\(E[w_1] = 0.3\\) lambda Numeric value 0 1; weight K_J anchor. Default 0.5 (balanced). lambda = 1 recovers K-fit. max_iter Integer; maximum optimization iterations. verbose Logical; TRUE, print progress. M Integer; quadrature nodes. loss_type Character; \"relative\" (default), \"adaptive\", \"absolute\". See dual_anchor_loss details.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/DPprior_dual.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Dual-Anchor Prior Calibration ‚Äî DPprior_dual","text":"S3 object class \"DPprior_fit\".","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/DPprior_dual.html","id":"critical-fix-","dir":"Reference","previous_headings":"","what":"Critical Fix (2025-12-29)","title":"Dual-Anchor Prior Calibration ‚Äî DPprior_dual","text":"original implementation used absolute squared errors L_K, causing severe scale mismatch. optimizer essentially ignore weight constraint. Example improvement lambda = 0.5: ABSOLUTE (broken): 0.5 percent reduction \\(P(w_1 > 0.5)\\) RELATIVE (fixed): 9 percent reduction ADAPTIVE: 18 percent reduction","code":""},{"path":"https://joonho112.github.io/DPprior/reference/DPprior_dual.html","id":"choosing-loss-type","dir":"Reference","previous_headings":"","what":"Choosing loss_type","title":"Dual-Anchor Prior Calibration ‚Äî DPprior_dual","text":"\"relative\": Good default. losses dimensionless. \"adaptive\": aggressive. Use want lambda = 0.5 give significant weight reduction. \"absolute\": Legacy, recommended.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/DPprior_dual.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Dual-Anchor Prior Calibration ‚Äî DPprior_dual","text":"Lee, J. (2026). Design-Conditional Prior Elicitation Dirichlet Process Mixtures. arXiv preprint arXiv:2602.06301.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/DPprior_dual.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Dual-Anchor Prior Calibration ‚Äî DPprior_dual","text":"","code":"# K-only fit fit_K <- DPprior_a2_newton(J = 50, mu_K = 5, var_K = 8) cat(\"K-only P(w_1 > 0.5):\", prob_w1_exceeds(0.5, fit_K$a, fit_K$b), \"\\n\") #> K-only P(w_1 > 0.5): 0.481478   # Dual-anchor with relative loss (default) fit_rel <- DPprior_dual(   fit_K,   w1_target = list(prob = list(threshold = 0.5, value = 0.3)),   lambda = 0.5,   loss_type = \"relative\" ) cat(\"Relative P(w_1 > 0.5):\", fit_rel$dual_anchor$w1_achieved$prob_gt_50, \"\\n\") #> Relative P(w_1 > 0.5): 0.4379077   # Dual-anchor with adaptive loss (more aggressive) fit_adp <- DPprior_dual(   fit_K,   w1_target = list(prob = list(threshold = 0.5, value = 0.3)),   lambda = 0.5,   loss_type = \"adaptive\" ) cat(\"Adaptive P(w_1 > 0.5):\", fit_adp$dual_anchor$w1_achieved$prob_gt_50, \"\\n\") #> Adaptive P(w_1 > 0.5): 0.3426554"},{"path":"https://joonho112.github.io/DPprior/reference/DPprior_error_bounds.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute A1 Approximation Error Bounds ‚Äî DPprior_error_bounds","title":"Compute A1 Approximation Error Bounds ‚Äî DPprior_error_bounds","text":"Comprehensive error analysis A1 large-J approximation. Implements error quantification framework Lee (2026, Section 3.3).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/DPprior_error_bounds.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute A1 Approximation Error Bounds ‚Äî DPprior_error_bounds","text":"","code":"DPprior_error_bounds(J, a, b, cJ = log(J), M = .QUAD_NODES_DEFAULT)"},{"path":"https://joonho112.github.io/DPprior/reference/DPprior_error_bounds.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute A1 Approximation Error Bounds ‚Äî DPprior_error_bounds","text":"J Integer; sample size. , b Numeric; Gamma hyperparameters (shape, rate). cJ Numeric; scaling constant (default: log(J)). M Integer; number quadrature nodes (default: 80).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/DPprior_error_bounds.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute A1 Approximation Error Bounds ‚Äî DPprior_error_bounds","text":"S3 object class \"DPprior_error_bounds\" components: J, , b, cJ Input parameters moment_errors List moment error metrics a1_moment_error tv_bounds List conditional marginal TV bounds recommendation \"A1_sufficient\" \"A2_recommended\" threshold_J Estimated J threshold A1 adequacy (NA)","code":""},{"path":"https://joonho112.github.io/DPprior/reference/DPprior_error_bounds.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute A1 Approximation Error Bounds ‚Äî DPprior_error_bounds","text":"recommendation based : A1 sufficient : mean relative error < 5\\ A2 recommended otherwise function provides: Moment errors: Exact vs A1 approximation mean variance TV bounds: Conditional bounds multiple alpha values, plus marginal bound Recommendation: Whether use A1 refine A2 Threshold: Minimum J A1 adequacy current prior","code":""},{"path":"https://joonho112.github.io/DPprior/reference/DPprior_error_bounds.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Compute A1 Approximation Error Bounds ‚Äî DPprior_error_bounds","text":"Lee, J. (2026). Design-Conditional Prior Elicitation Dirichlet Process Mixtures. arXiv preprint arXiv:2602.06301.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/DPprior_error_bounds.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute A1 Approximation Error Bounds ‚Äî DPprior_error_bounds","text":"","code":"# Check A1 adequacy for J=50, typical prior bounds <- DPprior_error_bounds(J = 50, a = 1.6, b = 1.2) print(bounds) #> DPprior A1 Approximation Error Analysis #> ==================================================  #>  #> Sample size J = 50, c_J = 3.9120 #> Gamma prior: alpha ~ Gamma(1.6000, 1.2000) [shape-rate] #> E[alpha] = 1.3333, CV(alpha) = 0.7906 #>  #> Moment Errors (A1 vs Exact): #> ---------------------------------------------  #>   E[K_J]:   exact =   5.0973, A1 =   6.2160, error =  21.95% #>   Var(K_J): exact =   9.5500, A1 =  22.2204, error = 132.67% #>  #> TV Bounds: #> ---------------------------------------------  #>   Marginal E[d_TV] <= 0.3642 #>   At E[alpha] = 1.33: #>     Poissonization: 0.2043 (raw: 0.9128) #>     Linearization:  0.1804 #>     Total:          0.3846 #>  #> Recommendation: A2_recommended #>   (A1 may not achieve < 5%% mean error for J <= 500 with this prior)  # For larger J, A1 becomes more adequate bounds_200 <- DPprior_error_bounds(J = 200, a = 1.6, b = 1.2) print(bounds_200) #> DPprior A1 Approximation Error Analysis #> ==================================================  #>  #> Sample size J = 200, c_J = 5.2983 #> Gamma prior: alpha ~ Gamma(1.6000, 1.2000) [shape-rate] #> E[alpha] = 1.3333, CV(alpha) = 0.7906 #>  #> Moment Errors (A1 vs Exact): #> ---------------------------------------------  #>   E[K_J]:   exact =   6.9134, A1 =   8.0644, error =  16.65% #>   Var(K_J): exact =  20.3210, A1 =  38.2557, error =  88.26% #>  #> TV Bounds: #> ---------------------------------------------  #>   Marginal E[d_TV] <= 0.2995 #>   At E[alpha] = 1.33: #>     Poissonization: 0.1500 (raw: 0.9389) #>     Linearization:  0.1571 #>     Total:          0.3071 #>  #> Recommendation: A2_recommended #>   (A1 may not achieve < 5%% mean error for J <= 500 with this prior)"},{"path":"https://joonho112.github.io/DPprior/reference/DPprior_fit.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit a Gamma Hyperprior for DP Concentration Parameter ‚Äî DPprior_fit","title":"Fit a Gamma Hyperprior for DP Concentration Parameter ‚Äî DPprior_fit","text":"Main entry point DPprior prior elicitation. Takes user-specified cluster count expectations returns calibrated Gamma(, b) parameters.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/DPprior_fit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit a Gamma Hyperprior for DP Concentration Parameter ‚Äî DPprior_fit","text":"","code":"DPprior_fit(   J,   mu_K,   var_K = NULL,   confidence = c(\"medium\", \"low\", \"high\"),   method = c(\"A2-MN\", \"A1\", \"A2-KL\"),   target_pmf = NULL,   check_diagnostics = TRUE,   warn_dominance = TRUE,   M = .QUAD_NODES_DEFAULT,   verbose = FALSE,   ... )"},{"path":"https://joonho112.github.io/DPprior/reference/DPprior_fit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit a Gamma Hyperprior for DP Concentration Parameter ‚Äî DPprior_fit","text":"J Integer; sample size (number sites/units). Must positive exceed maximum supported value (default: 500). mu_K Numeric; target expected number clusters E[K_J]. Must range (1, J]. Note: mu_K = 1 trivial (single cluster). var_K Numeric; target variance K_J. NULL, computed confidence argument. Must satisfy var_K <= (J-1)^2/4 (maximum possible variance K {1,...,J}). confidence Character; alternative var_K specifying uncertainty. One : \"low\": VIF = 5.0 (high uncertainty, wide prior) \"medium\": VIF = 2.5 (moderate uncertainty) \"high\": VIF = 1.5 (low uncertainty, concentrated prior) used var_K NULL. method Character; calibration method. One : \"A2-MN\" (default): Exact moment matching via Newton's method. Recommended accurate calibration. \"A1\": Fast closed-form approximation based shifted NegBin. Good initial exploration large J. Note: may project var_K feasible region var_K < mu_K - 1. \"A2-KL\": KL divergence minimization. Supports moment target (default) custom target PMF via target_pmf. target_pmf Numeric vector; optional custom target PMF A2-KL. provided, A2-KL uses PMF matching mode. Length must equal J. check_diagnostics Logical; TRUE (default), compute comprehensive diagnostics including weight distribution analysis. warn_dominance Logical; TRUE (default), issue warning prior implies high probability dominant cluster (P(w1 > 0.5) > 40%). M Integer; number quadrature nodes numerical integration. Default 80, provides good accuracy cases. verbose Logical; TRUE, print progress messages calibration. ... Additional arguments passed method-specific functions. Note: matching formal arguments forwarded backends.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/DPprior_fit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit a Gamma Hyperprior for DP Concentration Parameter ‚Äî DPprior_fit","text":"S3 object class \"DPprior_fit\" containing: Numeric; shape parameter calibrated Gamma hyperprior. b Numeric; rate parameter calibrated Gamma hyperprior. J Integer; sample size used calibration. target List; target specification including mu_K, var_K, confidence level (used), target type. method Character; calibration method used. converged Logical; whether calibration converged. iterations Integer; number iterations (iterative methods). fit List; achieved moments (mu_K, var_K) residual. diagnostics List; comprehensive diagnostics (requested). solver_diagnostics List; backend solver details (applicable). trace Data frame; iteration history (iterative methods).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/DPprior_fit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fit a Gamma Hyperprior for DP Concentration Parameter ‚Äî DPprior_fit","text":"function provides convenient interface specifying beliefs number clusters uncertainty, calibrates Gamma hyperprior Dirichlet Process concentration parameter alpha. function primary interface Design-Conditional Elicitation (DCE) described Lee (2026). underlying engine Two-Stage Moment Matching (TSMM): Stage 1 (A1) provides closed-form initialization, Stage 2 (A2-MN) refines exact moments via Newton iteration.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/DPprior_fit.html","id":"variance-constraints","dir":"Reference","previous_headings":"","what":"Variance Constraints","title":"Fit a Gamma Hyperprior for DP Concentration Parameter ‚Äî DPprior_fit","text":"target variance must satisfy two constraints: Upper bound: var_K <= (J-1)^2/4 (maximum possible variance distribution {1,...,J}) Lower bound (A1 ): var_K >= mu_K - 1 (NegBin feasibility). A1, infeasible variance projected boundary warning. A2-MN constraint.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/DPprior_fit.html","id":"diagnostics","dir":"Reference","previous_headings":"","what":"Diagnostics","title":"Fit a Gamma Hyperprior for DP Concentration Parameter ‚Äî DPprior_fit","text":"check_diagnostics = TRUE, function computes: Alpha distribution: E[alpha], Var(alpha), CV(alpha) K distribution: achieved moments, mode, quantiles Weight distribution: E[w_1], P(w_1 > 0.5), dominance risk Co-clustering: E[rho], interpretation Backend solver details preserved solver_diagnostics.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/DPprior_fit.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fit a Gamma Hyperprior for DP Concentration Parameter ‚Äî DPprior_fit","text":"Lee, J. (2026). Design-Conditional Prior Elicitation Dirichlet Process Mixtures. arXiv preprint arXiv:2602.06301.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/DPprior_fit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit a Gamma Hyperprior for DP Concentration Parameter ‚Äî DPprior_fit","text":"","code":"# Basic usage with target moments fit <- DPprior_fit(J = 50, mu_K = 5, var_K = 8) #> Warning: HIGH DOMINANCE RISK: P(w1 > 0.5) = 48.1% exceeds 40%. #>   This may indicate unintended prior behavior (Lee, 2026). #>   Consider using DPprior_dual() for weight-constrained elicitation. #>   See ?DPprior_diagnostics for interpretation. print(fit) #> DPprior Prior Elicitation Result #> =============================================  #>  #> Gamma Hyperprior: Œ± ~ Gamma(a = 2.0361, b = 1.6051) #>   E[Œ±] = 1.269, SD[Œ±] = 0.889 #>  #> Target (J = 50): #>   E[K_J]   = 5.00 #>   Var(K_J) = 8.00 #>  #> Achieved: #>   E[K_J] = 5.000000, Var(K_J) = 8.000000 #>   Residual = 7.60e-09 #>  #> Method: A2-MN (6 iterations) #>  #> Dominance Risk: HIGH ‚úò (P(w‚ÇÅ>0.5) = 48%)  # Using confidence level instead of explicit variance fit_medium <- DPprior_fit(J = 50, mu_K = 5, confidence = \"medium\") #> Warning: HIGH DOMINANCE RISK: P(w1 > 0.5) = 49.7% exceeds 40%. #>   This may indicate unintended prior behavior (Lee, 2026). #>   Consider using DPprior_dual() for weight-constrained elicitation. #>   See ?DPprior_diagnostics for interpretation. fit_low <- DPprior_fit(J = 50, mu_K = 5, confidence = \"low\") #> Warning: HIGH DOMINANCE RISK: P(w1 > 0.5) = 56.3% exceeds 40%. #>   This may indicate unintended prior behavior (Lee, 2026). #>   Consider using DPprior_dual() for weight-constrained elicitation. #>   See ?DPprior_diagnostics for interpretation.  # Quick approximation for exploration fit_quick <- DPprior_fit(J = 50, mu_K = 5, var_K = 8, method = \"A1\") #> Warning: HIGH DOMINANCE RISK: P(w1 > 0.5) = 52.1% exceeds 40%. #>   This may indicate unintended prior behavior (Lee, 2026). #>   Consider using DPprior_dual() for weight-constrained elicitation. #>   See ?DPprior_diagnostics for interpretation.  # Verbose output for debugging fit_verbose <- DPprior_fit(J = 50, mu_K = 5, var_K = 8, verbose = TRUE) #> Using A2-MN Newton refinement #> A2-MN Newton Solver #> Target: E[K]=5.0000, Var(K)=8.0000 #> A1 initialization: a0=4.000000, b0=3.912023 #> --------------------------------------------------------------------------------  #> Iter |          a |          b |       E[K] |     Var(K) |      ||F|| |     step |     det(J) #> --------------------------------------------------------------------------------  #>    1 |   4.000000 |   3.912023 |   4.461351 |   4.783136 |   3.26e+00 |   1.0000 |  -5.30e+00 #>    2 |   1.178650 |   0.911969 |   4.909046 |  10.854537 |   2.86e+00 |   1.0000 |  -2.16e+01 #>    3 |   1.844384 |   1.455254 |   4.974913 |   8.399473 |   4.00e-01 |   1.0000 |  -1.53e+01 #>    4 |   2.029223 |   1.599680 |   4.999187 |   8.013243 |   1.33e-02 |   1.0000 |  -1.43e+01 #>    5 |   2.036082 |   1.605046 |   4.999999 |   8.000021 |   2.08e-05 |   1.0000 |  -1.43e+01 #>    6 |   2.036093 |   1.605054 |   5.000000 |   8.000000 |   7.60e-09 |      --- |  -1.43e+01 #>  #> Converged: ||F|| = 7.60e-09 < 1.00e-08 #> Warning: HIGH DOMINANCE RISK: P(w1 > 0.5) = 48.1% exceeds 40%. #>   This may indicate unintended prior behavior (Lee, 2026). #>   Consider using DPprior_dual() for weight-constrained elicitation. #>   See ?DPprior_diagnostics for interpretation.  # Access results fit$a  # Gamma shape #> [1] 2.036093 fit$b  # Gamma rate #> [1] 1.605054 fit$fit$mu_K  # Achieved mean #> [1] 5 fit$diagnostics$weights$dominance_risk  # Dominance risk level #> [1] \"high\""},{"path":"https://joonho112.github.io/DPprior/reference/K_moments.html","id":null,"dir":"Reference","previous_headings":"","what":"Convenience Wrapper for Marginal Moments ‚Äî K_moments","title":"Convenience Wrapper for Marginal Moments ‚Äî K_moments","text":"Returns marginal mean variance named numeric vector.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/K_moments.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convenience Wrapper for Marginal Moments ‚Äî K_moments","text":"","code":"K_moments(J, a, b, M = .QUAD_NODES_DEFAULT)"},{"path":"https://joonho112.github.io/DPprior/reference/K_moments.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convenience Wrapper for Marginal Moments ‚Äî K_moments","text":"J Integer; sample size (positive integer >= 1). Numeric; shape parameter Gamma prior (> 0). b Numeric; rate parameter Gamma prior (> 0). M Integer; number quadrature nodes (default: 80).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/K_moments.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convenience Wrapper for Marginal Moments ‚Äî K_moments","text":"Named numeric vector c(mean = ..., var = ...).","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/K_moments.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convenience Wrapper for Marginal Moments ‚Äî K_moments","text":"","code":"K_moments(50, 2.0, 1.0) #>      mean       var  #>  6.639693 12.954502"},{"path":"https://joonho112.github.io/DPprior/reference/a1_moment_error.html","id":null,"dir":"Reference","previous_headings":"","what":"A1 Approximation Moment Errors ‚Äî a1_moment_error","title":"A1 Approximation Moment Errors ‚Äî a1_moment_error","text":"Computes discrepancy A1 (shifted NegBin) approximation exact marginal moments \\(K_J\\).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/a1_moment_error.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A1 Approximation Moment Errors ‚Äî a1_moment_error","text":"","code":"a1_moment_error(J, a, b, cJ = log(J), M = .QUAD_NODES_DEFAULT)"},{"path":"https://joonho112.github.io/DPprior/reference/a1_moment_error.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A1 Approximation Moment Errors ‚Äî a1_moment_error","text":"J Integer; sample size. , b Numeric; Gamma hyperparameters (shape, rate). cJ Numeric; scaling constant (default: log(J)). M Integer; number quadrature nodes (default: 80).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/a1_moment_error.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A1 Approximation Moment Errors ‚Äî a1_moment_error","text":"list components: exact_mean, exact_var Exact moments via Gauss-Laguerre quadrature a1_mean, a1_var A1 (shifted NegBin) approximation moments error_mean_abs, error_var_abs Absolute errors error_mean_rel, error_var_rel Relative errors (percentage)","code":""},{"path":"https://joonho112.github.io/DPprior/reference/a1_moment_error.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"A1 Approximation Moment Errors ‚Äî a1_moment_error","text":"A1 approximation models \\(K_J \\approx 1 + \\text{NegBin}(, p_J)\\) \\(p_J = b / (b + c_J)\\). NegBin(, p) moments : Mean: \\((1-p)/p\\) Variance: \\((1-p)/p^2\\)","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/a1_moment_error.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A1 Approximation Moment Errors ‚Äî a1_moment_error","text":"","code":"# Moment errors for J=50, Gamma(2, 1) prior errors <- a1_moment_error(J = 50, a = 2, b = 1) print(errors) #> $exact_mean #> [1] 6.639693 #>  #> $exact_var #> [1] 12.9545 #>  #> $a1_mean #> [1] 8.824046 #>  #> $a1_var #> [1] 38.43189 #>  #> $error_mean_abs #> [1] 2.184353 #>  #> $error_var_abs #> [1] 25.47739 #>  #> $error_mean_rel #> [1] 32.89841 #>  #> $error_var_rel #> [1] 196.6682 #>   # Compare A1 accuracy at different J values sapply(c(25, 50, 100, 200), function(J) {   err <- a1_moment_error(J, a = 2, b = 1)   c(mean_err = err$error_mean_rel, var_err = err$error_var_rel) }) #>               [,1]      [,2]      [,3]      [,4] #> mean_err  39.18536  32.89841  27.97236  24.15421 #> var_err  263.32276 196.66824 152.98144 123.40937  # Compare different scaling constants a1_moment_error(J = 50, a = 2, b = 1, cJ = log(50)) #> $exact_mean #> [1] 6.639693 #>  #> $exact_var #> [1] 12.9545 #>  #> $a1_mean #> [1] 8.824046 #>  #> $a1_var #> [1] 38.43189 #>  #> $error_mean_abs #> [1] 2.184353 #>  #> $error_var_abs #> [1] 25.47739 #>  #> $error_mean_rel #> [1] 32.89841 #>  #> $error_var_rel #> [1] 196.6682 #>  a1_moment_error(J = 50, a = 2, b = 1, cJ = digamma(50) + 0.5772) #> $exact_mean #> [1] 6.639693 #>  #> $exact_var #> [1] 12.9545 #>  #> $a1_mean #> [1] 9.958379 #>  #> $a1_var #> [1] 49.08466 #>  #> $error_mean_abs #> [1] 3.318686 #>  #> $error_var_abs #> [1] 36.13016 #>  #> $error_mean_rel #> [1] 49.98253 #>  #> $error_var_rel #> [1] 278.9004 #>"},{"path":"https://joonho112.github.io/DPprior/reference/as.data.frame.DPprior_fit.html","id":null,"dir":"Reference","previous_headings":"","what":"Coerce DPprior_fit to Data Frame ‚Äî as.data.frame.DPprior_fit","title":"Coerce DPprior_fit to Data Frame ‚Äî as.data.frame.DPprior_fit","text":"Coerce DPprior_fit Data Frame","code":""},{"path":"https://joonho112.github.io/DPprior/reference/as.data.frame.DPprior_fit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Coerce DPprior_fit to Data Frame ‚Äî as.data.frame.DPprior_fit","text":"","code":"# S3 method for class 'DPprior_fit' as.data.frame(x, row.names = NULL, optional = FALSE, ...)"},{"path":"https://joonho112.github.io/DPprior/reference/as.data.frame.DPprior_fit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Coerce DPprior_fit to Data Frame ‚Äî as.data.frame.DPprior_fit","text":"x DPprior_fit object. row.names Optional row names. optional Logical; TRUE, avoid setting names. ... Additional arguments (ignored).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/as.data.frame.DPprior_fit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Coerce DPprior_fit to Data Frame ‚Äî as.data.frame.DPprior_fit","text":"data frame one row containing fit results.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/as.data.frame.DPprior_fit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Coerce DPprior_fit to Data Frame ‚Äî as.data.frame.DPprior_fit","text":"","code":"fit <- DPprior_a1(J = 50, mu_K = 5, var_K = 8) as.data.frame(fit) #>   method  status a        b  J mu_K var_K mean_alpha cv_alpha scaling converged #> 1     A1 success 4 3.912023 50    5     8   1.022489      0.5     log      TRUE #>   iterations #> 1          0"},{"path":"https://joonho112.github.io/DPprior/reference/assert_nonnegative.html","id":null,"dir":"Reference","previous_headings":"","what":"Assert Non-negative Values ‚Äî assert_nonnegative","title":"Assert Non-negative Values ‚Äî assert_nonnegative","text":"Validates elements numeric vector non-negative finite.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/assert_nonnegative.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Assert Non-negative Values ‚Äî assert_nonnegative","text":"","code":"assert_nonnegative(x, name = \"x\")"},{"path":"https://joonho112.github.io/DPprior/reference/assert_nonnegative.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Assert Non-negative Values ‚Äî assert_nonnegative","text":"x Numeric vector validate. name Character string naming parameter (error messages).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/assert_nonnegative.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Assert Non-negative Values ‚Äî assert_nonnegative","text":"Invisible TRUE validation passes.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/assert_positive.html","id":null,"dir":"Reference","previous_headings":"","what":"Assert Positive Values ‚Äî assert_positive","title":"Assert Positive Values ‚Äî assert_positive","text":"Validates elements numeric vector strictly positive finite. Throws informative error validation fails.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/assert_positive.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Assert Positive Values ‚Äî assert_positive","text":"","code":"assert_positive(x, name = \"x\")"},{"path":"https://joonho112.github.io/DPprior/reference/assert_positive.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Assert Positive Values ‚Äî assert_positive","text":"x Numeric vector validate. name Character string naming parameter (error messages).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/assert_positive.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Assert Positive Values ‚Äî assert_positive","text":"Invisible TRUE validation passes.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/assert_positive.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Assert Positive Values ‚Äî assert_positive","text":"","code":"if (FALSE) { # \\dontrun{ assert_positive(c(1, 2, 3), \"alpha\") assert_positive(c(1, -1), \"alpha\") } # }"},{"path":"https://joonho112.github.io/DPprior/reference/assert_probability.html","id":null,"dir":"Reference","previous_headings":"","what":"Assert Valid Probability ‚Äî assert_probability","title":"Assert Valid Probability ‚Äî assert_probability","text":"Validates elements numeric vector valid probabilities range [0, 1] finite.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/assert_probability.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Assert Valid Probability ‚Äî assert_probability","text":"","code":"assert_probability(p, name = \"p\")"},{"path":"https://joonho112.github.io/DPprior/reference/assert_probability.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Assert Valid Probability ‚Äî assert_probability","text":"p Numeric vector probability values validate. name Character string naming parameter (error messages).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/assert_probability.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Assert Valid Probability ‚Äî assert_probability","text":"Invisible TRUE validation passes.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/assert_probability.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Assert Valid Probability ‚Äî assert_probability","text":"","code":"if (FALSE) { # \\dontrun{ assert_probability(0.5, \"p\") assert_probability(1.5, \"p\") } # }"},{"path":"https://joonho112.github.io/DPprior/reference/assert_valid_J.html","id":null,"dir":"Reference","previous_headings":"","what":"Assert Valid Sample Size J ‚Äî assert_valid_J","title":"Assert Valid Sample Size J ‚Äî assert_valid_J","text":"Validates J positive integer within supported range.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/assert_valid_J.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Assert Valid Sample Size J ‚Äî assert_valid_J","text":"","code":"assert_valid_J(J)"},{"path":"https://joonho112.github.io/DPprior/reference/assert_valid_J.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Assert Valid Sample Size J ‚Äî assert_valid_J","text":"J Sample size validate.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/assert_valid_J.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Assert Valid Sample Size J ‚Äî assert_valid_J","text":"Invisible TRUE validation passes.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/assert_valid_J.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Assert Valid Sample Size J ‚Äî assert_valid_J","text":"","code":"if (FALSE) { # \\dontrun{ assert_valid_J(50) assert_valid_J(0) assert_valid_J(1000) } # }"},{"path":"https://joonho112.github.io/DPprior/reference/assert_valid_k.html","id":null,"dir":"Reference","previous_headings":"","what":"Assert Valid Cluster Count k ‚Äî assert_valid_k","title":"Assert Valid Cluster Count k ‚Äî assert_valid_k","text":"Validates k valid cluster count given sample size J.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/assert_valid_k.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Assert Valid Cluster Count k ‚Äî assert_valid_k","text":"","code":"assert_valid_k(k, J)"},{"path":"https://joonho112.github.io/DPprior/reference/assert_valid_k.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Assert Valid Cluster Count k ‚Äî assert_valid_k","text":"k Cluster count validate. J Sample size (k must 1:J).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/assert_valid_k.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Assert Valid Cluster Count k ‚Äî assert_valid_k","text":"Invisible TRUE validation passes.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/build_gamma_quadrature.html","id":null,"dir":"Reference","previous_headings":"","what":"Build Quadrature for Gamma(a, b) Integration ‚Äî build_gamma_quadrature","title":"Build Quadrature for Gamma(a, b) Integration ‚Äî build_gamma_quadrature","text":"Transforms standard Gauss-Laguerre quadrature integration Gamma(, b) distribution shape rate b.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/build_gamma_quadrature.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Build Quadrature for Gamma(a, b) Integration ‚Äî build_gamma_quadrature","text":"","code":"build_gamma_quadrature(a, b, M = .QUAD_NODES_DEFAULT)"},{"path":"https://joonho112.github.io/DPprior/reference/build_gamma_quadrature.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Build Quadrature for Gamma(a, b) Integration ‚Äî build_gamma_quadrature","text":"Numeric; shape parameter Gamma distribution (must > 0). b Numeric; rate parameter Gamma distribution (must > 0). M Integer; number quadrature nodes (default: 80).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/build_gamma_quadrature.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Build Quadrature for Gamma(a, b) Integration ‚Äî build_gamma_quadrature","text":"list components: Shape parameter. b Rate parameter. alpha_nodes Numeric vector transformed nodes \\(\\alpha_m = x_m / b\\) \\(\\alpha\\) scale. weights_normalized Numeric vector normalized weights sum 1.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/build_gamma_quadrature.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Build Quadrature for Gamma(a, b) Integration ‚Äî build_gamma_quadrature","text":"\\(\\alpha \\sim \\text{Gamma}(, b)\\): $$E[g(\\alpha)] = \\frac{1}{\\Gamma()} \\int_0^\\infty g(x/b) x^{-1} e^{-x} dx$$ Using generalized Laguerre quadrature parameter \\(\\alpha_{\\text{param}} = - 1\\): $$E[g(\\alpha)] \\approx \\sum_{m=1}^M \\tilde{w}_m g(\\alpha_m)$$ \\(\\alpha_m = x_m / b\\) \\(\\tilde{w}_m\\) normalized weights summing 1. weights normalized log-space numerical stability, ensures monotone convergence M increases.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/build_gamma_quadrature.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Build Quadrature for Gamma(a, b) Integration ‚Äî build_gamma_quadrature","text":"","code":"# Build quadrature for Gamma(2.5, 1.5) quad <- build_gamma_quadrature(2.5, 1.5)  # Check weights sum to 1 sum(quad$weights_normalized) #> [1] 1  # Check mean: E[alpha] should be a/b = 2.5/1.5 sum(quad$weights_normalized * quad$alpha_nodes) #> [1] 1.666667"},{"path":"https://joonho112.github.io/DPprior/reference/cdf_K_given_alpha.html","id":null,"dir":"Reference","previous_headings":"","what":"CDF of K Given Alpha ‚Äî cdf_K_given_alpha","title":"CDF of K Given Alpha ‚Äî cdf_K_given_alpha","text":"Computes cumulative distribution function \\(P(K_J \\leq k \\mid \\alpha)\\) \\(k = 0, 1, \\ldots, J\\).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/cdf_K_given_alpha.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"CDF of K Given Alpha ‚Äî cdf_K_given_alpha","text":"","code":"cdf_K_given_alpha(J, alpha, logS)"},{"path":"https://joonho112.github.io/DPprior/reference/cdf_K_given_alpha.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"CDF of K Given Alpha ‚Äî cdf_K_given_alpha","text":"J Integer; sample size. alpha Numeric; DP concentration parameter. logS Matrix; pre-computed log-Stirling matrix.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/cdf_K_given_alpha.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"CDF of K Given Alpha ‚Äî cdf_K_given_alpha","text":"Numeric vector length \\(J+1\\) containing \\(P(K_J \\leq k \\mid \\alpha)\\) \\(k = 0, 1, \\ldots, J\\).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/cdf_K_given_alpha.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"CDF of K Given Alpha ‚Äî cdf_K_given_alpha","text":"CDF satisfies: \\(F(0) = 0\\) (since \\(P(K_J = 0) = 0\\)) \\(F(J) = 1\\) \\(F(k)\\) non-decreasing \\(k\\)","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/cdf_K_given_alpha.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"CDF of K Given Alpha ‚Äî cdf_K_given_alpha","text":"","code":"logS <- compute_log_stirling(50) cdf <- cdf_K_given_alpha(50, 2.0, logS)  # Verify CDF ends at 1 cdf[51]  # Should be 1 #> [1] 1  # P(K <= 5) cdf[6] #> [1] 0.2418684"},{"path":"https://joonho112.github.io/DPprior/reference/cdf_K_marginal.html","id":null,"dir":"Reference","previous_headings":"","what":"CDF of Marginal K Distribution ‚Äî cdf_K_marginal","title":"CDF of Marginal K Distribution ‚Äî cdf_K_marginal","text":"Computes cumulative distribution function \\(P(K_J \\leq k \\mid , b)\\) \\(k = 0, 1, \\ldots, J\\).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/cdf_K_marginal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"CDF of Marginal K Distribution ‚Äî cdf_K_marginal","text":"","code":"cdf_K_marginal(J, a, b, logS, M = .QUAD_NODES_DEFAULT)"},{"path":"https://joonho112.github.io/DPprior/reference/cdf_K_marginal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"CDF of Marginal K Distribution ‚Äî cdf_K_marginal","text":"J Integer; sample size. Numeric; shape parameter Gamma prior (> 0). b Numeric; rate parameter Gamma prior (> 0). logS Matrix; pre-computed log-Stirling matrix. M Integer; number quadrature nodes (default: 80).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/cdf_K_marginal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"CDF of Marginal K Distribution ‚Äî cdf_K_marginal","text":"Numeric vector length \\(J+1\\) containing \\(P(K_J \\leq k \\mid , b)\\) \\(k = 0, 1, \\ldots, J\\).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/cdf_K_marginal.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"CDF of Marginal K Distribution ‚Äî cdf_K_marginal","text":"CDF satisfies: \\(F(0) = 0\\) (since \\(P(K_J = 0) = 0\\)) \\(F(J) = 1\\) \\(F(k)\\) non-decreasing \\(k\\)","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/cdf_K_marginal.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"CDF of Marginal K Distribution ‚Äî cdf_K_marginal","text":"","code":"logS <- compute_log_stirling(50) cdf <- cdf_K_marginal(50, 1.5, 0.5, logS)  # Verify CDF ends at 1 cdf[51] #> [1] 1  # P(K <= 10) cdf[11] #> [1] 0.7009381"},{"path":"https://joonho112.github.io/DPprior/reference/cdf_w1.html","id":null,"dir":"Reference","previous_headings":"","what":"CDF of First Stick-Breaking Weight w‚ÇÅ ‚Äî cdf_w1","title":"CDF of First Stick-Breaking Weight w‚ÇÅ ‚Äî cdf_w1","text":"Computes P(w‚ÇÅ ‚â§ x | , b) using closed-form expression derived marginalizing Œ± ~ Gamma(, b).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/cdf_w1.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"CDF of First Stick-Breaking Weight w‚ÇÅ ‚Äî cdf_w1","text":"","code":"cdf_w1(x, a, b)"},{"path":"https://joonho112.github.io/DPprior/reference/cdf_w1.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"CDF of First Stick-Breaking Weight w‚ÇÅ ‚Äî cdf_w1","text":"x Numeric vector. Values outside unit interval allowed mapped boundary values CDF (0 x ‚â§ 0, 1 x ‚â• 1). Numeric; shape parameter Gamma prior Œ± (> 0). b Numeric; rate parameter Gamma prior Œ± (b > 0).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/cdf_w1.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"CDF of First Stick-Breaking Weight w‚ÇÅ ‚Äî cdf_w1","text":"Numeric vector CDF values F(x | , b) length x.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/cdf_w1.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"CDF of First Stick-Breaking Weight w‚ÇÅ ‚Äî cdf_w1","text":"unconditional CDF given : $$F_{w_1}(x | , b) = 1 - \\left(\\frac{b}{b - \\log(1-x)}\\right)^$$ implementation uses log1p expm1 numerical stability, particularly CDF close 0 (small x).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/cdf_w1.html","id":"interpretation","dir":"Reference","previous_headings":"","what":"Interpretation","title":"CDF of First Stick-Breaking Weight w‚ÇÅ ‚Äî cdf_w1","text":"weight w‚ÇÅ GEM (size-biased) order, ranked size. represents asymptotic cluster share randomly chosen unit, largest cluster proportion. See Lee (2026, Section 4) details.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/cdf_w1.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"CDF of First Stick-Breaking Weight w‚ÇÅ ‚Äî cdf_w1","text":"Lee, J. (2026). Design-Conditional Prior Elicitation Dirichlet Process Mixtures. arXiv preprint arXiv:2602.06301. Vicentini, C. Jermyn, . H. (2025). Prior selection precision parameter Dirichlet Process Mixtures. arXiv:2502.00864.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/cdf_w1.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"CDF of First Stick-Breaking Weight w‚ÇÅ ‚Äî cdf_w1","text":"","code":"# P(w‚ÇÅ ‚â§ 0.3) under standard prior cdf_w1(0.3, a = 2, b = 1) #> [1] 0.4566891  # Vectorized computation cdf_w1(c(0.1, 0.3, 0.5, 0.7), a = 1.6, b = 1.22) #> [1] 0.1241267 0.3365805 0.5131689 0.6666263"},{"path":"https://joonho112.github.io/DPprior/reference/check_dominance_risk.html","id":null,"dir":"Reference","previous_headings":"","what":"Quick Dominance Risk Check ‚Äî check_dominance_risk","title":"Quick Dominance Risk Check ‚Äî check_dominance_risk","text":"Fast check high dominance risk without computing full diagnostics.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/check_dominance_risk.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Quick Dominance Risk Check ‚Äî check_dominance_risk","text":"","code":"check_dominance_risk(a, b, threshold = 0.5, risk_level = 0.3)"},{"path":"https://joonho112.github.io/DPprior/reference/check_dominance_risk.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Quick Dominance Risk Check ‚Äî check_dominance_risk","text":"Numeric; shape parameter Gamma prior (> 0). b Numeric; rate parameter Gamma prior (> 0). threshold Numeric; dominance threshold (0, 1) (default: 0.5). risk_level Numeric; probability threshold flagging risk (default: 0.3).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/check_dominance_risk.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Quick Dominance Risk Check ‚Äî check_dominance_risk","text":"Logical; TRUE P(w1 > threshold) > risk_level.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/check_dominance_risk.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Quick Dominance Risk Check ‚Äî check_dominance_risk","text":"","code":"check_dominance_risk(1.60, 1.22) #> [1] TRUE check_dominance_risk(5, 1) #> [1] FALSE"},{"path":"https://joonho112.github.io/DPprior/reference/compare_a1_a2.html","id":null,"dir":"Reference","previous_headings":"","what":"Compare A1 vs A2 Accuracy ‚Äî compare_a1_a2","title":"Compare A1 vs A2 Accuracy ‚Äî compare_a1_a2","text":"Compares accuracy A1 closed-form A2 Newton methods.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/compare_a1_a2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compare A1 vs A2 Accuracy ‚Äî compare_a1_a2","text":"","code":"compare_a1_a2(J, mu_K, var_K, verbose = TRUE)"},{"path":"https://joonho112.github.io/DPprior/reference/compare_a1_a2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compare A1 vs A2 Accuracy ‚Äî compare_a1_a2","text":"J Integer; sample size. mu_K Numeric; target mean. var_K Numeric; target variance. verbose Logical; TRUE, print comparison.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/compare_a1_a2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compare A1 vs A2 Accuracy ‚Äî compare_a1_a2","text":"list A1 A2 results error comparison.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/compare_a1_a2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compare A1 vs A2 Accuracy ‚Äî compare_a1_a2","text":"","code":"compare_a1_a2(J = 50, mu_K = 5, var_K = 8) #> A1 vs A2 Comparison (J=50, mu_K=5.00, var_K=8.00) #> ------------------------------------------------------------  #>                                A1           A2 #> ------------------------------------------------------------  #> Shape (a)                4.000000     2.036093 #> Rate (b)                 3.912023     1.605054 #> E[K] achieved            4.461351 4.9999999992 #> Var achieved             4.783136 8.0000000076 #> Residual                 3.261649     7.60e-09 #> ------------------------------------------------------------  #> Improvement ratio: 429143906x"},{"path":"https://joonho112.github.io/DPprior/reference/compare_diagnostics.html","id":null,"dir":"Reference","previous_headings":"","what":"Compare Diagnostics Across Multiple Fits ‚Äî compare_diagnostics","title":"Compare Diagnostics Across Multiple Fits ‚Äî compare_diagnostics","text":"Creates comparison table diagnostic metrics multiple DPprior fits.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/compare_diagnostics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compare Diagnostics Across Multiple Fits ‚Äî compare_diagnostics","text":"","code":"compare_diagnostics(..., M = .QUAD_NODES_DEFAULT)"},{"path":"https://joonho112.github.io/DPprior/reference/compare_diagnostics.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compare Diagnostics Across Multiple Fits ‚Äî compare_diagnostics","text":"... Named DPprior_fit objects compare. M Integer; number quadrature nodes (default: 80).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/compare_diagnostics.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compare Diagnostics Across Multiple Fits ‚Äî compare_diagnostics","text":"data frame diagnostic metrics fit.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/compare_diagnostics.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compare Diagnostics Across Multiple Fits ‚Äî compare_diagnostics","text":"","code":"if (FALSE) { # \\dontrun{ fit_K <- DPprior_a2_newton(J = 50, mu_K = 5, var_K = 8) fit_dual <- DPprior_dual(fit_K,                          w1_target = list(prob = list(threshold = 0.5, value = 0.3))) compare_diagnostics(K_only = fit_K, Dual_anchor = fit_dual)  } # }"},{"path":"https://joonho112.github.io/DPprior/reference/compare_rho_w1.html","id":null,"dir":"Reference","previous_headings":"","what":"Compare rho and w1 Distributions ‚Äî compare_rho_w1","title":"Compare rho and w1 Distributions ‚Äî compare_rho_w1","text":"Compares marginal distributions rho w1 hyperprior alpha ~ Gamma(, b).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/compare_rho_w1.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compare rho and w1 Distributions ‚Äî compare_rho_w1","text":"","code":"compare_rho_w1(a, b, M = .QUAD_NODES_DEFAULT)"},{"path":"https://joonho112.github.io/DPprior/reference/compare_rho_w1.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compare rho and w1 Distributions ‚Äî compare_rho_w1","text":"Numeric; shape parameter Gamma prior alpha (> 0). b Numeric; rate parameter Gamma prior alpha (b > 0). M Integer; number quadrature nodes. Default 80.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/compare_rho_w1.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compare rho and w1 Distributions ‚Äî compare_rho_w1","text":"list containing: mean_rho E(rho) mean_w1 E(w1) mean_equal Logical; whether means equal var_rho Var(rho) var_w1 Var(w1) var_ratio Var(rho) / Var(w1)","code":""},{"path":"https://joonho112.github.io/DPprior/reference/compare_rho_w1.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compare rho and w1 Distributions ‚Äî compare_rho_w1","text":"E(rho) = E(w1), variances differ : Var(rho | alpha) = 2*alpha / ((1+alpha)^2*(2+alpha)*(3+alpha)) Var(w1 | alpha) = alpha / ((1+alpha)^2*(2+alpha)) Generally, Var(rho) < Var(w1) rho averages squared weights.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/compare_rho_w1.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compare rho and w1 Distributions ‚Äî compare_rho_w1","text":"","code":"if (FALSE) { # \\dontrun{ compare_rho_w1(a = 2, b = 1) compare_rho_w1(a = 1.6, b = 1.22)  } # }"},{"path":"https://joonho112.github.io/DPprior/reference/compare_to_negbin.html","id":null,"dir":"Reference","previous_headings":"","what":"Compare Exact Moments to NegBin Approximation ‚Äî compare_to_negbin","title":"Compare Exact Moments to NegBin Approximation ‚Äî compare_to_negbin","text":"Compares exact marginal moments (via quadrature) Negative Binomial approximation A1 method error analysis.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/compare_to_negbin.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compare Exact Moments to NegBin Approximation ‚Äî compare_to_negbin","text":"","code":"compare_to_negbin(J, a, b, M = .QUAD_NODES_DEFAULT)"},{"path":"https://joonho112.github.io/DPprior/reference/compare_to_negbin.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compare Exact Moments to NegBin Approximation ‚Äî compare_to_negbin","text":"J Integer; sample size. Numeric; shape parameter Gamma prior. b Numeric; rate parameter Gamma prior. M Integer; number quadrature nodes (default: 80).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/compare_to_negbin.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compare Exact Moments to NegBin Approximation ‚Äî compare_to_negbin","text":"list components: exact List exact mean var negbin List NegBin approximation mean var abs_error Absolute errors (negbin - exact) rel_error Relative errors","code":""},{"path":"https://joonho112.github.io/DPprior/reference/compare_to_negbin.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compare Exact Moments to NegBin Approximation ‚Äî compare_to_negbin","text":"NegBin approximation (A1 method Lee, 2026, Section 3.1) assumes: $$K_J - 1 | \\alpha \\approx \\text{Poisson}(\\alpha \\cdot c_J)$$ \\(c_J = \\log(J)\\). \\(\\alpha \\sim \\text{Gamma}(, b)\\): $$E[K_J] \\approx 1 + (/b) \\cdot c_J$$ $$Var(K_J) \\approx m \\cdot (1 + m/), \\quad m = (/b) \\cdot c_J$$ comparison helps diagnose A1 approximation insufficient exact A2 moment matching needed.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/compare_to_negbin.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compare Exact Moments to NegBin Approximation ‚Äî compare_to_negbin","text":"","code":"if (FALSE) { # \\dontrun{ # Large approximation error for small J compare_to_negbin(50, 1.5, 0.5)  # Error decreases with J compare_to_negbin(300, 1.5, 0.5)  } # }"},{"path":"https://joonho112.github.io/DPprior/reference/compute_K_diagnostics.html","id":null,"dir":"Reference","previous_headings":"","what":"K Distribution Diagnostics ‚Äî compute_K_diagnostics","title":"K Distribution Diagnostics ‚Äî compute_K_diagnostics","text":"Computes summary statistics marginal distribution K_J alpha distributed Gamma(, b).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/compute_K_diagnostics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"K Distribution Diagnostics ‚Äî compute_K_diagnostics","text":"","code":"compute_K_diagnostics(J, a, b, M = .QUAD_NODES_DEFAULT)"},{"path":"https://joonho112.github.io/DPprior/reference/compute_K_diagnostics.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"K Distribution Diagnostics ‚Äî compute_K_diagnostics","text":"J Integer; sample size (positive integer >= 1). Numeric; shape parameter Gamma prior (> 0). b Numeric; rate parameter Gamma prior (> 0). M Integer; number Gauss-Laguerre quadrature nodes (default: 80).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/compute_K_diagnostics.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"K Distribution Diagnostics ‚Äî compute_K_diagnostics","text":"list components: mean (expected value K), var (variance), sd, mode, median, quantiles (named integer vector), pmf (full PMF vector k = 1, ..., J).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/compute_alpha_diagnostics.html","id":null,"dir":"Reference","previous_headings":"","what":"Alpha Distribution Diagnostics ‚Äî compute_alpha_diagnostics","title":"Alpha Distribution Diagnostics ‚Äî compute_alpha_diagnostics","text":"Computes summary statistics alpha distributed Gamma(, b).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/compute_alpha_diagnostics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Alpha Distribution Diagnostics ‚Äî compute_alpha_diagnostics","text":"","code":"compute_alpha_diagnostics(a, b)"},{"path":"https://joonho112.github.io/DPprior/reference/compute_alpha_diagnostics.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Alpha Distribution Diagnostics ‚Äî compute_alpha_diagnostics","text":"Numeric; shape parameter Gamma prior (> 0). b Numeric; rate parameter Gamma prior (> 0).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/compute_alpha_diagnostics.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Alpha Distribution Diagnostics ‚Äî compute_alpha_diagnostics","text":"list components: mean (expected value Escales::alpha = /b), sd (standard deviation), cv (coefficient variation = 1/sqrt()), median, quantiles (named vector q5, q25, q50, q75, q95).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/compute_alpha_diagnostics.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Alpha Distribution Diagnostics ‚Äî compute_alpha_diagnostics","text":"coefficient variation depends shape parameter , making useful summary prior uncertainty regardless mean.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/compute_coclustering_diagnostics.html","id":null,"dir":"Reference","previous_headings":"","what":"Co-Clustering Diagnostics (rho) ‚Äî compute_coclustering_diagnostics","title":"Co-Clustering Diagnostics (rho) ‚Äî compute_coclustering_diagnostics","text":"Computes diagnostics rho = sum w_h squared, prior co-clustering probability.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/compute_coclustering_diagnostics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Co-Clustering Diagnostics (rho) ‚Äî compute_coclustering_diagnostics","text":"","code":"compute_coclustering_diagnostics(a, b, M = .QUAD_NODES_DEFAULT)"},{"path":"https://joonho112.github.io/DPprior/reference/compute_coclustering_diagnostics.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Co-Clustering Diagnostics (rho) ‚Äî compute_coclustering_diagnostics","text":"Numeric; shape parameter Gamma prior (> 0). b Numeric; rate parameter Gamma prior (> 0). M Integer; number quadrature nodes (default: 80).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/compute_coclustering_diagnostics.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Co-Clustering Diagnostics (rho) ‚Äî compute_coclustering_diagnostics","text":"list components: mean (expected co-clustering probability), var (variance), sd, interpretation (qualitative description co-clustering level).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/compute_coclustering_diagnostics.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Co-Clustering Diagnostics (rho) ‚Äî compute_coclustering_diagnostics","text":"Key identity Lee (2026, Section 4): expected co-clustering probability equals expected first stick-breaking weight.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/compute_error_landscape.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute A1 Error Landscape ‚Äî compute_error_landscape","title":"Compute A1 Error Landscape ‚Äî compute_error_landscape","text":"Computes error metrics grid (J, alpha) values visualization.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/compute_error_landscape.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute A1 Error Landscape ‚Äî compute_error_landscape","text":"","code":"compute_error_landscape(J_seq, alpha_seq, cJ_fun = log)"},{"path":"https://joonho112.github.io/DPprior/reference/compute_error_landscape.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute A1 Error Landscape ‚Äî compute_error_landscape","text":"J_seq Numeric vector; sequence J values. alpha_seq Numeric vector; sequence alpha values. cJ_fun Function; scaling constant function (default: log).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/compute_error_landscape.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute A1 Error Landscape ‚Äî compute_error_landscape","text":"data frame columns: J, alpha, lambda_exact, lambda_approx, pois_raw, pois_bound, lin_bound, total_tv.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/compute_error_landscape.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute A1 Error Landscape ‚Äî compute_error_landscape","text":"function useful creating error landscape visualizations shown Lee (2026, Section 3.3).","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/compute_error_landscape.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute A1 Error Landscape ‚Äî compute_error_landscape","text":"","code":"# Create error landscape landscape <- compute_error_landscape(   J_seq = c(25, 50, 100),   alpha_seq = c(0.5, 1, 2, 5) ) print(landscape) #>      J alpha lambda_exact lambda_approx  pois_raw pois_bound   lin_bound #> 1   25   0.5     1.591226      1.609438 0.2237019 0.11195092 0.007191254 #> 2   50   0.5     1.937775      1.956012 0.2287007 0.10102428 0.006529898 #> 3  100   0.5     2.284342      2.302585 0.2312006 0.09090357 0.006019094 #> 4   25   1.0     2.815958      3.218876 0.6057234 0.20223044 0.114762181 #> 5   50   1.0     3.499205      3.912023 0.6251327 0.17325087 0.106279606 #> 6  100   1.0     4.187378      4.605170 0.6349839 0.14933953 0.098874211 #> 7   25   2.0     4.708839      6.437752 1.4288108 0.30069611 0.357966296 #> 8   50   2.0     6.037626      7.824046 1.5020688 0.24819075 0.332807789 #> 9  100   2.0     7.394557      9.210340 1.5403277 0.20817759 0.309892875 #> 10  25   5.0     8.391602     16.094379 3.6856974 0.43911299 1.000000000 #> 11  50   5.0    11.460485     19.560115 4.0743712 0.35551097 0.993226480 #> 12 100   5.0    14.715366     23.025851 4.2938413 0.29179291 0.927912567 #>      total_tv #> 1  0.11914218 #> 2  0.10755418 #> 3  0.09692267 #> 4  0.31699262 #> 5  0.27953047 #> 6  0.24821374 #> 7  0.65866241 #> 8  0.58099854 #> 9  0.51807046 #> 10 1.00000000 #> 11 1.00000000 #> 12 1.00000000"},{"path":"https://joonho112.github.io/DPprior/reference/compute_linearization_bound.html","id":null,"dir":"Reference","previous_headings":"","what":"Mean-Linearization Error Bound ‚Äî compute_linearization_bound","title":"Mean-Linearization Error Bound ‚Äî compute_linearization_bound","text":"Computes upper bound TV distance two Poisson distributions, \\(\\text{Poisson}(\\lambda_J(\\alpha))\\) \\(\\text{Poisson}(\\alpha c_J)\\), using Poisson-Poisson KL divergence together Pinsker's inequality.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/compute_linearization_bound.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mean-Linearization Error Bound ‚Äî compute_linearization_bound","text":"","code":"compute_linearization_bound(J, alpha, cJ = log(J))"},{"path":"https://joonho112.github.io/DPprior/reference/compute_linearization_bound.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mean-Linearization Error Bound ‚Äî compute_linearization_bound","text":"J Integer; sample size. alpha Numeric; concentration parameter (vectorized). cJ Numeric; scaling constant (default: log(J)).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/compute_linearization_bound.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Mean-Linearization Error Bound ‚Äî compute_linearization_bound","text":"Numeric; upper bound via Pinsker's inequality.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/compute_linearization_bound.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Mean-Linearization Error Bound ‚Äî compute_linearization_bound","text":"Let \\(\\lambda = \\lambda_J(\\alpha)\\) (exact shifted mean) \\(\\lambda' = \\alpha c_J\\) (A1 approximate mean). KL divergence : $$KL(\\text{Poisson}(\\lambda) || \\text{Poisson}(\\lambda')) =       \\lambda \\log(\\lambda/\\lambda') + \\lambda' - \\lambda$$ Pinsker's inequality: $$d_{TV}(\\text{Poisson}(\\lambda), \\text{Poisson}(\\lambda')) \\le \\sqrt{KL/2}$$ Numerical safeguards handle edge cases \\(\\lambda\\) \\(c_J\\) zero.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/compute_linearization_bound.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Mean-Linearization Error Bound ‚Äî compute_linearization_bound","text":"Lee, J. (2026). Design-Conditional Prior Elicitation Dirichlet Process Mixtures. arXiv preprint arXiv:2602.06301.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/compute_linearization_bound.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mean-Linearization Error Bound ‚Äî compute_linearization_bound","text":"","code":"if (FALSE) { # \\dontrun{ # Linearization bound for J=50, alpha=1 compute_linearization_bound(J = 50, alpha = 1)  # Effect of J on linearization bound (should decrease) sapply(c(25, 50, 100, 200), function(J)   compute_linearization_bound(J, alpha = 2))  } # }"},{"path":"https://joonho112.github.io/DPprior/reference/compute_log_stirling.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Log Stirling Numbers (First Kind, Unsigned) ‚Äî compute_log_stirling","title":"Compute Log Stirling Numbers (First Kind, Unsigned) ‚Äî compute_log_stirling","text":"Computes logarithm unsigned Stirling numbers first kind \\(|s(J,k)|\\) \\(J\\) 0 J_max \\(k\\) 0 \\(J\\). Uses log-space recursion prevent numerical overflow.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/compute_log_stirling.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Log Stirling Numbers (First Kind, Unsigned) ‚Äî compute_log_stirling","text":"","code":"compute_log_stirling(J_max)"},{"path":"https://joonho112.github.io/DPprior/reference/compute_log_stirling.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Log Stirling Numbers (First Kind, Unsigned) ‚Äî compute_log_stirling","text":"J_max Maximum J value (non-negative integer, 500).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/compute_log_stirling.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Log Stirling Numbers (First Kind, Unsigned) ‚Äî compute_log_stirling","text":"lower triangular matrix dimension (J_max+1) x (J_max+1). Entry [J+1, k+1] contains \\(\\log|s(J,k)|\\) (using R's 1-based indexing). Invalid entries (k > J k < 1 J >= 1) contain -Inf.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/compute_log_stirling.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute Log Stirling Numbers (First Kind, Unsigned) ‚Äî compute_log_stirling","text":"unsigned Stirling numbers first kind \\(|s(J,k)|\\) count number permutations \\(J\\) elements exactly \\(k\\) disjoint cycles. Uses log-space recurrence relation: $$L_{J,k} = \\text{logsumexp}(L_{J-1,k-1}, \\log(J-1) + L_{J-1,k})$$ \\(L_{J,k} = \\log|s(J,k)|\\). Boundary conditions: \\(|s(0,0)| = 1\\) \\(\\rightarrow\\) L[1,1] = 0 \\(|s(J,0)| = 0\\) \\(J \\geq 1\\) \\(\\rightarrow\\) L[J+1,1] = -Inf \\(|s(J,J)| = 1\\) \\(J\\) \\(\\rightarrow\\) L[J+1,J+1] = 0 Complexity: O(J_max^2) time space. Results cached repeated use within session.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/compute_log_stirling.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Compute Log Stirling Numbers (First Kind, Unsigned) ‚Äî compute_log_stirling","text":"Antoniak, C. E. (1974). Mixtures Dirichlet Processes Applications Bayesian Nonparametric Problems. Annals Statistics, 2(6), 1152-1174.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/compute_log_stirling.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute Log Stirling Numbers (First Kind, Unsigned) ‚Äî compute_log_stirling","text":"","code":"# Compute Stirling numbers up to J=10 logS <- compute_log_stirling(10)  # Access |s(4,2)| = 11 exp(logS[5, 3]) #> [1] 11  # Access |s(5,3)| = 35 exp(logS[6, 4]) #> [1] 35"},{"path":"https://joonho112.github.io/DPprior/reference/compute_poissonization_bound.html","id":null,"dir":"Reference","previous_headings":"","what":"Poissonization Error Bound (Chen-Stein / Le Cam Bound) ‚Äî compute_poissonization_bound","title":"Poissonization Error Bound (Chen-Stein / Le Cam Bound) ‚Äî compute_poissonization_bound","text":"Computes upper bound conditional total variation distance shifted cluster count \\(S_J = K_J - 1\\) Poisson law mean (Poissonization error).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/compute_poissonization_bound.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Poissonization Error Bound (Chen-Stein / Le Cam Bound) ‚Äî compute_poissonization_bound","text":"","code":"compute_poissonization_bound(J, alpha, raw = FALSE)"},{"path":"https://joonho112.github.io/DPprior/reference/compute_poissonization_bound.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Poissonization Error Bound (Chen-Stein / Le Cam Bound) ‚Äî compute_poissonization_bound","text":"J Integer; sample size (number observations). alpha Numeric; concentration parameter (can vectorized). raw Logical; TRUE, return just sum(p_i^2) without prefactor. Default FALSE.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/compute_poissonization_bound.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Poissonization Error Bound (Chen-Stein / Le Cam Bound) ‚Äî compute_poissonization_bound","text":"Numeric vector; upper bound \\(d_{TV}(S_J | \\alpha, \\text{Poisson}(\\lambda_J(\\alpha)))\\).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/compute_poissonization_bound.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Poissonization Error Bound (Chen-Stein / Le Cam Bound) ‚Äî compute_poissonization_bound","text":"CRP representation, \\(S_J = \\sum_{=2}^J I_i\\) \\(I_i \\sim \\text{Bernoulli}(p_i)\\) \\(p_i = \\alpha / (\\alpha + - 1)\\). standard Chen-Stein/Le Cam bound gives: $$d_{TV}(S_J, \\text{Poisson}(\\lambda)) \\le       \\frac{1 - e^{-\\lambda}}{\\lambda} \\sum_{=2}^J p_i^2$$ \\(\\lambda = \\sum_{=2}^J p_i = E[S_J | \\alpha]\\). prefactor \\((1 - e^{-\\lambda})/\\lambda\\) always (0, 1] approaches 1 \\(\\lambda \\0\\). provides tighter bound simply using \\(\\sum p_i^2\\) alone. returned value capped 1 (since total variation always 0 1).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/compute_poissonization_bound.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Poissonization Error Bound (Chen-Stein / Le Cam Bound) ‚Äî compute_poissonization_bound","text":"Le Cam, L. (1960). approximation theorem Poisson binomial distribution. Pacific Journal Mathematics, 10(4), 1181-1197. Chen, L. H. Y. (1975). Poisson approximation dependent trials. Annals Probability, 3(3), 534-545. Lee, J. (2026). Design-Conditional Prior Elicitation Dirichlet Process Mixtures. arXiv preprint arXiv:2602.06301.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/compute_poissonization_bound.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Poissonization Error Bound (Chen-Stein / Le Cam Bound) ‚Äî compute_poissonization_bound","text":"","code":"if (FALSE) { # \\dontrun{ # Full Chen-Stein bound compute_poissonization_bound(J = 50, alpha = 1)  # Raw bound (sum of p_i^2) compute_poissonization_bound(J = 50, alpha = 1, raw = TRUE)  # Vectorized compute_poissonization_bound(J = 50, alpha = c(0.5, 1, 2, 5))  } # }"},{"path":"https://joonho112.github.io/DPprior/reference/compute_scaling_constant.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Scaling Constant for A1 Mapping ‚Äî compute_scaling_constant","title":"Compute Scaling Constant for A1 Mapping ‚Äî compute_scaling_constant","text":"Computes scaling constant \\(c_J\\) used A1 closed-form mapping. Three variants supported based asymptotic approximations.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/compute_scaling_constant.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Scaling Constant for A1 Mapping ‚Äî compute_scaling_constant","text":"","code":"compute_scaling_constant(   J,   scaling = c(\"log\", \"harmonic\", \"digamma\"),   mu_K = NULL )"},{"path":"https://joonho112.github.io/DPprior/reference/compute_scaling_constant.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Scaling Constant for A1 Mapping ‚Äî compute_scaling_constant","text":"J Integer; number items/sites (must >= 2). scaling Character; one \"log\", \"harmonic\", \"digamma\". mu_K Numeric; target mean K (required \"digamma\" scaling).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/compute_scaling_constant.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Scaling Constant for A1 Mapping ‚Äî compute_scaling_constant","text":"Numeric scalar; scaling constant \\(c_J\\).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/compute_scaling_constant.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute Scaling Constant for A1 Mapping ‚Äî compute_scaling_constant","text":"scaling constant appears Poisson proxy: $$K_J - 1 \\mid \\alpha \\approx \\text{Poisson}(\\alpha \\cdot c_J)$$ Available variants: log \\(c_J = \\log(J)\\), asymptotic leading term (default) harmonic \\(c_J = H_{J-1} = \\psi(J) + \\gamma\\), improves accuracy small/moderate J digamma \\(c_J = \\psi(\\tilde{\\alpha} + J) - \\psi(\\tilde{\\alpha})\\) \\(\\tilde{\\alpha} = (\\mu_K - 1)/\\log(J)\\), local correction","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/compute_scaling_constant.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute Scaling Constant for A1 Mapping ‚Äî compute_scaling_constant","text":"","code":"# Default log scaling compute_scaling_constant(50, \"log\") #> [1] 3.912023  # Harmonic scaling (better for moderate J) compute_scaling_constant(50, \"harmonic\") #> [1] 4.479205  # Digamma scaling (requires mu_K) compute_scaling_constant(50, \"digamma\", mu_K = 5) #> [1] 4.463254"},{"path":"https://joonho112.github.io/DPprior/reference/compute_sum_p_squared.html","id":null,"dir":"Reference","previous_headings":"","what":"Poissonization Error Bound (Raw Sum of Squared Probabilities) ‚Äî compute_sum_p_squared","title":"Poissonization Error Bound (Raw Sum of Squared Probabilities) ‚Äî compute_sum_p_squared","text":"Computes raw sum squared Bernoulli probabilities: $$\\sum_{=2}^{J} p_i^2 = \\alpha^2 [\\psi_1(\\alpha+1) - \\psi_1(\\alpha+J)]$$ \\(p_i = \\alpha / (\\alpha + - 1)\\).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/compute_sum_p_squared.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Poissonization Error Bound (Raw Sum of Squared Probabilities) ‚Äî compute_sum_p_squared","text":"","code":"compute_sum_p_squared(J, alpha)"},{"path":"https://joonho112.github.io/DPprior/reference/compute_sum_p_squared.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Poissonization Error Bound (Raw Sum of Squared Probabilities) ‚Äî compute_sum_p_squared","text":"J Integer; sample size (number observations). alpha Numeric; concentration parameter (can vectorized).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/compute_sum_p_squared.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Poissonization Error Bound (Raw Sum of Squared Probabilities) ‚Äî compute_sum_p_squared","text":"Numeric vector; sum squared probabilities alpha value.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/compute_sum_p_squared.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Poissonization Error Bound (Raw Sum of Squared Probabilities) ‚Äî compute_sum_p_squared","text":"quantity represents \"underdispersion gap\" conditional variance \\(K_J | \\alpha\\) Poisson mean. Poisson-binomial representation, \\(S_J = K_J - 1 = \\sum_{=2}^{J} I_i\\) \\(I_i \\sim \\text{Bernoulli}(p_i)\\). sum equals: $$\\sum_{=2}^{J} p_i^2 = \\alpha^2 [\\psi_1(\\alpha+1) - \\psi_1(\\alpha+J)]$$ using identity sums squared reciprocals.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/compute_sum_p_squared.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Poissonization Error Bound (Raw Sum of Squared Probabilities) ‚Äî compute_sum_p_squared","text":"Lee, J. (2026). Design-Conditional Prior Elicitation Dirichlet Process Mixtures. arXiv preprint arXiv:2602.06301.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/compute_sum_p_squared.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Poissonization Error Bound (Raw Sum of Squared Probabilities) ‚Äî compute_sum_p_squared","text":"","code":"if (FALSE) { # \\dontrun{ # Compute raw sum for J=50, alpha=1 compute_sum_p_squared(J = 50, alpha = 1)  # Vectorized over alpha compute_sum_p_squared(J = 50, alpha = c(0.5, 1, 2))  } # }"},{"path":"https://joonho112.github.io/DPprior/reference/compute_total_tv_bound.html","id":null,"dir":"Reference","previous_headings":"","what":"Total TV Error Bound (Conditional) ‚Äî compute_total_tv_bound","title":"Total TV Error Bound (Conditional) ‚Äî compute_total_tv_bound","text":"Computes combined conditional TV bound using triangle inequality: $$d_{TV}(K_J | \\alpha, 1 + \\text{NegBin}) \\le B_{\\text{Pois}} + B_{\\text{lin}}$$","code":""},{"path":"https://joonho112.github.io/DPprior/reference/compute_total_tv_bound.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Total TV Error Bound (Conditional) ‚Äî compute_total_tv_bound","text":"","code":"compute_total_tv_bound(J, alpha, cJ = log(J))"},{"path":"https://joonho112.github.io/DPprior/reference/compute_total_tv_bound.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Total TV Error Bound (Conditional) ‚Äî compute_total_tv_bound","text":"J Integer; sample size. alpha Numeric; concentration parameter (vectorized). cJ Numeric; scaling constant (default: log(J)).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/compute_total_tv_bound.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Total TV Error Bound (Conditional) ‚Äî compute_total_tv_bound","text":"Numeric; upper bound total TV error (capped 1).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/compute_total_tv_bound.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Total TV Error Bound (Conditional) ‚Äî compute_total_tv_bound","text":"result capped 1 since TV distance bounded 1. Lee (2026, Section 3.3, Theorem 1), total conditional TV error decomposes : Poissonization error: \\(S_J | \\alpha\\) vs \\(\\text{Poisson}(\\lambda_J(\\alpha))\\) Linearization error: \\(\\text{Poisson}(\\lambda_J(\\alpha))\\) vs \\(\\text{Poisson}(\\alpha c_J)\\)","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/compute_total_tv_bound.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Total TV Error Bound (Conditional) ‚Äî compute_total_tv_bound","text":"","code":"if (FALSE) { # \\dontrun{ # Total bound at alpha = E[alpha] under Gamma(2, 1) compute_total_tv_bound(J = 50, alpha = 2)  # Vectorized compute_total_tv_bound(J = 50, alpha = c(0.5, 1, 2, 5))  } # }"},{"path":"https://joonho112.github.io/DPprior/reference/compute_tradeoff_curve.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Pareto Trade-off Curve ‚Äî compute_tradeoff_curve","title":"Compute Pareto Trade-off Curve ‚Äî compute_tradeoff_curve","text":"Explores trade-K_J fit first-weight constraint lambda values.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/compute_tradeoff_curve.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Pareto Trade-off Curve ‚Äî compute_tradeoff_curve","text":"","code":"compute_tradeoff_curve(   J,   K_target,   w1_target,   lambda_seq = seq(0, 1, by = 0.1),   max_iter = 100L,   M = .QUAD_NODES_DEFAULT,   verbose = FALSE,   loss_type = c(\"relative\", \"adaptive\", \"absolute\") )"},{"path":"https://joonho112.github.io/DPprior/reference/compute_tradeoff_curve.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Pareto Trade-off Curve ‚Äî compute_tradeoff_curve","text":"J Integer; sample size. K_target List mu_K var_K. w1_target Weight target specification. lambda_seq Numeric vector lambda values. max_iter Integer; max iterations per optimization. M Integer; quadrature nodes. verbose Logical; print progress. loss_type Character; \"relative\", \"adaptive\", \"absolute\".","code":""},{"path":"https://joonho112.github.io/DPprior/reference/compute_tradeoff_curve.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Pareto Trade-off Curve ‚Äî compute_tradeoff_curve","text":"Data frame columns: lambda, , b, mu_K, var_K, K_loss, w_loss, w1_prob_gt_50, E_w1.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/compute_tradeoff_curve.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Compute Pareto Trade-off Curve ‚Äî compute_tradeoff_curve","text":"Lee, J. (2026). Design-Conditional Prior Elicitation Dirichlet Process Mixtures. arXiv preprint arXiv:2602.06301.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/compute_tradeoff_curve.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute Pareto Trade-off Curve ‚Äî compute_tradeoff_curve","text":"","code":"curve <- compute_tradeoff_curve(   J = 50,   K_target = list(mu_K = 5, var_K = 8),   w1_target = list(prob = list(threshold = 0.5, value = 0.25)),   lambda_seq = seq(0, 1, by = 0.1),   loss_type = \"relative\" )  # Visualize trade-off plot(curve$lambda, curve$w1_prob_gt_50, type = \"b\",      xlab = \"lambda\", ylab = \"P(w_1 > 0.5)\",      main = \"Weight Dominance vs Lambda\") abline(h = 0.25, lty = 2, col = \"red\")  # target"},{"path":"https://joonho112.github.io/DPprior/reference/compute_weight_diagnostics.html","id":null,"dir":"Reference","previous_headings":"","what":"Weight Distribution Diagnostics (w1) ‚Äî compute_weight_diagnostics","title":"Weight Distribution Diagnostics (w1) ‚Äî compute_weight_diagnostics","text":"Computes comprehensive diagnostics first stick-breaking weight. KEY diagnostic concerns unintended prior behavior (Lee, 2026, Section 4).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/compute_weight_diagnostics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Weight Distribution Diagnostics (w1) ‚Äî compute_weight_diagnostics","text":"","code":"compute_weight_diagnostics(   a,   b,   thresholds = c(0.3, 0.5, 0.7, 0.9),   M = .QUAD_NODES_DEFAULT )"},{"path":"https://joonho112.github.io/DPprior/reference/compute_weight_diagnostics.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Weight Distribution Diagnostics (w1) ‚Äî compute_weight_diagnostics","text":"Numeric; shape parameter Gamma prior (> 0). b Numeric; rate parameter Gamma prior (> 0). thresholds Numeric vector; thresholds computing P(w1 > t). Default c(0.3, 0.5, 0.7, 0.9). values must (0, 1). M Integer; number quadrature nodes moment computation (default: 80).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/compute_weight_diagnostics.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Weight Distribution Diagnostics (w1) ‚Äî compute_weight_diagnostics","text":"list components: mean (expected value first weight), median, quantiles (named vector), prob_exceeds (named vector exceedance probabilities threshold), dominance_risk (character: \"low\", \"moderate\", \"high\").","code":""},{"path":"https://joonho112.github.io/DPprior/reference/compute_weight_diagnostics.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Weight Distribution Diagnostics (w1) ‚Äî compute_weight_diagnostics","text":"weight w1 first stick-breaking weight GEM order (size-biased permutation), representing asymptotic cluster share randomly chosen unit. Dominance risk classification: \"low\": P(w1 > 0.5) < 0.2 \"moderate\": 0.2 <= P(w1 > 0.5) < 0.4 \"high\": P(w1 > 0.5) >= 0.4","code":""},{"path":"https://joonho112.github.io/DPprior/reference/compute_weight_diagnostics.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Weight Distribution Diagnostics (w1) ‚Äî compute_weight_diagnostics","text":"Lee, J. (2026). Design-Conditional Prior Elicitation Dirichlet Process Mixtures. arXiv preprint arXiv:2602.06301.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/compute_weight_diagnostics.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Weight Distribution Diagnostics (w1) ‚Äî compute_weight_diagnostics","text":"","code":"# Lee et al. DP-inform prior (known high dominance) compute_weight_diagnostics(1.60, 1.22) #> $mean #> [1] 0.508368 #>  #> $median #> [1] 0.4839219 #>  #> $quantiles #>         q5        q25        q50        q75        q95  #> 0.03896534 0.21361987 0.48392192 0.81393615 0.99878645  #>  #> $prob_exceeds #> prob_gt_0.3 prob_gt_0.5 prob_gt_0.7 prob_gt_0.9  #>   0.6634195   0.4868311   0.3333737   0.1833147  #>  #> $dominance_risk #> [1] \"high\" #>   # Lower dominance case compute_weight_diagnostics(5, 1) #> $mean #> [1] 0.1915145 #>  #> $median #> [1] 0.138171 #>  #> $quantiles #>         q5        q25        q50        q75        q95  #> 0.01025848 0.05750422 0.13817096 0.27349354 0.55981677  #>  #> $prob_exceeds #> prob_gt_0.3 prob_gt_0.5 prob_gt_0.7 prob_gt_0.9  #> 0.217581005 0.071866491 0.019229538 0.002545247  #>  #> $dominance_risk #> [1] \"low\" #>"},{"path":"https://joonho112.github.io/DPprior/reference/confidence_to_vif.html","id":null,"dir":"Reference","previous_headings":"","what":"Map a Qualitative Confidence Level to a Variance Inflation Factor (VIF) ‚Äî confidence_to_vif","title":"Map a Qualitative Confidence Level to a Variance Inflation Factor (VIF) ‚Äî confidence_to_vif","text":"Maps intuitive confidence levels VIF values easy prior specification.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/confidence_to_vif.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Map a Qualitative Confidence Level to a Variance Inflation Factor (VIF) ‚Äî confidence_to_vif","text":"","code":"confidence_to_vif(confidence = c(\"low\", \"medium\", \"high\"))"},{"path":"https://joonho112.github.io/DPprior/reference/confidence_to_vif.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Map a Qualitative Confidence Level to a Variance Inflation Factor (VIF) ‚Äî confidence_to_vif","text":"confidence Character; one \"low\", \"medium\", \"high\".","code":""},{"path":"https://joonho112.github.io/DPprior/reference/confidence_to_vif.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Map a Qualitative Confidence Level to a Variance Inflation Factor (VIF) ‚Äî confidence_to_vif","text":"Numeric; VIF value (5.0 low, 2.5 medium, 1.5 high).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/confidence_to_vif.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Map a Qualitative Confidence Level to a Variance Inflation Factor (VIF) ‚Äî confidence_to_vif","text":"mapping : low VIF = 5.0; high uncertainty \\(K_J\\) medium VIF = 2.5; moderate uncertainty high VIF = 1.5; high confidence (near Poisson boundary) Higher confidence implies lower variance, corresponds lower VIF. \"high\" setting (VIF = 1.5) close A1 feasibility boundary.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/confidence_to_vif.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Map a Qualitative Confidence Level to a Variance Inflation Factor (VIF) ‚Äî confidence_to_vif","text":"","code":"# Get VIF for medium confidence vif <- confidence_to_vif(\"medium\")  # Returns 2.5  # Complete workflow mu_K <- 5 vif <- confidence_to_vif(\"low\") var_K <- vif_to_variance(mu_K, vif) fit <- DPprior_a1(J = 50, mu_K = mu_K, var_K = var_K)"},{"path":"https://joonho112.github.io/DPprior/reference/confidence_to_vif_fit.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert Confidence Level to Variance Inflation Factor ‚Äî confidence_to_vif_fit","title":"Convert Confidence Level to Variance Inflation Factor ‚Äî confidence_to_vif_fit","text":"Maps qualitative confidence levels quantitative VIF values. VIF determines prior variance : Var(K) = VIF * (mu_K - 1).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/confidence_to_vif_fit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert Confidence Level to Variance Inflation Factor ‚Äî confidence_to_vif_fit","text":"","code":"confidence_to_vif_fit(confidence)"},{"path":"https://joonho112.github.io/DPprior/reference/confidence_to_vif_fit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert Confidence Level to Variance Inflation Factor ‚Äî confidence_to_vif_fit","text":"confidence Character; one \"low\", \"medium\", \"high\".","code":""},{"path":"https://joonho112.github.io/DPprior/reference/confidence_to_vif_fit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert Confidence Level to Variance Inflation Factor ‚Äî confidence_to_vif_fit","text":"Numeric; corresponding VIF value.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/confidence_to_vif_fit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Convert Confidence Level to Variance Inflation Factor ‚Äî confidence_to_vif_fit","text":"mapping : \"low\": VIF = 5.0 (high uncertainty cluster count) \"medium\": VIF = 2.5 (moderate uncertainty) \"high\": VIF = 1.5 (strong prior belief) values chosen provide wide range uncertainty levels. VIF = 5 corresponds \"little idea many clusters .\"","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/confidence_to_vif_fit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert Confidence Level to Variance Inflation Factor ‚Äî confidence_to_vif_fit","text":"","code":"if (FALSE) { # \\dontrun{ confidence_to_vif_fit(\"low\")     # 5.0 confidence_to_vif_fit(\"medium\")  # 2.5 confidence_to_vif_fit(\"high\")    # 1.5 } # }"},{"path":"https://joonho112.github.io/DPprior/reference/construct_target_pmf.html","id":null,"dir":"Reference","previous_headings":"","what":"Construct Target PMF from User Specification ‚Äî construct_target_pmf","title":"Construct Target PMF from User Specification ‚Äî construct_target_pmf","text":"Creates normalized target PMF either user-provided PMF vector target moment specification.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/construct_target_pmf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Construct Target PMF from User Specification ‚Äî construct_target_pmf","text":"","code":"construct_target_pmf(J, target)"},{"path":"https://joonho112.github.io/DPprior/reference/construct_target_pmf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Construct Target PMF from User Specification ‚Äî construct_target_pmf","text":"J Integer; sample size. target Either: Numeric vector length J J+1: direct PMF specification Named list mu_K var_K: construct moments","code":""},{"path":"https://joonho112.github.io/DPprior/reference/construct_target_pmf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Construct Target PMF from User Specification ‚Äî construct_target_pmf","text":"list components: pmf Numeric vector length J; normalized target PMF mu_K Target mean var_K Target variance df (moments provided) Chi-square degrees freedom scale (moments provided) Chi-square scale parameter","code":""},{"path":"https://joonho112.github.io/DPprior/reference/construct_target_pmf.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Construct Target PMF from User Specification ‚Äî construct_target_pmf","text":"Direct PMF specification: target numeric vector length J, treated PMF k = 1, ..., J. length J+1, k=0 entry dropped. Moment specification: target list mu_K var_K, discretized chi-square distribution matching moments constructed using: $$\\text{scale} = \\sigma^2_K / (2\\mu_K), \\quad \\text{df} = 2\\mu_K^2 / \\sigma^2_K$$","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/construct_target_pmf.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Construct Target PMF from User Specification ‚Äî construct_target_pmf","text":"","code":"if (FALSE) { # \\dontrun{ # Direct PMF result <- construct_target_pmf(50, rep(1, 50))  # Uniform on 1:50  # Moment specification result <- construct_target_pmf(50, list(mu_K = 5, var_K = 8)) result$mu_K  # 5 result$df    # 6.25  } # }"},{"path":"https://joonho112.github.io/DPprior/reference/convergence_quadrature.html","id":null,"dir":"Reference","previous_headings":"","what":"Convergence Diagnostic for Quadrature ‚Äî convergence_quadrature","title":"Convergence Diagnostic for Quadrature ‚Äî convergence_quadrature","text":"Examines quadrature accuracy improves increasing number nodes.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/convergence_quadrature.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convergence Diagnostic for Quadrature ‚Äî convergence_quadrature","text":"","code":"convergence_quadrature(   f,   a,   b,   M_values = c(10, 20, 50, 80, 100),   true_value = NULL )"},{"path":"https://joonho112.github.io/DPprior/reference/convergence_quadrature.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convergence Diagnostic for Quadrature ‚Äî convergence_quadrature","text":"f Function integrate. Numeric; shape parameter Gamma distribution. b Numeric; rate parameter Gamma distribution. M_values Integer vector; number nodes test. true_value Numeric; known true value (optional).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/convergence_quadrature.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convergence Diagnostic for Quadrature ‚Äî convergence_quadrature","text":"data frame columns: M, estimate, change, relative_change.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/convergence_quadrature.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convergence Diagnostic for Quadrature ‚Äî convergence_quadrature","text":"","code":"if (FALSE) { # \\dontrun{ # Check convergence for E[alpha] convergence_quadrature(identity, 2.5, 1.5,                        M_values = c(10, 20, 50, 80, 100),                        true_value = 2.5/1.5)  } # }"},{"path":"https://joonho112.github.io/DPprior/reference/cv_K_given_alpha.html","id":null,"dir":"Reference","previous_headings":"","what":"Coefficient of Variation for K Given Alpha ‚Äî cv_K_given_alpha","title":"Coefficient of Variation for K Given Alpha ‚Äî cv_K_given_alpha","text":"Computes coefficient variation (CV) \\(K_J | \\alpha\\), defined \\(CV = SD(K) / E[K]\\).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/cv_K_given_alpha.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Coefficient of Variation for K Given Alpha ‚Äî cv_K_given_alpha","text":"","code":"cv_K_given_alpha(J, alpha)"},{"path":"https://joonho112.github.io/DPprior/reference/cv_K_given_alpha.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Coefficient of Variation for K Given Alpha ‚Äî cv_K_given_alpha","text":"J Sample size (integer >= 1). alpha Concentration parameter (positive numeric, vectorized).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/cv_K_given_alpha.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Coefficient of Variation for K Given Alpha ‚Äî cv_K_given_alpha","text":"Numeric vector coefficients variation.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/cv_alpha_to_variance.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert CV(alpha) to Variance ‚Äî cv_alpha_to_variance","title":"Convert CV(alpha) to Variance ‚Äî cv_alpha_to_variance","text":"Converts coefficient variation specification \\(\\alpha\\) implied variance \\(K_J\\) A1 approximation.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/cv_alpha_to_variance.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert CV(alpha) to Variance ‚Äî cv_alpha_to_variance","text":"","code":"cv_alpha_to_variance(mu_K, cv_alpha)"},{"path":"https://joonho112.github.io/DPprior/reference/cv_alpha_to_variance.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert CV(alpha) to Variance ‚Äî cv_alpha_to_variance","text":"mu_K Numeric; target prior mean \\(K_J\\). cv_alpha Numeric; target coefficient variation \\(\\alpha\\).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/cv_alpha_to_variance.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert CV(alpha) to Variance ‚Äî cv_alpha_to_variance","text":"Numeric; implied variance \\(K_J\\).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/cv_alpha_to_variance.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Convert CV(alpha) to Variance ‚Äî cv_alpha_to_variance","text":"A1 approximation: $$\\text{CV}(\\alpha) = 1/\\sqrt{} = \\frac{\\sqrt{\\sigma^2_K - m}}{m}$$ \\(m = \\mu_K - 1\\). Inverting: $$\\sigma^2_K = m + (\\text{CV}(\\alpha) \\cdot m)^2 = m(1 + \\text{CV}(\\alpha)^2 \\cdot m)$$","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/cv_alpha_to_variance.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert CV(alpha) to Variance ‚Äî cv_alpha_to_variance","text":"","code":"# CV(alpha) = 0.5 means moderate prior concentration var_K <- cv_alpha_to_variance(mu_K = 5, cv_alpha = 0.5)  # Verify round-trip fit <- DPprior_a1(J = 50, mu_K = 5, var_K = var_K) 1 / sqrt(fit$a)  # Should be approximately 0.5 #> [1] 0.5"},{"path":"https://joonho112.github.io/DPprior/reference/cv_rho.html","id":null,"dir":"Reference","previous_headings":"","what":"Coefficient of Variation of rho ‚Äî cv_rho","title":"Coefficient of Variation of rho ‚Äî cv_rho","text":"Computes CV(rho) = SD(rho) / E(rho) alpha ~ Gamma(, b).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/cv_rho.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Coefficient of Variation of rho ‚Äî cv_rho","text":"","code":"cv_rho(a, b, M = .QUAD_NODES_DEFAULT)"},{"path":"https://joonho112.github.io/DPprior/reference/cv_rho.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Coefficient of Variation of rho ‚Äî cv_rho","text":"Numeric; shape parameter Gamma prior alpha (> 0). b Numeric; rate parameter Gamma prior alpha (b > 0). M Integer; number quadrature nodes. Default 80.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/cv_rho.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Coefficient of Variation of rho ‚Äî cv_rho","text":"Numeric; coefficient variation.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/cv_rho.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Coefficient of Variation of rho ‚Äî cv_rho","text":"","code":"cv_rho(a = 2, b = 1) #> [1] 0.5937869 cv_rho(a = 1.6, b = 1.22) #> [1] 0.5240019"},{"path":"https://joonho112.github.io/DPprior/reference/density_w1.html","id":null,"dir":"Reference","previous_headings":"","what":"Density of w‚ÇÅ ‚Äî density_w1","title":"Density of w‚ÇÅ ‚Äî density_w1","text":"Computes probability density p(w‚ÇÅ = x | , b).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/density_w1.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Density of w‚ÇÅ ‚Äî density_w1","text":"","code":"density_w1(x, a, b, log = FALSE)"},{"path":"https://joonho112.github.io/DPprior/reference/density_w1.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Density of w‚ÇÅ ‚Äî density_w1","text":"x Numeric vector; evaluation points. Numeric; shape parameter Gamma prior Œ± (> 0). b Numeric; rate parameter Gamma prior Œ± (b > 0). log Logical; TRUE, returns log-density. Default FALSE.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/density_w1.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Density of w‚ÇÅ ‚Äî density_w1","text":"Numeric vector density (log-density log = TRUE) values. Returns 0 (-Inf log scale) x outside (0, 1).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/density_w1.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Density of w‚ÇÅ ‚Äî density_w1","text":"marginal density w‚ÇÅ : $$p(w_1 | , b) = \\frac{\\cdot b^}{(1-w_1) \\cdot [b - \\log(1-w_1)]^{+1}}$$ Important: small values (< 1), density significant mass concentrated close x = 1.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/density_w1.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Density of w‚ÇÅ ‚Äî density_w1","text":"","code":"# Density at several points x <- seq(0.1, 0.9, by = 0.1) density_w1(x, a = 2, b = 1) #> [1] 1.6454157 1.3661794 1.1442068 0.9665754 0.8240923 0.7105355 0.6227160 #> [8] 0.5628065 0.5552236  # Log-density for numerical stability density_w1(0.5, a = 2, b = 1, log = TRUE) #> [1] -0.1934727"},{"path":"https://joonho112.github.io/DPprior/reference/discretize_chisq.html","id":null,"dir":"Reference","previous_headings":"","what":"Discretize Chi-Square to K_J Support ‚Äî discretize_chisq","title":"Discretize Chi-Square to K_J Support ‚Äî discretize_chisq","text":"Converts (possibly scaled) chi-square distribution discrete PMF \\(\\{1, \\dots, J\\}\\) using continuity-corrected binning: $$p(k) = P(k - 0.5 < X \\le k + 0.5), \\quad k = 1, \\dots, J$$ followed renormalization.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/discretize_chisq.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Discretize Chi-Square to K_J Support ‚Äî discretize_chisq","text":"","code":"discretize_chisq(J, df, scale = 1)"},{"path":"https://joonho112.github.io/DPprior/reference/discretize_chisq.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Discretize Chi-Square to K_J Support ‚Äî discretize_chisq","text":"J Integer; maximum value (support upper bound). df Numeric; degrees freedom. scale Numeric; scale parameter (default 1). scale != 1, assumes \\(X = scale \\cdot \\chi^2_{df}\\).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/discretize_chisq.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Discretize Chi-Square to K_J Support ‚Äî discretize_chisq","text":"Numeric vector length J; PMF \\(\\{1, \\dots, J\\}\\).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/discretize_chisq.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Discretize Chi-Square to K_J Support ‚Äî discretize_chisq","text":"scaled chi-square distribution \\(Y = scale \\cdot X\\) \\(X \\sim \\chi^2_{df}\\): \\(E[Y] = scale \\cdot df\\) \\(Var[Y] = scale^2 \\cdot 2 \\cdot df\\) Matching target moments: Given target mean \\(\\mu_K\\) variance \\(\\sigma^2_K\\): \\(scale = \\sigma^2_K / (2 \\mu_K)\\) \\(df = 2 \\mu_K^2 / \\sigma^2_K\\)","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/discretize_chisq.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Discretize Chi-Square to K_J Support ‚Äî discretize_chisq","text":"","code":"# Chi-square with target moments mu=5, var=8 mu_K <- 5 var_K <- 8 scale <- var_K / (2 * mu_K) df <- 2 * mu_K^2 / var_K pmf <- discretize_chisq(50, df = df, scale = scale)  # Verify moments k_vals <- 1:50 sum(k_vals * pmf)  # ~5 #> [1] 5.01509"},{"path":"https://joonho112.github.io/DPprior/reference/dispersion_K_given_alpha.html","id":null,"dir":"Reference","previous_headings":"","what":"Dispersion Index for K Given Alpha ‚Äî dispersion_K_given_alpha","title":"Dispersion Index for K Given Alpha ‚Äî dispersion_K_given_alpha","text":"Computes dispersion index (variance--mean ratio) \\(K_J | \\alpha\\). Always < 1 distribution (underdispersion).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/dispersion_K_given_alpha.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dispersion Index for K Given Alpha ‚Äî dispersion_K_given_alpha","text":"","code":"dispersion_K_given_alpha(J, alpha)"},{"path":"https://joonho112.github.io/DPprior/reference/dispersion_K_given_alpha.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Dispersion Index for K Given Alpha ‚Äî dispersion_K_given_alpha","text":"J Sample size (integer >= 1). alpha Concentration parameter (positive numeric, vectorized).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/dispersion_K_given_alpha.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Dispersion Index for K Given Alpha ‚Äî dispersion_K_given_alpha","text":"Numeric vector dispersion indices.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/dmean_dalpha.html","id":null,"dir":"Reference","previous_headings":"","what":"Derivative of Conditional Mean w.r.t. Alpha ‚Äî dmean_dalpha","title":"Derivative of Conditional Mean w.r.t. Alpha ‚Äî dmean_dalpha","text":"Computes \\(\\frac{d}{d\\alpha} \\mathbb{E}[K_J \\mid \\alpha]\\). used internally building Jacobians Newton-type solvers.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/dmean_dalpha.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Derivative of Conditional Mean w.r.t. Alpha ‚Äî dmean_dalpha","text":"","code":"dmean_dalpha(J, alpha)"},{"path":"https://joonho112.github.io/DPprior/reference/dmean_dalpha.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Derivative of Conditional Mean w.r.t. Alpha ‚Äî dmean_dalpha","text":"J Sample size (integer >= 1). alpha Concentration parameter (positive numeric, vectorized).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/dmean_dalpha.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Derivative of Conditional Mean w.r.t. Alpha ‚Äî dmean_dalpha","text":"Numeric vector derivatives (length alpha).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/dmean_dalpha.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Derivative of Conditional Mean w.r.t. Alpha ‚Äî dmean_dalpha","text":"Closed form: $$\\frac{d}{d\\alpha}\\mu_J(\\alpha) =       \\{\\psi(\\alpha+J)-\\psi(\\alpha)\\} + \\alpha\\{\\psi_1(\\alpha+J)-\\psi_1(\\alpha)\\}$$ derivative always positive \\(\\alpha > 0\\), confirming \\(E[K_J | \\alpha]\\) strictly increasing \\(\\alpha\\).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/dmean_dalpha.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Derivative of Conditional Mean w.r.t. Alpha ‚Äî dmean_dalpha","text":"","code":"if (FALSE) { # \\dontrun{ dmean_dalpha(50, 2.0)  # Verify with finite difference J <- 50; alpha <- 2.0; eps <- 1e-6 fd <- (mean_K_given_alpha(J, alpha + eps) -        mean_K_given_alpha(J, alpha - eps)) / (2 * eps) abs(fd - dmean_dalpha(J, alpha)) < 1e-5  # TRUE  } # }"},{"path":"https://joonho112.github.io/DPprior/reference/dot-ALPHA_SMALL_MOMENTS.html","id":null,"dir":"Reference","previous_headings":"","what":"Threshold for Small Alpha Guard ‚Äî .ALPHA_SMALL_MOMENTS","title":"Threshold for Small Alpha Guard ‚Äî .ALPHA_SMALL_MOMENTS","text":"value, use limiting behavior directly avoid numerical cancellation digamma/trigamma expressions.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/dot-ALPHA_SMALL_MOMENTS.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Threshold for Small Alpha Guard ‚Äî .ALPHA_SMALL_MOMENTS","text":"","code":".ALPHA_SMALL_MOMENTS"},{"path":"https://joonho112.github.io/DPprior/reference/dot-ALPHA_SMALL_MOMENTS.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Threshold for Small Alpha Guard ‚Äî .ALPHA_SMALL_MOMENTS","text":"object class numeric length 1.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/dot-EULER_GAMMA.html","id":null,"dir":"Reference","previous_headings":"","what":"Euler-Mascheroni Constant ‚Äî .EULER_GAMMA","title":"Euler-Mascheroni Constant ‚Äî .EULER_GAMMA","text":"Euler-Mascheroni constant (gamma), approximately 0.5772. Used harmonic sum approximations asymptotic expansions.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/dot-EULER_GAMMA.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Euler-Mascheroni Constant ‚Äî .EULER_GAMMA","text":"","code":".EULER_GAMMA"},{"path":"https://joonho112.github.io/DPprior/reference/dot-EULER_GAMMA.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Euler-Mascheroni Constant ‚Äî .EULER_GAMMA","text":"object class numeric length 1.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/dot-MAX_J_DEFAULT.html","id":null,"dir":"Reference","previous_headings":"","what":"Maximum Supported Sample Size ‚Äî .MAX_J_DEFAULT","title":"Maximum Supported Sample Size ‚Äî .MAX_J_DEFAULT","text":"Default maximum value J (sample size) supported package. Pre-computed Stirling number tables limited size.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/dot-MAX_J_DEFAULT.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Maximum Supported Sample Size ‚Äî .MAX_J_DEFAULT","text":"","code":".MAX_J_DEFAULT"},{"path":"https://joonho112.github.io/DPprior/reference/dot-MAX_J_DEFAULT.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Maximum Supported Sample Size ‚Äî .MAX_J_DEFAULT","text":"object class integer length 1.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/dot-QUAD_NODES_DEFAULT.html","id":null,"dir":"Reference","previous_headings":"","what":"Default Number of Quadrature Nodes ‚Äî .QUAD_NODES_DEFAULT","title":"Default Number of Quadrature Nodes ‚Äî .QUAD_NODES_DEFAULT","text":"Default number Gauss-Laguerre quadrature nodes numerical integration Gamma distributions.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/dot-QUAD_NODES_DEFAULT.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Default Number of Quadrature Nodes ‚Äî .QUAD_NODES_DEFAULT","text":"","code":".QUAD_NODES_DEFAULT"},{"path":"https://joonho112.github.io/DPprior/reference/dot-QUAD_NODES_DEFAULT.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Default Number of Quadrature Nodes ‚Äî .QUAD_NODES_DEFAULT","text":"object class integer length 1.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/dot-QUAD_NODES_VERIFICATION.html","id":null,"dir":"Reference","previous_headings":"","what":"Default Quadrature Nodes for Verification ‚Äî .QUAD_NODES_VERIFICATION","title":"Default Quadrature Nodes for Verification ‚Äî .QUAD_NODES_VERIFICATION","text":"Higher M value recommended Jacobian verification due slower convergence score-weighted integrands.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/dot-QUAD_NODES_VERIFICATION.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Default Quadrature Nodes for Verification ‚Äî .QUAD_NODES_VERIFICATION","text":"","code":".QUAD_NODES_VERIFICATION"},{"path":"https://joonho112.github.io/DPprior/reference/dot-QUAD_NODES_VERIFICATION.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Default Quadrature Nodes for Verification ‚Äî .QUAD_NODES_VERIFICATION","text":"object class integer length 1.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/dot-TOL_NEWTON.html","id":null,"dir":"Reference","previous_headings":"","what":"Newton Method Convergence Tolerance ‚Äî .TOL_NEWTON","title":"Newton Method Convergence Tolerance ‚Äî .TOL_NEWTON","text":"Convergence tolerance Newton's method moment matching.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/dot-TOL_NEWTON.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Newton Method Convergence Tolerance ‚Äî .TOL_NEWTON","text":"","code":".TOL_NEWTON"},{"path":"https://joonho112.github.io/DPprior/reference/dot-TOL_NEWTON.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Newton Method Convergence Tolerance ‚Äî .TOL_NEWTON","text":"object class numeric length 1.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/dot-TOL_PROJECTION_BUFFER.html","id":null,"dir":"Reference","previous_headings":"","what":"Feasibility Projection Buffer ‚Äî .TOL_PROJECTION_BUFFER","title":"Feasibility Projection Buffer ‚Äî .TOL_PROJECTION_BUFFER","text":"Small buffer projecting feasible region negative binomial approximation.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/dot-TOL_PROJECTION_BUFFER.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Feasibility Projection Buffer ‚Äî .TOL_PROJECTION_BUFFER","text":"","code":".TOL_PROJECTION_BUFFER"},{"path":"https://joonho112.github.io/DPprior/reference/dot-TOL_PROJECTION_BUFFER.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Feasibility Projection Buffer ‚Äî .TOL_PROJECTION_BUFFER","text":"object class numeric length 1.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/dot-a2_kl_compute_kl.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute KL Divergence from Target to Induced PMF ‚Äî .a2_kl_compute_kl","title":"Compute KL Divergence from Target to Induced PMF ‚Äî .a2_kl_compute_kl","text":"Compute KL Divergence Target Induced PMF","code":""},{"path":"https://joonho112.github.io/DPprior/reference/dot-a2_kl_compute_kl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute KL Divergence from Target to Induced PMF ‚Äî .a2_kl_compute_kl","text":"","code":".a2_kl_compute_kl(target_pmf, induced_pmf, eps = 1e-15)"},{"path":"https://joonho112.github.io/DPprior/reference/dot-a2_kl_compute_kl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute KL Divergence from Target to Induced PMF ‚Äî .a2_kl_compute_kl","text":"target_pmf Numeric vector; normalized PMF (length J). induced_pmf Numeric vector; normalized induced PMF (length J). eps Numeric; small constant avoid log(0).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/dot-a2_kl_compute_kl.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute KL Divergence from Target to Induced PMF ‚Äî .a2_kl_compute_kl","text":"Numeric; KL divergence (non-negative).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/dot-a2_kl_induced_pmf.html","id":null,"dir":"Reference","previous_headings":"","what":"Induced Marginal PMF of K_J under alpha ~ Gamma(a, b) ‚Äî .a2_kl_induced_pmf","title":"Induced Marginal PMF of K_J under alpha ~ Gamma(a, b) ‚Äî .a2_kl_induced_pmf","text":"Induced Marginal PMF K_J alpha ~ Gamma(, b)","code":""},{"path":"https://joonho112.github.io/DPprior/reference/dot-a2_kl_induced_pmf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Induced Marginal PMF of K_J under alpha ~ Gamma(a, b) ‚Äî .a2_kl_induced_pmf","text":"","code":".a2_kl_induced_pmf(J, a, b, logS, M)"},{"path":"https://joonho112.github.io/DPprior/reference/dot-a2_kl_induced_pmf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Induced Marginal PMF of K_J under alpha ~ Gamma(a, b) ‚Äî .a2_kl_induced_pmf","text":"J Integer; sample size. , b Gamma hyperparameters. logS Matrix; log-Stirling numbers (compute_log_stirling(J)). M Quadrature nodes.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/dot-a2_kl_induced_pmf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Induced Marginal PMF of K_J under alpha ~ Gamma(a, b) ‚Äî .a2_kl_induced_pmf","text":"Numeric vector length J; PMF k = 1,...,J.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/dot-a2_kl_normalize_pmf.html","id":null,"dir":"Reference","previous_headings":"","what":"Normalize and Validate a Target PMF on {1, ..., J} ‚Äî .a2_kl_normalize_pmf","title":"Normalize and Validate a Target PMF on {1, ..., J} ‚Äî .a2_kl_normalize_pmf","text":"Normalize Validate Target PMF {1, ..., J}","code":""},{"path":"https://joonho112.github.io/DPprior/reference/dot-a2_kl_normalize_pmf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Normalize and Validate a Target PMF on {1, ..., J} ‚Äî .a2_kl_normalize_pmf","text":"","code":".a2_kl_normalize_pmf(target_pmf, J)"},{"path":"https://joonho112.github.io/DPprior/reference/dot-a2_kl_normalize_pmf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Normalize and Validate a Target PMF on {1, ..., J} ‚Äî .a2_kl_normalize_pmf","text":"target_pmf Numeric vector; unnormalized target PMF. J Integer; sample size.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/dot-a2_kl_normalize_pmf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Normalize and Validate a Target PMF on {1, ..., J} ‚Äî .a2_kl_normalize_pmf","text":"Numeric vector; normalized PMF length J (support k=1,...,J).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/dot-check_logS_size.html","id":null,"dir":"Reference","previous_headings":"","what":"Validate Precomputed Log-Stirling Matrix Size ‚Äî .check_logS_size","title":"Validate Precomputed Log-Stirling Matrix Size ‚Äî .check_logS_size","text":"Checks log-Stirling matrix properly formatted large enough given sample size J.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/dot-check_logS_size.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Validate Precomputed Log-Stirling Matrix Size ‚Äî .check_logS_size","text":"","code":".check_logS_size(J, logS)"},{"path":"https://joonho112.github.io/DPprior/reference/dot-check_logS_size.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Validate Precomputed Log-Stirling Matrix Size ‚Äî .check_logS_size","text":"J Sample size (integer >= 1). logS Pre-computed log-Stirling matrix compute_log_stirling().","code":""},{"path":"https://joonho112.github.io/DPprior/reference/dot-check_logS_size.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Validate Precomputed Log-Stirling Matrix Size ‚Äî .check_logS_size","text":"Invisible TRUE validation passes.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/dot-dpprior_base_dual_comparison.html","id":null,"dir":"Reference","previous_headings":"","what":"Base R dual comparison fallback ‚Äî .dpprior_base_dual_comparison","title":"Base R dual comparison fallback ‚Äî .dpprior_base_dual_comparison","text":"Base R dual comparison fallback","code":""},{"path":"https://joonho112.github.io/DPprior/reference/dot-dpprior_base_dual_comparison.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Base R dual comparison fallback ‚Äî .dpprior_base_dual_comparison","text":"","code":".dpprior_base_dual_comparison(a_K, b_K, a_dual, b_dual, J, lambda, title)"},{"path":"https://joonho112.github.io/DPprior/reference/dot-dpprior_compute_summary.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Summary Statistics ‚Äî .dpprior_compute_summary","title":"Compute Summary Statistics ‚Äî .dpprior_compute_summary","text":"Compute Summary Statistics","code":""},{"path":"https://joonho112.github.io/DPprior/reference/dot-dpprior_compute_summary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Summary Statistics ‚Äî .dpprior_compute_summary","text":"","code":".dpprior_compute_summary(   fit = NULL,   a = NULL,   b = NULL,   J = NULL,   ci_level = 0.95 )"},{"path":"https://joonho112.github.io/DPprior/reference/dot-dpprior_dashboard_gtable.html","id":null,"dir":"Reference","previous_headings":"","what":"Create Dashboard using gtable (no patchwork needed) ‚Äî .dpprior_dashboard_gtable","title":"Create Dashboard using gtable (no patchwork needed) ‚Äî .dpprior_dashboard_gtable","text":"Create Dashboard using gtable (patchwork needed)","code":""},{"path":"https://joonho112.github.io/DPprior/reference/dot-dpprior_dashboard_gtable.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create Dashboard using gtable (no patchwork needed) ‚Äî .dpprior_dashboard_gtable","text":"","code":".dpprior_dashboard_gtable(p1, p2, p3, p4, title = NULL)"},{"path":"https://joonho112.github.io/DPprior/reference/dot-dpprior_dual_comparison_table.html","id":null,"dir":"Reference","previous_headings":"","what":"Dual comparison summary table ‚Äî .dpprior_dual_comparison_table","title":"Dual comparison summary table ‚Äî .dpprior_dual_comparison_table","text":"Dual comparison summary table","code":""},{"path":"https://joonho112.github.io/DPprior/reference/dot-dpprior_dual_comparison_table.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dual comparison summary table ‚Äî .dpprior_dual_comparison_table","text":"","code":".dpprior_dual_comparison_table(   a_K,   b_K,   a_dual,   b_dual,   J,   dual_info,   base_size = 11 )"},{"path":"https://joonho112.github.io/DPprior/reference/dot-dpprior_get_K_pmf.html","id":null,"dir":"Reference","previous_headings":"","what":"Hierarchical K PMF Computation with Fallbacks ‚Äî .dpprior_get_K_pmf","title":"Hierarchical K PMF Computation with Fallbacks ‚Äî .dpprior_get_K_pmf","text":"Hierarchical K PMF Computation Fallbacks","code":""},{"path":"https://joonho112.github.io/DPprior/reference/dot-dpprior_get_K_pmf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hierarchical K PMF Computation with Fallbacks ‚Äî .dpprior_get_K_pmf","text":"","code":".dpprior_get_K_pmf(J, a, b, M = NULL)"},{"path":"https://joonho112.github.io/DPprior/reference/dot-dpprior_is_dual.html","id":null,"dir":"Reference","previous_headings":"","what":"Check if Fit is from Dual-Anchor Calibration ‚Äî .dpprior_is_dual","title":"Check if Fit is from Dual-Anchor Calibration ‚Äî .dpprior_is_dual","text":"Checks whether DPprior_fit object originated DPprior_dual(). stricter check ensures dual_anchor component expected structure.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/dot-dpprior_is_dual.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check if Fit is from Dual-Anchor Calibration ‚Äî .dpprior_is_dual","text":"","code":".dpprior_is_dual(fit)"},{"path":"https://joonho112.github.io/DPprior/reference/dot-dpprior_is_dual.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check if Fit is from Dual-Anchor Calibration ‚Äî .dpprior_is_dual","text":"fit DPprior_fit object.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/dot-dpprior_is_dual.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check if Fit is from Dual-Anchor Calibration ‚Äî .dpprior_is_dual","text":"Logical; TRUE dual-anchor fit valid structure.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/dot-dpprior_summary_table_plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary Table Plot ‚Äî .dpprior_summary_table_plot","title":"Summary Table Plot ‚Äî .dpprior_summary_table_plot","text":"Summary Table Plot","code":""},{"path":"https://joonho112.github.io/DPprior/reference/dot-dpprior_summary_table_plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary Table Plot ‚Äî .dpprior_summary_table_plot","text":"","code":".dpprior_summary_table_plot(fit, base_size = 11, ci_level = 0.95)"},{"path":"https://joonho112.github.io/DPprior/reference/dot-get_K_pmf_support.html","id":null,"dir":"Reference","previous_headings":"","what":"Get K_J PMF via pmf_K_marginal ‚Äî .get_K_pmf_support","title":"Get K_J PMF via pmf_K_marginal ‚Äî .get_K_pmf_support","text":"Internal helper computes marginal PMF K_J using pmf_K_marginal() Stirling numbers.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/dot-get_K_pmf_support.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get K_J PMF via pmf_K_marginal ‚Äî .get_K_pmf_support","text":"","code":".get_K_pmf_support(J, a, b, M = .QUAD_NODES_DEFAULT)"},{"path":"https://joonho112.github.io/DPprior/reference/dot-get_K_pmf_support.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get K_J PMF via pmf_K_marginal ‚Äî .get_K_pmf_support","text":"J Integer; sample size. , b Numeric; Gamma hyperparameters. M Integer; quadrature nodes.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/dot-get_K_pmf_support.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get K_J PMF via pmf_K_marginal ‚Äî .get_K_pmf_support","text":"List pmf (numeric vector) support (integer vector).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/dual_anchor_diagnostics.html","id":null,"dir":"Reference","previous_headings":"","what":"Dual-Anchor Diagnostic Comparison ‚Äî dual_anchor_diagnostics","title":"Dual-Anchor Diagnostic Comparison ‚Äî dual_anchor_diagnostics","text":"Dual-Anchor Diagnostic Comparison","code":""},{"path":"https://joonho112.github.io/DPprior/reference/dual_anchor_diagnostics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dual-Anchor Diagnostic Comparison ‚Äî dual_anchor_diagnostics","text":"","code":"dual_anchor_diagnostics(fit_dual, fit_K_only = NULL, M = .QUAD_NODES_DEFAULT)"},{"path":"https://joonho112.github.io/DPprior/reference/dual_anchor_diagnostics.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Dual-Anchor Diagnostic Comparison ‚Äî dual_anchor_diagnostics","text":"fit_dual Dual-anchor DPprior_fit object. fit_K_only Optional K-DPprior_fit object. M Integer; quadrature nodes.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/dual_anchor_diagnostics.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Dual-Anchor Diagnostic Comparison ‚Äî dual_anchor_diagnostics","text":"Data frame comparing metrics.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/dual_anchor_diagnostics.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Dual-Anchor Diagnostic Comparison ‚Äî dual_anchor_diagnostics","text":"Lee, J. (2026). Design-Conditional Prior Elicitation Dirichlet Process Mixtures. arXiv preprint arXiv:2602.06301.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/dual_anchor_loss.html","id":null,"dir":"Reference","previous_headings":"","what":"Dual-Anchor Loss Function ‚Äî dual_anchor_loss","title":"Dual-Anchor Loss Function ‚Äî dual_anchor_loss","text":"Computes combined loss K_J first-weight targets used dual-anchor calibration framework.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/dual_anchor_loss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dual-Anchor Loss Function ‚Äî dual_anchor_loss","text":"","code":"dual_anchor_loss(   a,   b,   J,   K_target,   w1_target,   lambda,   M = .QUAD_NODES_DEFAULT,   loss_type = c(\"relative\", \"adaptive\", \"absolute\"),   L_K_scale = NULL,   L_w_scale = NULL )"},{"path":"https://joonho112.github.io/DPprior/reference/dual_anchor_loss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Dual-Anchor Loss Function ‚Äî dual_anchor_loss","text":"Numeric; shape parameter Gamma prior (> 0). b Numeric; rate parameter Gamma prior (b > 0). J Integer; sample size. K_target List components mu_K var_K. w1_target List specifying first-weight target (quantile, prob, mean). lambda Numeric value 0 1; weight K_J loss component. M Integer; number Gauss-Laguerre quadrature nodes. loss_type Character; type loss scaling: \"relative\" (DEFAULT) Normalized squared errors - losses dimensionless comparable. RECOMMENDED cases. \"adaptive\" Scaled initial loss magnitudes - gives aggressive weight reduction. Use lambda=0.5 truly mean \"equal importance\". \"absolute\" Legacy behavior - RECOMMENDED, causes optimizer essentially ignore weight constraint. L_K_scale, L_w_scale Numeric; scaling factors adaptive loss. used loss_type = \"adaptive\". NULL, computed internally.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/dual_anchor_loss.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Dual-Anchor Loss Function ‚Äî dual_anchor_loss","text":"Numeric; combined loss value.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/dual_anchor_loss.html","id":"loss-scaling-comparison","dir":"Reference","previous_headings":"","what":"Loss Scaling Comparison","title":"Dual-Anchor Loss Function ‚Äî dual_anchor_loss","text":"typical K-solution \\(P(w_1 > 0.5)\\) approximately 0.48, target = 0.30: ABSOLUTE: L_K approximately 0, L_w approximately 0.03. move causes L_K >> L_w. Optimizer stays K-. BROKEN. RELATIVE: L_K_rel approximately 0, L_w approximately 0.03. dimensionless. lambda = 0.5 gives approximately 9 percent reduction \\(P(w_1 > 0.5)\\). ADAPTIVE: Losses normalized initial magnitudes. lambda = 0.5 gives approximately 18 percent reduction \\(P(w_1 > 0.5)\\).","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/dvar_dalpha.html","id":null,"dir":"Reference","previous_headings":"","what":"Derivative of Conditional Variance w.r.t. Alpha ‚Äî dvar_dalpha","title":"Derivative of Conditional Variance w.r.t. Alpha ‚Äî dvar_dalpha","text":"Computes \\(\\frac{d}{d\\alpha} \\mathrm{Var}(K_J \\mid \\alpha)\\).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/dvar_dalpha.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Derivative of Conditional Variance w.r.t. Alpha ‚Äî dvar_dalpha","text":"","code":"dvar_dalpha(J, alpha)"},{"path":"https://joonho112.github.io/DPprior/reference/dvar_dalpha.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Derivative of Conditional Variance w.r.t. Alpha ‚Äî dvar_dalpha","text":"J Sample size (integer >= 1). alpha Concentration parameter (positive numeric, vectorized).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/dvar_dalpha.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Derivative of Conditional Variance w.r.t. Alpha ‚Äî dvar_dalpha","text":"Numeric vector derivatives (length alpha).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/dvar_dalpha.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Derivative of Conditional Variance w.r.t. Alpha ‚Äî dvar_dalpha","text":"Uses summation form: $$\\frac{d}{d\\alpha} v_J(\\alpha) = \\sum_{r=1}^{J-1} \\frac{r(r - \\alpha)}{(\\alpha + r)^3}$$ derivative can positive negative depending \\(\\alpha\\).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/exact_K_moments.html","id":null,"dir":"Reference","previous_headings":"","what":"Exact Marginal Moments of K_J under Gamma Prior ‚Äî exact_K_moments","title":"Exact Marginal Moments of K_J under Gamma Prior ‚Äî exact_K_moments","text":"Computes exact marginal mean \\(E[K_J]\\) variance \\(Var(K_J)\\) DP concentration parameter follows Gamma(, b) prior.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/exact_K_moments.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Exact Marginal Moments of K_J under Gamma Prior ‚Äî exact_K_moments","text":"","code":"exact_K_moments(J, a, b, M = .QUAD_NODES_DEFAULT)"},{"path":"https://joonho112.github.io/DPprior/reference/exact_K_moments.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Exact Marginal Moments of K_J under Gamma Prior ‚Äî exact_K_moments","text":"J Integer; sample size (positive integer >= 1). Numeric; shape parameter Gamma prior (> 0). b Numeric; rate parameter Gamma prior (> 0). M Integer; number quadrature nodes (default: 80).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/exact_K_moments.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Exact Marginal Moments of K_J under Gamma Prior ‚Äî exact_K_moments","text":"named list components: mean Marginal mean \\(E[K_J | , b]\\) var Marginal variance \\(Var(K_J | , b)\\) sd Marginal standard deviation cv Coefficient variation (sd/mean)","code":""},{"path":"https://joonho112.github.io/DPprior/reference/exact_K_moments.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Exact Marginal Moments of K_J under Gamma Prior ‚Äî exact_K_moments","text":"Uses Gauss-Laguerre quadrature numerically evaluate: $$M_1(,b) = E_{\\alpha \\sim \\Gamma(,b)}[\\mu_J(\\alpha)]$$ $$V(,b) = E[v_J(\\alpha)] + E[\\mu_J(\\alpha)^2] - M_1^2$$ \\(\\mu_J(\\alpha)\\) \\(v_J(\\alpha)\\) conditional mean variance Module 03. Law Total Variance decomposes marginal variance : Within-alpha variance: \\(E[v_J(\\alpha)]\\) -alpha variance: \\(Var(\\mu_J(\\alpha))\\) Key properties: mean bounded: \\(1 \\leq E[K_J] \\leq J\\) Despite conditional underdispersion (\\(v_J(\\alpha) < \\mu_J(\\alpha)\\)), marginal distribution typically overdispersed Marginal variance exceeds conditional variance \\(\\alpha = E[\\alpha]\\)","code":""},{"path":"https://joonho112.github.io/DPprior/reference/exact_K_moments.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Exact Marginal Moments of K_J under Gamma Prior ‚Äî exact_K_moments","text":"Antoniak, C. E. (1974). Mixtures Dirichlet Processes. Annals Statistics, 2(6), 1152-1174.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/exact_K_moments.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Exact Marginal Moments of K_J under Gamma Prior ‚Äî exact_K_moments","text":"","code":"# Example: J=50, Gamma(1.5, 0.5) prior result <- exact_K_moments(50, 1.5, 0.5) print(result) #> $mean #> [1] 8.355487 #>  #> $var #> [1] 22.76895 #>  #> $sd #> [1] 4.771682 #>  #> $cv #> [1] 0.5710837 #>   # Compare with conditional variance at E[alpha] = 3 cond_var <- var_K_given_alpha(50, 3.0) result$var > cond_var  # TRUE: marginal > conditional #> [1] TRUE  # Verify mean bounds 1 <= result$mean && result$mean <= 50  # TRUE #> [1] TRUE"},{"path":"https://joonho112.github.io/DPprior/reference/expected_tv_bound.html","id":null,"dir":"Reference","previous_headings":"","what":"Expected TV Bound Under Gamma Prior ‚Äî expected_tv_bound","title":"Expected TV Bound Under Gamma Prior ‚Äî expected_tv_bound","text":"Integrates conditional TV bound \\(\\alpha \\sim \\text{Gamma}(, b)\\) obtain marginal error bound.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/expected_tv_bound.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Expected TV Bound Under Gamma Prior ‚Äî expected_tv_bound","text":"","code":"expected_tv_bound(J, a, b, cJ = log(J), M = .QUAD_NODES_DEFAULT)"},{"path":"https://joonho112.github.io/DPprior/reference/expected_tv_bound.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Expected TV Bound Under Gamma Prior ‚Äî expected_tv_bound","text":"J Integer; sample size. , b Numeric; Gamma hyperparameters. cJ Numeric; scaling constant (default: log(J)). M Integer; number quadrature nodes.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/expected_tv_bound.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Expected TV Bound Under Gamma Prior ‚Äî expected_tv_bound","text":"Numeric; \\(E[d_{TV} \\text{ bound} | , b]\\).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/expected_tv_bound.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Expected TV Bound Under Gamma Prior ‚Äî expected_tv_bound","text":"Lee (2026, Section 3.3, Corollary 1), TV error exact prior predictive \\(p(S_J | , b)\\) A1 shifted NegBin proxy bounded : $$d_{TV}(P^{\\text{exact}}, Q^{A1}) \\le E_{\\alpha \\sim \\Gamma(,b)}[B_{\\text{Pois}} + B_{\\text{lin}}]$$ follows mixture contraction property TV distance.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/expected_tv_bound.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Expected TV Bound Under Gamma Prior ‚Äî expected_tv_bound","text":"","code":"if (FALSE) { # \\dontrun{ # Marginal TV bound for J=100, Gamma(1, 1) expected_tv_bound(J = 100, a = 1, b = 1)  } # }"},{"path":"https://joonho112.github.io/DPprior/reference/find_a1_threshold_J.html","id":null,"dir":"Reference","previous_headings":"","what":"Find Threshold J for A1 Adequacy ‚Äî find_a1_threshold_J","title":"Find Threshold J for A1 Adequacy ‚Äî find_a1_threshold_J","text":"Determines minimum sample size J A1 approximation achieves target accuracy moment matching.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/find_a1_threshold_J.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find Threshold J for A1 Adequacy ‚Äî find_a1_threshold_J","text":"","code":"find_a1_threshold_J(   a,   b,   target_error = 0.05,   target_var_error = NULL,   J_min = 10,   J_max = 500,   step = 10 )"},{"path":"https://joonho112.github.io/DPprior/reference/find_a1_threshold_J.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find Threshold J for A1 Adequacy ‚Äî find_a1_threshold_J","text":", b Numeric; Gamma hyperparameters. target_error Numeric; target relative error mean (default: 5%). target_var_error Numeric; target relative error variance (default: 2 * target_error). J_min, J_max Integer; search range J. step Integer; step size search.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/find_a1_threshold_J.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find Threshold J for A1 Adequacy ‚Äî find_a1_threshold_J","text":"Integer; minimum J achieving target accuracy, NA found.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/find_a1_threshold_J.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Find Threshold J for A1 Adequacy ‚Äî find_a1_threshold_J","text":"Searches J values find smallest J : Mean relative error < target_error Variance relative error < target_var_error Note: many parameter combinations, especially high \\(E[\\alpha]\\), A1 approximation may never achieve low errors within practical J ranges. cases, A2 refinement recommended.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/find_a1_threshold_J.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Find Threshold J for A1 Adequacy ‚Äî find_a1_threshold_J","text":"","code":"if (FALSE) { # \\dontrun{ # Find threshold for 5% mean error find_a1_threshold_J(a = 1, b = 2)  # For higher E[alpha], threshold may not exist find_a1_threshold_J(a = 2, b = 1)  # Likely returns NA } # }"},{"path":"https://joonho112.github.io/DPprior/reference/gauss_laguerre_nodes.html","id":null,"dir":"Reference","previous_headings":"","what":"Gauss-Laguerre Quadrature Nodes and Weights ‚Äî gauss_laguerre_nodes","title":"Gauss-Laguerre Quadrature Nodes and Weights ‚Äî gauss_laguerre_nodes","text":"Computes generalized Gauss-Laguerre quadrature nodes weights via eigendecomposition Jacobi matrix. used approximate integrals form \\(\\int_0^\\infty f(x) x^\\beta e^{-x} dx\\).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/gauss_laguerre_nodes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gauss-Laguerre Quadrature Nodes and Weights ‚Äî gauss_laguerre_nodes","text":"","code":"gauss_laguerre_nodes(M, alpha_param = 0)"},{"path":"https://joonho112.github.io/DPprior/reference/gauss_laguerre_nodes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gauss-Laguerre Quadrature Nodes and Weights ‚Äî gauss_laguerre_nodes","text":"M Integer; number quadrature nodes (least 1, typically 40-120). alpha_param Numeric; Laguerre parameter (must > -1). standard Laguerre polynomials, use 0. integrating Gamma(, b), use alpha_param = - 1.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/gauss_laguerre_nodes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gauss-Laguerre Quadrature Nodes and Weights ‚Äî gauss_laguerre_nodes","text":"list components: nodes Numeric vector quadrature nodes \\(x_m\\). weights Numeric vector quadrature weights \\(w_m\\). weights_log Numeric vector \\(\\log(w_m)\\) numerical stability.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/gauss_laguerre_nodes.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Gauss-Laguerre Quadrature Nodes and Weights ‚Äî gauss_laguerre_nodes","text":"algorithm constructs tridiagonal Jacobi matrix \\(J\\) size \\(M \\times M\\): Diagonal: \\(a_k = 2k + 1 + \\alpha\\) \\(k = 0, \\ldots, M-1\\) -diagonal: \\(b_k = \\sqrt{k(k + \\alpha)}\\) \\(k = 1, \\ldots, M-1\\) Eigendecomposition \\(J = V D V^T\\) yields: Nodes = eigenvalues (diagonal \\(D\\)) Weights = \\(\\Gamma(\\alpha + 1) \\cdot V[1,:]^2\\) generalized Laguerre polynomials \\(L_n^{(\\alpha)}(x)\\) orthogonal respect weight function \\(w(x) = x^\\alpha e^{-x}\\) \\([0, \\infty)\\).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/gauss_laguerre_nodes.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Gauss-Laguerre Quadrature Nodes and Weights ‚Äî gauss_laguerre_nodes","text":"Golub, G. H., & Welsch, J. H. (1969). Calculation Gauss Quadrature Rules. Mathematics Computation, 23(106), 221-230.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/gauss_laguerre_nodes.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Gauss-Laguerre Quadrature Nodes and Weights ‚Äî gauss_laguerre_nodes","text":"","code":"# Standard Laguerre (alpha_param = 0) quad <- gauss_laguerre_nodes(40) sum(quad$weights)  # Should equal Gamma(1) = 1 #> [1] 1  # For Gamma(2.5, b) integration, use alpha_param = 1.5 quad <- gauss_laguerre_nodes(80, alpha_param = 1.5) sum(quad$weights)  # Should equal Gamma(2.5) #> [1] 1.32934"},{"path":"https://joonho112.github.io/DPprior/reference/get_log_stirling.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Single Log-Stirling Value with Bounds Checking ‚Äî get_log_stirling","title":"Get Single Log-Stirling Value with Bounds Checking ‚Äî get_log_stirling","text":"Safe accessor log-Stirling matrix automatic bounds checking. Returns -Inf invalid indices (k > J, k < 1).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/get_log_stirling.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Single Log-Stirling Value with Bounds Checking ‚Äî get_log_stirling","text":"","code":"get_log_stirling(J, k, logS)"},{"path":"https://joonho112.github.io/DPprior/reference/get_log_stirling.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Single Log-Stirling Value with Bounds Checking ‚Äî get_log_stirling","text":"J Sample size (non-negative integer). k Number clusters (integer). logS Pre-computed log-Stirling matrix compute_log_stirling.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/get_log_stirling.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Single Log-Stirling Value with Bounds Checking ‚Äî get_log_stirling","text":"value \\(\\log|s(J,k)|\\), -Inf k > J k < 1.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/get_log_stirling.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get Single Log-Stirling Value with Bounds Checking ‚Äî get_log_stirling","text":"","code":"if (FALSE) { # \\dontrun{ logS <- compute_log_stirling(10)  # Valid access get_log_stirling(4, 2, logS)  # Invalid access returns -Inf get_log_stirling(4, 5, logS) get_log_stirling(4, 0, logS)  } # }"},{"path":"https://joonho112.github.io/DPprior/reference/get_stirling_row.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Stirling Numbers for a Fixed J ‚Äî get_stirling_row","title":"Get Stirling Numbers for a Fixed J ‚Äî get_stirling_row","text":"Returns vector \\(\\log|s(J,k)|\\) \\(k = 1, \\ldots, J\\).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/get_stirling_row.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Stirling Numbers for a Fixed J ‚Äî get_stirling_row","text":"","code":"get_stirling_row(J, logS)"},{"path":"https://joonho112.github.io/DPprior/reference/get_stirling_row.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Stirling Numbers for a Fixed J ‚Äî get_stirling_row","text":"J Sample size (positive integer). logS Pre-computed log-Stirling matrix compute_log_stirling.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/get_stirling_row.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Stirling Numbers for a Fixed J ‚Äî get_stirling_row","text":"Numeric vector length J containing \\(\\log|s(J,k)|\\) \\(k = 1, \\ldots, J\\).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/get_stirling_row.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get Stirling Numbers for a Fixed J ‚Äî get_stirling_row","text":"","code":"if (FALSE) { # \\dontrun{ logS <- compute_log_stirling(10) log_s_row <- get_stirling_row(5, logS) exp(log_s_row)  } # }"},{"path":"https://joonho112.github.io/DPprior/reference/integrate_gamma.html","id":null,"dir":"Reference","previous_headings":"","what":"Integrate Function Against Gamma Distribution ‚Äî integrate_gamma","title":"Integrate Function Against Gamma Distribution ‚Äî integrate_gamma","text":"High-level interface computing \\(E[f(\\alpha)]\\) \\(\\alpha \\sim \\text{Gamma}(, b)\\).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/integrate_gamma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Integrate Function Against Gamma Distribution ‚Äî integrate_gamma","text":"","code":"integrate_gamma(f, a, b, M = .QUAD_NODES_DEFAULT)"},{"path":"https://joonho112.github.io/DPprior/reference/integrate_gamma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Integrate Function Against Gamma Distribution ‚Äî integrate_gamma","text":"f Function integrate; must accept single numeric argument return single numeric value. Numeric; shape parameter Gamma distribution (must > 0). b Numeric; rate parameter Gamma distribution (must > 0). M Integer; number quadrature nodes (default: 80).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/integrate_gamma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Integrate Function Against Gamma Distribution ‚Äî integrate_gamma","text":"Numeric; approximation \\(E[f(\\alpha)]\\).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/integrate_gamma.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Integrate Function Against Gamma Distribution ‚Äî integrate_gamma","text":"Uses Gauss-Laguerre quadrature approximate: $$E[f(\\alpha)] = \\int_0^\\infty f(\\alpha) \\frac{b^}{\\Gamma()} \\alpha^{-1} e^{-b\\alpha} d\\alpha$$ approximation : $$E[f(\\alpha)] \\approx \\sum_{m=1}^M w_m f(\\alpha_m)$$ \\(\\alpha_m\\) quadrature nodes \\(w_m\\) normalized weights. polynomial integrands degree \\(2M - 1\\), quadrature exact. smooth functions, accuracy improves rapidly \\(M\\).","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/integrate_gamma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Integrate Function Against Gamma Distribution ‚Äî integrate_gamma","text":"","code":"# E[alpha] for Gamma(2.5, 1.5) should be 2.5/1.5 integrate_gamma(identity, 2.5, 1.5) #> [1] 1.666667  # E[alpha^2] for Gamma(2.5, 1.5) should be 2.5*3.5/1.5^2 integrate_gamma(function(x) x^2, 2.5, 1.5) #> [1] 3.888889  # More complex function integrate_gamma(function(x) log(x + 1), 2.5, 1.5) #> [1] 0.9102673"},{"path":"https://joonho112.github.io/DPprior/reference/kl_divergence_K.html","id":null,"dir":"Reference","previous_headings":"","what":"KL Divergence Between Target and Induced K_J PMFs ‚Äî kl_divergence_K","title":"KL Divergence Between Target and Induced K_J PMFs ‚Äî kl_divergence_K","text":"Computes KL divergence \\(D_{KL}(p^* \\| p_{,b})\\) target PMF induced marginal PMF \\(K_J\\) \\(\\alpha \\sim Gamma(, b)\\).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/kl_divergence_K.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"KL Divergence Between Target and Induced K_J PMFs ‚Äî kl_divergence_K","text":"","code":"kl_divergence_K(target_pmf, a, b, J, M = .QUAD_NODES_DEFAULT)"},{"path":"https://joonho112.github.io/DPprior/reference/kl_divergence_K.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"KL Divergence Between Target and Induced K_J PMFs ‚Äî kl_divergence_K","text":"target_pmf Numeric vector; target PMF K_J. Can length J (support k=1,...,J) J+1 (support k=0,...,J, k=0 ignored). Numeric; shape parameter Gamma hyperprior (> 0). b Numeric; rate parameter Gamma hyperprior (b > 0). J Integer; sample size. M Integer; number quadrature nodes. Default: 80.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/kl_divergence_K.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"KL Divergence Between Target and Induced K_J PMFs ‚Äî kl_divergence_K","text":"Numeric scalar; \\(D_{KL}(p^* \\| p_{,b})\\) (non-negative).","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/kl_divergence_K.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"KL Divergence Between Target and Induced K_J PMFs ‚Äî kl_divergence_K","text":"","code":"J <- 50 target <- rep(1/J, J)  # uniform target over k=1,...,J kl_divergence_K(target, a = 2, b = 1, J = J) #> [1] 10.49288"},{"path":"https://joonho112.github.io/DPprior/reference/kl_divergence_pmf.html","id":null,"dir":"Reference","previous_headings":"","what":"KL Divergence Between Two PMFs ‚Äî kl_divergence_pmf","title":"KL Divergence Between Two PMFs ‚Äî kl_divergence_pmf","text":"Computes Kullback-Leibler divergence \\(D_{KL}(p \\| q)\\) two probability mass functions.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/kl_divergence_pmf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"KL Divergence Between Two PMFs ‚Äî kl_divergence_pmf","text":"","code":"kl_divergence_pmf(p, q, eps = 1e-15)"},{"path":"https://joonho112.github.io/DPprior/reference/kl_divergence_pmf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"KL Divergence Between Two PMFs ‚Äî kl_divergence_pmf","text":"p Numeric vector; target PMF (reference distribution). q Numeric vector; comparison PMF. eps Numeric; small value prevent log(0). Default: 1e-15.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/kl_divergence_pmf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"KL Divergence Between Two PMFs ‚Äî kl_divergence_pmf","text":"Numeric scalar; KL divergence (non-negative).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/kl_divergence_pmf.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"KL Divergence Between Two PMFs ‚Äî kl_divergence_pmf","text":"KL divergence defined : $$D_{KL}(p \\| q) = \\sum_k p(k) \\log\\frac{p(k)}{q(k)}$$ indices \\(p(k) > \\epsilon\\) included sum. Properties: \\(D_{KL}(p \\| q) \\geq 0\\) equality iff \\(p = q\\) symmetric: \\(D_{KL}(p \\| q) \\neq D_{KL}(q \\| p)\\)","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/kl_divergence_pmf.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"KL Divergence Between Two PMFs ‚Äî kl_divergence_pmf","text":"","code":"p <- c(0.2, 0.5, 0.3) kl_divergence_pmf(p, p)  # 0 #> [1] 0  q <- c(0.3, 0.4, 0.3) kl_divergence_pmf(p, q) #> [1] 0.03047875"},{"path":"https://joonho112.github.io/DPprior/reference/log_pmf_K_given_alpha.html","id":null,"dir":"Reference","previous_headings":"","what":"Log-PMF of K Given Alpha (Antoniak Distribution) ‚Äî log_pmf_K_given_alpha","title":"Log-PMF of K Given Alpha (Antoniak Distribution) ‚Äî log_pmf_K_given_alpha","text":"Computes \\(\\log P(K_J = k \\mid \\alpha)\\) \\(k = 0, 1, \\ldots, J\\).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/log_pmf_K_given_alpha.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Log-PMF of K Given Alpha (Antoniak Distribution) ‚Äî log_pmf_K_given_alpha","text":"","code":"log_pmf_K_given_alpha(J, alpha, logS)"},{"path":"https://joonho112.github.io/DPprior/reference/log_pmf_K_given_alpha.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Log-PMF of K Given Alpha (Antoniak Distribution) ‚Äî log_pmf_K_given_alpha","text":"J Integer; sample size (number observations, must >= 1). alpha Numeric; DP concentration parameter (must positive scalar). logS Matrix; pre-computed log-Stirling matrix compute_log_stirling.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/log_pmf_K_given_alpha.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Log-PMF of K Given Alpha (Antoniak Distribution) ‚Äî log_pmf_K_given_alpha","text":"Numeric vector length \\(J+1\\) containing \\(\\log P(K_J = k \\mid \\alpha)\\) \\(k = 0, 1, \\ldots, J\\). Note entry [1] corresponds \\(k=0\\) always equals -Inf (since \\(P(K_J = 0) = 0\\)).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/log_pmf_K_given_alpha.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Log-PMF of K Given Alpha (Antoniak Distribution) ‚Äî log_pmf_K_given_alpha","text":"Uses Antoniak distribution formula log-space: $$\\log P(K_J = k \\mid \\alpha) = \\log|s(J,k)| + k\\log\\alpha - \\log(\\alpha)_J$$ \\(|s(J,k)|\\) unsigned Stirling number first kind \\((\\alpha)_J\\) rising factorial. log-space computation numerically stable large \\(J\\) direct computation overflow.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/log_pmf_K_given_alpha.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Log-PMF of K Given Alpha (Antoniak Distribution) ‚Äî log_pmf_K_given_alpha","text":"","code":"logS <- compute_log_stirling(50) log_pmf <- log_pmf_K_given_alpha(50, 2.0, logS)  # Convert to probabilities (numerically stable softmax) pmf <- exp(log_pmf - max(log_pmf)) pmf <- pmf / sum(pmf) sum(pmf)  # Should be 1 #> [1] 1  # Or use pmf_K_given_alpha() directly pmf2 <- pmf_K_given_alpha(50, 2.0, logS) sum(pmf2)  # Should be 1 #> [1] 1"},{"path":"https://joonho112.github.io/DPprior/reference/log_pmf_K_marginal.html","id":null,"dir":"Reference","previous_headings":"","what":"Log Marginal PMF of K_J under Gamma Hyperprior ‚Äî log_pmf_K_marginal","title":"Log Marginal PMF of K_J under Gamma Hyperprior ‚Äî log_pmf_K_marginal","text":"Computes \\(\\log P(K_J = k \\mid , b)\\) \\(k = 0, 1, \\ldots, J\\) using log-space mixing numerical stability.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/log_pmf_K_marginal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Log Marginal PMF of K_J under Gamma Hyperprior ‚Äî log_pmf_K_marginal","text":"","code":"log_pmf_K_marginal(J, a, b, logS, M = .QUAD_NODES_DEFAULT)"},{"path":"https://joonho112.github.io/DPprior/reference/log_pmf_K_marginal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Log Marginal PMF of K_J under Gamma Hyperprior ‚Äî log_pmf_K_marginal","text":"J Integer; sample size (must >= 1). Numeric; shape parameter Gamma prior (must > 0). b Numeric; rate parameter Gamma prior (must > 0). logS Matrix; pre-computed log-Stirling matrix compute_log_stirling. M Integer; number quadrature nodes (default: .QUAD_NODES_DEFAULT).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/log_pmf_K_marginal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Log Marginal PMF of K_J under Gamma Hyperprior ‚Äî log_pmf_K_marginal","text":"Numeric vector length \\(J+1\\) containing log-probabilities \\(k = 0, 1, \\ldots, J\\). Entry [1] corresponds \\(k=0\\) always -Inf.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/log_pmf_K_marginal.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Log Marginal PMF of K_J under Gamma Hyperprior ‚Äî log_pmf_K_marginal","text":"routine normalizes \\(P(K_J = \\cdot \\mid \\alpha_m)\\) quadrature node mixing, mixes log-space via logsumexp_vec: $$\\log p_k \\approx \\log\\sum_m \\exp\\{\\log w_m + \\log p_{k\\mid m}\\}.$$ log-space computation essential numerical stability : J large (tail probabilities become small) Alpha values span wide range (extreme quadrature nodes) Parameters lead concentrated distributions","code":""},{"path":"https://joonho112.github.io/DPprior/reference/log_rising_factorial.html","id":null,"dir":"Reference","previous_headings":"","what":"Log Rising Factorial (Pochhammer Symbol) ‚Äî log_rising_factorial","title":"Log Rising Factorial (Pochhammer Symbol) ‚Äî log_rising_factorial","text":"Computes logarithm rising factorial (Pochhammer symbol) \\((\\alpha)_J = \\alpha(\\alpha+1)\\cdots(\\alpha+J-1)\\).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/log_rising_factorial.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Log Rising Factorial (Pochhammer Symbol) ‚Äî log_rising_factorial","text":"","code":"log_rising_factorial(alpha, J)"},{"path":"https://joonho112.github.io/DPprior/reference/log_rising_factorial.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Log Rising Factorial (Pochhammer Symbol) ‚Äî log_rising_factorial","text":"alpha Numeric; concentration parameter (must positive scalar). J Integer; number terms (must >= 1).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/log_rising_factorial.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Log Rising Factorial (Pochhammer Symbol) ‚Äî log_rising_factorial","text":"Numeric; \\(\\log(\\alpha)_J\\).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/log_rising_factorial.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Log Rising Factorial (Pochhammer Symbol) ‚Äî log_rising_factorial","text":"Uses identity: $$(\\alpha)_J = \\frac{\\Gamma(\\alpha+J)}{\\Gamma(\\alpha)}$$ Therefore: $$\\log(\\alpha)_J = \\log\\Gamma(\\alpha+J) - \\log\\Gamma(\\alpha)$$ numerically stable \\(\\alpha > 0\\) \\(J \\geq 1\\).","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/log_rising_factorial.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Log Rising Factorial (Pochhammer Symbol) ‚Äî log_rising_factorial","text":"","code":"if (FALSE) { # \\dontrun{ # (2)_3 = 2 * 3 * 4 = 24 exp(log_rising_factorial(2, 3))  # (1)_5 = 5! exp(log_rising_factorial(1, 5)) factorial(5)  } # }"},{"path":"https://joonho112.github.io/DPprior/reference/logsumexp.html","id":null,"dir":"Reference","previous_headings":"","what":"Numerically Stable Log-Sum-Exp (Binary) ‚Äî logsumexp","title":"Numerically Stable Log-Sum-Exp (Binary) ‚Äî logsumexp","text":"Computes log(exp() + exp(b)) numerically stable way, avoiding overflow underflow.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/logsumexp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Numerically Stable Log-Sum-Exp (Binary) ‚Äî logsumexp","text":"","code":"logsumexp(a, b)"},{"path":"https://joonho112.github.io/DPprior/reference/logsumexp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Numerically Stable Log-Sum-Exp (Binary) ‚Äî logsumexp","text":"Numeric vector log-scale values. b Numeric vector log-scale values (recycled match length ).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/logsumexp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Numerically Stable Log-Sum-Exp (Binary) ‚Äî logsumexp","text":"Numeric vector log(exp() + exp(b)).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/logsumexp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Numerically Stable Log-Sum-Exp (Binary) ‚Äî logsumexp","text":"Uses identity: $$\\log(\\exp() + \\exp(b)) = \\max(,b) + \\log(1 + \\exp(-|-b|))$$ formulation ensures numerical stability even extreme values (e.g., = 1000 = -1000). Special cases: inputs -Inf, returns -Inf. either input Inf, returns Inf.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/logsumexp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Numerically Stable Log-Sum-Exp (Binary) ‚Äî logsumexp","text":"","code":"# Standard case logsumexp(log(2), log(3)) #> [1] 1.609438  # Extreme values that would overflow with naive implementation logsumexp(1000, 1000) #> [1] 1000.693  # Edge cases with Inf logsumexp(-Inf, -Inf) #> [1] -Inf"},{"path":"https://joonho112.github.io/DPprior/reference/logsumexp_vec.html","id":null,"dir":"Reference","previous_headings":"","what":"Vectorized Log-Sum-Exp ‚Äî logsumexp_vec","title":"Vectorized Log-Sum-Exp ‚Äî logsumexp_vec","text":"Computes log(sum(exp(x))) numeric vector numerically stable way.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/logsumexp_vec.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Vectorized Log-Sum-Exp ‚Äî logsumexp_vec","text":"","code":"logsumexp_vec(x)"},{"path":"https://joonho112.github.io/DPprior/reference/logsumexp_vec.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Vectorized Log-Sum-Exp ‚Äî logsumexp_vec","text":"x Numeric vector log-scale values.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/logsumexp_vec.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Vectorized Log-Sum-Exp ‚Äî logsumexp_vec","text":"Scalar value equal log(sum(exp(x))).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/logsumexp_vec.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Vectorized Log-Sum-Exp ‚Äî logsumexp_vec","text":"Subtracts maximum exponentiating prevent overflow: $$\\log\\sum_i \\exp(x_i) = \\max_i x_i + \\log\\sum_i \\exp(x_i - \\max_i x_i)$$ Special cases: entries -Inf, returns -Inf. entry Inf, returns Inf. Empty vector throws error.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/logsumexp_vec.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Vectorized Log-Sum-Exp ‚Äî logsumexp_vec","text":"","code":"# Sum of equal values logsumexp_vec(c(0, 0, 0, 0)) #> [1] 1.386294  # Extreme values logsumexp_vec(c(1000, 1000, 1000)) #> [1] 1001.099  # All -Inf logsumexp_vec(c(-Inf, -Inf)) #> [1] -Inf"},{"path":"https://joonho112.github.io/DPprior/reference/marginal_moments_with_jacobian.html","id":null,"dir":"Reference","previous_headings":"","what":"Marginal Moments with Jacobian ‚Äî marginal_moments_with_jacobian","title":"Marginal Moments with Jacobian ‚Äî marginal_moments_with_jacobian","text":"Computes marginal moments Jacobian matrix respect Gamma hyperparameters (, b). Used Newton-type optimization.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/marginal_moments_with_jacobian.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Marginal Moments with Jacobian ‚Äî marginal_moments_with_jacobian","text":"","code":"marginal_moments_with_jacobian(J, a, b, M = .QUAD_NODES_DEFAULT)"},{"path":"https://joonho112.github.io/DPprior/reference/marginal_moments_with_jacobian.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Marginal Moments with Jacobian ‚Äî marginal_moments_with_jacobian","text":"J Integer; sample size. Numeric; shape parameter Gamma prior. b Numeric; rate parameter Gamma prior. M Integer; number quadrature nodes (default: 80).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/marginal_moments_with_jacobian.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Marginal Moments with Jacobian ‚Äî marginal_moments_with_jacobian","text":"list components: mean Marginal mean var Marginal variance jacobian 2x2 matrix partial derivatives","code":""},{"path":"https://joonho112.github.io/DPprior/reference/marginal_moments_with_jacobian.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Marginal Moments with Jacobian ‚Äî marginal_moments_with_jacobian","text":"Jacobian matrix : $$J = \\begin{pmatrix}   \\partial M_1 / \\partial & \\partial M_1 / \\partial b \\\\   \\partial V / \\partial & \\partial V / \\partial b \\end{pmatrix}$$ Derivatives computed using score function identity: $$\\frac{\\partial}{\\partial \\theta} E[f(\\alpha)] = E[f(\\alpha) \\cdot s_\\theta(\\alpha)]$$ \\(s_\\theta(\\alpha) = \\partial \\log p(\\alpha | , b) / \\partial \\theta\\). Gamma(, b): \\(s_a(\\alpha) = \\log(b) - \\psi() + \\log(\\alpha)\\) \\(s_b(\\alpha) = /b - \\alpha\\)","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/marginal_moments_with_jacobian.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Marginal Moments with Jacobian ‚Äî marginal_moments_with_jacobian","text":"","code":"if (FALSE) { # \\dontrun{ result <- marginal_moments_with_jacobian(50, 2.0, 1.0) result$jacobian  } # }"},{"path":"https://joonho112.github.io/DPprior/reference/mean_K_from_marginal_pmf.html","id":null,"dir":"Reference","previous_headings":"","what":"Mean of Marginal K from PMF ‚Äî mean_K_from_marginal_pmf","title":"Mean of Marginal K from PMF ‚Äî mean_K_from_marginal_pmf","text":"Computes \\(E[K_J \\mid , b]\\) marginal PMF.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/mean_K_from_marginal_pmf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mean of Marginal K from PMF ‚Äî mean_K_from_marginal_pmf","text":"","code":"mean_K_from_marginal_pmf(J, a, b, logS, M = .QUAD_NODES_DEFAULT)"},{"path":"https://joonho112.github.io/DPprior/reference/mean_K_from_marginal_pmf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mean of Marginal K from PMF ‚Äî mean_K_from_marginal_pmf","text":"J Integer; sample size. Numeric; shape parameter Gamma prior. b Numeric; rate parameter Gamma prior. logS Matrix; pre-computed log-Stirling matrix. M Integer; number quadrature nodes.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/mean_K_from_marginal_pmf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Mean of Marginal K from PMF ‚Äî mean_K_from_marginal_pmf","text":"Numeric; marginal mean.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/mean_K_from_marginal_pmf.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mean of Marginal K from PMF ‚Äî mean_K_from_marginal_pmf","text":"","code":"if (FALSE) { # \\dontrun{ logS <- compute_log_stirling(50) mean_K_from_marginal_pmf(50, 1.5, 0.5, logS)  } # }"},{"path":"https://joonho112.github.io/DPprior/reference/mean_K_from_pmf.html","id":null,"dir":"Reference","previous_headings":"","what":"Mean of K from PMF ‚Äî mean_K_from_pmf","title":"Mean of K from PMF ‚Äî mean_K_from_pmf","text":"Computes \\(E[K_J \\mid \\alpha]\\) summing PMF. primarily verification closed-form digamma formula.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/mean_K_from_pmf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mean of K from PMF ‚Äî mean_K_from_pmf","text":"","code":"mean_K_from_pmf(J, alpha, logS)"},{"path":"https://joonho112.github.io/DPprior/reference/mean_K_from_pmf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mean of K from PMF ‚Äî mean_K_from_pmf","text":"J Integer; sample size. alpha Numeric; DP concentration parameter. logS Matrix; pre-computed log-Stirling matrix.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/mean_K_from_pmf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Mean of K from PMF ‚Äî mean_K_from_pmf","text":"Numeric; conditional mean \\(E[K_J \\mid \\alpha]\\).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/mean_K_from_pmf.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mean of K from PMF ‚Äî mean_K_from_pmf","text":"","code":"if (FALSE) { # \\dontrun{ logS <- compute_log_stirling(50)  # Should match mean_K_given_alpha(50, 2.0) mean_K_from_pmf(50, 2.0, logS) mean_K_given_alpha(50, 2.0)  } # }"},{"path":"https://joonho112.github.io/DPprior/reference/mean_K_given_alpha.html","id":null,"dir":"Reference","previous_headings":"","what":"Conditional Mean of K_J Given Alpha ‚Äî mean_K_given_alpha","title":"Conditional Mean of K_J Given Alpha ‚Äî mean_K_given_alpha","text":"Computes \\(\\mathbb{E}[K_J \\mid \\alpha]\\) Dirichlet process prior.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/mean_K_given_alpha.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conditional Mean of K_J Given Alpha ‚Äî mean_K_given_alpha","text":"","code":"mean_K_given_alpha(J, alpha)"},{"path":"https://joonho112.github.io/DPprior/reference/mean_K_given_alpha.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conditional Mean of K_J Given Alpha ‚Äî mean_K_given_alpha","text":"J Sample size (integer >= 1). alpha Concentration parameter (positive numeric, vectorized).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/mean_K_given_alpha.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Conditional Mean of K_J Given Alpha ‚Äî mean_K_given_alpha","text":"Numeric vector conditional means (length alpha).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/mean_K_given_alpha.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Conditional Mean of K_J Given Alpha ‚Äî mean_K_given_alpha","text":"Uses digamma closed form: $$\\mu_J(\\alpha) = \\alpha\\{\\psi(\\alpha+J)-\\psi(\\alpha)\\}$$ \\(\\psi(\\cdot)\\) digamma function. equivalent direct summation: $$\\mu_J(\\alpha) = \\sum_{=1}^{J} \\frac{\\alpha}{\\alpha + - 1}$$ Limiting behavior: \\(\\alpha \\0^+\\): \\(\\mu_J(\\alpha) \\1\\) \\(\\alpha \\\\infty\\): \\(\\mu_J(\\alpha) \\J\\) numerical stability, values alpha < 1e-10 return limit 1.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/mean_K_given_alpha.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Conditional Mean of K_J Given Alpha ‚Äî mean_K_given_alpha","text":"","code":"mean_K_given_alpha(50, 2.0) #> [1] 7.037626 mean_K_given_alpha(50, c(0.5, 1, 2, 5)) #> [1]  2.937775  4.499205  7.037626 12.460485  # Limiting behavior mean_K_given_alpha(50, 1e-10)  # Returns 1 #> [1] 1 mean_K_given_alpha(50, 1e6)    # Returns ~50 #> [1] 49.99878"},{"path":"https://joonho112.github.io/DPprior/reference/mean_K_given_alpha_safe.html","id":null,"dir":"Reference","previous_headings":"","what":"Conditional Mean of K Given Alpha (Enhanced) ‚Äî mean_K_given_alpha_safe","title":"Conditional Mean of K Given Alpha (Enhanced) ‚Äî mean_K_given_alpha_safe","text":"Computes \\(E[K_J | \\alpha]\\) proper handling small alpha values.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/mean_K_given_alpha_safe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conditional Mean of K Given Alpha (Enhanced) ‚Äî mean_K_given_alpha_safe","text":"","code":"mean_K_given_alpha_safe(J, alpha)"},{"path":"https://joonho112.github.io/DPprior/reference/mean_K_given_alpha_safe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conditional Mean of K Given Alpha (Enhanced) ‚Äî mean_K_given_alpha_safe","text":"J Integer; sample size. alpha Numeric vector; concentration parameter values.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/mean_K_given_alpha_safe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Conditional Mean of K Given Alpha (Enhanced) ‚Äî mean_K_given_alpha_safe","text":"Numeric vector conditional means.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/mean_K_given_alpha_safe.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Conditional Mean of K Given Alpha (Enhanced) ‚Äî mean_K_given_alpha_safe","text":"small alpha (< 1e-12), returns 1.0 limiting value. avoids numerical issues digamma near-zero arguments.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/mean_K_given_alpha_sum.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Conditional Mean via Direct Summation ‚Äî mean_K_given_alpha_sum","title":"Compute Conditional Mean via Direct Summation ‚Äî mean_K_given_alpha_sum","text":"verification purposes .","code":""},{"path":"https://joonho112.github.io/DPprior/reference/mean_K_given_alpha_sum.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Conditional Mean via Direct Summation ‚Äî mean_K_given_alpha_sum","text":"","code":"mean_K_given_alpha_sum(J, alpha)"},{"path":"https://joonho112.github.io/DPprior/reference/mean_K_given_alpha_sum.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Conditional Mean via Direct Summation ‚Äî mean_K_given_alpha_sum","text":"J Sample size. alpha Concentration parameter (scalar).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/mean_K_given_alpha_sum.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Conditional Mean via Direct Summation ‚Äî mean_K_given_alpha_sum","text":"Numeric; conditional mean computed via summation.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/mean_rho.html","id":null,"dir":"Reference","previous_headings":"","what":"Marginal Mean of rho ‚Äî mean_rho","title":"Marginal Mean of rho ‚Äî mean_rho","text":"Computes E(rho | , b) alpha ~ Gamma(, b) (shape-rate).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/mean_rho.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Marginal Mean of rho ‚Äî mean_rho","text":"","code":"mean_rho(a, b, M = .QUAD_NODES_DEFAULT)"},{"path":"https://joonho112.github.io/DPprior/reference/mean_rho.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Marginal Mean of rho ‚Äî mean_rho","text":"Numeric; shape parameter Gamma prior alpha (> 0). b Numeric; rate parameter Gamma prior alpha (b > 0). M Integer; number quadrature nodes. Default 80.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/mean_rho.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Marginal Mean of rho ‚Äî mean_rho","text":"Numeric; E(rho | , b).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/mean_rho.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Marginal Mean of rho ‚Äî mean_rho","text":"Uses Gauss-Laguerre quadrature via integrate_gamma. key identity E(rho | alpha) = E(w1 | alpha) = 1/(1+alpha), E(rho | , b) equals E(w1 | , b) (full distributions differ). Interpretation: E(rho) > 0.5: High prior co-clustering probability E(rho) (0.2, 0.5): Moderate co-clustering E(rho) < 0.2: Low co-clustering (fragmented prior)","code":""},{"path":"https://joonho112.github.io/DPprior/reference/mean_rho.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Marginal Mean of rho ‚Äî mean_rho","text":"Lee, J. (2026). Design-Conditional Prior Elicitation Dirichlet Process Mixtures. arXiv preprint arXiv:2602.06301.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/mean_rho.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Marginal Mean of rho ‚Äî mean_rho","text":"","code":"mean_rho(a = 2, b = 1) #> [1] 0.4036526 mean_rho(a = 1.6, b = 1.22) #> [1] 0.508368"},{"path":"https://joonho112.github.io/DPprior/reference/mean_rho_given_alpha.html","id":null,"dir":"Reference","previous_headings":"","what":"Conditional Mean of rho Given Alpha ‚Äî mean_rho_given_alpha","title":"Conditional Mean of rho Given Alpha ‚Äî mean_rho_given_alpha","text":"Computes conditional mean E(rho | alpha) co-clustering probability rho = sum_h w_h^2 Dirichlet Process.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/mean_rho_given_alpha.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conditional Mean of rho Given Alpha ‚Äî mean_rho_given_alpha","text":"","code":"mean_rho_given_alpha(alpha)"},{"path":"https://joonho112.github.io/DPprior/reference/mean_rho_given_alpha.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conditional Mean of rho Given Alpha ‚Äî mean_rho_given_alpha","text":"alpha Numeric vector; concentration parameter(s) (must positive).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/mean_rho_given_alpha.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Conditional Mean of rho Given Alpha ‚Äî mean_rho_given_alpha","text":"Numeric vector; E(rho | alpha) = 1/(1+alpha).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/mean_rho_given_alpha.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Conditional Mean of rho Given Alpha ‚Äî mean_rho_given_alpha","text":"co-clustering probability rho = sum(w_h^2) h >= 1 conditional mean: $$E[\\rho | \\alpha] = \\frac{1}{1 + \\alpha}$$ equals E(w1 | alpha) since w1 ~ Beta(1, alpha) mean 1/(1+alpha). Interpretation: alpha -> 0: E(rho|alpha) -> 1 (observations one cluster) alpha -> Inf: E(rho|alpha) -> 0 (infinitely many small clusters) alpha = 1: E(rho|alpha) = 0.5 (moderate clustering)","code":""},{"path":"https://joonho112.github.io/DPprior/reference/mean_rho_given_alpha.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Conditional Mean of rho Given Alpha ‚Äî mean_rho_given_alpha","text":"Lee, J. (2026). Design-Conditional Prior Elicitation Dirichlet Process Mixtures. arXiv preprint arXiv:2602.06301.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/mean_rho_given_alpha.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Conditional Mean of rho Given Alpha ‚Äî mean_rho_given_alpha","text":"","code":"mean_rho_given_alpha(1.0) #> [1] 0.5 mean_rho_given_alpha(c(0.5, 1, 2, 5, 10)) #> [1] 0.66666667 0.50000000 0.33333333 0.16666667 0.09090909"},{"path":"https://joonho112.github.io/DPprior/reference/mean_rho_sq.html","id":null,"dir":"Reference","previous_headings":"","what":"Marginal Second Moment of rho ‚Äî mean_rho_sq","title":"Marginal Second Moment of rho ‚Äî mean_rho_sq","text":"Computes E(rho^2 | , b) mixing E(rho^2 | alpha) alpha ~ Gamma(, b).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/mean_rho_sq.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Marginal Second Moment of rho ‚Äî mean_rho_sq","text":"","code":"mean_rho_sq(a, b, M = .QUAD_NODES_DEFAULT)"},{"path":"https://joonho112.github.io/DPprior/reference/mean_rho_sq.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Marginal Second Moment of rho ‚Äî mean_rho_sq","text":"Numeric; shape parameter Gamma prior alpha (> 0). b Numeric; rate parameter Gamma prior alpha (b > 0). M Integer; number quadrature nodes. Default 80.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/mean_rho_sq.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Marginal Second Moment of rho ‚Äî mean_rho_sq","text":"Numeric; E(rho^2 | , b).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/mean_rho_sq_given_alpha.html","id":null,"dir":"Reference","previous_headings":"","what":"Conditional Second Moment of rho Given Alpha ‚Äî mean_rho_sq_given_alpha","title":"Conditional Second Moment of rho Given Alpha ‚Äî mean_rho_sq_given_alpha","text":"Computes E(rho^2 | alpha) = (alpha + 6) / ((alpha+1)(alpha+2)(alpha+3)).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/mean_rho_sq_given_alpha.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conditional Second Moment of rho Given Alpha ‚Äî mean_rho_sq_given_alpha","text":"","code":"mean_rho_sq_given_alpha(alpha)"},{"path":"https://joonho112.github.io/DPprior/reference/mean_rho_sq_given_alpha.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conditional Second Moment of rho Given Alpha ‚Äî mean_rho_sq_given_alpha","text":"alpha Numeric vector; concentration parameter(s) (must positive).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/mean_rho_sq_given_alpha.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Conditional Second Moment of rho Given Alpha ‚Äî mean_rho_sq_given_alpha","text":"Numeric vector; E(rho^2 | alpha).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/mean_rho_sq_given_alpha.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Conditional Second Moment of rho Given Alpha ‚Äî mean_rho_sq_given_alpha","text":"Used internally variance computation via identity: Var(rho|alpha) = E(rho^2|alpha) - E(rho|alpha)^2","code":""},{"path":"https://joonho112.github.io/DPprior/reference/mean_w1.html","id":null,"dir":"Reference","previous_headings":"","what":"Mean of w‚ÇÅ ‚Äî mean_w1","title":"Mean of w‚ÇÅ ‚Äî mean_w1","text":"Computes E(w‚ÇÅ | , b) via Gauss-Laguerre quadrature.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/mean_w1.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mean of w‚ÇÅ ‚Äî mean_w1","text":"","code":"mean_w1(a, b, M = .QUAD_NODES_DEFAULT)"},{"path":"https://joonho112.github.io/DPprior/reference/mean_w1.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mean of w‚ÇÅ ‚Äî mean_w1","text":"Numeric; shape parameter Gamma prior Œ± (> 0). b Numeric; rate parameter Gamma prior Œ± (b > 0). M Integer; number quadrature nodes. Default 80.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/mean_w1.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Mean of w‚ÇÅ ‚Äî mean_w1","text":"Numeric; E(w‚ÇÅ).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/mean_w1.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Mean of w‚ÇÅ ‚Äî mean_w1","text":"expectation computed using identity: $$E[w_1 | , b] = E\\left[\\frac{1}{1+\\alpha}\\right] = I_1(, b)$$ integral evaluated via Gauss-Laguerre quadrature. Key identity: E(w‚ÇÅ | , b) = E(œÅ | , b) œÅ = Œ£w‚Çï¬≤ co-clustering probability.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/mean_w1.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Mean of w‚ÇÅ ‚Äî mean_w1","text":"Lee, J. (2026). Design-Conditional Prior Elicitation Dirichlet Process Mixtures. arXiv preprint arXiv:2602.06301.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/mean_w1.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mean of w‚ÇÅ ‚Äî mean_w1","text":"","code":"mean_w1(a = 2, b = 1)       # ~0.404 #> [1] 0.4036526 mean_w1(a = 1.6, b = 1.22)  # ~0.508 #> [1] 0.508368"},{"path":"https://joonho112.github.io/DPprior/reference/mode_K_given_alpha.html","id":null,"dir":"Reference","previous_headings":"","what":"Mode of K Given Alpha ‚Äî mode_K_given_alpha","title":"Mode of K Given Alpha ‚Äî mode_K_given_alpha","text":"Computes mode (likely value) \\(K_J \\mid \\alpha\\).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/mode_K_given_alpha.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mode of K Given Alpha ‚Äî mode_K_given_alpha","text":"","code":"mode_K_given_alpha(J, alpha, logS)"},{"path":"https://joonho112.github.io/DPprior/reference/mode_K_given_alpha.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mode of K Given Alpha ‚Äî mode_K_given_alpha","text":"J Integer; sample size. alpha Numeric; DP concentration parameter. logS Matrix; pre-computed log-Stirling matrix.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/mode_K_given_alpha.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Mode of K Given Alpha ‚Äî mode_K_given_alpha","text":"Integer; value \\(k\\) maximizes \\(P(K_J = k \\mid \\alpha)\\).","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/mode_K_given_alpha.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mode of K Given Alpha ‚Äî mode_K_given_alpha","text":"","code":"logS <- compute_log_stirling(50) mode_K_given_alpha(50, 2.0, logS) #> [1] 7"},{"path":"https://joonho112.github.io/DPprior/reference/mode_K_marginal.html","id":null,"dir":"Reference","previous_headings":"","what":"Mode of Marginal K Distribution ‚Äî mode_K_marginal","title":"Mode of Marginal K Distribution ‚Äî mode_K_marginal","text":"Computes mode (likely value) marginal distribution \\(K_J\\).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/mode_K_marginal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mode of Marginal K Distribution ‚Äî mode_K_marginal","text":"","code":"mode_K_marginal(J, a, b, logS, M = .QUAD_NODES_DEFAULT)"},{"path":"https://joonho112.github.io/DPprior/reference/mode_K_marginal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mode of Marginal K Distribution ‚Äî mode_K_marginal","text":"J Integer; sample size. Numeric; shape parameter Gamma prior (> 0). b Numeric; rate parameter Gamma prior (> 0). logS Matrix; pre-computed log-Stirling matrix. M Integer; number quadrature nodes (default: 80).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/mode_K_marginal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Mode of Marginal K Distribution ‚Äî mode_K_marginal","text":"Integer; value \\(k\\) maximizes \\(P(K_J = k \\mid , b)\\).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/mode_K_marginal.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Mode of Marginal K Distribution ‚Äî mode_K_marginal","text":"mode always >= 1 since \\(P(K_J = 0) = 0\\).","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/mode_K_marginal.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mode of Marginal K Distribution ‚Äî mode_K_marginal","text":"","code":"logS <- compute_log_stirling(50) mode_K_marginal(50, 1.5, 0.5, logS) #> [1] 6"},{"path":"https://joonho112.github.io/DPprior/reference/moments_K_given_alpha.html","id":null,"dir":"Reference","previous_headings":"","what":"Conditional Mean and Variance of K_J Given Alpha ‚Äî moments_K_given_alpha","title":"Conditional Mean and Variance of K_J Given Alpha ‚Äî moments_K_given_alpha","text":"Convenience wrapper returning conditional moments one call.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/moments_K_given_alpha.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conditional Mean and Variance of K_J Given Alpha ‚Äî moments_K_given_alpha","text":"","code":"moments_K_given_alpha(J, alpha)"},{"path":"https://joonho112.github.io/DPprior/reference/moments_K_given_alpha.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conditional Mean and Variance of K_J Given Alpha ‚Äî moments_K_given_alpha","text":"J Sample size (integer >= 1). alpha Concentration parameter (positive numeric, vectorized).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/moments_K_given_alpha.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Conditional Mean and Variance of K_J Given Alpha ‚Äî moments_K_given_alpha","text":"alpha scalar, named numeric vector c(mean = ..., var = ...). alpha vector, numeric matrix two columns mean var (one row per element alpha).","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/moments_K_given_alpha.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Conditional Mean and Variance of K_J Given Alpha ‚Äî moments_K_given_alpha","text":"","code":"moments_K_given_alpha(50, 2.0) #>     mean      var  #> 7.037626 4.535558  moments_K_given_alpha(50, c(0.5, 1, 2, 5)) #>           mean      var #> [1,]  2.937775 1.709074 #> [2,]  4.499205 2.874073 #> [3,]  7.037626 4.535558 #> [4,] 12.460485 7.386114"},{"path":"https://joonho112.github.io/DPprior/reference/moments_with_jacobian.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Marginal Moments and Jacobian Simultaneously ‚Äî moments_with_jacobian","title":"Compute Marginal Moments and Jacobian Simultaneously ‚Äî moments_with_jacobian","text":"Computes exact marginal moments \\(M_1 = E[K_J]\\) \\(V = Var(K_J)\\) along Jacobian matrix moment map \\(F(,b) = (M_1, V)\\) using score function identities.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/moments_with_jacobian.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Marginal Moments and Jacobian Simultaneously ‚Äî moments_with_jacobian","text":"","code":"moments_with_jacobian(J, a, b, M = .QUAD_NODES_DEFAULT)"},{"path":"https://joonho112.github.io/DPprior/reference/moments_with_jacobian.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Marginal Moments and Jacobian Simultaneously ‚Äî moments_with_jacobian","text":"J Integer; sample size (number observations/sites). Numeric; shape parameter Gamma prior \\(\\alpha\\) (> 0). b Numeric; rate parameter Gamma prior \\(\\alpha\\) (> 0). M Integer; number quadrature nodes (default: 80).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/moments_with_jacobian.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Marginal Moments and Jacobian Simultaneously ‚Äî moments_with_jacobian","text":"named list components: mean Marginal mean \\(E[K_J]\\) var Marginal variance \\(Var(K_J)\\) jacobian 2x2 Jacobian matrix structure: $$J_F = \\begin{bmatrix} \\partial M_1/\\partial & \\partial M_1/\\partial b \\\\                                  \\partial V/\\partial & \\partial V/\\partial b \\end{bmatrix}$$","code":""},{"path":"https://joonho112.github.io/DPprior/reference/moments_with_jacobian.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute Marginal Moments and Jacobian Simultaneously ‚Äî moments_with_jacobian","text":"function uses score identity (Lee, 2026, Section 3.2, Corollary 1) compute exact derivatives without finite differences: $$\\frac{\\partial}{\\partial\\theta} E[f(\\alpha)] = E[f(\\alpha) \\cdot s_\\theta(\\alpha)]$$ Jacobian components computed : \\(\\partial M_1/\\partial \\theta = E[\\mu_J(\\alpha) \\cdot s_\\theta(\\alpha)]\\) \\(\\partial V/\\partial \\theta = \\partial E[v_J]/\\partial \\theta +              \\partial E[\\mu_J^2]/\\partial \\theta - 2 M_1 \\partial M_1/\\partial \\theta\\) Numerical Considerations: score function s_a contains log(alpha), causes slower quadrature convergence compared moment computation. verification, use higher M (e.g., 120-200). small alpha values (< 1e-12) handled limiting values.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/moments_with_jacobian.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Compute Marginal Moments and Jacobian Simultaneously ‚Äî moments_with_jacobian","text":"Lee, J. (2026). Design-Conditional Prior Elicitation Dirichlet Process Mixtures. arXiv preprint arXiv:2602.06301.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/moments_with_jacobian.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute Marginal Moments and Jacobian Simultaneously ‚Äî moments_with_jacobian","text":"","code":"# Compute moments and Jacobian for J=50, a=2, b=1 result <- moments_with_jacobian(J = 50, a = 2.0, b = 1.0) print(result$mean)      # E[K_J] #> [1] 6.639693 print(result$var)       # Var(K_J) #> [1] 12.9545 print(result$jacobian)  # 2x2 Jacobian matrix #>           da         db #> dM1 2.245605  -4.135585 #> dV  2.943578 -13.038228  # Use in Newton iteration target <- c(5.0, 8.0)  # Target (E[K], Var(K)) current <- c(result$mean, result$var) residual <- current - target delta <- solve(result$jacobian, -residual)"},{"path":"https://joonho112.github.io/DPprior/reference/plot.DPprior_fit.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Method for DPprior_fit Objects ‚Äî plot.DPprior_fit","title":"Plot Method for DPprior_fit Objects ‚Äî plot.DPprior_fit","text":"Creates visualizations prior elicitation result. Multiple plot types available, including individual distribution plots comprehensive dashboards.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/plot.DPprior_fit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Method for DPprior_fit Objects ‚Äî plot.DPprior_fit","text":"","code":"# S3 method for class 'DPprior_fit' plot(   x,   type = c(\"auto\", \"dashboard\", \"alpha\", \"K\", \"w1\", \"dual\", \"comparison\"),   engine = c(\"ggplot2\", \"base\"),   ... )"},{"path":"https://joonho112.github.io/DPprior/reference/plot.DPprior_fit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Method for DPprior_fit Objects ‚Äî plot.DPprior_fit","text":"x DPprior_fit object. type Character; type plot create: \"auto\" (Default) Automatically selects appropriate plot type. Uses \"dual\" dual-anchor fits, \"dashboard\" otherwise. \"dashboard\" 4-panel dashboard showing alpha, K, w1, summary. \"alpha\" Prior density concentration parameter alpha. \"K\" Prior PMF number clusters \\(K_J\\). \"w1\" Prior density first stick-breaking weight w1. \"dual\" Dual-anchor comparison dashboard (dual-anchor fits). \"comparison\" \"dual\". engine Character; graphics engine use: \"ggplot2\" (default) \"base\". ... Additional arguments passed underlying plot functions. Common options include: base_size Base font size (default: 11) ci_level Credible interval level alpha plot (default: 0.95) title Optional title dashboard show TRUE, display plot; FALSE, return silently","code":""},{"path":"https://joonho112.github.io/DPprior/reference/plot.DPprior_fit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Method for DPprior_fit Objects ‚Äî plot.DPprior_fit","text":"Depends plot type engine: ggplot2: Returns ggplot object gtable (dashboards) base: Returns invisible(NULL)","code":""},{"path":"https://joonho112.github.io/DPprior/reference/plot.DPprior_fit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot Method for DPprior_fit Objects ‚Äî plot.DPprior_fit","text":"\"auto\" type recommended use cases. automatically detects whether fit object dual-anchor calibration selects appropriate visualization. dual-anchor fits, comparison dashboard shows: Alpha prior: K-vs Dual-anchor K distribution comparison w1 distribution comparison dominance threshold Summary comparison table","code":""},{"path":"https://joonho112.github.io/DPprior/reference/plot.DPprior_fit.html","id":"plot-type-details","dir":"Reference","previous_headings":"","what":"Plot Type Details","title":"Plot Method for DPprior_fit Objects ‚Äî plot.DPprior_fit","text":"dashboard 2x2 grid showing: () Alpha prior density CI (B) \\(K_J\\) prior PMF mode mean (C) w1 prior density dominance shading (D) Summary statistics table alpha Gamma(, b) density : - Mean line (dashed) - Credible interval (shaded region) - Annotation moments CI K Bar plot \\(P(K_J = k)\\) : - Target mean line - Achieved mean line - Optional CDF overlay w1 Density plot : - Dominance region shading (w1 > 0.5) - Threshold lines - Exceedance probabilities","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/plot.DPprior_fit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Method for DPprior_fit Objects ‚Äî plot.DPprior_fit","text":"","code":"# Create a fit object fit <- DPprior_fit(J = 50, mu_K = 5, var_K = 8) #> Warning: HIGH DOMINANCE RISK: P(w1 > 0.5) = 48.1% exceeds 40%. #>   This may indicate unintended prior behavior (Lee, 2026). #>   Consider using DPprior_dual() for weight-constrained elicitation. #>   See ?DPprior_diagnostics for interpretation.  # Auto-detect best plot type plot(fit)  #> TableGrob (2 x 2) \"dpprior_dashboard\": 4 grobs #>   z     cells              name           grob #> 1 1 (1-1,1-1) dpprior_dashboard gtable[layout] #> 2 2 (2-2,1-1) dpprior_dashboard gtable[layout] #> 3 3 (1-1,2-2) dpprior_dashboard gtable[layout] #> 4 4 (2-2,2-2) dpprior_dashboard gtable[layout]  # Specific plot types plot(fit, type = \"alpha\")   plot(fit, type = \"K\")   plot(fit, type = \"w1\")   plot(fit, type = \"dashboard\")  #> TableGrob (2 x 2) \"dpprior_dashboard\": 4 grobs #>   z     cells              name           grob #> 1 1 (1-1,1-1) dpprior_dashboard gtable[layout] #> 2 2 (2-2,1-1) dpprior_dashboard gtable[layout] #> 3 3 (1-1,2-2) dpprior_dashboard gtable[layout] #> 4 4 (2-2,2-2) dpprior_dashboard gtable[layout]  # With custom options plot(fit, type = \"dashboard\", title = \"My Prior Analysis\")  #> TableGrob (3 x 2) \"dpprior_dashboard\": 5 grobs #>   z     cells              name                grob #> 1 1 (2-2,1-1) dpprior_dashboard      gtable[layout] #> 2 2 (3-3,1-1) dpprior_dashboard      gtable[layout] #> 3 3 (2-2,2-2) dpprior_dashboard      gtable[layout] #> 4 4 (3-3,2-2) dpprior_dashboard      gtable[layout] #> 5 5 (1-1,1-2) dpprior_dashboard text[GRID.text.710]  # Dual-anchor comparison fit_K <- DPprior_a2_newton(J = 50, mu_K = 5, var_K = 8) fit_dual <- DPprior_dual(fit_K, w1_target = list(prob = list(threshold = 0.5, value = 0.3))) plot(fit_dual)  # Auto-selects dual comparison  #> TableGrob (3 x 2) \"dpprior_dashboard\": 5 grobs #>   z     cells              name                grob #> 1 1 (2-2,1-1) dpprior_dashboard      gtable[layout] #> 2 2 (3-3,1-1) dpprior_dashboard      gtable[layout] #> 3 3 (2-2,2-2) dpprior_dashboard      gtable[layout] #> 4 4 (3-3,2-2) dpprior_dashboard      gtable[layout] #> 5 5 (1-1,1-2) dpprior_dashboard text[GRID.text.886] plot(fit_dual, type = \"comparison\")  # Explicit  #> TableGrob (3 x 2) \"dpprior_dashboard\": 5 grobs #>   z     cells              name                 grob #> 1 1 (2-2,1-1) dpprior_dashboard       gtable[layout] #> 2 2 (3-3,1-1) dpprior_dashboard       gtable[layout] #> 3 3 (2-2,2-2) dpprior_dashboard       gtable[layout] #> 4 4 (3-3,2-2) dpprior_dashboard       gtable[layout] #> 5 5 (1-1,1-2) dpprior_dashboard text[GRID.text.1059]"},{"path":"https://joonho112.github.io/DPprior/reference/plot_K_prior.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Prior PMF of K_J ‚Äî plot_K_prior","title":"Plot Prior PMF of K_J ‚Äî plot_K_prior","text":"Plot Prior PMF K_J","code":""},{"path":"https://joonho112.github.io/DPprior/reference/plot_K_prior.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Prior PMF of K_J ‚Äî plot_K_prior","text":"","code":"plot_K_prior(   fit = NULL,   J = NULL,   a = NULL,   b = NULL,   engine = c(\"ggplot2\", \"base\"),   base_size = 11,   max_k = NULL,   show_cdf = FALSE,   show = TRUE )"},{"path":"https://joonho112.github.io/DPprior/reference/plot_K_prior.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Prior PMF of K_J ‚Äî plot_K_prior","text":"fit DPprior_fit object, NULL J, , b provided directly. J Integer; sample size (used fit NULL). Numeric; shape parameter (used fit NULL). b Numeric; rate parameter (used fit NULL). engine \"ggplot2\" (default) \"base\". base_size Base font size. max_k Maximum k display. NULL, auto-determined CDF >= 0.999. show_cdf TRUE, overlay CDF line. Default FALSE. show TRUE, print plot.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/plot_K_prior.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Prior PMF of K_J ‚Äî plot_K_prior","text":"ggplot object invisible(NULL) base.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/plot_K_prior.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Prior PMF of K_J ‚Äî plot_K_prior","text":"","code":"fit <- DPprior_fit(J = 50, mu_K = 5, var_K = 8) #> Warning: HIGH DOMINANCE RISK: P(w1 > 0.5) = 48.1% exceeds 40%. #>   This may indicate unintended prior behavior (Lee, 2026). #>   Consider using DPprior_dual() for weight-constrained elicitation. #>   See ?DPprior_diagnostics for interpretation. plot_K_prior(fit)    plot_K_prior(J = 50, a = 1.6, b = 1.2)"},{"path":"https://joonho112.github.io/DPprior/reference/plot_alpha_prior.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Prior Density of Alpha ‚Äî plot_alpha_prior","title":"Plot Prior Density of Alpha ‚Äî plot_alpha_prior","text":"Plot Prior Density Alpha","code":""},{"path":"https://joonho112.github.io/DPprior/reference/plot_alpha_prior.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Prior Density of Alpha ‚Äî plot_alpha_prior","text":"","code":"plot_alpha_prior(   fit = NULL,   a = NULL,   b = NULL,   engine = c(\"ggplot2\", \"base\"),   base_size = 11,   ci_level = 0.95,   n_grid = 500,   show = TRUE )"},{"path":"https://joonho112.github.io/DPprior/reference/plot_alpha_prior.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Prior Density of Alpha ‚Äî plot_alpha_prior","text":"fit DPprior_fit object, NULL b provided directly. Numeric; shape parameter (used fit NULL). b Numeric; rate parameter (used fit NULL). engine \"ggplot2\" (default) \"base\". base_size Base font size. ci_level Credible interval level (default 0.95). n_grid Number grid points. show TRUE, print plot.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/plot_alpha_prior.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Prior Density of Alpha ‚Äî plot_alpha_prior","text":"ggplot object invisible(NULL) base.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/plot_alpha_prior.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Prior Density of Alpha ‚Äî plot_alpha_prior","text":"","code":"# From fit object fit <- DPprior_fit(J = 50, mu_K = 5, var_K = 8) #> Warning: HIGH DOMINANCE RISK: P(w1 > 0.5) = 48.1% exceeds 40%. #>   This may indicate unintended prior behavior (Lee, 2026). #>   Consider using DPprior_dual() for weight-constrained elicitation. #>   See ?DPprior_diagnostics for interpretation. plot_alpha_prior(fit)    # Direct parameter specification plot_alpha_prior(a = 1.6, b = 1.2)"},{"path":"https://joonho112.github.io/DPprior/reference/plot_dual_comparison.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Dual-Anchor Comparison Dashboard ‚Äî plot_dual_comparison","title":"Plot Dual-Anchor Comparison Dashboard ‚Äî plot_dual_comparison","text":"Creates comparison dashboard showing K-vs dual-anchor solutions. Displays changes alpha, K, w1 distributions side--side.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/plot_dual_comparison.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Dual-Anchor Comparison Dashboard ‚Äî plot_dual_comparison","text":"","code":"plot_dual_comparison(   fit_dual,   fit_K_only = NULL,   engine = c(\"ggplot2\", \"base\"),   base_size = 10,   title = NULL,   show = TRUE )"},{"path":"https://joonho112.github.io/DPprior/reference/plot_dual_comparison.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Dual-Anchor Comparison Dashboard ‚Äî plot_dual_comparison","text":"fit_dual DPprior_fit object DPprior_dual(). fit_K_only Optional K-fit. NULL, extracted fit_dual$dual_anchor$init. engine \"ggplot2\" (default) \"base\". base_size Base font size. title Optional title dashboard. show TRUE, draw plot.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/plot_dual_comparison.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Dual-Anchor Comparison Dashboard ‚Äî plot_dual_comparison","text":"gtable grob list ggplot objects.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/plot_dual_comparison.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Dual-Anchor Comparison Dashboard ‚Äî plot_dual_comparison","text":"","code":"fit_K <- DPprior_fit(J = 50, mu_K = 5, var_K = 8) #> Warning: HIGH DOMINANCE RISK: P(w1 > 0.5) = 48.1% exceeds 40%. #>   This may indicate unintended prior behavior (Lee, 2026). #>   Consider using DPprior_dual() for weight-constrained elicitation. #>   See ?DPprior_diagnostics for interpretation. fit_dual <- DPprior_dual(fit_K,   w1_target = list(prob = list(threshold = 0.5, value = 0.3)),   lambda = 0.5) plot_dual_comparison(fit_dual)  #> TableGrob (3 x 2) \"dpprior_dashboard\": 5 grobs #>   z     cells              name                 grob #> 1 1 (2-2,1-1) dpprior_dashboard       gtable[layout] #> 2 2 (3-3,1-1) dpprior_dashboard       gtable[layout] #> 3 3 (2-2,2-2) dpprior_dashboard       gtable[layout] #> 4 4 (3-3,2-2) dpprior_dashboard       gtable[layout] #> 5 5 (1-1,1-2) dpprior_dashboard text[GRID.text.1555]"},{"path":"https://joonho112.github.io/DPprior/reference/plot_dual_dashboard.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Dual-Anchor Extended Dashboard ‚Äî plot_dual_dashboard","title":"Plot Dual-Anchor Extended Dashboard ‚Äî plot_dual_dashboard","text":"Creates extended dashboard dual-anchor results 6 panels: () Alpha comparison, (B) K comparison, (C) w1 comparison, (D) Summary table, (E) Loss decomposition, (F) Parameter trajectory.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/plot_dual_dashboard.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Dual-Anchor Extended Dashboard ‚Äî plot_dual_dashboard","text":"","code":"plot_dual_dashboard(   fit_dual,   tradeoff_data = NULL,   engine = c(\"ggplot2\", \"base\"),   base_size = 10,   title = NULL,   show = TRUE )"},{"path":"https://joonho112.github.io/DPprior/reference/plot_dual_dashboard.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Dual-Anchor Extended Dashboard ‚Äî plot_dual_dashboard","text":"fit_dual DPprior_fit object DPprior_dual(). tradeoff_data Optional trade-curve data trajectory plot. engine \"ggplot2\" (default) \"base\". base_size Base font size. title Optional title. show TRUE, draw plot.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/plot_dual_dashboard.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Dual-Anchor Extended Dashboard ‚Äî plot_dual_dashboard","text":"gtable grob invisible(NULL).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/plot_dual_dashboard.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Plot Dual-Anchor Extended Dashboard ‚Äî plot_dual_dashboard","text":"Lee, J. (2026). Design-Conditional Prior Elicitation Dirichlet Process Mixtures. arXiv preprint arXiv:2602.06301.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/plot_prior_dashboard.html","id":null,"dir":"Reference","previous_headings":"","what":"4-Panel Prior Dashboard ‚Äî plot_prior_dashboard","title":"4-Panel Prior Dashboard ‚Äî plot_prior_dashboard","text":"4-Panel Prior Dashboard","code":""},{"path":"https://joonho112.github.io/DPprior/reference/plot_prior_dashboard.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"4-Panel Prior Dashboard ‚Äî plot_prior_dashboard","text":"","code":"plot_prior_dashboard(   fit,   engine = c(\"ggplot2\", \"base\"),   base_size = 11,   ci_level = 0.95,   title = NULL,   show = TRUE )"},{"path":"https://joonho112.github.io/DPprior/reference/plot_prior_dashboard.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"4-Panel Prior Dashboard ‚Äî plot_prior_dashboard","text":"fit DPprior_fit object. engine \"ggplot2\" (default) \"base\". base_size Base font size. ci_level Credible interval level. title Optional overall title dashboard. show TRUE, draw dashboard.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/plot_prior_dashboard.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"4-Panel Prior Dashboard ‚Äî plot_prior_dashboard","text":"gtable grob (ggplot2) invisible(NULL) base.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/plot_prior_dashboard.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"4-Panel Prior Dashboard ‚Äî plot_prior_dashboard","text":"Lee, J. (2026). Design-Conditional Prior Elicitation Dirichlet Process Mixtures. arXiv preprint arXiv:2602.06301.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/plot_tradeoff_curve.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Trade-off Curve ‚Äî plot_tradeoff_curve","title":"Plot Trade-off Curve ‚Äî plot_tradeoff_curve","text":"Visualizes Pareto trade-K_J fit weight constraint across different lambda values.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/plot_tradeoff_curve.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Trade-off Curve ‚Äî plot_tradeoff_curve","text":"","code":"plot_tradeoff_curve(   tradeoff_data,   metric = c(\"w1_prob_gt_50\", \"E_w1\", \"K_loss\", \"var_K\"),   target_value = NULL,   engine = c(\"ggplot2\", \"base\"),   base_size = 11,   title = NULL,   show = TRUE )"},{"path":"https://joonho112.github.io/DPprior/reference/plot_tradeoff_curve.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Trade-off Curve ‚Äî plot_tradeoff_curve","text":"tradeoff_data Data frame compute_tradeoff_curve(). metric metric plot y-axis: \"w1_prob_gt_50\" (default), \"E_w1\", \"K_loss\", \"var_K\". target_value Optional target value mark horizontal line. engine \"ggplot2\" (default) \"base\". base_size Base font size. title Optional title. show TRUE, print plot.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/plot_tradeoff_curve.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Trade-off Curve ‚Äî plot_tradeoff_curve","text":"ggplot object invisible(NULL).","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/plot_tradeoff_curve.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Trade-off Curve ‚Äî plot_tradeoff_curve","text":"","code":"curve <- compute_tradeoff_curve(   J = 50,   K_target = list(mu_K = 5, var_K = 8),   w1_target = list(prob = list(threshold = 0.5, value = 0.25)),   lambda_seq = seq(0, 1, by = 0.1) ) plot_tradeoff_curve(curve, target_value = 0.25)"},{"path":"https://joonho112.github.io/DPprior/reference/plot_tradeoff_dashboard.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Trade-off Multi-Panel ‚Äî plot_tradeoff_dashboard","title":"Plot Trade-off Multi-Panel ‚Äî plot_tradeoff_dashboard","text":"Creates multi-panel view trade-curve showing multiple metrics.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/plot_tradeoff_dashboard.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Trade-off Multi-Panel ‚Äî plot_tradeoff_dashboard","text":"","code":"plot_tradeoff_dashboard(   tradeoff_data,   w1_target_prob = NULL,   engine = c(\"ggplot2\", \"base\"),   base_size = 10,   title = NULL,   show = TRUE )"},{"path":"https://joonho112.github.io/DPprior/reference/plot_tradeoff_dashboard.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Trade-off Multi-Panel ‚Äî plot_tradeoff_dashboard","text":"tradeoff_data Data frame compute_tradeoff_curve(). w1_target_prob Optional target probability P(w1 > 0.5). engine \"ggplot2\" (default) \"base\". base_size Base font size. title Optional title. show TRUE, draw plot.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/plot_tradeoff_dashboard.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Trade-off Multi-Panel ‚Äî plot_tradeoff_dashboard","text":"gtable grob list ggplot objects.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/plot_w1_prior.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Prior Density of w1 ‚Äî plot_w1_prior","title":"Plot Prior Density of w1 ‚Äî plot_w1_prior","text":"Plot Prior Density w1","code":""},{"path":"https://joonho112.github.io/DPprior/reference/plot_w1_prior.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Prior Density of w1 ‚Äî plot_w1_prior","text":"","code":"plot_w1_prior(   fit = NULL,   a = NULL,   b = NULL,   engine = c(\"ggplot2\", \"base\"),   base_size = 11,   thresholds = c(0.5, 0.9),   n_grid = 500,   show = TRUE )"},{"path":"https://joonho112.github.io/DPprior/reference/plot_w1_prior.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Prior Density of w1 ‚Äî plot_w1_prior","text":"fit DPprior_fit object, NULL , b provided directly. Numeric; shape parameter (used fit NULL). b Numeric; rate parameter (used fit NULL). engine \"ggplot2\" (default) \"base\". base_size Base font size. thresholds Dominance thresholds (default: c(0.5, 0.9)). n_grid Number grid points. show TRUE, print plot.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/plot_w1_prior.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Prior Density of w1 ‚Äî plot_w1_prior","text":"ggplot object invisible(NULL) base.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/plot_w1_prior.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Prior Density of w1 ‚Äî plot_w1_prior","text":"","code":"fit <- DPprior_fit(J = 50, mu_K = 5, var_K = 8) #> Warning: HIGH DOMINANCE RISK: P(w1 > 0.5) = 48.1% exceeds 40%. #>   This may indicate unintended prior behavior (Lee, 2026). #>   Consider using DPprior_dual() for weight-constrained elicitation. #>   See ?DPprior_diagnostics for interpretation. plot_w1_prior(fit)    plot_w1_prior(a = 1.6, b = 1.2)"},{"path":"https://joonho112.github.io/DPprior/reference/pmf_K_given_alpha.html","id":null,"dir":"Reference","previous_headings":"","what":"PMF of K Given Alpha (Antoniak Distribution) ‚Äî pmf_K_given_alpha","title":"PMF of K Given Alpha (Antoniak Distribution) ‚Äî pmf_K_given_alpha","text":"Computes \\(P(K_J = k \\mid \\alpha)\\) \\(k = 0, 1, \\ldots, J\\) using Antoniak distribution derived Dirichlet process.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/pmf_K_given_alpha.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"PMF of K Given Alpha (Antoniak Distribution) ‚Äî pmf_K_given_alpha","text":"","code":"pmf_K_given_alpha(J, alpha, logS, normalize = TRUE)"},{"path":"https://joonho112.github.io/DPprior/reference/pmf_K_given_alpha.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"PMF of K Given Alpha (Antoniak Distribution) ‚Äî pmf_K_given_alpha","text":"J Integer; sample size (number observations, must >= 1). alpha Numeric; DP concentration parameter (must positive scalar). logS Matrix; pre-computed log-Stirling matrix compute_log_stirling. normalize Logical; TRUE (default), use softmax normalization numerical stability. FALSE, return raw exponentiated values.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/pmf_K_given_alpha.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"PMF of K Given Alpha (Antoniak Distribution) ‚Äî pmf_K_given_alpha","text":"Numeric vector length \\(J+1\\) containing \\(P(K_J = k \\mid \\alpha)\\) \\(k = 0, 1, \\ldots, J\\). Entry [1] corresponds \\(k=0\\) always equals 0. vector sums 1 (normalize = TRUE).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/pmf_K_given_alpha.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"PMF of K Given Alpha (Antoniak Distribution) ‚Äî pmf_K_given_alpha","text":"Antoniak distribution gives exact PMF number occupied clusters \\(K_J\\) Dirichlet process concentration parameter \\(\\alpha\\): $$P(K_J = k \\mid \\alpha) = |s(J,k)| \\frac{\\alpha^k}{(\\alpha)_J}$$ \\(|s(J,k)|\\) unsigned Stirling number first kind \\((\\alpha)_J\\) rising factorial. Key properties: \\(P(K_J = 0) = 0\\) always (least one cluster exists) \\(P(K_J = J) > 0\\) \\(\\alpha > 0\\) \\(\\alpha \\0^+\\), mass concentrates \\(K_J = 1\\) \\(\\alpha \\\\infty\\), mass concentrates \\(K_J = J\\) Even though Antoniak formula theoretically normalized, converting log-probabilities probability scale via exp() can underflow large J extreme alpha. Setting normalize=TRUE mitigates applying softmax() log-PMF.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/pmf_K_given_alpha.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"PMF of K Given Alpha (Antoniak Distribution) ‚Äî pmf_K_given_alpha","text":"Antoniak, C. E. (1974). Mixtures Dirichlet Processes Applications Bayesian Nonparametric Problems. Annals Statistics, 2(6), 1152-1174.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/pmf_K_given_alpha.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"PMF of K Given Alpha (Antoniak Distribution) ‚Äî pmf_K_given_alpha","text":"","code":"# Compute PMF for J=50, alpha=2 logS <- compute_log_stirling(50) pmf <- pmf_K_given_alpha(50, 2.0, logS)  # Verify normalization sum(pmf)  # Should be 1 #> [1] 1  # Verify P(K=0) = 0 pmf[1]    # Should be 0 #> [1] 0  # Most likely number of clusters (mode) which.max(pmf) - 1  # Subtract 1 for 0-indexing #> [1] 7  # Compare with moments k_vals <- 0:50 mean_K <- sum(k_vals * pmf) var_K <- sum(k_vals^2 * pmf) - mean_K^2  # These should match digamma formulas mean_K_given_alpha(50, 2.0) #> [1] 7.037626 var_K_given_alpha(50, 2.0) #> [1] 4.535558"},{"path":"https://joonho112.github.io/DPprior/reference/pmf_K_marginal.html","id":null,"dir":"Reference","previous_headings":"","what":"Marginal PMF of K_J under Gamma Hyperprior ‚Äî pmf_K_marginal","title":"Marginal PMF of K_J under Gamma Hyperprior ‚Äî pmf_K_marginal","text":"Computes \\(P(K_J = k \\mid , b)\\) \\(k = 0, 1, \\ldots, J\\) \\(\\alpha \\sim \\mathrm{Gamma}(, b)\\) (shape-rate parameterization).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/pmf_K_marginal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Marginal PMF of K_J under Gamma Hyperprior ‚Äî pmf_K_marginal","text":"","code":"pmf_K_marginal(J, a, b, logS, M = .QUAD_NODES_DEFAULT)"},{"path":"https://joonho112.github.io/DPprior/reference/pmf_K_marginal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Marginal PMF of K_J under Gamma Hyperprior ‚Äî pmf_K_marginal","text":"J Integer; sample size (positive integer >= 1). Numeric; shape parameter Gamma prior (> 0). b Numeric; rate parameter Gamma prior (> 0). logS Matrix; pre-computed log-Stirling matrix compute_log_stirling. M Integer; number quadrature nodes (default: 80).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/pmf_K_marginal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Marginal PMF of K_J under Gamma Hyperprior ‚Äî pmf_K_marginal","text":"Numeric vector length \\(J+1\\) containing \\(P(K_J = k \\mid , b)\\) \\(k = 0, 1, \\ldots, J\\). Entry [1] corresponds \\(k=0\\) always equals 0. vector sums 1.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/pmf_K_marginal.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Marginal PMF of K_J under Gamma Hyperprior ‚Äî pmf_K_marginal","text":"Uses Gauss-Laguerre quadrature numerically evaluate: $$P(K_J = k \\mid , b) = \\int_0^\\infty P(K_J = k \\mid \\alpha) \\cdot g_{,b}(\\alpha) d\\alpha$$ $$\\approx \\sum_{m=1}^M \\tilde{w}_m \\cdot P(K_J = k \\mid \\alpha_m)$$ \\(P(K_J = k \\mid \\alpha)\\) Antoniak distribution Module 04 \\((\\alpha_m, \\tilde{w}_m)\\) transformed quadrature nodes normalized weights Module 02. Implementation: mixing performed log-space numerical stability. critical large J extreme parameter values. Key properties: \\(P(K_J = 0) = 0\\) always (least one cluster exists) PMF sums 1 Moments PMF match exact_K_moments() within numerical tolerance Mode typically near \\(E[K_J]\\) may differ","code":""},{"path":"https://joonho112.github.io/DPprior/reference/pmf_K_marginal.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Marginal PMF of K_J under Gamma Hyperprior ‚Äî pmf_K_marginal","text":"Antoniak, C. E. (1974). Mixtures Dirichlet Processes Applications Bayesian Nonparametric Problems. Annals Statistics, 2(6), 1152-1174.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/pmf_K_marginal.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Marginal PMF of K_J under Gamma Hyperprior ‚Äî pmf_K_marginal","text":"","code":"# Pre-compute Stirling numbers logS <- compute_log_stirling(50)  # Compute marginal PMF for J=50, Gamma(1.5, 0.5) prior pmf <- pmf_K_marginal(50, 1.5, 0.5, logS)  # Verify normalization sum(pmf) #> [1] 1  # Most likely number of clusters which.max(pmf) - 1 #> [1] 6  # Compare mean with exact_K_moments k_vals <- 0:50 mean_pmf <- sum(k_vals * pmf) exact <- exact_K_moments(50, 1.5, 0.5) abs(mean_pmf - exact$mean) #> [1] 7.105427e-15"},{"path":"https://joonho112.github.io/DPprior/reference/poisson_kl_divergence.html","id":null,"dir":"Reference","previous_headings":"","what":"Poisson-Poisson KL Divergence ‚Äî poisson_kl_divergence","title":"Poisson-Poisson KL Divergence ‚Äî poisson_kl_divergence","text":"Computes Kullback-Leibler divergence two Poisson distributions: $$KL(\\text{Poisson}(\\lambda) || \\text{Poisson}(\\lambda')) =       \\lambda \\log(\\lambda/\\lambda') + \\lambda' - \\lambda$$","code":""},{"path":"https://joonho112.github.io/DPprior/reference/poisson_kl_divergence.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Poisson-Poisson KL Divergence ‚Äî poisson_kl_divergence","text":"","code":"poisson_kl_divergence(lambda, lambda_prime)"},{"path":"https://joonho112.github.io/DPprior/reference/poisson_kl_divergence.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Poisson-Poisson KL Divergence ‚Äî poisson_kl_divergence","text":"lambda Numeric; mean first Poisson distribution. lambda_prime Numeric; mean second Poisson distribution.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/poisson_kl_divergence.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Poisson-Poisson KL Divergence ‚Äî poisson_kl_divergence","text":"Numeric; KL divergence (non-negative, possibly Inf).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/poisson_kl_divergence.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Poisson-Poisson KL Divergence ‚Äî poisson_kl_divergence","text":"Special cases: \\(\\lambda = 0\\) \\(\\lambda' = 0\\): KL = 0 \\(\\lambda = 0\\) \\(\\lambda' > 0\\): KL = \\(\\lambda'\\) \\(\\lambda > 0\\) \\(\\lambda' = 0\\): KL = Inf","code":""},{"path":"https://joonho112.github.io/DPprior/reference/print.DPprior_diagnostics.html","id":null,"dir":"Reference","previous_headings":"","what":"Print Method for DPprior_diagnostics Objects ‚Äî print.DPprior_diagnostics","title":"Print Method for DPprior_diagnostics Objects ‚Äî print.DPprior_diagnostics","text":"Print Method DPprior_diagnostics Objects","code":""},{"path":"https://joonho112.github.io/DPprior/reference/print.DPprior_diagnostics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print Method for DPprior_diagnostics Objects ‚Äî print.DPprior_diagnostics","text":"","code":"# S3 method for class 'DPprior_diagnostics' print(x, ...)"},{"path":"https://joonho112.github.io/DPprior/reference/print.DPprior_diagnostics.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print Method for DPprior_diagnostics Objects ‚Äî print.DPprior_diagnostics","text":"x object class \"DPprior_diagnostics\". ... Additional arguments (ignored).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/print.DPprior_diagnostics.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print Method for DPprior_diagnostics Objects ‚Äî print.DPprior_diagnostics","text":"Invisibly returns input object.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/print.DPprior_error_bounds.html","id":null,"dir":"Reference","previous_headings":"","what":"Print Method for DPprior_error_bounds Objects ‚Äî print.DPprior_error_bounds","title":"Print Method for DPprior_error_bounds Objects ‚Äî print.DPprior_error_bounds","text":"Displays formatted summary A1 approximation error analysis.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/print.DPprior_error_bounds.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print Method for DPprior_error_bounds Objects ‚Äî print.DPprior_error_bounds","text":"","code":"# S3 method for class 'DPprior_error_bounds' print(x, ...)"},{"path":"https://joonho112.github.io/DPprior/reference/print.DPprior_error_bounds.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print Method for DPprior_error_bounds Objects ‚Äî print.DPprior_error_bounds","text":"x object class \"DPprior_error_bounds\". ... Additional arguments (ignored).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/print.DPprior_error_bounds.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print Method for DPprior_error_bounds Objects ‚Äî print.DPprior_error_bounds","text":"Invisibly returns input object.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/print.DPprior_fit.html","id":null,"dir":"Reference","previous_headings":"","what":"Print Method for DPprior_fit Objects ‚Äî print.DPprior_fit","title":"Print Method for DPprior_fit Objects ‚Äî print.DPprior_fit","text":"Displays concise, informative summary prior elicitation result, including Gamma hyperprior specification, target vs achieved fit, dominance risk assessment.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/print.DPprior_fit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print Method for DPprior_fit Objects ‚Äî print.DPprior_fit","text":"","code":"# S3 method for class 'DPprior_fit' print(x, digits = 4, ...)"},{"path":"https://joonho112.github.io/DPprior/reference/print.DPprior_fit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print Method for DPprior_fit Objects ‚Äî print.DPprior_fit","text":"x DPprior_fit object. digits Integer; number significant digits display. Default 4. ... Additional arguments (currently unused).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/print.DPprior_fit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print Method for DPprior_fit Objects ‚Äî print.DPprior_fit","text":"Invisibly returns x.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/print.DPprior_fit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Print Method for DPprior_fit Objects ‚Äî print.DPprior_fit","text":"output includes: Gamma hyperprior parameters (, b) moments Escales::alpha SDscales::alpha Target specification (J, \\(E[K_J]\\), \\(Var(K_J)\\)) Achieved fit residual error Method used iteration count Quick dominance risk summary (diagnostics available)","code":""},{"path":"https://joonho112.github.io/DPprior/reference/print.DPprior_fit.html","id":"dominance-risk","dir":"Reference","previous_headings":"","what":"Dominance Risk","title":"Print Method for DPprior_fit Objects ‚Äî print.DPprior_fit","text":"diagnostics computed, dominance risk displayed : LOW: P(w1 > 0.5) < 20\\ MODERATE: 20\\ HIGH: P(w1 > 0.5) >= 40\\","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/print.DPprior_fit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print Method for DPprior_fit Objects ‚Äî print.DPprior_fit","text":"","code":"# Create a fit object fit <- DPprior_fit(J = 50, mu_K = 5, var_K = 8) #> Warning: HIGH DOMINANCE RISK: P(w1 > 0.5) = 48.1% exceeds 40%. #>   This may indicate unintended prior behavior (Lee, 2026). #>   Consider using DPprior_dual() for weight-constrained elicitation. #>   See ?DPprior_diagnostics for interpretation. print(fit) #> DPprior Prior Elicitation Result #> =============================================  #>  #> Gamma Hyperprior: Œ± ~ Gamma(a = 2.0361, b = 1.6051) #>   E[Œ±] = 1.269, SD[Œ±] = 0.889 #>  #> Target (J = 50): #>   E[K_J]   = 5.00 #>   Var(K_J) = 8.00 #>  #> Achieved: #>   E[K_J] = 5.000000, Var(K_J) = 8.000000 #>   Residual = 7.60e-09 #>  #> Method: A2-MN (6 iterations) #>  #> Dominance Risk: HIGH ‚úò (P(w‚ÇÅ>0.5) = 48%)  # With custom digits print(fit, digits = 6) #> DPprior Prior Elicitation Result #> =============================================  #>  #> Gamma Hyperprior: Œ± ~ Gamma(a = 2.036093, b = 1.605054) #>   E[Œ±] = 1.269, SD[Œ±] = 0.889 #>  #> Target (J = 50): #>   E[K_J]   = 5.00 #>   Var(K_J) = 8.00 #>  #> Achieved: #>   E[K_J] = 5.00000000, Var(K_J) = 8.00000001 #>   Residual = 7.60e-09 #>  #> Method: A2-MN (6 iterations) #>  #> Dominance Risk: HIGH ‚úò (P(w‚ÇÅ>0.5) = 48%)"},{"path":"https://joonho112.github.io/DPprior/reference/print.rho_summary.html","id":null,"dir":"Reference","previous_headings":"","what":"Print Method for rho_summary Objects ‚Äî print.rho_summary","title":"Print Method for rho_summary Objects ‚Äî print.rho_summary","text":"Print Method rho_summary Objects","code":""},{"path":"https://joonho112.github.io/DPprior/reference/print.rho_summary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print Method for rho_summary Objects ‚Äî print.rho_summary","text":"","code":"# S3 method for class 'rho_summary' print(x, digits = 4, ...)"},{"path":"https://joonho112.github.io/DPprior/reference/print.rho_summary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print Method for rho_summary Objects ‚Äî print.rho_summary","text":"x object class \"rho_summary\". digits Integer; number digits printing. ... Additional arguments (ignored).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/print.rho_summary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print Method for rho_summary Objects ‚Äî print.rho_summary","text":"Invisibly returns input object.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/print.summary.DPprior_fit.html","id":null,"dir":"Reference","previous_headings":"","what":"Print Method for summary.DPprior_fit ‚Äî print.summary.DPprior_fit","title":"Print Method for summary.DPprior_fit ‚Äî print.summary.DPprior_fit","text":"Print Method summary.DPprior_fit","code":""},{"path":"https://joonho112.github.io/DPprior/reference/print.summary.DPprior_fit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print Method for summary.DPprior_fit ‚Äî print.summary.DPprior_fit","text":"","code":"# S3 method for class 'summary.DPprior_fit' print(x, diagnostics = FALSE, max_trace = 10L, ...)"},{"path":"https://joonho112.github.io/DPprior/reference/print.summary.DPprior_fit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print Method for summary.DPprior_fit ‚Äî print.summary.DPprior_fit","text":"x summary.DPprior_fit object. diagnostics Logical; TRUE, print full diagnostics. Default FALSE. max_trace Integer; maximum number trace rows display. Default 10. ... Additional arguments (currently unused).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/print.summary.DPprior_fit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print Method for summary.DPprior_fit ‚Äî print.summary.DPprior_fit","text":"Invisibly returns x.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/print.w1_summary.html","id":null,"dir":"Reference","previous_headings":"","what":"Print Method for w1_summary Objects ‚Äî print.w1_summary","title":"Print Method for w1_summary Objects ‚Äî print.w1_summary","text":"Print Method w1_summary Objects","code":""},{"path":"https://joonho112.github.io/DPprior/reference/print.w1_summary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print Method for w1_summary Objects ‚Äî print.w1_summary","text":"","code":"# S3 method for class 'w1_summary' print(x, digits = 4, ...)"},{"path":"https://joonho112.github.io/DPprior/reference/print.w1_summary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print Method for w1_summary Objects ‚Äî print.w1_summary","text":"x object class \"w1_summary\". digits Integer; number digits printing. ... Additional arguments (ignored).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/print.w1_summary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print Method for w1_summary Objects ‚Äî print.w1_summary","text":"Invisibly returns input object.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/prob_w1_exceeds.html","id":null,"dir":"Reference","previous_headings":"","what":"Survival Function of w‚ÇÅ ‚Äî prob_w1_exceeds","title":"Survival Function of w‚ÇÅ ‚Äî prob_w1_exceeds","text":"Computes P(w‚ÇÅ > t | , b) = 1 - F(t), probability first stick-breaking weight exceeds threshold t.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/prob_w1_exceeds.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Survival Function of w‚ÇÅ ‚Äî prob_w1_exceeds","text":"","code":"prob_w1_exceeds(t, a, b)"},{"path":"https://joonho112.github.io/DPprior/reference/prob_w1_exceeds.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Survival Function of w‚ÇÅ ‚Äî prob_w1_exceeds","text":"t Numeric vector thresholds. Values outside unit interval allowed mapped boundary values (1 t ‚â§ 0, 0 t ‚â• 1). Numeric; shape parameter Gamma prior Œ± (> 0). b Numeric; rate parameter Gamma prior Œ± (b > 0).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/prob_w1_exceeds.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Survival Function of w‚ÇÅ ‚Äî prob_w1_exceeds","text":"Numeric vector survival probabilities.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/prob_w1_exceeds.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Survival Function of w‚ÇÅ ‚Äî prob_w1_exceeds","text":"survival function closed form: $$P(w_1 > t | , b) = \\left(\\frac{b}{b - \\log(1-t)}\\right)^$$ key quantity dominance risk assessment (Lee, 2026, Section 4). large P(w‚ÇÅ > 0.5) indicates high prior probability single cluster dominates mixture.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/prob_w1_exceeds.html","id":"dominance-risk-interpretation","dir":"Reference","previous_headings":"","what":"Dominance Risk Interpretation","title":"Survival Function of w‚ÇÅ ‚Äî prob_w1_exceeds","text":"P(w‚ÇÅ > 0.5) ‚âà 0.5: moderate dominance risk P(w‚ÇÅ > 0.9) ‚âà 0.1: low extreme dominance risk","code":""},{"path":"https://joonho112.github.io/DPprior/reference/prob_w1_exceeds.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Survival Function of w‚ÇÅ ‚Äî prob_w1_exceeds","text":"Lee, J. (2026). Design-Conditional Prior Elicitation Dirichlet Process Mixtures. arXiv preprint arXiv:2602.06301.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/prob_w1_exceeds.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Survival Function of w‚ÇÅ ‚Äî prob_w1_exceeds","text":"","code":"# P(w‚ÇÅ > 0.5): \"dominant cluster\" probability prob_w1_exceeds(0.5, a = 1.6, b = 1.22)  # ~0.487 (Lee et al. DP-inform) #> [1] 0.4868311 prob_w1_exceeds(0.5, a = 2, b = 1)       # ~0.349 #> [1] 0.3488274"},{"path":"https://joonho112.github.io/DPprior/reference/quantile_K_given_alpha.html","id":null,"dir":"Reference","previous_headings":"","what":"Quantile of K Given Alpha ‚Äî quantile_K_given_alpha","title":"Quantile of K Given Alpha ‚Äî quantile_K_given_alpha","text":"Computes \\(p\\)-th quantile \\(K_J \\mid \\alpha\\), defined smallest \\(k\\) \\(P(K_J \\leq k \\mid \\alpha) \\geq p\\).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/quantile_K_given_alpha.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Quantile of K Given Alpha ‚Äî quantile_K_given_alpha","text":"","code":"quantile_K_given_alpha(p, J, alpha, logS)"},{"path":"https://joonho112.github.io/DPprior/reference/quantile_K_given_alpha.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Quantile of K Given Alpha ‚Äî quantile_K_given_alpha","text":"p Numeric; probability level(s) \\([0, 1]\\). Can scalar vector. J Integer; sample size. alpha Numeric; DP concentration parameter. logS Matrix; pre-computed log-Stirling matrix.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/quantile_K_given_alpha.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Quantile of K Given Alpha ‚Äî quantile_K_given_alpha","text":"Integer (integer vector); \\(p\\)-th quantile(s) \\(K_J \\mid \\alpha\\).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/quantile_K_given_alpha.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Quantile of K Given Alpha ‚Äî quantile_K_given_alpha","text":"\\(p = 0.5\\), gives median. Note discrete distributions, quantile defined smallest value CDF meets exceeds \\(p\\). Edge cases: \\(p = 0\\): returns 0 (first k CDF >= 0) \\(p = 1\\): returns J (maximum possible K)","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/quantile_K_given_alpha.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Quantile of K Given Alpha ‚Äî quantile_K_given_alpha","text":"","code":"logS <- compute_log_stirling(50)  # Single quantile (median) quantile_K_given_alpha(0.5, 50, 2.0, logS) #> [1] 7  # Multiple quantiles quantile_K_given_alpha(c(0.25, 0.5, 0.75), 50, 2.0, logS) #> [1] 6 7 8  # Edge cases quantile_K_given_alpha(0, 50, 2.0, logS)  # Returns 0 #> [1] 0 quantile_K_given_alpha(1, 50, 2.0, logS)  # Returns 50 #> [1] 50"},{"path":"https://joonho112.github.io/DPprior/reference/quantile_K_marginal.html","id":null,"dir":"Reference","previous_headings":"","what":"Quantile of Marginal K Distribution ‚Äî quantile_K_marginal","title":"Quantile of Marginal K Distribution ‚Äî quantile_K_marginal","text":"Computes \\(p\\)-th quantile marginal distribution \\(K_J\\).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/quantile_K_marginal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Quantile of Marginal K Distribution ‚Äî quantile_K_marginal","text":"","code":"quantile_K_marginal(p, J, a, b, logS, M = .QUAD_NODES_DEFAULT)"},{"path":"https://joonho112.github.io/DPprior/reference/quantile_K_marginal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Quantile of Marginal K Distribution ‚Äî quantile_K_marginal","text":"p Numeric; probability level(s) \\([0, 1]\\). Can scalar vector. J Integer; sample size. Numeric; shape parameter Gamma prior (> 0). b Numeric; rate parameter Gamma prior (> 0). logS Matrix; pre-computed log-Stirling matrix. M Integer; number quadrature nodes (default: 80).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/quantile_K_marginal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Quantile of Marginal K Distribution ‚Äî quantile_K_marginal","text":"Integer vector quantiles (length p). element smallest \\(k\\) \\(P(K_J \\leq k) \\geq p\\).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/quantile_K_marginal.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Quantile of Marginal K Distribution ‚Äî quantile_K_marginal","text":"standard quantile definition discrete distributions: \\(Q(p) = \\min\\{k : F(k) \\geq p\\}\\). function vectorized p, allowing efficient computation multiple quantiles single call.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/quantile_K_marginal.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Quantile of Marginal K Distribution ‚Äî quantile_K_marginal","text":"","code":"logS <- compute_log_stirling(50)  # Single quantile (median) quantile_K_marginal(0.5, 50, 1.5, 0.5, logS) #> [1] 8  # Multiple quantiles at once quantile_K_marginal(c(0.1, 0.25, 0.5, 0.75, 0.9), 50, 1.5, 0.5, logS) #> [1]  3  5  8 11 15  # Interquartile range qs <- quantile_K_marginal(c(0.25, 0.75), 50, 1.5, 0.5, logS) diff(qs) #> [1] 6"},{"path":"https://joonho112.github.io/DPprior/reference/quantile_w1.html","id":null,"dir":"Reference","previous_headings":"","what":"Quantile Function of w‚ÇÅ ‚Äî quantile_w1","title":"Quantile Function of w‚ÇÅ ‚Äî quantile_w1","text":"Computes inverse CDF: Q(u | , b) = F‚Åª¬π(u).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/quantile_w1.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Quantile Function of w‚ÇÅ ‚Äî quantile_w1","text":"","code":"quantile_w1(u, a, b)"},{"path":"https://joonho112.github.io/DPprior/reference/quantile_w1.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Quantile Function of w‚ÇÅ ‚Äî quantile_w1","text":"u Numeric vector probability levels unit interval. Values u ‚â§ 0 return 0 u ‚â• 1 return 1. Numeric; shape parameter Gamma prior Œ± (> 0). b Numeric; rate parameter Gamma prior Œ± (b > 0).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/quantile_w1.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Quantile Function of w‚ÇÅ ‚Äî quantile_w1","text":"Numeric vector quantile values Q(u | , b).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/quantile_w1.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Quantile Function of w‚ÇÅ ‚Äî quantile_w1","text":"quantile function closed form: $$Q_{w_1}(u | , b) = 1 - \\exp\\left(b \\left[1 - (1-u)^{-1/}\\right]\\right)$$ implementation computes (1-u)^(-1/) log space stability u close 1. Numerical Note: small values (< 1) u close 1, quantile approaches 1 rapidly may round 1.0 double precision.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/quantile_w1.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Quantile Function of w‚ÇÅ ‚Äî quantile_w1","text":"Lee, J. (2026). Design-Conditional Prior Elicitation Dirichlet Process Mixtures. arXiv preprint arXiv:2602.06301.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/quantile_w1.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Quantile Function of w‚ÇÅ ‚Äî quantile_w1","text":"","code":"# Median of w‚ÇÅ quantile_w1(0.5, a = 2, b = 1)  # ~0.339 #> [1] 0.3391402  # 90th percentile quantile_w1(0.9, a = 2, b = 1)  # ~0.732 #> [1] 0.8849373"},{"path":"https://joonho112.github.io/DPprior/reference/rho_conditional_grid.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute rho Conditional Moments on alpha Grid ‚Äî rho_conditional_grid","title":"Compute rho Conditional Moments on alpha Grid ‚Äî rho_conditional_grid","text":"Computes conditional mean variance rho grid alpha values. Useful visualization rho varies alpha.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/rho_conditional_grid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute rho Conditional Moments on alpha Grid ‚Äî rho_conditional_grid","text":"","code":"rho_conditional_grid(alpha_grid = seq(0.1, 10, length.out = 100))"},{"path":"https://joonho112.github.io/DPprior/reference/rho_conditional_grid.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute rho Conditional Moments on alpha Grid ‚Äî rho_conditional_grid","text":"alpha_grid Numeric vector; grid alpha values. Default seq(0.1, 10, length.= 100).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/rho_conditional_grid.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute rho Conditional Moments on alpha Grid ‚Äî rho_conditional_grid","text":"data frame columns: alpha Grid points mean E(rho | alpha) var Var(rho | alpha) sd SD(rho | alpha)","code":""},{"path":"https://joonho112.github.io/DPprior/reference/rho_conditional_grid.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute rho Conditional Moments on alpha Grid ‚Äî rho_conditional_grid","text":"","code":"df <- rho_conditional_grid() plot(df$alpha, df$mean, type = \"l\",      xlab = expression(alpha), ylab = expression(E(rho)))"},{"path":"https://joonho112.github.io/DPprior/reference/rrho.html","id":null,"dir":"Reference","previous_headings":"","what":"Random Generation from rho Distribution ‚Äî rrho","title":"Random Generation from rho Distribution ‚Äî rrho","text":"Generates random samples rho = sum w_h^2 distribution stick-breaking simulation.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/rrho.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Random Generation from rho Distribution ‚Äî rrho","text":"","code":"rrho(n, a, b, n_sticks = 500L)"},{"path":"https://joonho112.github.io/DPprior/reference/rrho.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Random Generation from rho Distribution ‚Äî rrho","text":"n Integer; number samples generate. Numeric; shape parameter Gamma prior alpha (> 0). b Numeric; rate parameter Gamma prior alpha (b > 0). n_sticks Integer; number sticks truncation. Default 500.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/rrho.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Random Generation from rho Distribution ‚Äî rrho","text":"Numeric vector length n; random samples rho distribution.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/rrho.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Random Generation from rho Distribution ‚Äî rrho","text":"Uses hierarchical representation: alpha ~ Gamma(, b) v_h | alpha ~ Beta(1, alpha) independently h = 1, ..., n_sticks w_1 = v_1, w_h = v_h * prod(1 - v_l) l < h rho = sum w_h^2 Useful Monte Carlo validation analytical formulas.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/rrho.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Random Generation from rho Distribution ‚Äî rrho","text":"","code":"set.seed(42) rho_samples <- rrho(1000, a = 2, b = 1) mean(rho_samples) #> [1] 0.4096141 mean_rho(a = 2, b = 1) #> [1] 0.4036526"},{"path":"https://joonho112.github.io/DPprior/reference/rw1.html","id":null,"dir":"Reference","previous_headings":"","what":"Random Generation from w‚ÇÅ Distribution ‚Äî rw1","title":"Random Generation from w‚ÇÅ Distribution ‚Äî rw1","text":"Generates random samples w‚ÇÅ distribution first sampling Œ± ~ Gamma(, b), w‚ÇÅ | Œ± ~ Beta(1, Œ±).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/rw1.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Random Generation from w‚ÇÅ Distribution ‚Äî rw1","text":"","code":"rw1(n, a, b)"},{"path":"https://joonho112.github.io/DPprior/reference/rw1.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Random Generation from w‚ÇÅ Distribution ‚Äî rw1","text":"n Integer; number samples generate. Numeric; shape parameter Gamma prior Œ± (> 0). b Numeric; rate parameter Gamma prior Œ± (b > 0).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/rw1.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Random Generation from w‚ÇÅ Distribution ‚Äî rw1","text":"Numeric vector length n; random samples w‚ÇÅ distribution.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/rw1.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Random Generation from w‚ÇÅ Distribution ‚Äî rw1","text":"function uses hierarchical representation: Œ± ~ Gamma(, b) w‚ÇÅ | Œ± ~ Beta(1, Œ±) Useful Monte Carlo validation closed-form functions.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/rw1.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Random Generation from w‚ÇÅ Distribution ‚Äî rw1","text":"","code":"# Generate samples set.seed(42) samples <- rw1(10000, a = 2, b = 1)  # Compare empirical vs theoretical mean mean(samples)          # ~0.404 #> [1] 0.4023996 mean_w1(a = 2, b = 1)  # 0.4037 #> [1] 0.4036526"},{"path":"https://joonho112.github.io/DPprior/reference/score_a.html","id":null,"dir":"Reference","previous_headings":"","what":"Score Function with Respect to Shape Parameter a ‚Äî score_a","title":"Score Function with Respect to Shape Parameter a ‚Äî score_a","text":"Computes score function \\(s_a(\\alpha) = \\partial/\\partial \\log g_{,b}(\\alpha)\\) Gamma(, b) distribution.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/score_a.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Score Function with Respect to Shape Parameter a ‚Äî score_a","text":"","code":"score_a(alpha, a, b)"},{"path":"https://joonho112.github.io/DPprior/reference/score_a.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Score Function with Respect to Shape Parameter a ‚Äî score_a","text":"alpha Numeric vector; points evaluate. Numeric scalar; shape parameter Gamma distribution (> 0). b Numeric scalar; rate parameter Gamma distribution (> 0).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/score_a.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Score Function with Respect to Shape Parameter a ‚Äî score_a","text":"Numeric vector length alpha.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/score_a.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Score Function with Respect to Shape Parameter a ‚Äî score_a","text":"Gamma(shape = , rate = b) distribution density $$g_{,b}(\\alpha) = \\frac{b^}{\\Gamma()} \\alpha^{-1} e^{-b\\alpha},$$ score function respect : $$s_a(\\alpha) = \\log b - \\psi() + \\log \\alpha,$$ \\(\\psi\\) digamma function. fundamental property score functions expectation zero: $$E_{\\alpha \\sim g_{,b}}[s_a(\\alpha)] = 0.$$ Numerical Note: log(alpha) term causes slower quadrature convergence score-weighted integrands compared moments . Use higher M (e.g., 120-200) verification purposes.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/score_a.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Score Function with Respect to Shape Parameter a ‚Äî score_a","text":"Lee, J. (2026). Design-Conditional Prior Elicitation Dirichlet Process Mixtures. arXiv preprint arXiv:2602.06301.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/score_a.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Score Function with Respect to Shape Parameter a ‚Äî score_a","text":"","code":"# Evaluate score at several points alpha_vals <- c(0.5, 1.0, 2.0, 5.0) score_a(alpha_vals, a = 2.0, b = 1.0) #> [1] -1.1159315 -0.4227843  0.2703628  1.1866536"},{"path":"https://joonho112.github.io/DPprior/reference/score_b.html","id":null,"dir":"Reference","previous_headings":"","what":"Score Function with Respect to Rate Parameter b ‚Äî score_b","title":"Score Function with Respect to Rate Parameter b ‚Äî score_b","text":"Computes score function \\(s_b(\\alpha) = \\partial/\\partial b \\log g_{,b}(\\alpha)\\) Gamma(, b) distribution.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/score_b.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Score Function with Respect to Rate Parameter b ‚Äî score_b","text":"","code":"score_b(alpha, a, b)"},{"path":"https://joonho112.github.io/DPprior/reference/score_b.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Score Function with Respect to Rate Parameter b ‚Äî score_b","text":"alpha Numeric vector; points evaluate. Numeric scalar; shape parameter Gamma distribution (> 0). b Numeric scalar; rate parameter Gamma distribution (> 0).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/score_b.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Score Function with Respect to Rate Parameter b ‚Äî score_b","text":"Numeric vector length alpha.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/score_b.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Score Function with Respect to Rate Parameter b ‚Äî score_b","text":"Gamma(shape = , rate = b) distribution, score function respect b : $$s_b(\\alpha) = \\frac{}{b} - \\alpha.$$ fundamental property score functions expectation zero: $$E_{\\alpha \\sim g_{,b}}[s_b(\\alpha)] = 0.$$ Unlike score_a, function linear \\(\\alpha\\), expectation converges quickly quadrature.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/score_b.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Score Function with Respect to Rate Parameter b ‚Äî score_b","text":"Lee, J. (2026). Design-Conditional Prior Elicitation Dirichlet Process Mixtures. arXiv preprint arXiv:2602.06301.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/score_b.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Score Function with Respect to Rate Parameter b ‚Äî score_b","text":"","code":"# Evaluate score at several points alpha_vals <- c(0.5, 1.0, 2.0, 5.0) score_b(alpha_vals, a = 2.0, b = 1.0) #> [1]  1.5  1.0  0.0 -3.0"},{"path":"https://joonho112.github.io/DPprior/reference/softmax.html","id":null,"dir":"Reference","previous_headings":"","what":"Numerically Stable Softmax ‚Äî softmax","title":"Numerically Stable Softmax ‚Äî softmax","text":"Computes softmax transformation numeric vector, returning probability vector sums 1.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/softmax.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Numerically Stable Softmax ‚Äî softmax","text":"","code":"softmax(x)"},{"path":"https://joonho112.github.io/DPprior/reference/softmax.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Numerically Stable Softmax ‚Äî softmax","text":"x Numeric vector log-odds arbitrary real values.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/softmax.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Numerically Stable Softmax ‚Äî softmax","text":"Numeric vector probabilities summing 1.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/softmax.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Numerically Stable Softmax ‚Äî softmax","text":"softmax function defined : $$p_i = \\frac{\\exp(x_i)}{\\sum_j \\exp(x_j)}$$ implementation subtracts maximum value exponentiating ensure numerical stability extreme inputs. Special cases: x contains Inf values, probability mass split uniformly across Inf entries. Empty vector throws error.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/softmax.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Numerically Stable Softmax ‚Äî softmax","text":"","code":"if (FALSE) { # \\dontrun{ softmax(c(1, 2, 3)) sum(softmax(c(1, 2, 3)))  # Works with extreme values softmax(c(1000, 1001, 1002))  # Inf handling softmax(c(1, Inf, Inf))  } # }"},{"path":"https://joonho112.github.io/DPprior/reference/summary.DPprior_diagnostics.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary Method for DPprior_diagnostics Objects ‚Äî summary.DPprior_diagnostics","title":"Summary Method for DPprior_diagnostics Objects ‚Äî summary.DPprior_diagnostics","text":"Summary Method DPprior_diagnostics Objects","code":""},{"path":"https://joonho112.github.io/DPprior/reference/summary.DPprior_diagnostics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary Method for DPprior_diagnostics Objects ‚Äî summary.DPprior_diagnostics","text":"","code":"# S3 method for class 'DPprior_diagnostics' summary(object, ...)"},{"path":"https://joonho112.github.io/DPprior/reference/summary.DPprior_diagnostics.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary Method for DPprior_diagnostics Objects ‚Äî summary.DPprior_diagnostics","text":"object object class \"DPprior_diagnostics\". ... Additional arguments (ignored).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/summary.DPprior_diagnostics.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summary Method for DPprior_diagnostics Objects ‚Äî summary.DPprior_diagnostics","text":"data frame key diagnostic metrics.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/summary.DPprior_error_bounds.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary Method for DPprior_error_bounds Objects ‚Äî summary.DPprior_error_bounds","title":"Summary Method for DPprior_error_bounds Objects ‚Äî summary.DPprior_error_bounds","text":"Provides detailed summary including conditional bounds multiple alpha values.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/summary.DPprior_error_bounds.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary Method for DPprior_error_bounds Objects ‚Äî summary.DPprior_error_bounds","text":"","code":"# S3 method for class 'DPprior_error_bounds' summary(object, ...)"},{"path":"https://joonho112.github.io/DPprior/reference/summary.DPprior_error_bounds.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary Method for DPprior_error_bounds Objects ‚Äî summary.DPprior_error_bounds","text":"object object class \"DPprior_error_bounds\". ... Additional arguments (ignored).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/summary.DPprior_error_bounds.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summary Method for DPprior_error_bounds Objects ‚Äî summary.DPprior_error_bounds","text":"Invisibly returns input object.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/summary.DPprior_fit.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary Method for DPprior_fit Objects ‚Äî summary.DPprior_fit","title":"Summary Method for DPprior_fit Objects ‚Äî summary.DPprior_fit","text":"Produces comprehensive summary prior elicitation result, including detailed parameter information, target vs achieved comparison, full diagnostic statistics.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/summary.DPprior_fit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary Method for DPprior_fit Objects ‚Äî summary.DPprior_fit","text":"","code":"# S3 method for class 'DPprior_fit' summary(object, print_output = TRUE, ...)"},{"path":"https://joonho112.github.io/DPprior/reference/summary.DPprior_fit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary Method for DPprior_fit Objects ‚Äî summary.DPprior_fit","text":"object DPprior_fit object. print_output Logical; TRUE (default), prints summary console. FALSE, returns summary list silently. ... Additional arguments (currently unused).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/summary.DPprior_fit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summary Method for DPprior_fit Objects ‚Äî summary.DPprior_fit","text":"object class \"summary.DPprior_fit\" containing: method: Calibration method used status: Convergence status gamma_prior: List (, b) parameters alpha_summary: List Escales::alpha, Varscales::alpha, CVscales::alpha target: Target specification achieved: Achieved fit errors: Absolute relative fitting errors converged: Logical convergence flag iterations: Number iterations diagnostics: Full diagnostic information (available)","code":""},{"path":"https://joonho112.github.io/DPprior/reference/summary.DPprior_fit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Summary Method for DPprior_fit Objects ‚Äî summary.DPprior_fit","text":"printed summary includes: Basic information (J, method) Gamma hyperprior parameters derived statistics Target vs Achieved comparison table error metrics Full diagnostics alpha, K, w1 distributions (computed) Iteration trace (first 10 rows, available)","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/summary.DPprior_fit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summary Method for DPprior_fit Objects ‚Äî summary.DPprior_fit","text":"","code":"# Create a fit object fit <- DPprior_fit(J = 50, mu_K = 5, var_K = 8, check_diagnostics = TRUE) #> Warning: HIGH DOMINANCE RISK: P(w1 > 0.5) = 48.1% exceeds 40%. #>   This may indicate unintended prior behavior (Lee, 2026). #>   Consider using DPprior_dual() for weight-constrained elicitation. #>   See ?DPprior_diagnostics for interpretation. summary(fit) #> DPprior Prior Elicitation Summary #> ============================================================  #>  #> Sample size: J = 50 #> Method: A2-MN #> Status: success #>  #> Gamma Hyperprior: #> ----------------------------------------  #>   Shape (a) = 2.036093 #>   Rate (b)  = 1.605054 #>   E[Œ±] = 1.2686, SD[Œ±] = 0.8890, CV[Œ±] = 0.7008 #>  #> Target vs Achieved: #> ----------------------------------------  #>                         Target     Achieved        Error #>   E[K_J]                5.0000       5.0000     8.31e-10 #>   Var(K_J)              8.0000       8.0000     7.55e-09 #>  #> Diagnostics: #> ----------------------------------------  #>   Alpha: #>     Mean = 1.2686, SD = 0.8890, CV = 0.7008 #>     90% CI: [0.230, 2.992] #>   K_J: #>     Mean = 5.00, SD = 2.83, Mode = 3 #>   First weight (w‚ÇÅ): #>     Mean = 0.5014 #>     P(w‚ÇÅ > 0.5) = 48.1% #>     P(w‚ÇÅ > 0.9) = 16.3% #>     Dominance risk: HIGH #>  #> Iteration Trace: #> ----------------------------------------  #>   iter        a         b       M1         V     residual step   det_Jlog #> 1    1 4.000000 3.9120230 4.461351  4.783136 3.261649e+00    1  -5.300969 #> 2    2 1.178650 0.9119694 4.909046 10.854537 2.855986e+00    1 -21.553612 #> 3    3 1.844384 1.4552538 4.974913  8.399473 4.002603e-01    1 -15.313512 #> 4    4 2.029223 1.5996801 4.999187  8.013243 1.326844e-02    1 -14.298307 #> 5    5 2.036082 1.6050455 4.999999  8.000021 2.078492e-05    1 -14.263052 #> 6    6 2.036093 1.6050541 5.000000  8.000000 7.600363e-09   NA -14.262997 #>  #> Diagnostics: dominance risk = HIGH (use diagnostics=TRUE for full report) #>   # Store summary without printing summ <- summary(fit, print_output = FALSE) str(summ) #> List of 13 #>  $ method       : chr \"A2-MN\" #>  $ status       : chr \"success\" #>  $ gamma_prior  :List of 2 #>   ..$ a: num 2.04 #>   ..$ b: num 1.61 #>  $ alpha_summary:List of 4 #>   ..$ E_alpha  : num 1.27 #>   ..$ Var_alpha: num 0.79 #>   ..$ SD_alpha : num 0.889 #>   ..$ CV_alpha : num 0.701 #>  $ target       :List of 4 #>   ..$ mu_K      : num 5 #>   ..$ var_K     : num 8 #>   ..$ var_K_used: num 8 #>   ..$ confidence: chr NA #>  $ achieved     :List of 3 #>   ..$ mu_K    : num 5 #>   ..$ var_K   : num 8 #>   ..$ residual: num 7.6e-09 #>  $ errors       :List of 4 #>   ..$ mu_K_abs     : num 8.31e-10 #>   ..$ var_K_abs    : num 7.55e-09 #>   ..$ mu_K_rel_pct : num 1.66e-08 #>   ..$ var_K_rel_pct: num 9.44e-08 #>  $ scaling      :List of 1 #>   ..$ J: num 50 #>  $ converged    : logi TRUE #>  $ iterations   : int 6 #>  $ diagnostics  :List of 8 #>   ..$ J           : int 50 #>   ..$ a           : num 2.04 #>   ..$ b           : num 1.61 #>   ..$ alpha       :List of 5 #>   .. ..$ mean     : num 1.27 #>   .. ..$ sd       : num 0.889 #>   .. ..$ cv       : num 0.701 #>   .. ..$ median   : num 1.07 #>   .. ..$ quantiles: Named num [1:5] 0.23 0.615 1.068 1.706 2.992 #>   .. .. ..- attr(*, \"names\")= chr [1:5] \"q5\" \"q25\" \"q50\" \"q75\" ... #>   ..$ K           :List of 7 #>   .. ..$ mean     : num 5 #>   .. ..$ var      : num 8 #>   .. ..$ sd       : num 2.83 #>   .. ..$ mode     : int 3 #>   .. ..$ median   : int 5 #>   .. ..$ quantiles: Named int [1:5] 1 3 5 7 10 #>   .. .. ..- attr(*, \"names\")= chr [1:5] \"q5\" \"q25\" \"q50\" \"q75\" ... #>   .. ..$ pmf      : num [1:50] 0.0746 0.1247 0.1473 0.1472 0.132 ... #>   ..$ weights     :List of 5 #>   .. ..$ mean          : num 0.501 #>   .. ..$ median        : num 0.478 #>   .. ..$ quantiles     : Named num [1:5] 0.0401 0.2162 0.4784 0.7911 0.9954 #>   .. .. ..- attr(*, \"names\")= chr [1:5] \"q5\" \"q25\" \"q50\" \"q75\" ... #>   .. ..$ prob_exceeds  : Named num [1:2] 0.481 0.163 #>   .. .. ..- attr(*, \"names\")= chr [1:2] \"prob_gt_0.5\" \"prob_gt_0.9\" #>   .. ..$ dominance_risk: chr \"high\" #>   ..$ coclustering:List of 4 #>   .. ..$ mean          : num 0.501 #>   .. ..$ var           : num 0.065 #>   .. ..$ sd            : num 0.255 #>   .. ..$ interpretation: chr \"High prior co-clustering: most unit pairs expected in same cluster\" #>   ..$ warnings    : chr [1:2] \"HIGH DOMINANCE RISK: P(w1 > 0.5) = 48.1% exceeds 40%\" \"NEAR-DEGENERATE RISK: P(w1 > 0.9) = 16.3% exceeds 15%\" #>   ..- attr(*, \"class\")= chr \"DPprior_diagnostics\" #>  $ trace        :'data.frame':\t6 obs. of  8 variables: #>   ..$ iter    : int [1:6] 1 2 3 4 5 6 #>   ..$ a       : num [1:6] 4 1.18 1.84 2.03 2.04 ... #>   ..$ b       : num [1:6] 3.912 0.912 1.455 1.6 1.605 ... #>   ..$ M1      : num [1:6] 4.46 4.91 4.97 5 5 ... #>   ..$ V       : num [1:6] 4.78 10.85 8.4 8.01 8 ... #>   ..$ residual: num [1:6] 3.26 2.86 4.00e-01 1.33e-02 2.08e-05 ... #>   ..$ step    : num [1:6] 1 1 1 1 1 NA #>   ..$ det_Jlog: num [1:6] -5.3 -21.6 -15.3 -14.3 -14.3 ... #>  $ dual_anchor  : NULL #>  - attr(*, \"class\")= chr \"summary.DPprior_fit\""},{"path":"https://joonho112.github.io/DPprior/reference/summary_K_given_alpha.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary of Conditional Moments ‚Äî summary_K_given_alpha","title":"Summary of Conditional Moments ‚Äî summary_K_given_alpha","text":"Returns comprehensive summary conditional distribution K given alpha.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/summary_K_given_alpha.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary of Conditional Moments ‚Äî summary_K_given_alpha","text":"","code":"summary_K_given_alpha(J, alpha)"},{"path":"https://joonho112.github.io/DPprior/reference/summary_K_given_alpha.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary of Conditional Moments ‚Äî summary_K_given_alpha","text":"J Sample size (integer >= 1). alpha Concentration parameter (scalar).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/summary_K_given_alpha.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summary of Conditional Moments ‚Äî summary_K_given_alpha","text":"list components: J, alpha, mean, var, sd, cv, dispersion, dmean_dalpha.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/summary_K_given_alpha.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summary of Conditional Moments ‚Äî summary_K_given_alpha","text":"","code":"if (FALSE) { # \\dontrun{ summary_K_given_alpha(50, 2.0)  } # }"},{"path":"https://joonho112.github.io/DPprior/reference/summary_K_marginal.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary Statistics for Marginal K Distribution ‚Äî summary_K_marginal","title":"Summary Statistics for Marginal K Distribution ‚Äî summary_K_marginal","text":"Computes comprehensive summary statistics marginal distribution \\(K_J\\) Gamma prior \\(\\alpha\\).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/summary_K_marginal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary Statistics for Marginal K Distribution ‚Äî summary_K_marginal","text":"","code":"summary_K_marginal(   J,   a,   b,   logS,   M = .QUAD_NODES_DEFAULT,   probs = c(0.05, 0.25, 0.5, 0.75, 0.95) )"},{"path":"https://joonho112.github.io/DPprior/reference/summary_K_marginal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary Statistics for Marginal K Distribution ‚Äî summary_K_marginal","text":"J Integer; sample size (positive integer >= 1). Numeric; shape parameter Gamma prior (> 0). b Numeric; rate parameter Gamma prior (> 0). logS Matrix; pre-computed log-Stirling matrix. M Integer; number quadrature nodes (default: 80). probs Numeric vector; probability levels quantiles (default: c(0.05, 0.25, 0.5, 0.75, 0.95)).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/summary_K_marginal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summary Statistics for Marginal K Distribution ‚Äî summary_K_marginal","text":"list components: J Sample size Gamma shape parameter b Gamma rate parameter mean Mean \\(E[K_J \\mid , b]\\) var Variance \\(Var(K_J \\mid , b)\\) sd Standard deviation cv Coefficient variation (sd/mean) mode Mode (likely value) median Median (50th percentile) quantiles Named integer vector quantiles probs pmf Full PMF vector cdf Full CDF vector","code":""},{"path":"https://joonho112.github.io/DPprior/reference/summary_K_marginal.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Summary Statistics for Marginal K Distribution ‚Äî summary_K_marginal","text":"function provides complete summary marginal distribution, combining PMF-based CDF-based statistics. mean variance computed PMF match exact_K_moments() within numerical tolerance. probs argument allows customization quantiles report, making flexible different reporting needs.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/summary_K_marginal.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summary Statistics for Marginal K Distribution ‚Äî summary_K_marginal","text":"","code":"logS <- compute_log_stirling(50) summary <- summary_K_marginal(50, 1.5, 0.5, logS)  # View main statistics summary$mean #> [1] 8.355487 summary$var #> [1] 22.76895 summary$mode #> [1] 6 summary$quantiles #>  q5 q25 q50 q75 q95  #>   2   5   8  11  17   # Custom quantiles summary2 <- summary_K_marginal(50, 1.5, 0.5, logS,                                probs = c(0.025, 0.5, 0.975)) summary2$quantiles #>  q2 q50 q98  #>   1   8  19   # Compare with exact moments exact <- exact_K_moments(50, 1.5, 0.5) c(summary$mean - exact$mean, summary$var - exact$var) #> [1] -7.105427e-15 -4.263256e-14"},{"path":"https://joonho112.github.io/DPprior/reference/summary_pmf_K_given_alpha.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary of Conditional PMF ‚Äî summary_pmf_K_given_alpha","title":"Summary of Conditional PMF ‚Äî summary_pmf_K_given_alpha","text":"Returns comprehensive summary conditional distribution \\(K_J \\mid \\alpha\\).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/summary_pmf_K_given_alpha.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary of Conditional PMF ‚Äî summary_pmf_K_given_alpha","text":"","code":"summary_pmf_K_given_alpha(J, alpha, logS)"},{"path":"https://joonho112.github.io/DPprior/reference/summary_pmf_K_given_alpha.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary of Conditional PMF ‚Äî summary_pmf_K_given_alpha","text":"J Integer; sample size. alpha Numeric; DP concentration parameter. logS Matrix; pre-computed log-Stirling matrix.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/summary_pmf_K_given_alpha.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summary of Conditional PMF ‚Äî summary_pmf_K_given_alpha","text":"list components: J Sample size alpha Concentration parameter mean Conditional mean \\(E[K_J \\mid \\alpha]\\) var Conditional variance \\(Var(K_J \\mid \\alpha)\\) sd Conditional standard deviation mode likely value K median Median K quantiles 25th, 50th, 75th percentiles pmf Full PMF vector cdf Full CDF vector","code":""},{"path":"https://joonho112.github.io/DPprior/reference/summary_pmf_K_given_alpha.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summary of Conditional PMF ‚Äî summary_pmf_K_given_alpha","text":"","code":"if (FALSE) { # \\dontrun{ logS <- compute_log_stirling(50) summary <- summary_pmf_K_given_alpha(50, 2.0, logS) print(summary)  } # }"},{"path":"https://joonho112.github.io/DPprior/reference/summary_quadrature.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Quadrature Information Summary ‚Äî summary_quadrature","title":"Get Quadrature Information Summary ‚Äî summary_quadrature","text":"Returns summary information quadrature nodes weights given Gamma(, b) distribution.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/summary_quadrature.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Quadrature Information Summary ‚Äî summary_quadrature","text":"","code":"summary_quadrature(a, b, M = .QUAD_NODES_DEFAULT)"},{"path":"https://joonho112.github.io/DPprior/reference/summary_quadrature.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Quadrature Information Summary ‚Äî summary_quadrature","text":"Numeric; shape parameter Gamma distribution. b Numeric; rate parameter Gamma distribution. M Integer; number quadrature nodes.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/summary_quadrature.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Quadrature Information Summary ‚Äî summary_quadrature","text":"list components: n_nodes Number quadrature nodes. alpha_range Range alpha nodes (min, max). weight_range Range normalized weights (min, max). gamma_mean Theoretical mean Gamma(, b). gamma_sd Theoretical SD Gamma(, b). coverage Approximate coverage terms SD mean.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/summary_quadrature.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get Quadrature Information Summary ‚Äî summary_quadrature","text":"","code":"if (FALSE) { # \\dontrun{ summary_quadrature(2.5, 1.5, M = 80)  } # }"},{"path":"https://joonho112.github.io/DPprior/reference/summary_rho.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary Statistics for rho Distribution ‚Äî summary_rho","title":"Summary Statistics for rho Distribution ‚Äî summary_rho","text":"Computes comprehensive summary statistics co-clustering probability rho hierarchical prior alpha ~ Gamma(, b).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/summary_rho.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary Statistics for rho Distribution ‚Äî summary_rho","text":"","code":"summary_rho(a, b, M = .QUAD_NODES_DEFAULT)"},{"path":"https://joonho112.github.io/DPprior/reference/summary_rho.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary Statistics for rho Distribution ‚Äî summary_rho","text":"Numeric; shape parameter Gamma prior alpha (> 0). b Numeric; rate parameter Gamma prior alpha (b > 0). M Integer; number quadrature nodes. Default 80.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/summary_rho.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summary Statistics for rho Distribution ‚Äî summary_rho","text":"list class \"rho_summary\" containing: mean E(rho | , b) var Var(rho | , b) sd SD(rho | , b) = sqrt(Var) cv Coefficient variation SD/mean interpretation Qualitative interpretation co-clustering level params List input parameters (, b) alpha_prior Summary alpha prior (mean, sd, cv) conditional_at_alpha_mean Conditional moments evaluated E(alpha)","code":""},{"path":"https://joonho112.github.io/DPprior/reference/summary_rho.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Summary Statistics for rho Distribution ‚Äî summary_rho","text":"co-clustering probability rho indicates likely two randomly chosen observations belong cluster priori. Interpretation guidelines: E(rho) > 0.5: High co-clustering; pairs expected cluster E(rho) (0.2, 0.5): Moderate co-clustering E(rho) < 0.2: Low co-clustering; fragmented prior conditional_at_alpha_mean component provides \"plug-\" estimate comparison: moments alpha fixed prior mean.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/summary_rho.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summary Statistics for rho Distribution ‚Äî summary_rho","text":"","code":"summary_rho(a = 2, b = 1) #> Co-Clustering Probability (rho) Summary #> ==================================================  #>  #> Gamma prior: alpha ~ Gamma(2.0000, 1.0000) #> E[alpha] = 2.0000, SD(alpha) = 1.4142, CV(alpha) = 70.7% #>  #> Marginal distribution of rho: #> -----------------------------------  #>   Mean:   0.4037 #>   SD:     0.2397 #>   CV:     59.4% #>  #> Conditional at E[alpha] = 2.0000 (plug-in): #> -----------------------------------  #>   E[rho | E[alpha]]:   0.3333 #>   Var(rho | E[alpha]): 0.0222 #>  #> Interpretation: #> -----------------------------------  #>   Moderate co-clustering summary_rho(a = 1.6, b = 1.22) #> Co-Clustering Probability (rho) Summary #> ==================================================  #>  #> Gamma prior: alpha ~ Gamma(1.6000, 1.2200) #> E[alpha] = 1.3115, SD(alpha) = 1.0368, CV(alpha) = 79.1% #>  #> Marginal distribution of rho: #> -----------------------------------  #>   Mean:   0.5084 #>   SD:     0.2664 #>   CV:     52.4% #>  #> Conditional at E[alpha] = 1.3115 (plug-in): #> -----------------------------------  #>   E[rho | E[alpha]]:   0.4326 #>   Var(rho | E[alpha]): 0.0344 #>  #> Interpretation: #> -----------------------------------  #>   High co-clustering: most pairs expected in same cluster"},{"path":"https://joonho112.github.io/DPprior/reference/summary_w1.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary Statistics for w‚ÇÅ Distribution ‚Äî summary_w1","title":"Summary Statistics for w‚ÇÅ Distribution ‚Äî summary_w1","text":"Computes comprehensive summary statistics w‚ÇÅ distribution.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/summary_w1.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary Statistics for w‚ÇÅ Distribution ‚Äî summary_w1","text":"","code":"summary_w1(   a,   b,   probs = c(0.05, 0.25, 0.5, 0.75, 0.95),   M = .QUAD_NODES_DEFAULT )"},{"path":"https://joonho112.github.io/DPprior/reference/summary_w1.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary Statistics for w‚ÇÅ Distribution ‚Äî summary_w1","text":"Numeric; shape parameter Gamma prior Œ± (> 0). b Numeric; rate parameter Gamma prior Œ± (b > 0). probs Numeric vector; quantile probabilities. Default c(0.05, 0.25, 0.5, 0.75, 0.95). M Integer; number quadrature nodes mean/variance. Default 80.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/summary_w1.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summary Statistics for w‚ÇÅ Distribution ‚Äî summary_w1","text":"list class \"w1_summary\" containing: mean E(w‚ÇÅ) var Var(w‚ÇÅ) sd SD(w‚ÇÅ) = sqrt(Var(w‚ÇÅ)) median Median w‚ÇÅ quantiles Named vector quantiles prob_gt_50 P(w‚ÇÅ > 0.5), dominance indicator prob_gt_90 P(w‚ÇÅ > 0.9), extreme dominance indicator params List input parameters (, b)","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/summary_w1.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summary Statistics for w‚ÇÅ Distribution ‚Äî summary_w1","text":"","code":"# Standard summary summary_w1(a = 2, b = 1) #> w1 Distribution Summary #> =============================================  #>  #> Gamma prior: alpha ~ Gamma(2.0000, 1.0000) #> E[alpha] = 2.0000, CV(alpha) = 70.71% #>  #> Location and Scale: #> ------------------------------  #>   Mean:   0.4037 #>   Median: 0.3391 #>   SD:     0.2995 #>  #> Quantiles: #> ------------------------------  #>   q5: 0.0256 #>   q25: 0.1433 #>   q50: 0.3391 #>   q75: 0.6321 #>   q95: 0.9689  #>  #> Dominance Risk: #> ------------------------------  #>   P(w1 > 0.5): 0.3488 #>   P(w1 > 0.9): 0.0917  # Lee et al. DP-inform prior summary_w1(a = 1.6, b = 1.22) #> w1 Distribution Summary #> =============================================  #>  #> Gamma prior: alpha ~ Gamma(1.6000, 1.2200) #> E[alpha] = 1.3115, CV(alpha) = 79.06% #>  #> Location and Scale: #> ------------------------------  #>   Mean:   0.5084 #>   Median: 0.4839 #>   SD:     0.3244 #>  #> Quantiles: #> ------------------------------  #>   q5: 0.0390 #>   q25: 0.2136 #>   q50: 0.4839 #>   q75: 0.8139 #>   q95: 0.9988  #>  #> Dominance Risk: #> ------------------------------  #>   P(w1 > 0.5): 0.4868 #>   P(w1 > 0.9): 0.1833"},{"path":"https://joonho112.github.io/DPprior/reference/test_newton_convergence.html","id":null,"dir":"Reference","previous_headings":"","what":"Test Newton Convergence Using the Jacobian ‚Äî test_newton_convergence","title":"Test Newton Convergence Using the Jacobian ‚Äî test_newton_convergence","text":"Verifies Jacobian enables fast Newton convergence moment matching.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/test_newton_convergence.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Test Newton Convergence Using the Jacobian ‚Äî test_newton_convergence","text":"","code":"test_newton_convergence(   J,   mu_target,   var_target,   a0 = 2,   b0 = 1,   max_iter = 15L,   tol = 1e-08,   verbose = TRUE )"},{"path":"https://joonho112.github.io/DPprior/reference/test_newton_convergence.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Test Newton Convergence Using the Jacobian ‚Äî test_newton_convergence","text":"J Integer; sample size. mu_target Numeric; target mean. var_target Numeric; target variance. a0 Numeric; initial shape parameter. b0 Numeric; initial rate parameter. max_iter Integer; maximum iterations. tol Numeric; convergence tolerance. verbose Logical; TRUE, print iteration history.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/test_newton_convergence.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Test Newton Convergence Using the Jacobian ‚Äî test_newton_convergence","text":"Logical; TRUE Newton converges.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/theme_DPprior.html","id":null,"dir":"Reference","previous_headings":"","what":"Publication-Quality Theme for DPprior Plots ‚Äî theme_DPprior","title":"Publication-Quality Theme for DPprior Plots ‚Äî theme_DPprior","text":"Publication-Quality Theme DPprior Plots","code":""},{"path":"https://joonho112.github.io/DPprior/reference/theme_DPprior.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Publication-Quality Theme for DPprior Plots ‚Äî theme_DPprior","text":"","code":"theme_DPprior(base_size = 11, base_family = \"\")"},{"path":"https://joonho112.github.io/DPprior/reference/theme_DPprior.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Publication-Quality Theme for DPprior Plots ‚Äî theme_DPprior","text":"base_size Numeric; base font size (default: 11). base_family Character; base font family (default: \"\").","code":""},{"path":"https://joonho112.github.io/DPprior/reference/theme_DPprior.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Publication-Quality Theme for DPprior Plots ‚Äî theme_DPprior","text":"ggplot2 theme object.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/validate_moments_conditional.html","id":null,"dir":"Reference","previous_headings":"","what":"Validate Conditional Moments Computation ‚Äî validate_moments_conditional","title":"Validate Conditional Moments Computation ‚Äî validate_moments_conditional","text":"Validates polygamma formulas direct summation.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/validate_moments_conditional.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Validate Conditional Moments Computation ‚Äî validate_moments_conditional","text":"","code":"validate_moments_conditional(J, alpha, tol = 1e-10, verbose = TRUE)"},{"path":"https://joonho112.github.io/DPprior/reference/validate_moments_conditional.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Validate Conditional Moments Computation ‚Äî validate_moments_conditional","text":"J Sample size. alpha Concentration parameter. tol Tolerance (default: 1e-10). verbose Print results TRUE.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/validate_moments_conditional.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Validate Conditional Moments Computation ‚Äî validate_moments_conditional","text":"Logical; TRUE validation passes.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/validate_stirling.html","id":null,"dir":"Reference","previous_headings":"","what":"Validate Stirling Number Computation ‚Äî validate_stirling","title":"Validate Stirling Number Computation ‚Äî validate_stirling","text":"Validates log-Stirling matrix known reference values. Useful testing verification.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/validate_stirling.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Validate Stirling Number Computation ‚Äî validate_stirling","text":"","code":"validate_stirling(logS, verbose = TRUE)"},{"path":"https://joonho112.github.io/DPprior/reference/validate_stirling.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Validate Stirling Number Computation ‚Äî validate_stirling","text":"logS Pre-computed log-Stirling matrix compute_log_stirling. verbose Logical; TRUE, print validation results.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/validate_stirling.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Validate Stirling Number Computation ‚Äî validate_stirling","text":"Logical indicating whether validations passed.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/validate_stirling.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Validate Stirling Number Computation ‚Äî validate_stirling","text":"Checks known values: \\(|s(4,2)| = 11\\) \\(|s(5,3)| = 35\\) \\(|s(10,5)| = 269325\\)","code":""},{"path":"https://joonho112.github.io/DPprior/reference/validate_stirling.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Validate Stirling Number Computation ‚Äî validate_stirling","text":"","code":"logS <- compute_log_stirling(10) validate_stirling(logS) #> PASS: |s(4,2)| = 11 (expected 11) #> PASS: |s(5,3)| = 35 (expected 35) #> PASS: |s(6,3)| = 225 (expected 225) #> PASS: |s(10,5)| = 269325 (expected 269325) #> [1] TRUE"},{"path":"https://joonho112.github.io/DPprior/reference/var_K_from_marginal_pmf.html","id":null,"dir":"Reference","previous_headings":"","what":"Variance of Marginal K from PMF ‚Äî var_K_from_marginal_pmf","title":"Variance of Marginal K from PMF ‚Äî var_K_from_marginal_pmf","text":"Computes \\(Var(K_J \\mid , b)\\) marginal PMF.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/var_K_from_marginal_pmf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Variance of Marginal K from PMF ‚Äî var_K_from_marginal_pmf","text":"","code":"var_K_from_marginal_pmf(J, a, b, logS, M = .QUAD_NODES_DEFAULT)"},{"path":"https://joonho112.github.io/DPprior/reference/var_K_from_marginal_pmf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Variance of Marginal K from PMF ‚Äî var_K_from_marginal_pmf","text":"J Integer; sample size. Numeric; shape parameter Gamma prior. b Numeric; rate parameter Gamma prior. logS Matrix; pre-computed log-Stirling matrix. M Integer; number quadrature nodes.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/var_K_from_marginal_pmf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Variance of Marginal K from PMF ‚Äî var_K_from_marginal_pmf","text":"Numeric; marginal variance.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/var_K_from_marginal_pmf.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Variance of Marginal K from PMF ‚Äî var_K_from_marginal_pmf","text":"","code":"if (FALSE) { # \\dontrun{ logS <- compute_log_stirling(50) var_K_from_marginal_pmf(50, 1.5, 0.5, logS)  } # }"},{"path":"https://joonho112.github.io/DPprior/reference/var_K_from_pmf.html","id":null,"dir":"Reference","previous_headings":"","what":"Variance of K from PMF ‚Äî var_K_from_pmf","title":"Variance of K from PMF ‚Äî var_K_from_pmf","text":"Computes \\(Var(K_J \\mid \\alpha)\\) summing PMF. primarily verification closed-form trigamma formula.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/var_K_from_pmf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Variance of K from PMF ‚Äî var_K_from_pmf","text":"","code":"var_K_from_pmf(J, alpha, logS)"},{"path":"https://joonho112.github.io/DPprior/reference/var_K_from_pmf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Variance of K from PMF ‚Äî var_K_from_pmf","text":"J Integer; sample size. alpha Numeric; DP concentration parameter. logS Matrix; pre-computed log-Stirling matrix.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/var_K_from_pmf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Variance of K from PMF ‚Äî var_K_from_pmf","text":"Numeric; conditional variance \\(Var(K_J \\mid \\alpha)\\).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/var_K_from_pmf.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Variance of K from PMF ‚Äî var_K_from_pmf","text":"","code":"if (FALSE) { # \\dontrun{ logS <- compute_log_stirling(50)  # Should match var_K_given_alpha(50, 2.0) var_K_from_pmf(50, 2.0, logS) var_K_given_alpha(50, 2.0)  } # }"},{"path":"https://joonho112.github.io/DPprior/reference/var_K_given_alpha.html","id":null,"dir":"Reference","previous_headings":"","what":"Conditional Variance of K_J Given Alpha ‚Äî var_K_given_alpha","title":"Conditional Variance of K_J Given Alpha ‚Äî var_K_given_alpha","text":"Computes \\(\\mathrm{Var}(K_J \\mid \\alpha)\\) Dirichlet process prior.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/var_K_given_alpha.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conditional Variance of K_J Given Alpha ‚Äî var_K_given_alpha","text":"","code":"var_K_given_alpha(J, alpha)"},{"path":"https://joonho112.github.io/DPprior/reference/var_K_given_alpha.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conditional Variance of K_J Given Alpha ‚Äî var_K_given_alpha","text":"J Sample size (integer >= 1). alpha Concentration parameter (positive numeric, vectorized).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/var_K_given_alpha.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Conditional Variance of K_J Given Alpha ‚Äî var_K_given_alpha","text":"Numeric vector conditional variances (length alpha).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/var_K_given_alpha.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Conditional Variance of K_J Given Alpha ‚Äî var_K_given_alpha","text":"Uses trigamma closed form: $$v_J(\\alpha) = \\mu_J(\\alpha) - \\alpha^2\\{\\psi_1(\\alpha) - \\psi_1(\\alpha+J)\\}$$ \\(\\psi_1(\\cdot)\\) trigamma function. equivalent direct summation: $$v_J(\\alpha) = \\sum_{=1}^{J} \\frac{\\alpha(-1)}{(\\alpha + - 1)^2}$$ Key property: \\(0 < v_J(\\alpha) < \\mu_J(\\alpha)\\) \\(\\alpha > 0\\) (conditional underdispersion). Limiting behavior: \\(\\alpha \\0^+\\): \\(v_J(\\alpha) \\0\\) \\(\\alpha \\\\infty\\): \\(v_J(\\alpha) \\0\\) numerical stability: Values alpha < 1e-10 return limit 0. Output enforced non-negative via pmax(, 0).","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/var_K_given_alpha.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Conditional Variance of K_J Given Alpha ‚Äî var_K_given_alpha","text":"","code":"var_K_given_alpha(50, 2.0) #> [1] 4.535558 var_K_given_alpha(50, c(0.5, 1, 2, 5)) #> [1] 1.709074 2.874073 4.535558 7.386114  # Verify underdispersion J <- 50; alpha <- 2.0 mean_K_given_alpha(J, alpha) > var_K_given_alpha(J, alpha)  # TRUE #> [1] TRUE"},{"path":"https://joonho112.github.io/DPprior/reference/var_K_given_alpha_safe.html","id":null,"dir":"Reference","previous_headings":"","what":"Conditional Variance of K Given Alpha (Enhanced) ‚Äî var_K_given_alpha_safe","title":"Conditional Variance of K Given Alpha (Enhanced) ‚Äî var_K_given_alpha_safe","text":"Computes \\(Var(K_J | \\alpha)\\) proper handling small alpha values.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/var_K_given_alpha_safe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conditional Variance of K Given Alpha (Enhanced) ‚Äî var_K_given_alpha_safe","text":"","code":"var_K_given_alpha_safe(J, alpha)"},{"path":"https://joonho112.github.io/DPprior/reference/var_K_given_alpha_safe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conditional Variance of K Given Alpha (Enhanced) ‚Äî var_K_given_alpha_safe","text":"J Integer; sample size. alpha Numeric vector; concentration parameter values.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/var_K_given_alpha_safe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Conditional Variance of K Given Alpha (Enhanced) ‚Äî var_K_given_alpha_safe","text":"Numeric vector conditional variances.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/var_K_given_alpha_safe.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Conditional Variance of K Given Alpha (Enhanced) ‚Äî var_K_given_alpha_safe","text":"small alpha (< 1e-12), returns 0.0 limiting value.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/var_K_given_alpha_sum.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Conditional Variance via Direct Summation ‚Äî var_K_given_alpha_sum","title":"Compute Conditional Variance via Direct Summation ‚Äî var_K_given_alpha_sum","text":"verification purposes .","code":""},{"path":"https://joonho112.github.io/DPprior/reference/var_K_given_alpha_sum.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Conditional Variance via Direct Summation ‚Äî var_K_given_alpha_sum","text":"","code":"var_K_given_alpha_sum(J, alpha)"},{"path":"https://joonho112.github.io/DPprior/reference/var_K_given_alpha_sum.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Conditional Variance via Direct Summation ‚Äî var_K_given_alpha_sum","text":"J Sample size. alpha Concentration parameter (scalar).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/var_K_given_alpha_sum.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Conditional Variance via Direct Summation ‚Äî var_K_given_alpha_sum","text":"Numeric; conditional variance computed via summation.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/var_rho.html","id":null,"dir":"Reference","previous_headings":"","what":"Marginal Variance of rho ‚Äî var_rho","title":"Marginal Variance of rho ‚Äî var_rho","text":"Computes Var(rho | , b) alpha ~ Gamma(, b) (shape-rate).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/var_rho.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Marginal Variance of rho ‚Äî var_rho","text":"","code":"var_rho(a, b, M = .QUAD_NODES_DEFAULT)"},{"path":"https://joonho112.github.io/DPprior/reference/var_rho.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Marginal Variance of rho ‚Äî var_rho","text":"Numeric; shape parameter Gamma prior alpha (> 0). b Numeric; rate parameter Gamma prior alpha (b > 0). M Integer; number quadrature nodes. Default 80.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/var_rho.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Marginal Variance of rho ‚Äî var_rho","text":"Numeric; Var(rho | , b).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/var_rho.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Marginal Variance of rho ‚Äî var_rho","text":"Uses law total variance: $$Var(\\rho | , b) = E[Var(\\rho | \\alpha)] + Var(E[\\rho | \\alpha])$$ : Var(rho | alpha) = 2*alpha / ((1+alpha)^2*(2+alpha)*(3+alpha)) E(rho | alpha) = 1/(1+alpha) Note: Unlike E(rho), Var(rho) != Var(w1) general, conditional variances differ.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/var_rho.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Marginal Variance of rho ‚Äî var_rho","text":"Lee, J. (2026). Design-Conditional Prior Elicitation Dirichlet Process Mixtures. arXiv preprint arXiv:2602.06301.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/var_rho.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Marginal Variance of rho ‚Äî var_rho","text":"","code":"var_rho(a = 2, b = 1) #> [1] 0.05744825"},{"path":"https://joonho112.github.io/DPprior/reference/var_rho_given_alpha.html","id":null,"dir":"Reference","previous_headings":"","what":"Conditional Variance of rho Given Alpha ‚Äî var_rho_given_alpha","title":"Conditional Variance of rho Given Alpha ‚Äî var_rho_given_alpha","text":"Computes conditional variance Var(rho | alpha).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/var_rho_given_alpha.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conditional Variance of rho Given Alpha ‚Äî var_rho_given_alpha","text":"","code":"var_rho_given_alpha(alpha)"},{"path":"https://joonho112.github.io/DPprior/reference/var_rho_given_alpha.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conditional Variance of rho Given Alpha ‚Äî var_rho_given_alpha","text":"alpha Numeric vector; concentration parameter(s) (must positive).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/var_rho_given_alpha.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Conditional Variance of rho Given Alpha ‚Äî var_rho_given_alpha","text":"Numeric vector; Var(rho | alpha).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/var_rho_given_alpha.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Conditional Variance of rho Given Alpha ‚Äî var_rho_given_alpha","text":"conditional variance : $$Var(\\rho | \\alpha) = \\frac{2\\alpha}{(1+\\alpha)^2(2+\\alpha)(3+\\alpha)}$$ derived GEM recursion: rho = V^2 + (1-V)^2 * rho' V ~ Beta(1, alpha) rho' independent copy rho. Properties: Var(rho|alpha) = 0 alpha -> 0 (degenerate rho = 1) Var(rho|alpha) -> 0 alpha -> Inf (degenerate rho = 0) Maximum variance occurs intermediate alpha","code":""},{"path":"https://joonho112.github.io/DPprior/reference/var_rho_given_alpha.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Conditional Variance of rho Given Alpha ‚Äî var_rho_given_alpha","text":"Lee, J. (2026). Design-Conditional Prior Elicitation Dirichlet Process Mixtures. arXiv preprint arXiv:2602.06301.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/var_rho_given_alpha.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Conditional Variance of rho Given Alpha ‚Äî var_rho_given_alpha","text":"","code":"var_rho_given_alpha(2) #> [1] 0.02222222 var_rho_given_alpha(c(0.5, 1, 2, 5, 10)) #> [1] 0.050793651 0.041666667 0.022222222 0.004960317 0.001059547"},{"path":"https://joonho112.github.io/DPprior/reference/var_w1.html","id":null,"dir":"Reference","previous_headings":"","what":"Variance of w‚ÇÅ ‚Äî var_w1","title":"Variance of w‚ÇÅ ‚Äî var_w1","text":"Computes Var(w‚ÇÅ | , b) using law total variance.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/var_w1.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Variance of w‚ÇÅ ‚Äî var_w1","text":"","code":"var_w1(a, b, M = .QUAD_NODES_DEFAULT)"},{"path":"https://joonho112.github.io/DPprior/reference/var_w1.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Variance of w‚ÇÅ ‚Äî var_w1","text":"Numeric; shape parameter Gamma prior Œ± (> 0). b Numeric; rate parameter Gamma prior Œ± (b > 0). M Integer; number quadrature nodes. Default 80.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/var_w1.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Variance of w‚ÇÅ ‚Äî var_w1","text":"Numeric; Var(w‚ÇÅ).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/var_w1.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Variance of w‚ÇÅ ‚Äî var_w1","text":"Uses law total variance: $$Var(w_1) = E[Var(w_1 | \\alpha)] + Var(E[w_1 | \\alpha])$$ w‚ÇÅ | Œ± ~ Beta(1, Œ±), : E(w‚ÇÅ | Œ±) = 1/(1+Œ±) Var(w‚ÇÅ | Œ±) = Œ± / ((1+Œ±)¬≤(2+Œ±))","code":""},{"path":"https://joonho112.github.io/DPprior/reference/var_w1.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Variance of w‚ÇÅ ‚Äî var_w1","text":"Lee, J. (2026). Design-Conditional Prior Elicitation Dirichlet Process Mixtures. arXiv preprint arXiv:2602.06301.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/var_w1.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Variance of w‚ÇÅ ‚Äî var_w1","text":"","code":"var_w1(a = 2, b = 1)       # ~0.090 #> [1] 0.08968429 var_w1(a = 1.6, b = 1.22)  # ~0.105 #> [1] 0.1052062"},{"path":"https://joonho112.github.io/DPprior/reference/variance_inflation_ratio.html","id":null,"dir":"Reference","previous_headings":"","what":"Variance Inflation Ratio ‚Äî variance_inflation_ratio","title":"Variance Inflation Ratio ‚Äî variance_inflation_ratio","text":"Computes ratio \\(Var(K_J) / E[K_J]\\) overdispersion measure.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/variance_inflation_ratio.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Variance Inflation Ratio ‚Äî variance_inflation_ratio","text":"","code":"variance_inflation_ratio(J, a, b, M = .QUAD_NODES_DEFAULT)"},{"path":"https://joonho112.github.io/DPprior/reference/variance_inflation_ratio.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Variance Inflation Ratio ‚Äî variance_inflation_ratio","text":"J Integer; sample size. Numeric; shape parameter Gamma prior. b Numeric; rate parameter Gamma prior. M Integer; number quadrature nodes (default: 80).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/variance_inflation_ratio.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Variance Inflation Ratio ‚Äî variance_inflation_ratio","text":"Numeric; variance inflation ratio (VIR).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/variance_inflation_ratio.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Variance Inflation Ratio ‚Äî variance_inflation_ratio","text":"Poisson distribution, ratio equals 1. marginal distribution \\(K_J\\) Gamma prior \\(\\alpha\\), ratio typically > 1, indicating overdispersion. ratio useful : Diagnosing appropriateness Poisson approximations Comparing different prior specifications Understanding \"spread\" induced uncertainty \\(\\alpha\\)","code":""},{"path":"https://joonho112.github.io/DPprior/reference/variance_inflation_ratio.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Variance Inflation Ratio ‚Äî variance_inflation_ratio","text":"","code":"if (FALSE) { # \\dontrun{ # Typical overdispersion vir <- variance_inflation_ratio(50, 2.0, 1.0) vir > 1  # TRUE: overdispersed  # Compare across prior specifications variance_inflation_ratio(50, 2.0, 0.5)  # Higher uncertainty in alpha variance_inflation_ratio(50, 8.0, 4.0)  # Same mean, lower variance in alpha  } # }"},{"path":"https://joonho112.github.io/DPprior/reference/verify_DPprior_fit.html","id":null,"dir":"Reference","previous_headings":"","what":"Verify DPprior_fit Module ‚Äî verify_DPprior_fit","title":"Verify DPprior_fit Module ‚Äî verify_DPprior_fit","text":"Runs comprehensive verification tests DPprior_fit module.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_DPprior_fit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Verify DPprior_fit Module ‚Äî verify_DPprior_fit","text":"","code":"verify_DPprior_fit(verbose = TRUE)"},{"path":"https://joonho112.github.io/DPprior/reference/verify_DPprior_fit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Verify DPprior_fit Module ‚Äî verify_DPprior_fit","text":"verbose Logical; TRUE, print detailed test output.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_DPprior_fit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Verify DPprior_fit Module ‚Äî verify_DPprior_fit","text":"Invisibly returns TRUE tests pass.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_DPprior_fit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Verify DPprior_fit Module ‚Äî verify_DPprior_fit","text":"","code":"if (FALSE) { # \\dontrun{ verify_DPprior_fit()  } # }"},{"path":"https://joonho112.github.io/DPprior/reference/verify_a1_mapping_all.html","id":null,"dir":"Reference","previous_headings":"","what":"Run All Module 10 Verification Tests ‚Äî verify_a1_mapping_all","title":"Run All Module 10 Verification Tests ‚Äî verify_a1_mapping_all","text":"Comprehensive verification suite A1 closed-form mapping module.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_a1_mapping_all.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run All Module 10 Verification Tests ‚Äî verify_a1_mapping_all","text":"","code":"verify_a1_mapping_all(verbose = TRUE)"},{"path":"https://joonho112.github.io/DPprior/reference/verify_a1_mapping_all.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run All Module 10 Verification Tests ‚Äî verify_a1_mapping_all","text":"verbose Logical; TRUE, print detailed results.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_a1_mapping_all.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run All Module 10 Verification Tests ‚Äî verify_a1_mapping_all","text":"Logical; TRUE tests pass.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_a1_mapping_all.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Run All Module 10 Verification Tests ‚Äî verify_a1_mapping_all","text":"","code":"if (FALSE) { # \\dontrun{ verify_a1_mapping_all()  } # }"},{"path":"https://joonho112.github.io/DPprior/reference/verify_a1_roundtrip.html","id":null,"dir":"Reference","previous_headings":"","what":"Verify A1 Mapping via Round-Trip ‚Äî verify_a1_roundtrip","title":"Verify A1 Mapping via Round-Trip ‚Äî verify_a1_roundtrip","text":"Tests A1 mapping computing forward model (NegBin moments) derived \\((, b)\\) parameters comparing targets.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_a1_roundtrip.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Verify A1 Mapping via Round-Trip ‚Äî verify_a1_roundtrip","text":"","code":"verify_a1_roundtrip(fit, tol = 1e-08, verbose = TRUE)"},{"path":"https://joonho112.github.io/DPprior/reference/verify_a1_roundtrip.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Verify A1 Mapping via Round-Trip ‚Äî verify_a1_roundtrip","text":"fit DPprior_fit object DPprior_a1. tol Numeric; tolerance relative error comparison. verbose Logical; TRUE, print verification details.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_a1_roundtrip.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Verify A1 Mapping via Round-Trip ‚Äî verify_a1_roundtrip","text":"Logical; TRUE round-trip succeeds within tolerance.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_a1_roundtrip.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Verify A1 Mapping via Round-Trip ‚Äî verify_a1_roundtrip","text":"A1 NegBin approximation: $$K_J - 1 \\sim \\text{NegBin}(, p)$$ \\(p = b/(b + c_J)\\).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_a1_roundtrip.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Verify A1 Mapping via Round-Trip ‚Äî verify_a1_roundtrip","text":"","code":"if (FALSE) { # \\dontrun{ fit <- DPprior_a1(J = 50, mu_K = 5, var_K = 8) verify_a1_roundtrip(fit)  } # }"},{"path":"https://joonho112.github.io/DPprior/reference/verify_a2_all.html","id":null,"dir":"Reference","previous_headings":"","what":"Run All A2-MN Verification Tests ‚Äî verify_a2_all","title":"Run All A2-MN Verification Tests ‚Äî verify_a2_all","text":"Comprehensive verification suite A2-MN Newton solver.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_a2_all.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run All A2-MN Verification Tests ‚Äî verify_a2_all","text":"","code":"verify_a2_all(verbose = TRUE)"},{"path":"https://joonho112.github.io/DPprior/reference/verify_a2_all.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run All A2-MN Verification Tests ‚Äî verify_a2_all","text":"verbose Logical; TRUE, print detailed results.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_a2_all.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run All A2-MN Verification Tests ‚Äî verify_a2_all","text":"Logical; TRUE tests pass.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_a2_all.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Run All A2-MN Verification Tests ‚Äî verify_a2_all","text":"","code":"if (FALSE) { # \\dontrun{ verify_a2_all()  } # }"},{"path":"https://joonho112.github.io/DPprior/reference/verify_a2_kl.html","id":null,"dir":"Reference","previous_headings":"","what":"Verify A2-KL Optimization ‚Äî verify_a2_kl","title":"Verify A2-KL Optimization ‚Äî verify_a2_kl","text":"Runs verification tests A2-KL optimization algorithm.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_a2_kl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Verify A2-KL Optimization ‚Äî verify_a2_kl","text":"","code":"verify_a2_kl(verbose = TRUE)"},{"path":"https://joonho112.github.io/DPprior/reference/verify_a2_kl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Verify A2-KL Optimization ‚Äî verify_a2_kl","text":"verbose Logical; TRUE, print detailed results.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_a2_kl.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Verify A2-KL Optimization ‚Äî verify_a2_kl","text":"Logical; TRUE tests pass.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_a2_kl.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Verify A2-KL Optimization ‚Äî verify_a2_kl","text":"","code":"if (FALSE) { # \\dontrun{ verify_a2_kl()  } # }"},{"path":"https://joonho112.github.io/DPprior/reference/verify_a2_kl_all.html","id":null,"dir":"Reference","previous_headings":"","what":"Run All Module 12 Verification Tests ‚Äî verify_a2_kl_all","title":"Run All Module 12 Verification Tests ‚Äî verify_a2_kl_all","text":"Comprehensive verification suite A2-KL module.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_a2_kl_all.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run All Module 12 Verification Tests ‚Äî verify_a2_kl_all","text":"","code":"verify_a2_kl_all(verbose = TRUE)"},{"path":"https://joonho112.github.io/DPprior/reference/verify_a2_kl_all.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run All Module 12 Verification Tests ‚Äî verify_a2_kl_all","text":"verbose Logical; TRUE, print detailed results.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_a2_kl_all.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run All Module 12 Verification Tests ‚Äî verify_a2_kl_all","text":"Logical; TRUE tests pass.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_a2_kl_all.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Run All Module 12 Verification Tests ‚Äî verify_a2_kl_all","text":"","code":"if (FALSE) { # \\dontrun{ verify_a2_kl_all()  } # }"},{"path":"https://joonho112.github.io/DPprior/reference/verify_a2_moment_matching.html","id":null,"dir":"Reference","previous_headings":"","what":"Verify A2-MN Moment Matching ‚Äî verify_a2_moment_matching","title":"Verify A2-MN Moment Matching ‚Äî verify_a2_moment_matching","text":"Tests A2-MN solver achieves exact moment matching.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_a2_moment_matching.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Verify A2-MN Moment Matching ‚Äî verify_a2_moment_matching","text":"","code":"verify_a2_moment_matching(J, mu_K, var_K, tol = 1e-06, verbose = TRUE)"},{"path":"https://joonho112.github.io/DPprior/reference/verify_a2_moment_matching.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Verify A2-MN Moment Matching ‚Äî verify_a2_moment_matching","text":"J Integer; sample size. mu_K Numeric; target mean. var_K Numeric; target variance. tol Numeric; tolerance verification. verbose Logical; TRUE, print results.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_a2_moment_matching.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Verify A2-MN Moment Matching ‚Äî verify_a2_moment_matching","text":"Logical; TRUE verification passes.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_a2_moment_matching.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Verify A2-MN Moment Matching ‚Äî verify_a2_moment_matching","text":"","code":"if (FALSE) { # \\dontrun{ verify_a2_moment_matching(J = 50, mu_K = 5, var_K = 8)  } # }"},{"path":"https://joonho112.github.io/DPprior/reference/verify_cdf_properties.html","id":null,"dir":"Reference","previous_headings":"","what":"Verify CDF Properties ‚Äî verify_cdf_properties","title":"Verify CDF Properties ‚Äî verify_cdf_properties","text":"Verifies CDF non-decreasing ends 1.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_cdf_properties.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Verify CDF Properties ‚Äî verify_cdf_properties","text":"","code":"verify_cdf_properties(J, alpha, logS, tol = 1e-10, verbose = TRUE)"},{"path":"https://joonho112.github.io/DPprior/reference/verify_cdf_properties.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Verify CDF Properties ‚Äî verify_cdf_properties","text":"J Integer; sample size. alpha Numeric; DP concentration parameter. logS Matrix; pre-computed log-Stirling matrix. tol Numeric; tolerance (default: 1e-10). verbose Logical; TRUE, print results.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_cdf_properties.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Verify CDF Properties ‚Äî verify_cdf_properties","text":"Logical; TRUE verification passes.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_derivative.html","id":null,"dir":"Reference","previous_headings":"","what":"Verify Derivative via Finite Difference ‚Äî verify_derivative","title":"Verify Derivative via Finite Difference ‚Äî verify_derivative","text":"Verifies analytic derivative conditional mean finite difference approximation.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_derivative.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Verify Derivative via Finite Difference ‚Äî verify_derivative","text":"","code":"verify_derivative(J, alpha, eps = 1e-06, tol = 1e-05, verbose = TRUE)"},{"path":"https://joonho112.github.io/DPprior/reference/verify_derivative.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Verify Derivative via Finite Difference ‚Äî verify_derivative","text":"J Sample size (integer >= 1). alpha Concentration parameter (positive scalar). eps Finite difference step size (default: 1e-6). tol Tolerance comparison (default: 1e-5). verbose Logical; TRUE, print results.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_derivative.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Verify Derivative via Finite Difference ‚Äî verify_derivative","text":"Logical; TRUE derivative matches finite difference.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_derivative.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Verify Derivative via Finite Difference ‚Äî verify_derivative","text":"","code":"if (FALSE) { # \\dontrun{ verify_derivative(50, 2.0)  } # }"},{"path":"https://joonho112.github.io/DPprior/reference/verify_diagnostics.html","id":null,"dir":"Reference","previous_headings":"","what":"Verify Diagnostics Module ‚Äî verify_diagnostics","title":"Verify Diagnostics Module ‚Äî verify_diagnostics","text":"Runs comprehensive tests diagnostics module.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_diagnostics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Verify Diagnostics Module ‚Äî verify_diagnostics","text":"","code":"verify_diagnostics(verbose = TRUE)"},{"path":"https://joonho112.github.io/DPprior/reference/verify_diagnostics.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Verify Diagnostics Module ‚Äî verify_diagnostics","text":"verbose Logical; TRUE, print detailed output.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_diagnostics.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Verify Diagnostics Module ‚Äî verify_diagnostics","text":"Invisibly returns TRUE tests pass.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_dual_anchor.html","id":null,"dir":"Reference","previous_headings":"","what":"Verify Dual-Anchor Module ‚Äî verify_dual_anchor","title":"Verify Dual-Anchor Module ‚Äî verify_dual_anchor","text":"Verify Dual-Anchor Module","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_dual_anchor.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Verify Dual-Anchor Module ‚Äî verify_dual_anchor","text":"","code":"verify_dual_anchor(verbose = TRUE)"},{"path":"https://joonho112.github.io/DPprior/reference/verify_dual_anchor.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Verify Dual-Anchor Module ‚Äî verify_dual_anchor","text":"verbose Logical; print detailed output.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_dual_anchor.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Verify Dual-Anchor Module ‚Äî verify_dual_anchor","text":"Invisible TRUE tests pass.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_dual_anchor.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Verify Dual-Anchor Module ‚Äî verify_dual_anchor","text":"","code":"if (FALSE) { # \\dontrun{ verify_dual_anchor(verbose = TRUE)  } # }"},{"path":"https://joonho112.github.io/DPprior/reference/verify_jacobian.html","id":null,"dir":"Reference","previous_headings":"","what":"Verify Jacobian Against Finite Differences ‚Äî verify_jacobian","title":"Verify Jacobian Against Finite Differences ‚Äî verify_jacobian","text":"Compares analytically computed Jacobian (via score identities) numerical finite differences validate implementation.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_jacobian.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Verify Jacobian Against Finite Differences ‚Äî verify_jacobian","text":"","code":"verify_jacobian(   J,   a,   b,   eps = 1e-06,   M = .QUAD_NODES_VERIFICATION,   verbose = TRUE )"},{"path":"https://joonho112.github.io/DPprior/reference/verify_jacobian.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Verify Jacobian Against Finite Differences ‚Äî verify_jacobian","text":"J Integer; sample size. Numeric; shape parameter. b Numeric; rate parameter. eps Numeric; step size finite differences (default: 1e-6). M Integer; number quadrature nodes (default: 200 verification). verbose Logical; TRUE, print detailed comparison.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_jacobian.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Verify Jacobian Against Finite Differences ‚Äî verify_jacobian","text":"named list components: analytic analytically computed Jacobian numeric numerically computed Jacobian (finite differences) abs_error Matrix absolute errors rel_error Matrix relative errors max_rel_error Maximum relative error across entries pass Logical; TRUE max relative error < 0.01","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_jacobian.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Verify Jacobian Against Finite Differences ‚Äî verify_jacobian","text":"Uses central finite differences: $$\\frac{\\partial f}{\\partial } \\approx \\frac{f(+\\epsilon) - f(-\\epsilon)}{2\\epsilon}$$ Important: SECONDARY verification method analytical Jacobian finite differences use quadrature layer. independent verification, compare adaptive integration (scipy.integrate.quad Python).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_jacobian.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Verify Jacobian Against Finite Differences ‚Äî verify_jacobian","text":"","code":"# Verify Jacobian for a specific case result <- verify_jacobian(J = 50, a = 2.0, b = 1.0, verbose = TRUE) #> Jacobian Verification (J=50, a=2.00, b=1.00, M=200) #> ------------------------------------------------------------  #>  #> Analytic Jacobian (score-based): #>   dM1/da =   2.24553449  dM1/db =  -4.13558517 #>   dV/da  =   2.94445788  dV/db  = -13.03822850 #>  #> Numeric Jacobian (finite diff): #>   dM1/da =   2.24552030  dM1/db =  -4.13558517 #>   dV/da  =   2.94463271  dV/db  = -13.03822849 #>  #> Relative Errors: #>   dM1/da: 6.32e-06  dM1/db: 1.29e-11 #>   dV/da:  5.94e-05  dV/db:  6.13e-10 #>  #> Max Relative Error: 5.94e-05 [PASS]"},{"path":"https://joonho112.github.io/DPprior/reference/verify_jacobian_all.html","id":null,"dir":"Reference","previous_headings":"","what":"Run All Module 07 Verification Tests ‚Äî verify_jacobian_all","title":"Run All Module 07 Verification Tests ‚Äî verify_jacobian_all","text":"Comprehensive verification suite score-based Jacobian module.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_jacobian_all.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run All Module 07 Verification Tests ‚Äî verify_jacobian_all","text":"","code":"verify_jacobian_all(verbose = TRUE)"},{"path":"https://joonho112.github.io/DPprior/reference/verify_jacobian_all.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run All Module 07 Verification Tests ‚Äî verify_jacobian_all","text":"verbose Logical; TRUE, print detailed results.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_jacobian_all.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run All Module 07 Verification Tests ‚Äî verify_jacobian_all","text":"Logical; TRUE tests pass.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_jacobian_all.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Run All Module 07 Verification Tests ‚Äî verify_jacobian_all","text":"","code":"if (FALSE) { # \\dontrun{ verify_jacobian_all()  } # }"},{"path":"https://joonho112.github.io/DPprior/reference/verify_kl_divergence.html","id":null,"dir":"Reference","previous_headings":"","what":"Verify KL Divergence Properties ‚Äî verify_kl_divergence","title":"Verify KL Divergence Properties ‚Äî verify_kl_divergence","text":"Runs verification tests KL divergence computations.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_kl_divergence.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Verify KL Divergence Properties ‚Äî verify_kl_divergence","text":"","code":"verify_kl_divergence(verbose = TRUE)"},{"path":"https://joonho112.github.io/DPprior/reference/verify_kl_divergence.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Verify KL Divergence Properties ‚Äî verify_kl_divergence","text":"verbose Logical; TRUE, print detailed results.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_kl_divergence.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Verify KL Divergence Properties ‚Äî verify_kl_divergence","text":"Logical; TRUE tests pass.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_kl_divergence.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Verify KL Divergence Properties ‚Äî verify_kl_divergence","text":"","code":"if (FALSE) { # \\dontrun{ verify_kl_divergence()  } # }"},{"path":"https://joonho112.github.io/DPprior/reference/verify_marginal_moments.html","id":null,"dir":"Reference","previous_headings":"","what":"Verify Marginal Moments Properties ‚Äî verify_marginal_moments","title":"Verify Marginal Moments Properties ‚Äî verify_marginal_moments","text":"Runs verification tests marginal moment computations.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_marginal_moments.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Verify Marginal Moments Properties ‚Äî verify_marginal_moments","text":"","code":"verify_marginal_moments(J, a, b, verbose = TRUE)"},{"path":"https://joonho112.github.io/DPprior/reference/verify_marginal_moments.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Verify Marginal Moments Properties ‚Äî verify_marginal_moments","text":"J Integer; sample size test. Numeric; shape parameter test. b Numeric; rate parameter test. verbose Logical; TRUE, print detailed results.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_marginal_moments.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Verify Marginal Moments Properties ‚Äî verify_marginal_moments","text":"Logical; TRUE verifications pass.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_marginal_moments.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Verify Marginal Moments Properties ‚Äî verify_marginal_moments","text":"","code":"if (FALSE) { # \\dontrun{ verify_marginal_moments(50, 2.0, 1.0)  } # }"},{"path":"https://joonho112.github.io/DPprior/reference/verify_moments_marginal_all.html","id":null,"dir":"Reference","previous_headings":"","what":"Run All Module 05 Verification Tests ‚Äî verify_moments_marginal_all","title":"Run All Module 05 Verification Tests ‚Äî verify_moments_marginal_all","text":"Comprehensive verification suite marginal moments module.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_moments_marginal_all.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run All Module 05 Verification Tests ‚Äî verify_moments_marginal_all","text":"","code":"verify_moments_marginal_all(verbose = TRUE)"},{"path":"https://joonho112.github.io/DPprior/reference/verify_moments_marginal_all.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run All Module 05 Verification Tests ‚Äî verify_moments_marginal_all","text":"verbose Logical; TRUE, print detailed results.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_moments_marginal_all.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run All Module 05 Verification Tests ‚Äî verify_moments_marginal_all","text":"Logical; TRUE tests pass.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_moments_marginal_all.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Run All Module 05 Verification Tests ‚Äî verify_moments_marginal_all","text":"","code":"if (FALSE) { # \\dontrun{ verify_moments_marginal_all()  } # }"},{"path":"https://joonho112.github.io/DPprior/reference/verify_pmf_all.html","id":null,"dir":"Reference","previous_headings":"","what":"Run All PMF Verifications ‚Äî verify_pmf_all","title":"Run All PMF Verifications ‚Äî verify_pmf_all","text":"Runs comprehensive verification tests conditional PMF module.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_pmf_all.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run All PMF Verifications ‚Äî verify_pmf_all","text":"","code":"verify_pmf_all(   J_values = c(10, 50, 100),   alpha_values = c(0.5, 1, 2, 5),   verbose = TRUE )"},{"path":"https://joonho112.github.io/DPprior/reference/verify_pmf_all.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run All PMF Verifications ‚Äî verify_pmf_all","text":"J_values Integer vector; sample sizes test. alpha_values Numeric vector; concentration parameters test. verbose Logical; TRUE, print detailed results.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_pmf_all.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run All PMF Verifications ‚Äî verify_pmf_all","text":"Logical; TRUE verifications pass.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_pmf_all.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Run All PMF Verifications ‚Äî verify_pmf_all","text":"","code":"if (FALSE) { # \\dontrun{ verify_pmf_all()  } # }"},{"path":"https://joonho112.github.io/DPprior/reference/verify_pmf_marginal_all.html","id":null,"dir":"Reference","previous_headings":"","what":"Run All Module 06 Verification Tests ‚Äî verify_pmf_marginal_all","title":"Run All Module 06 Verification Tests ‚Äî verify_pmf_marginal_all","text":"Comprehensive verification suite marginal PMF module.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_pmf_marginal_all.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run All Module 06 Verification Tests ‚Äî verify_pmf_marginal_all","text":"","code":"verify_pmf_marginal_all(verbose = TRUE)"},{"path":"https://joonho112.github.io/DPprior/reference/verify_pmf_marginal_all.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run All Module 06 Verification Tests ‚Äî verify_pmf_marginal_all","text":"verbose Logical; TRUE, print detailed results.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_pmf_marginal_all.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run All Module 06 Verification Tests ‚Äî verify_pmf_marginal_all","text":"Logical; TRUE tests pass.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_pmf_marginal_all.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Run All Module 06 Verification Tests ‚Äî verify_pmf_marginal_all","text":"","code":"if (FALSE) { # \\dontrun{ verify_pmf_marginal_all()  } # }"},{"path":"https://joonho112.github.io/DPprior/reference/verify_pmf_marginal_convergence.html","id":null,"dir":"Reference","previous_headings":"","what":"Verify Quadrature Convergence ‚Äî verify_pmf_marginal_convergence","title":"Verify Quadrature Convergence ‚Äî verify_pmf_marginal_convergence","text":"Checks marginal PMF converges number quadrature nodes increases.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_pmf_marginal_convergence.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Verify Quadrature Convergence ‚Äî verify_pmf_marginal_convergence","text":"","code":"verify_pmf_marginal_convergence(   J,   a,   b,   logS,   M_values = c(20L, 40L, 80L, 120L),   verbose = TRUE )"},{"path":"https://joonho112.github.io/DPprior/reference/verify_pmf_marginal_convergence.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Verify Quadrature Convergence ‚Äî verify_pmf_marginal_convergence","text":"J Integer; sample size. Numeric; shape parameter Gamma prior. b Numeric; rate parameter Gamma prior. logS Matrix; pre-computed log-Stirling matrix. M_values Integer vector; quadrature node counts test. verbose Logical; TRUE, print results.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_pmf_marginal_convergence.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Verify Quadrature Convergence ‚Äî verify_pmf_marginal_convergence","text":"Data frame convergence results.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_pmf_marginal_convergence.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Verify Quadrature Convergence ‚Äî verify_pmf_marginal_convergence","text":"","code":"if (FALSE) { # \\dontrun{ logS <- compute_log_stirling(50) verify_pmf_marginal_convergence(50, 1.5, 0.5, logS)  } # }"},{"path":"https://joonho112.github.io/DPprior/reference/verify_pmf_marginal_moments.html","id":null,"dir":"Reference","previous_headings":"","what":"Verify Moments Consistency ‚Äî verify_pmf_marginal_moments","title":"Verify Moments Consistency ‚Äî verify_pmf_marginal_moments","text":"Verifies moments computed marginal PMF match exact_K_moments().","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_pmf_marginal_moments.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Verify Moments Consistency ‚Äî verify_pmf_marginal_moments","text":"","code":"verify_pmf_marginal_moments(   J,   a,   b,   logS,   M = .QUAD_NODES_DEFAULT,   tol = 1e-06,   verbose = TRUE )"},{"path":"https://joonho112.github.io/DPprior/reference/verify_pmf_marginal_moments.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Verify Moments Consistency ‚Äî verify_pmf_marginal_moments","text":"J Integer; sample size. Numeric; shape parameter Gamma prior. b Numeric; rate parameter Gamma prior. logS Matrix; pre-computed log-Stirling matrix. M Integer; number quadrature nodes. tol Numeric; tolerance comparisons. verbose Logical; TRUE, print results.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_pmf_marginal_moments.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Verify Moments Consistency ‚Äî verify_pmf_marginal_moments","text":"Logical; TRUE moments match within tolerance.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_pmf_marginal_moments.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Verify Moments Consistency ‚Äî verify_pmf_marginal_moments","text":"","code":"if (FALSE) { # \\dontrun{ logS <- compute_log_stirling(50) verify_pmf_marginal_moments(50, 1.5, 0.5, logS)  } # }"},{"path":"https://joonho112.github.io/DPprior/reference/verify_pmf_marginal_properties.html","id":null,"dir":"Reference","previous_headings":"","what":"Verify Marginal PMF Properties ‚Äî verify_pmf_marginal_properties","title":"Verify Marginal PMF Properties ‚Äî verify_pmf_marginal_properties","text":"Verifies marginal PMF satisfies basic probability properties.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_pmf_marginal_properties.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Verify Marginal PMF Properties ‚Äî verify_pmf_marginal_properties","text":"","code":"verify_pmf_marginal_properties(   J,   a,   b,   logS,   M = .QUAD_NODES_DEFAULT,   tol = 1e-10,   verbose = TRUE )"},{"path":"https://joonho112.github.io/DPprior/reference/verify_pmf_marginal_properties.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Verify Marginal PMF Properties ‚Äî verify_pmf_marginal_properties","text":"J Integer; sample size. Numeric; shape parameter Gamma prior. b Numeric; rate parameter Gamma prior. logS Matrix; pre-computed log-Stirling matrix. M Integer; number quadrature nodes. tol Numeric; tolerance comparisons. verbose Logical; TRUE, print results.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_pmf_marginal_properties.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Verify Marginal PMF Properties ‚Äî verify_pmf_marginal_properties","text":"Logical; TRUE verifications pass.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_pmf_marginal_properties.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Verify Marginal PMF Properties ‚Äî verify_pmf_marginal_properties","text":"","code":"if (FALSE) { # \\dontrun{ logS <- compute_log_stirling(50) verify_pmf_marginal_properties(50, 1.5, 0.5, logS)  } # }"},{"path":"https://joonho112.github.io/DPprior/reference/verify_pmf_moments.html","id":null,"dir":"Reference","previous_headings":"","what":"Verify PMF Consistency with Moments ‚Äî verify_pmf_moments","title":"Verify PMF Consistency with Moments ‚Äî verify_pmf_moments","text":"Verifies moments computed PMF match closed-form digamma/trigamma formulas.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_pmf_moments.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Verify PMF Consistency with Moments ‚Äî verify_pmf_moments","text":"","code":"verify_pmf_moments(J, alpha, logS, tol = 1e-08, verbose = TRUE)"},{"path":"https://joonho112.github.io/DPprior/reference/verify_pmf_moments.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Verify PMF Consistency with Moments ‚Äî verify_pmf_moments","text":"J Integer; sample size. alpha Numeric; DP concentration parameter. logS Matrix; pre-computed log-Stirling matrix. tol Numeric; tolerance comparison (default: 1e-8). verbose Logical; TRUE, print results.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_pmf_moments.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Verify PMF Consistency with Moments ‚Äî verify_pmf_moments","text":"Logical; TRUE verification passes.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_pmf_moments.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Verify PMF Consistency with Moments ‚Äî verify_pmf_moments","text":"","code":"if (FALSE) { # \\dontrun{ logS <- compute_log_stirling(50) verify_pmf_moments(50, 2.0, logS)  } # }"},{"path":"https://joonho112.github.io/DPprior/reference/verify_pmf_normalization.html","id":null,"dir":"Reference","previous_headings":"","what":"Verify PMF Normalization ‚Äî verify_pmf_normalization","title":"Verify PMF Normalization ‚Äî verify_pmf_normalization","text":"Verifies PMF sums 1.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_pmf_normalization.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Verify PMF Normalization ‚Äî verify_pmf_normalization","text":"","code":"verify_pmf_normalization(J, alpha, logS, tol = 1e-10, verbose = TRUE)"},{"path":"https://joonho112.github.io/DPprior/reference/verify_pmf_normalization.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Verify PMF Normalization ‚Äî verify_pmf_normalization","text":"J Integer; sample size. alpha Numeric; DP concentration parameter. logS Matrix; pre-computed log-Stirling matrix. tol Numeric; tolerance (default: 1e-10). verbose Logical; TRUE, print results.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_pmf_normalization.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Verify PMF Normalization ‚Äî verify_pmf_normalization","text":"Logical; TRUE verification passes.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_quadrature.html","id":null,"dir":"Reference","previous_headings":"","what":"Verify Quadrature Accuracy Against Known Gamma Moments ‚Äî verify_quadrature","title":"Verify Quadrature Accuracy Against Known Gamma Moments ‚Äî verify_quadrature","text":"Validates quadrature implementation comparing computed expectations known closed-form Gamma distribution moments.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_quadrature.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Verify Quadrature Accuracy Against Known Gamma Moments ‚Äî verify_quadrature","text":"","code":"verify_quadrature(a, b, M, tol = 1e-10, verbose = TRUE)"},{"path":"https://joonho112.github.io/DPprior/reference/verify_quadrature.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Verify Quadrature Accuracy Against Known Gamma Moments ‚Äî verify_quadrature","text":"Numeric; shape parameter Gamma distribution. b Numeric; rate parameter Gamma distribution. M Integer; number quadrature nodes. tol Numeric; tolerance verification (default: 1e-10). verbose Logical; TRUE, print detailed results.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_quadrature.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Verify Quadrature Accuracy Against Known Gamma Moments ‚Äî verify_quadrature","text":"Logical; TRUE moments match within tolerance.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_quadrature.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Verify Quadrature Accuracy Against Known Gamma Moments ‚Äî verify_quadrature","text":"\\(\\alpha \\sim \\text{Gamma}(, b)\\): \\(E[\\alpha] = /b\\) \\(E[\\alpha^2] = (+1)/b^2\\) \\(Var(\\alpha) = /b^2\\)","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_quadrature.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Verify Quadrature Accuracy Against Known Gamma Moments ‚Äî verify_quadrature","text":"","code":"if (FALSE) { # \\dontrun{ # Should return TRUE verify_quadrature(2.5, 1.5, M = 80)  # More challenging case verify_quadrature(0.5, 2.0, M = 100, verbose = TRUE)  } # }"},{"path":"https://joonho112.github.io/DPprior/reference/verify_quadrature_convergence.html","id":null,"dir":"Reference","previous_headings":"","what":"Verify Quadrature Convergence for Marginal Moments ‚Äî verify_quadrature_convergence","title":"Verify Quadrature Convergence for Marginal Moments ‚Äî verify_quadrature_convergence","text":"Tests marginal moments converge number quadrature nodes increases.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_quadrature_convergence.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Verify Quadrature Convergence for Marginal Moments ‚Äî verify_quadrature_convergence","text":"","code":"verify_quadrature_convergence(   J,   a,   b,   M_values = c(20, 40, 60, 80, 100, 120),   verbose = TRUE )"},{"path":"https://joonho112.github.io/DPprior/reference/verify_quadrature_convergence.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Verify Quadrature Convergence for Marginal Moments ‚Äî verify_quadrature_convergence","text":"J Integer; sample size. Numeric; shape parameter. b Numeric; rate parameter. M_values Integer vector; numbers quadrature nodes test. verbose Logical; TRUE, print detailed results.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_quadrature_convergence.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Verify Quadrature Convergence for Marginal Moments ‚Äî verify_quadrature_convergence","text":"Data frame convergence results.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_quadrature_convergence.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Verify Quadrature Convergence for Marginal Moments ‚Äî verify_quadrature_convergence","text":"","code":"if (FALSE) { # \\dontrun{ verify_quadrature_convergence(50, 1.5, 0.5)  } # }"},{"path":"https://joonho112.github.io/DPprior/reference/verify_rho_conditional_variance.html","id":null,"dir":"Reference","previous_headings":"","what":"Verify Conditional Variance Formula ‚Äî verify_rho_conditional_variance","title":"Verify Conditional Variance Formula ‚Äî verify_rho_conditional_variance","text":"Verifies Var(rho|alpha) = E(rho^2|alpha) - E(rho|alpha)^2.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_rho_conditional_variance.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Verify Conditional Variance Formula ‚Äî verify_rho_conditional_variance","text":"","code":"verify_rho_conditional_variance(alpha, tol = 1e-12)"},{"path":"https://joonho112.github.io/DPprior/reference/verify_rho_conditional_variance.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Verify Conditional Variance Formula ‚Äî verify_rho_conditional_variance","text":"alpha Numeric; concentration parameter (must positive). tol Numeric; tolerance comparison. Default 1e-12.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_rho_conditional_variance.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Verify Conditional Variance Formula ‚Äî verify_rho_conditional_variance","text":"Logical; TRUE formula holds.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_rho_variance_decomposition.html","id":null,"dir":"Reference","previous_headings":"","what":"Verify Variance Decomposition ‚Äî verify_rho_variance_decomposition","title":"Verify Variance Decomposition ‚Äî verify_rho_variance_decomposition","text":"Verifies law total variance decomposition Var(rho).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_rho_variance_decomposition.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Verify Variance Decomposition ‚Äî verify_rho_variance_decomposition","text":"","code":"verify_rho_variance_decomposition(   a,   b,   tol = 1e-10,   M = .QUAD_NODES_DEFAULT,   verbose = FALSE )"},{"path":"https://joonho112.github.io/DPprior/reference/verify_rho_variance_decomposition.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Verify Variance Decomposition ‚Äî verify_rho_variance_decomposition","text":"Numeric; shape parameter Gamma prior alpha (> 0). b Numeric; rate parameter Gamma prior alpha (b > 0). tol Numeric; tolerance comparison. Default 1e-10. M Integer; number quadrature nodes. Default 80. verbose Logical; TRUE, print detailed results.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_rho_variance_decomposition.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Verify Variance Decomposition ‚Äî verify_rho_variance_decomposition","text":"Logical; TRUE decomposition holds within tolerance.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_s3_methods.html","id":null,"dir":"Reference","previous_headings":"","what":"Verify S3 Methods Module ‚Äî verify_s3_methods","title":"Verify S3 Methods Module ‚Äî verify_s3_methods","text":"Runs comprehensive verification tests S3 methods module.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_s3_methods.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Verify S3 Methods Module ‚Äî verify_s3_methods","text":"","code":"verify_s3_methods(verbose = TRUE)"},{"path":"https://joonho112.github.io/DPprior/reference/verify_s3_methods.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Verify S3 Methods Module ‚Äî verify_s3_methods","text":"verbose Logical; TRUE, print detailed test output.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_s3_methods.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Verify S3 Methods Module ‚Äî verify_s3_methods","text":"Invisibly returns TRUE tests pass.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_s3_methods.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Verify S3 Methods Module ‚Äî verify_s3_methods","text":"","code":"if (FALSE) { # \\dontrun{ verify_s3_methods()  } # }"},{"path":"https://joonho112.github.io/DPprior/reference/verify_score_expectation.html","id":null,"dir":"Reference","previous_headings":"","what":"Verify Score Function Zero Expectation Property ‚Äî verify_score_expectation","title":"Verify Score Function Zero Expectation Property ‚Äî verify_score_expectation","text":"Verifies fundamental property \\(E[s_\\theta(\\alpha)] = 0\\) score functions.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_score_expectation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Verify Score Function Zero Expectation Property ‚Äî verify_score_expectation","text":"","code":"verify_score_expectation(a, b, M = .QUAD_NODES_VERIFICATION, verbose = TRUE)"},{"path":"https://joonho112.github.io/DPprior/reference/verify_score_expectation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Verify Score Function Zero Expectation Property ‚Äî verify_score_expectation","text":"Numeric; shape parameter. b Numeric; rate parameter. M Integer; number quadrature nodes. verbose Logical; TRUE, print results.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_score_expectation.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Verify Score Function Zero Expectation Property ‚Äî verify_score_expectation","text":"named list components: E_score_a Expectation \\(s_a\\) E_score_b Expectation \\(s_b\\)","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_score_expectation.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Verify Score Function Zero Expectation Property ‚Äî verify_score_expectation","text":"fundamental property score functions. Due quadrature approximation error, computed expectations may exactly zero. Expected behavior: E[s_b] close zero (typically < 1e-14) s_b linear alpha. E[s_a] may show larger errors (1e-2 small ) due log(alpha) term causing slower quadrature convergence. rigorous verification, use adaptive integration (e.g., Python scipy.integrate.quad) provides independent ground truth.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_score_expectation.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Verify Score Function Zero Expectation Property ‚Äî verify_score_expectation","text":"","code":"if (FALSE) { # \\dontrun{ verify_score_expectation(a = 2.0, b = 1.0, verbose = TRUE)  } # }"},{"path":"https://joonho112.github.io/DPprior/reference/verify_stirling_row_sum.html","id":null,"dir":"Reference","previous_headings":"","what":"Verify Row Sum Identity for Stirling Numbers ‚Äî verify_stirling_row_sum","title":"Verify Row Sum Identity for Stirling Numbers ‚Äî verify_stirling_row_sum","text":"Verifies row sum Stirling numbers equals J! row. fundamental identity: \\(\\sum_{k=1}^{J} |s(J,k)| = J!\\)","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_stirling_row_sum.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Verify Row Sum Identity for Stirling Numbers ‚Äî verify_stirling_row_sum","text":"","code":"verify_stirling_row_sum(   logS,   J_values = 2:10,   tolerance = 1e-10,   verbose = TRUE )"},{"path":"https://joonho112.github.io/DPprior/reference/verify_stirling_row_sum.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Verify Row Sum Identity for Stirling Numbers ‚Äî verify_stirling_row_sum","text":"logS Pre-computed log-Stirling matrix compute_log_stirling. J_values Vector J values verify (default: 2:10). tolerance Numerical tolerance comparison (default: 1e-10). verbose Logical; TRUE, print verification results.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_stirling_row_sum.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Verify Row Sum Identity for Stirling Numbers ‚Äî verify_stirling_row_sum","text":"Logical indicating whether verifications passed.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_stirling_row_sum.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Verify Row Sum Identity for Stirling Numbers ‚Äî verify_stirling_row_sum","text":"unsigned Stirling numbers first kind satisfy: $$\\sum_{k=1}^{J} |s(J,k)| = J!$$ identity follows fact \\(|s(J,k)|\\) counts permutations J elements exactly k cycles, total number permutations J!.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_stirling_row_sum.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Verify Row Sum Identity for Stirling Numbers ‚Äî verify_stirling_row_sum","text":"","code":"if (FALSE) { # \\dontrun{ logS <- compute_log_stirling(15) verify_stirling_row_sum(logS, J_values = 2:10)  } # }"},{"path":"https://joonho112.github.io/DPprior/reference/verify_underdispersion.html","id":null,"dir":"Reference","previous_headings":"","what":"Verify Underdispersion Inequality ‚Äî verify_underdispersion","title":"Verify Underdispersion Inequality ‚Äî verify_underdispersion","text":"Verifies \\(0 < Var(K_J | \\alpha) < E[K_J | \\alpha]\\) specified values \\(\\alpha\\).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_underdispersion.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Verify Underdispersion Inequality ‚Äî verify_underdispersion","text":"","code":"verify_underdispersion(   J,   alpha_values = c(0.1, 0.5, 1, 2, 5, 10),   verbose = TRUE )"},{"path":"https://joonho112.github.io/DPprior/reference/verify_underdispersion.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Verify Underdispersion Inequality ‚Äî verify_underdispersion","text":"J Sample size (integer >= 1). alpha_values Numeric vector alpha values test (default: c(0.1, 0.5, 1, 2, 5, 10)). verbose Logical; TRUE, print results.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_underdispersion.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Verify Underdispersion Inequality ‚Äî verify_underdispersion","text":"Logical; TRUE inequality holds alpha values.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_underdispersion.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Verify Underdispersion Inequality ‚Äî verify_underdispersion","text":"","code":"verify_underdispersion(50) #> Underdispersion verification (J=50): #>   alpha= 0.10: E[K]=  1.4328, Var(K)=  0.4186, D=0.2922 [PASS] #>   alpha= 0.50: E[K]=  2.9378, Var(K)=  1.7091, D=0.5818 [PASS] #>   alpha= 1.00: E[K]=  4.4992, Var(K)=  2.8741, D=0.6388 [PASS] #>   alpha= 2.00: E[K]=  7.0376, Var(K)=  4.5356, D=0.6445 [PASS] #>   alpha= 5.00: E[K]= 12.4605, Var(K)=  7.3861, D=0.5928 [PASS] #>   alpha=10.00: E[K]= 18.3424, Var(K)=  9.5064, D=0.5183 [PASS] verify_underdispersion(50, c(0.1, 1, 10), verbose = TRUE) #> Underdispersion verification (J=50): #>   alpha= 0.10: E[K]=  1.4328, Var(K)=  0.4186, D=0.2922 [PASS] #>   alpha= 1.00: E[K]=  4.4992, Var(K)=  2.8741, D=0.6388 [PASS] #>   alpha=10.00: E[K]= 18.3424, Var(K)=  9.5064, D=0.5183 [PASS]"},{"path":"https://joonho112.github.io/DPprior/reference/verify_visualization.html","id":null,"dir":"Reference","previous_headings":"","what":"Verify Visualization Module ‚Äî verify_visualization","title":"Verify Visualization Module ‚Äî verify_visualization","text":"Verify Visualization Module","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_visualization.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Verify Visualization Module ‚Äî verify_visualization","text":"","code":"verify_visualization(verbose = TRUE)"},{"path":"https://joonho112.github.io/DPprior/reference/verify_visualization.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Verify Visualization Module ‚Äî verify_visualization","text":"verbose Logical; TRUE, print progress messages. Default TRUE.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_w1_rho_identity.html","id":null,"dir":"Reference","previous_headings":"","what":"Verify the Identity E(w1) = E(rho) ‚Äî verify_w1_rho_identity","title":"Verify the Identity E(w1) = E(rho) ‚Äî verify_w1_rho_identity","text":"Checks mean identity E(w1 | , b) = E(rho | , b), follows E(rho | alpha) = E(w1 | alpha) = 1/(1+alpha).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_w1_rho_identity.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Verify the Identity E(w1) = E(rho) ‚Äî verify_w1_rho_identity","text":"","code":"verify_w1_rho_identity(a, b, tol = 1e-10, M = .QUAD_NODES_DEFAULT)"},{"path":"https://joonho112.github.io/DPprior/reference/verify_w1_rho_identity.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Verify the Identity E(w1) = E(rho) ‚Äî verify_w1_rho_identity","text":"Numeric; shape parameter Gamma prior alpha (> 0). b Numeric; rate parameter Gamma prior alpha (b > 0). tol Numeric; absolute tolerance. Default 1e-10. M Integer; number quadrature nodes. Default 80.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_w1_rho_identity.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Verify the Identity E(w1) = E(rho) ‚Äî verify_w1_rho_identity","text":"Logical; TRUE identity holds within tolerance.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_w1_rho_identity.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Verify the Identity E(w1) = E(rho) ‚Äî verify_w1_rho_identity","text":"","code":"if (FALSE) { # \\dontrun{ verify_w1_rho_identity(2, 1) verify_w1_rho_identity(1.6, 1.22) } # }"},{"path":"https://joonho112.github.io/DPprior/reference/verify_zero_probability.html","id":null,"dir":"Reference","previous_headings":"","what":"Verify Zero Probability at K=0 ‚Äî verify_zero_probability","title":"Verify Zero Probability at K=0 ‚Äî verify_zero_probability","text":"Verifies P(K_J = 0 | alpha) = 0.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_zero_probability.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Verify Zero Probability at K=0 ‚Äî verify_zero_probability","text":"","code":"verify_zero_probability(J, alpha, logS, tol = 1e-15, verbose = TRUE)"},{"path":"https://joonho112.github.io/DPprior/reference/verify_zero_probability.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Verify Zero Probability at K=0 ‚Äî verify_zero_probability","text":"J Integer; sample size. alpha Numeric; DP concentration parameter. logS Matrix; pre-computed log-Stirling matrix. tol Numeric; tolerance (default: 1e-15). verbose Logical; TRUE, print results.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/verify_zero_probability.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Verify Zero Probability at K=0 ‚Äî verify_zero_probability","text":"Logical; TRUE verification passes.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/vif_to_variance.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert Variance Inflation Factor to Variance ‚Äî vif_to_variance","title":"Convert Variance Inflation Factor to Variance ‚Äî vif_to_variance","text":"Converts Variance Inflation Factor (VIF) specification actual variance \\(K_J\\).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/vif_to_variance.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert Variance Inflation Factor to Variance ‚Äî vif_to_variance","text":"","code":"vif_to_variance(mu_K, vif)"},{"path":"https://joonho112.github.io/DPprior/reference/vif_to_variance.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert Variance Inflation Factor to Variance ‚Äî vif_to_variance","text":"mu_K Numeric; target prior mean \\(K_J\\). vif Numeric; Variance Inflation Factor (must >= 1 A1 feasibility).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/vif_to_variance.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert Variance Inflation Factor to Variance ‚Äî vif_to_variance","text":"Numeric; variance \\(K_J\\) computed \\((\\mu_K - 1) \\times \\text{VIF}\\).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/vif_to_variance.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Convert Variance Inflation Factor to Variance ‚Äî vif_to_variance","text":"VIF defined : $$\\text{VIF} = \\frac{\\sigma^2_K}{\\mu_K - 1}$$ Interpretation: VIF = 1 Poisson variance (exact boundary A1) VIF > 1 Overdispersion (required A1 feasibility) VIF < 1 Underdispersion (infeasible A1, allowed)","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/vif_to_variance.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert Variance Inflation Factor to Variance ‚Äî vif_to_variance","text":"","code":"# VIF = 2 means variance is twice the Poisson variance vif_to_variance(mu_K = 5, vif = 2)  # Returns 8 #> [1] 8  # Use with DPprior_a1 fit <- DPprior_a1(J = 50, mu_K = 5, var_K = vif_to_variance(5, 2))"},{"path":"https://joonho112.github.io/DPprior/reference/vif_to_variance_fit.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert VIF to Target Variance ‚Äî vif_to_variance_fit","title":"Convert VIF to Target Variance ‚Äî vif_to_variance_fit","text":"Computes target variance Variance Inflation Factor.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/vif_to_variance_fit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert VIF to Target Variance ‚Äî vif_to_variance_fit","text":"","code":"vif_to_variance_fit(mu_K, vif)"},{"path":"https://joonho112.github.io/DPprior/reference/vif_to_variance_fit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert VIF to Target Variance ‚Äî vif_to_variance_fit","text":"mu_K Numeric; target expected number clusters. vif Numeric; Variance Inflation Factor (must > 1).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/vif_to_variance_fit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert VIF to Target Variance ‚Äî vif_to_variance_fit","text":"Numeric; target variance: vif * (mu_K - 1).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/vif_to_variance_fit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Convert VIF to Target Variance ‚Äî vif_to_variance_fit","text":"VIF relates variance shifted mean (mu_K - 1): $$Var(K_J) = VIF \\cdot (\\mu_K - 1)$$ parameterization natural shifted NegBin approximation.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/reference/vif_to_variance_fit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert VIF to Target Variance ‚Äî vif_to_variance_fit","text":"","code":"if (FALSE) { # \\dontrun{ vif_to_variance_fit(5, 2.5)  # 10 = 2.5 * (5 - 1) } # }"},{"path":"https://joonho112.github.io/DPprior/reference/w1_grid.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute w‚ÇÅ Distribution on Grid ‚Äî w1_grid","title":"Compute w‚ÇÅ Distribution on Grid ‚Äî w1_grid","text":"Computes CDF, PDF, survival function grid x values. Useful visualization comparison across different priors.","code":""},{"path":"https://joonho112.github.io/DPprior/reference/w1_grid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute w‚ÇÅ Distribution on Grid ‚Äî w1_grid","text":"","code":"w1_grid(a, b, x_grid = seq(0.01, 0.99, length.out = 100))"},{"path":"https://joonho112.github.io/DPprior/reference/w1_grid.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute w‚ÇÅ Distribution on Grid ‚Äî w1_grid","text":"Numeric; shape parameter Gamma prior Œ±. b Numeric; rate parameter Gamma prior Œ±. x_grid Numeric vector; grid x values (0, 1). Default seq(0.01, 0.99, length.= 100).","code":""},{"path":"https://joonho112.github.io/DPprior/reference/w1_grid.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute w‚ÇÅ Distribution on Grid ‚Äî w1_grid","text":"data frame columns: x Grid points cdf CDF values F(x) pdf Density values p(x) survival Survival function S(x) = 1 - F(x)","code":""},{"path":"https://joonho112.github.io/DPprior/reference/w1_grid.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute w‚ÇÅ Distribution on Grid ‚Äî w1_grid","text":"","code":"# Compute on default grid df <- w1_grid(a = 2, b = 1)  # Plot all three functions par(mfrow = c(1, 3)) plot(df$x, df$cdf, type = \"l\", main = \"CDF\", xlab = \"x\", ylab = \"F(x)\") plot(df$x, df$pdf, type = \"l\", main = \"PDF\", xlab = \"x\", ylab = \"p(x)\") plot(df$x, df$survival, type = \"l\", main = \"Survival\", xlab = \"x\", ylab = \"S(x)\")"},{"path":[]},{"path":"https://joonho112.github.io/DPprior/news/index.html","id":"initial-cran-release-1-0-0","dir":"Changelog","previous_headings":"","what":"Initial CRAN Release","title":"DPprior 1.0.0","text":"first public release DPprior package, providing tools principled prior elicitation concentration parameter Œ± Dirichlet Process (DP) mixture models.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/news/index.html","id":"elicitation-engine-1-0-0","dir":"Changelog","previous_headings":"Core Features","what":"Elicitation Engine","title":"DPprior 1.0.0","text":"Supports confidence levels (‚Äúlow‚Äù, ‚Äúmedium‚Äù, ‚Äúhigh‚Äù) easy specification Direct variance specification precise control Automatic algorithm selection (A1 closed-form A2 Newton refinement) Near-instantaneous computation Exploits asymptotic relationship K_J | Œ± ~ Poisson(Œ± log J) Typically converges 2-4 iterations Guaranteed accuracy specified tolerance","code":""},{"path":"https://joonho112.github.io/DPprior/news/index.html","id":"dual-anchor-framework-1-0-0","dir":"Changelog","previous_headings":"Core Features","what":"Dual-Anchor Framework","title":"DPprior 1.0.0","text":"Addresses ‚Äúunintended prior‚Äù problem (Vicentini & Jermyn, 2025) Flexible weighting K w‚ÇÅ targets via Œª parameter Supports probability, quantile, moment constraints w‚ÇÅ prob_w1_exceeds(): Compute P(w‚ÇÅ > threshold) dominance risk assessment mean_w1(), var_w1(): First second moments largest weight quantile_w1(): Quantiles w‚ÇÅ distribution","code":""},{"path":"https://joonho112.github.io/DPprior/news/index.html","id":"exact-computation-1-0-0","dir":"Changelog","previous_headings":"Core Features","what":"Exact Computation","title":"DPprior 1.0.0","text":"Log-scale numerical stability large J Vectorized efficiency pmf_K_given_alpha(): Exact Antoniak distribution P(K = k | Œ±) mean_K_given_alpha(), var_K_given_alpha(): Conditional moments K","code":""},{"path":"https://joonho112.github.io/DPprior/news/index.html","id":"diagnostic-tools-1-0-0","dir":"Changelog","previous_headings":"Core Features","what":"Diagnostic Tools","title":"DPprior 1.0.0","text":"Checks K, w‚ÇÅ, œÅ, Œ± distributions Identifies dominance risk (high P(w‚ÇÅ > 0.5)) Computes effective sample sizes plot.DPprior_fit(): Four-panel diagnostic dashboard summary.DPprior_fit(): Detailed numerical summary","code":""},{"path":"https://joonho112.github.io/DPprior/news/index.html","id":"utility-functions-1-0-0","dir":"Changelog","previous_headings":"Core Features","what":"Utility Functions","title":"DPprior 1.0.0","text":"vif_to_variance(): Convert variance inflation factor Var(K) confidence_to_vif(): Map confidence levels VIF values integrate_gamma(): High-precision Gauss-Laguerre integration exact_K_moments(): Marginal moments E[K] Var(K) Gamma prior","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPprior/news/index.html","id":"cran-compliance-1-0-0","dir":"Changelog","previous_headings":"Package Infrastructure","what":"CRAN Compliance","title":"DPprior 1.0.0","text":"Passes R CMD check 0 errors, 0 warnings, 0 notes Complete roxygen2-managed NAMESPACE 77 exported functions 11 S3 methods examples use \\dontrun{} \\donttest{} appropriate non-standard dependencies; base R + stats + graphics Imports","code":""},{"path":"https://joonho112.github.io/DPprior/news/index.html","id":"focused-public-api-1-0-0","dir":"Changelog","previous_headings":"Package Infrastructure","what":"Focused Public API","title":"DPprior 1.0.0","text":"77 carefully curated exports organized across 13 functional groups: core elicitation, approximation algorithms, Stirling numbers, K distribution (conditional marginal), weight distribution, co-clustering probability, diagnostics, visualization, S3 methods, numerical utilities, computation, validation/verification","code":""},{"path":"https://joonho112.github.io/DPprior/news/index.html","id":"test-suite-1-0-0","dir":"Changelog","previous_headings":"Package Infrastructure","what":"Test Suite","title":"DPprior 1.0.0","text":"2,084 unit tests via testthat 3.0 Coverage spans 20 source modules (R/00 R/18 plus DPprior-package) Tests verify mathematical identities, numerical accuracy, edge cases, S3 method contracts, visualization output","code":""},{"path":"https://joonho112.github.io/DPprior/news/index.html","id":"documentation-1-0-0","dir":"Changelog","previous_headings":"Package Infrastructure","what":"Documentation","title":"DPprior 1.0.0","text":"49 @family cross-reference tags across 7 conceptual families 27 @references blocks citing Lee (2026) arXiv:2602.06301 Terminology standardized Design-Conditional Elicitation (DCE) Two-Stage Moment Matching (TSMM)","code":""},{"path":"https://joonho112.github.io/DPprior/news/index.html","id":"numerical-robustness-1-0-0","dir":"Changelog","previous_headings":"Package Infrastructure","what":"Numerical Robustness","title":"DPprior 1.0.0","text":"11 named constants R/00_constants.R reproducible thresholds exp() overflow protection via .EXP_MAX clamping BFGS optimization Singular Jacobian fallback using correct gradient direction (J^T F) Division--near-zero guards relative error computation PMF normalization guards zero/non-finite sums","code":""},{"path":"https://joonho112.github.io/DPprior/news/index.html","id":"comprehensive-vignettes-1-0-0","dir":"Changelog","previous_headings":"Package Infrastructure","what":"Comprehensive Vignettes","title":"DPprior 1.0.0","text":"12 vignettes organized two tracks: Applied Researchers Track: - Introduction: prior elicitation matters - Quick Start: first prior 5 minutes - Applied Guide: Complete elicitation workflow - Dual-Anchor: Control counts weights - Diagnostics: Verify prior behavior - Case Studies: Multisite trials meta-analysis Methodological Researchers Track: - Theory Overview: Mathematical foundations - Stirling Numbers: Antoniak distribution details - Approximations: A1 closed-form theory - Newton Algorithm: A2 exact moment matching - Weight Distributions: w‚ÇÅ, œÅ, dual-anchor framework - API Reference: Complete function documentation","code":""},{"path":"https://joonho112.github.io/DPprior/news/index.html","id":"pkgdown-website-1-0-0","dir":"Changelog","previous_headings":"Package Infrastructure","what":"pkgdown Website","title":"DPprior 1.0.0","text":"Full pkgdown site https://joonho112.github.io/DPprior/ Reference index organized 13 sections matching public API Articles index Applied Methodological tracks Search functionality enabled Favicons PWA manifest configured","code":""},{"path":"https://joonho112.github.io/DPprior/news/index.html","id":"methodological-foundation-1-0-0","dir":"Changelog","previous_headings":"","what":"Methodological Foundation","title":"DPprior 1.0.0","text":"package implements Design-Conditional Elicitation (DCE) methodology, extending original DORO approach (Dorazio, 2009) : A1 closed-form approximation: Instant initial estimates using asymptotic Negative Binomial distribution K_J Gamma prior Œ± (Zito et al., 2024) A2 Newton refinement: Exact moment matching using numerically stable computation Stirling numbers Gauss-Laguerre quadrature Dual-anchor extension: Joint control K w‚ÇÅ distributions, addressing sample-size-independent concerns raised Vicentini & Jermyn (2025)","code":""},{"path":"https://joonho112.github.io/DPprior/news/index.html","id":"references-1-0-0","dir":"Changelog","previous_headings":"","what":"References","title":"DPprior 1.0.0","text":"Dorazio, R. M. (2009). selecting prior precision parameter Dirichlet process mixture models. Journal Statistical Planning Inference, 139(10), 3384‚Äì3390. Lee, J. (2026). Design-conditional prior elicitation Dirichlet process mixtures. arXiv preprint arXiv:2602.06301. Lee, J., Che, J., Rabe-Hesketh, S., Feller, ., & Miratrix, L. (2025). Improving estimation site-specific effects distribution multisite trials. Journal Educational Behavioral Statistics, 50(5), 731‚Äì764. Vicentini, C., & Jermyn, . H. (2025). Prior selection precision parameter Dirichlet process mixtures. arXiv:2502.00864. Zito, ., Rigon, T., & Dunson, D. B. (2024). Bayesian nonparametric modeling latent partitions via Stirling-gamma priors. arXiv:2306.02360.","code":""},{"path":"https://joonho112.github.io/DPprior/news/index.html","id":"acknowledgments-1-0-0","dir":"Changelog","previous_headings":"","what":"Acknowledgments","title":"DPprior 1.0.0","text":"project supported Institute Education Sciences, U.S. Department Education, Grant R305D240078 University Alabama.","code":""}]
